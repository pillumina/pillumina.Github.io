<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[VeRL] AgentLoop源码走读 | CctoctoFX</title><meta name=keywords content="framework,verl,sglang"><meta name=description content="最近 RL sys 圈子的吴锡斌老师在 verl 上设计了将 rollout 与 tool 调用解耦的 AgentLoop，实现了自由灵活的 mutli-turn RL。在每个 AgentLoop 内部，rollout engine 只对外提供一个 token-in-token-out 的接口，而 tool 调用则通过 ToolAgentLoop 来实现。我个人比较喜欢这样解耦的设计，同时，AgentLoop 的代码结构也比较清晰。我个人学习了一次整个代码后，觉着 AgentLoop 的设计甚是不错，但是 ActorRolloutRefWorker 的历史包袱还是很重。
本文简单分析了 agent loop 的源码，并给出了一些自己的看法。
如果我们把整个 ActorRolloutRefWorker 当做一个 sgl.Engine 的话，AgentLoop 里面包装的两层 AsyncSGLangServer 和 AsyncLLMServerManager。AsyncSGLangServer 相当于在 sgl.Engine 上包装了 fastapi 成了 server，而 AsyncLLMServerManager 是在 server 上包了一层 router 做 load balance，相当于 sglang 的 router。这两层设计都是合理的，主要麻烦的是 ActorRolloutRefWorker，层层调用，最后一共经过 7 个 class 才调到 sgl.Engine，最近 verl 团队也在致力于对这块 worker class 的重构，敬请期待。最后，AgentLoopManager，AgentLoopWorker 和 AgentLoop 这三层，我觉得 AgentLoopWorker 可能未必有必要，其他两层挺合理的。"><meta name=author content="Me"><link rel=canonical href=https://pillumina.github.io/posts/aiinfra/09-verl-agentloop/><link crossorigin=anonymous href=/assets/css/stylesheet.9d388901283682bb45dd422fcaa0d0a2054a3c8ff47c9cc6b2baab15508b1b90.css integrity="sha256-nTiJASg2grtF3UIvyqDQogVKPI/0fJzGsrqrFVCLG5A=" rel="preload stylesheet" as=style><link rel=icon href=https://pillumina.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://pillumina.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://pillumina.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://pillumina.github.io/apple-touch-icon.png><link rel=mask-icon href=https://pillumina.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://pillumina.github.io/posts/aiinfra/09-verl-agentloop/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js crossorigin=anonymous></script><script>(function(){function t(){return document.querySelector(".post-content")||document.querySelector(".post-single")||document.body}function n(e){return/\$\$[\s\S]+?\$\$|\\\(|\\\)|\\\[|\\\]/.test(e)}function s(e){if(window.__mathjaxLoaded)return;window.__mathjaxLoaded=!0,window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code","tt"],ignoreHtmlClass:"no-math"}};var t=document.createElement("script");t.src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js",t.defer=!0,t.onload=function(){window.MathJax&&window.MathJax.typesetPromise&&window.MathJax.typesetPromise([e]).catch(function(e){console.warn("MathJax typeset error",e)})},document.head.appendChild(t)}function e(){try{if(typeof renderMathInElement=="function"){const e=t();renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\[",right:"\\]",display:!0},{left:"\\(",right:"\\)",display:!1}],throwOnError:!1,strict:!1,trust:!0,ignoredTags:["script","noscript","style","textarea","pre","code","tt"],ignoredClasses:["no-math"],macros:{"\\boldsymbol":"\\mathbf{#1}","\\bm":"\\mathbf{#1}"}}),setTimeout(function(){n(e.innerHTML)&&s(e)},200)}}catch(e){console.warn("KaTeX render error:",e)}}document.addEventListener("DOMContentLoaded",function(){e(),setTimeout(e,200)}),window.addEventListener("load",function(){setTimeout(e,0)})})()</script><script src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script><script>const config={startOnLoad:!0,theme:"neutral",themeVariables:{lineColor:"#0f0f0f"},flowchart:{useMaxWidth:!1,htmlLabels:!0}};mermaid.initialize(config),window.onload=()=>{window.mermaid.init(0[0],document.querySelectorAll(".language-mermaid"))}</script><link rel=stylesheet href=/css/custom.min.bda7229c4269a242639e058fb11a4782f02f8d77071ba16609befee67cc41c49.css integrity="sha256-vacinEJpokJjngWPsRpHgvAvjXcHG6FmCb7+5nzEHEk="><script>document.addEventListener("DOMContentLoaded",function(){const t=document.querySelectorAll("h1[id], h2[id], h3[id], h4[id], h5[id], h6[id]"),n=document.querySelectorAll(".toc a");if(t.length===0||n.length===0)return;const s={};t.forEach(e=>{s[e.id]=e.offsetTop});function i(){const t=window.scrollY+100;let e="";for(const[n,o]of Object.entries(s))if(t>=o)e=n;else break;return e}function o(){const e=i();if(n.forEach(e=>{e.classList.remove("active")}),e){const t=document.querySelector(`.toc a[href="#${e}"]`);t&&t.classList.add("active")}}let e=!1;window.addEventListener("scroll",function(){e||(window.requestAnimationFrame(function(){o(),e=!1}),e=!0)}),o()})</script><meta property="og:url" content="https://pillumina.github.io/posts/aiinfra/09-verl-agentloop/"><meta property="og:site_name" content="CctoctoFX"><meta property="og:title" content="[VeRL] AgentLoop源码走读"><meta property="og:description" content="最近 RL sys 圈子的吴锡斌老师在 verl 上设计了将 rollout 与 tool 调用解耦的 AgentLoop，实现了自由灵活的 mutli-turn RL。在每个 AgentLoop 内部，rollout engine 只对外提供一个 token-in-token-out 的接口，而 tool 调用则通过 ToolAgentLoop 来实现。我个人比较喜欢这样解耦的设计，同时，AgentLoop 的代码结构也比较清晰。我个人学习了一次整个代码后，觉着 AgentLoop 的设计甚是不错，但是 ActorRolloutRefWorker 的历史包袱还是很重。
本文简单分析了 agent loop 的源码，并给出了一些自己的看法。
如果我们把整个 ActorRolloutRefWorker 当做一个 sgl.Engine 的话，AgentLoop 里面包装的两层 AsyncSGLangServer 和 AsyncLLMServerManager。AsyncSGLangServer 相当于在 sgl.Engine 上包装了 fastapi 成了 server，而 AsyncLLMServerManager 是在 server 上包了一层 router 做 load balance，相当于 sglang 的 router。这两层设计都是合理的，主要麻烦的是 ActorRolloutRefWorker，层层调用，最后一共经过 7 个 class 才调到 sgl.Engine，最近 verl 团队也在致力于对这块 worker class 的重构，敬请期待。最后，AgentLoopManager，AgentLoopWorker 和 AgentLoop 这三层，我觉得 AgentLoopWorker 可能未必有必要，其他两层挺合理的。"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-08-14T11:30:12+08:00"><meta property="article:modified_time" content="2025-08-14T11:30:12+08:00"><meta property="article:tag" content="Framework"><meta property="article:tag" content="Verl"><meta property="article:tag" content="Sglang"><meta property="og:image" content="https://pillumina.github.io/imgs/icon_head.png"><meta property="og:see_also" content="https://pillumina.github.io/posts/aiinfra/10-verl-dataproto/"><meta property="og:see_also" content="https://pillumina.github.io/posts/aiinfra/05-verl-params/"><meta property="og:see_also" content="https://pillumina.github.io/posts/aiinfra/08-verl-multiturn-2/"><meta property="og:see_also" content="https://pillumina.github.io/posts/aiinfra/07-verl-multiturn-1/"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://pillumina.github.io/imgs/icon_head.png"><meta name=twitter:title content="[VeRL] AgentLoop源码走读"><meta name=twitter:description content="最近 RL sys 圈子的吴锡斌老师在 verl 上设计了将 rollout 与 tool 调用解耦的 AgentLoop，实现了自由灵活的 mutli-turn RL。在每个 AgentLoop 内部，rollout engine 只对外提供一个 token-in-token-out 的接口，而 tool 调用则通过 ToolAgentLoop 来实现。我个人比较喜欢这样解耦的设计，同时，AgentLoop 的代码结构也比较清晰。我个人学习了一次整个代码后，觉着 AgentLoop 的设计甚是不错，但是 ActorRolloutRefWorker 的历史包袱还是很重。
本文简单分析了 agent loop 的源码，并给出了一些自己的看法。
如果我们把整个 ActorRolloutRefWorker 当做一个 sgl.Engine 的话，AgentLoop 里面包装的两层 AsyncSGLangServer 和 AsyncLLMServerManager。AsyncSGLangServer 相当于在 sgl.Engine 上包装了 fastapi 成了 server，而 AsyncLLMServerManager 是在 server 上包了一层 router 做 load balance，相当于 sglang 的 router。这两层设计都是合理的，主要麻烦的是 ActorRolloutRefWorker，层层调用，最后一共经过 7 个 class 才调到 sgl.Engine，最近 verl 团队也在致力于对这块 worker class 的重构，敬请期待。最后，AgentLoopManager，AgentLoopWorker 和 AgentLoop 这三层，我觉得 AgentLoopWorker 可能未必有必要，其他两层挺合理的。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://pillumina.github.io/posts/"},{"@type":"ListItem","position":2,"name":"AI Infra","item":"https://pillumina.github.io/posts/aiinfra/"},{"@type":"ListItem","position":3,"name":"[VeRL] AgentLoop源码走读","item":"https://pillumina.github.io/posts/aiinfra/09-verl-agentloop/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[VeRL] AgentLoop源码走读","name":"[VeRL] AgentLoop源码走读","description":"最近 RL sys 圈子的吴锡斌老师在 verl 上设计了将 rollout 与 tool 调用解耦的 AgentLoop，实现了自由灵活的 mutli-turn RL。在每个 AgentLoop 内部，rollout engine 只对外提供一个 token-in-token-out 的接口，而 tool 调用则通过 ToolAgentLoop 来实现。我个人比较喜欢这样解耦的设计，同时，AgentLoop 的代码结构也比较清晰。我个人学习了一次整个代码后，觉着 AgentLoop 的设计甚是不错，但是 ActorRolloutRefWorker 的历史包袱还是很重。\n本文简单分析了 agent loop 的源码，并给出了一些自己的看法。\n如果我们把整个 ActorRolloutRefWorker 当做一个 sgl.Engine 的话，AgentLoop 里面包装的两层 AsyncSGLangServer 和 AsyncLLMServerManager。AsyncSGLangServer 相当于在 sgl.Engine 上包装了 fastapi 成了 server，而 AsyncLLMServerManager 是在 server 上包了一层 router 做 load balance，相当于 sglang 的 router。这两层设计都是合理的，主要麻烦的是 ActorRolloutRefWorker，层层调用，最后一共经过 7 个 class 才调到 sgl.Engine，最近 verl 团队也在致力于对这块 worker class 的重构，敬请期待。最后，AgentLoopManager，AgentLoopWorker 和 AgentLoop 这三层，我觉得 AgentLoopWorker 可能未必有必要，其他两层挺合理的。\n","keywords":["framework","verl","sglang"],"articleBody":"最近 RL sys 圈子的吴锡斌老师在 verl 上设计了将 rollout 与 tool 调用解耦的 AgentLoop，实现了自由灵活的 mutli-turn RL。在每个 AgentLoop 内部，rollout engine 只对外提供一个 token-in-token-out 的接口，而 tool 调用则通过 ToolAgentLoop 来实现。我个人比较喜欢这样解耦的设计，同时，AgentLoop 的代码结构也比较清晰。我个人学习了一次整个代码后，觉着 AgentLoop 的设计甚是不错，但是 ActorRolloutRefWorker 的历史包袱还是很重。\n本文简单分析了 agent loop 的源码，并给出了一些自己的看法。\n如果我们把整个 ActorRolloutRefWorker 当做一个 sgl.Engine 的话，AgentLoop 里面包装的两层 AsyncSGLangServer 和 AsyncLLMServerManager。AsyncSGLangServer 相当于在 sgl.Engine 上包装了 fastapi 成了 server，而 AsyncLLMServerManager 是在 server 上包了一层 router 做 load balance，相当于 sglang 的 router。这两层设计都是合理的，主要麻烦的是 ActorRolloutRefWorker，层层调用，最后一共经过 7 个 class 才调到 sgl.Engine，最近 verl 团队也在致力于对这块 worker class 的重构，敬请期待。最后，AgentLoopManager，AgentLoopWorker 和 AgentLoop 这三层，我觉得 AgentLoopWorker 可能未必有必要，其他两层挺合理的。\nRelated Resources Script\nhttps://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/rlhf/verl/multi-turn/tool_examples/agent_loop.md\nRelated PR\nhttps://github.com/volcengine/verl/pull/2124\nDesign Docs\nhttps://github.com/volcengine/verl/pull/2563\nhttps://github.com/volcengine/verl/pull/A2598\nCommit we are looking at\nhttps://github.com/volcengine/verl/tree/c5b189a1af496d0bc68320cd1d5bd7a1f1e3638a\n使用 AgentLoop 安装 verl-sglang 的最新版本：\n1 2 3 4 5 6 7 8 cd ~ git clone https://github.com/volcengine/verl.git cd verl python -m uv pip install wheel setuptools python3 -m uv pip install -e \".[sglang]\" --prerelease=allow python3 -m uv pip install -r ./requirements.txt --no-build-isolation python3 -m uv pip install torch_memory_saver 具体实现自己的 agent loop（见下文分析），然后配置 config 文件：\n1 2 3 actor_rollout_ref.rollout.mode=async \\ actor_rollout_ref.rollout.multi_turn.enable=true \\ actor_rollout_ref.rollout.name=sglang \\ 注意，不使用 actor_rollout_ref.rollout.mode=async 的话，会启用 SGLangRollout 本身管理的 mutli-turn 功能，在效果上和 AgentLoop 完全一致。\n最后，在数据集构建过程中添加一个新的 agent_name 字段，比如我们在 ~/verl/examples/data_preprocess/gsm8k_multiturn_w_tool.py 中追加 \"agent_name\": \"tool_agent\"：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def make_map_fn(split): def process_fn(example, idx): question_raw = example.pop(\"question\") question = question_raw + \" \" + instruction_following answer_raw = example.pop(\"answer\") solution = extract_solution(answer_raw) data = { \"data_source\": data_source, # new column for agent loop \"agent_name\": \"tool_agent\", \"prompt\": [ { #... } ] } return data return process_fn 调用总览 main_ppo.py -\u003e RayPPOTrainer(fit)-\u003e AgentLoopManager(async) -\u003e AgentLoopWorker -\u003e AsyncLLMServerManager -\u003e AsyncSGLangServer -\u003e AsyncActorRolloutRefWorker -\u003e SGLangRollout -\u003e AsyncEngine -\u003e sgl.Engine\nTaskRunner 启动训练，调用 RayPPOTrainer.fit()。 RayPPOTrainer 管理训练流程，调用 AgentLoopManager.generate_sequences() 开始层层向下调用，同时初始化 AsyncActorRolloutRefWorker。 AgentLoopManager 初始化 dp 个 AsyncSGLangServer，随后，初始化 num_rollout_workers 个 AgentLoopWorker。 接着，每个 AgentLoopWorker 根据 agent_name 从预先注册好的 _agent_loop_registry 初始化自身管理的 train_batch_size / num_rollout_workers 个 AgentLoop 实例，对于 GRPO，train_batch_size 需要乘以 group size。用户可以依照自身需求注册新的 AgentLoop，目前通过 ToolAgentLoop 来完全覆盖了 SGLangRollout 中基于 _req_level_generate_sequences 实现的 tool call 管理。也就是说， 先前的 multi-turn RL 的 tool 状态管理是在 SGLangRollout 内实现的，而 AgentLoop 将这层管理抽象了出来，SGLangRollout 只是向上包装为 AsyncSGLangServer 来完成 token-in-token-out。 AgentLoop 初始化后，管理 tool 调用的各种状态，并且根据 policy 的返回情况，向下层层调用 AsyncLLMServerManager -\u003e AsyncSGLangServer -\u003e AsyncActorRolloutRefWorker -\u003e SGLangRollout -\u003e AsyncEngine -\u003e sgl.Engine，得到模型输出。 返回输出后，AgentLoop生命周期结束。 AgentLoopWorker收集所有AgentLoop的返回值，上交给AgentLoopManager，等待下一次调用。 AgentLoopManager收集所有AgentLoopWorker的返回值，返回。 AgentLoopManager AgentLoop 的最顶层管理者，负责管理 AgentLoopWorker 以及 LLM servers 的生命周期。核心方法是generate_sequences：向下层层调用，得到 policy model 在给定的 agent loop 环境下的 trajectories。\n核心 API 在 RayPPOTrainer 中被初始化：\n1 2 3 4 5 6 7 8 if self.config.actor_rollout_ref.rollout.mode == \"async\": from verl.experimental.agent_loop import AgentLoopManager self.async_rollout_mode = True self.async_rollout_manager = AgentLoopManager( config=self.config, worker_group=self.actor_rollout_wg, ) 具体的初始化非常简洁：\n__init__\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def __init__(self, config: DictConfig, worker_group: RayWorkerGroup): \"\"\"Initialize agent loop manager. Args: config (DictConfig): trainer config. worker_group (RayWorkerGroup): ActorRolloutRef worker group. \"\"\" self.config = config self.worker_group = worker_group self._initialize_llm_servers() self._init_agent_loop_workers() # Initially we're in sleep mode. self.sleep() 传入 ActorRolloutRefWOrker 对应的 worker group，在_initialize_llm_servers里用来查找对应的 RolloutWorker； 初始化 llm server 和 agent loop workers； _initialize_llm_servers\n计算 dp size：self.rollout_dp_size = self.worker_group.world_size // self.rollout_tp_size 通过async_server_class(rollout_backend=self.config.actor_rollout_ref.rollout.name)获取服务器类，如 Async``SGLang``Server，作为和下层的 sgl.Engine 通信的转接层。 用 ray 初始化 dp size 个 server，为每个 dp rank 创建 server 实例。 通过ray.get(server.get_server_address.remote())获取并记录每个服务器的地址 调用ray.get([server.init_engine.remote() for server in self.async_llm_servers])；server 从 ray 通过前缀查询，在已经初始化好的 ray actor 中拿到自己对应的所有 SGLang engine。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def _initialize_llm_servers(self): # 计算 dp size self.rollout_tp_size = self.config.actor_rollout_ref.rollout.tensor_model_parallel_size self.rollout_dp_size = self.worker_group.world_size // self.rollout_tp_size # 获取 worker 信息用于节点亲和性调度 register_center = ray.get_actor(f\"{self.worker_group.name_prefix}_register_center\") workers_info = ray.get(register_center.get_worker_info.remote()) assert len(workers_info) == self.worker_group.world_size self.async_llm_servers = [None] * self.rollout_dp_size self.server_addresses = [None] * self.rollout_dp_size # 根据 config 拿到对应的 server, e.g., AsyncSGLangServer if self.config.actor_rollout_ref.rollout.agent.custom_async_server: server_class = async_server_class( rollout_backend=self.config.actor_rollout_ref.rollout.name, rollout_backend_module=self.config.actor_rollout_ref.rollout.agent.custom_async_server.path, rollout_backend_class=self.config.actor_rollout_ref.rollout.agent.custom_async_server.name, ) else: server_class = async_server_class(rollout_backend=self.config.actor_rollout_ref.rollout.name) # 用 ray 初始化 dp rank 个 AsyncServer unready_dp_ranks = set(range(self.rollout_dp_size)) while len(unready_dp_ranks) \u003e 0: servers = { rollout_dp_rank: server_class.options( # 确保 AsyncServer 与对应的工作器在同一节点 scheduling_strategy=ray.util.scheduling_strategies.NodeAffinitySchedulingStrategy( node_id=workers_info[rollout_dp_rank * self.rollout_tp_size], soft=False, ), name=f\"async_llm_server_{rollout_dp_rank}\", ).remote(self.config, self.rollout_dp_size, rollout_dp_rank, self.worker_group.name_prefix) for rollout_dp_rank in unready_dp_ranks } # 记录 server 地址 for rollout_dp_rank, server in servers.items(): try: address = ray.get(server.get_server_address.remote()) self.server_addresses[rollout_dp_rank] = address self.async_llm_servers[rollout_dp_rank] = server unready_dp_ranks.remove(rollout_dp_rank) except Exception: ray.kill(server) print(f\"rollout server {rollout_dp_rank} failed, maybe address already in use, restarting...\") # 初始化 server，这个初始化是 server 从 ray 中拿到自己 dp 对应的所有 worker ray.get([server.init_engine.remote() for server in self.async_llm_servers]) _init_agent_loop_workers\n在 ray 上初始化 rollout.agent.num_workers 个 AgentLoopWorker：\n1 2 3 4 5 6 7 8 def _init_agent_loop_workers(self): self.agent_loop_workers = [] for i in range(self.config.actor_rollout_ref.rollout.agent.num_workers): self.agent_loop_workers.append( AgentLoopWorker.options( name=f\"agent_loop_worker_{i}\", ).remote(self.config, self.async_llm_servers) ) generate_sequences\n如果配置了free_cache_engine，先调用self.wake_up() chunkes = prompts.chunk(len(self.agent_loop_workers)) 将输入批次按 AgentLoopWorker 数量分块。 每个 agentLoopWorker 处理自身的 chunk，通过ray.get([worker.generate_sequences.remote(chunk) for ...])并行执行并得到结果； 处理完成后调用self.sleep()让 server 进入睡眠状态以释放显存 计算生成序列和工具调用的性能指标 合并所有 A``gentLoopWorker 的输出并返回 Code link [here]\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def generate_sequences(self, prompts: DataProto) -\u003e DataProto: if self.config.actor_rollout_ref.rollout.free_cache_engine: self.wake_up() # 唤醒所有 LLM 服务器 chunkes = prompts.chunk(len(self.agent_loop_workers)) # 按 worker 数量分块 outputs = ray.get( [worker.generate_sequences.remote(chunk) for worker, chunk in zip(self.agent_loop_workers, chunkes)] ) # 并行分发到各个 AgentLoopWorker output = DataProto.concat(outputs) # 聚合所有 worker 的输出 if self.config.actor_rollout_ref.rollout.free_cache_engine: self.sleep() # 让服务器进入睡眠状态，释放显存 # 计算性能指标 metrics = [output.meta_info[\"metrics\"] for output in outputs] timing = self._performance_metrics(metrics, output) output.meta_info = {\"timing\": timing} return output AsyncSGLangServer 基于 SGLang 的异步服务器实现，继承自AsyncServerBase。作为 Ray 远程 actor 运行，负责将收到的请求转发给下层的 SGLang Engine。出于 SGLang 的设计，调用 generate 的时候只需要对 master worker（verl 的 inference tp 0）调用即可。\n核心 API init_engine\n异步初始化 SGLang 引擎：\n通过ray.util.list_named_actors查找所有匹配的 actors； 根据命名规则 self.wg_prefix + \"WorkerDict_\" 解析 actor 名称； 根据 dp_rank 和 tp_size 分配 actor，确定 master worker（tp rank 0） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 async def init_engine(self): if self.workers: # avoid init twice return all_actors = ray.util.list_named_actors(all_namespaces=True) matched_actors = [ actor for actor in all_actors if actor.get(\"name\", None).startswith(self.wg_prefix + \"WorkerDict_\") ] gpu_per_node = len(set([actor[\"name\"].split(\":\")[1] for actor in matched_actors])) # total gpu num assert len(matched_actors) == self._dp_size * self._tp_size for matched_actor in matched_actors: fields = matched_actor[\"name\"].split(\":\") assert len(fields) == 2, f\"invalid actor name: {matched_actor['name']}\" pg_index, local_rank = int(fields[0].split(\"_\")[-1]), int(fields[1]) current_global_rank = gpu_per_node * pg_index + local_rank worker_dp_rank = current_global_rank // self._tp_size worker_tp_rank = current_global_rank % self._tp_size if worker_dp_rank == self._dp_rank: worker = ray.get_actor(**matched_actor) self.workers.append(worker) if worker_tp_rank == 0: self.master_worker = worker chat_completion\n处理 chat_completion 请求：\n1 2 3 4 5 async def chat_completion(self, raw_request: Request): request = await raw_request.json() output_future = self.master_worker.chat_completion.remote(request) [outputs] = await asyncio.gather(output_future) return JSONResponse(outputs) 将请求转发给 master worker 处理 返回 JSON 格式的响应 generate\nToken in token out 来获得 SGLang Engine 的 inference 结果：\n1 2 async def generate(self, prompt_ids: List[int], sampling_params: Dict[str, Any], request_id: str) -\u003e List[int]: return await self.master_worker.generate.remote(prompt_ids, sampling_params, request_id) 直接调用 master worker 的生成方法 支持自定义采样参数 AsyncLLMServerManager 管理多个 OpenAI 兼容的 LLM 服务器 (例如 Async``SGLang``Server)，提供负载均衡和会话粘性功能。支持最少请求负载均衡算法，确保多轮对话发送到同一服务器以实现自动前缀缓存。可以认为就是简单的 router/load balancer 层。\n初始化\n配置服务器句柄列表，随机打乱顺序 初始化最少请求负载均衡器：self.weighted_serveres = [[0, (hash(server), server)] for server in server_handles] 创建 LRU 缓存：self.request_id_to_server = LRUCache(maxsize=max_cache_size)用于 request_id 到服务器的映射 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 def __init__(self, config: DictConfig, server_handles: List[ray.actor.ActorHandle], max_cache_size: int = 10000): \"\"\"Initialize the AsyncLLMServerManager. Args: config (DictConfig): YAML config. server_handles (List[ray.actor.ActorHandle]): OpenAI compatible LLM server actor handles. max_cache_size (int, optional): max cache size for request_id to server mapping. Defaults to 10000. \"\"\" self.config = config self.server_handles = server_handles random.shuffle(self.server_handles) # Least requests load balancing self.weighted_serveres = [[0, (hash(server), server)] for server in server_handles] heapq.heapify(self.weighted_serveres) # LRU cache to map request_id to server self.request_id_to_server = LRUCache(maxsize=max_cache_size) _choose_server\n1 2 3 4 5 6 7 8 9 def _choose_server(self, request_id: str) -\u003e ray.actor.ActorHandle: if request_id in self.request_id_to_server: return self.request_id_to_server[request_id] # 会话粘性 server = self.weighted_serveres[0][1][1] # 最少请求的服务器 self.weighted_serveres[0][0] += 1 # 增加请求计数 heapq.heapreplace(self.weighted_serveres, self.weighted_serveres[0]) self.request_id_to_server[request_id] = server return server 会话粘性：相同 request_id 发送给同一 server 最少请求：新请求分配给当前负载最轻的 server 动态更新：使用堆结构维护服务器负载状态 generate\n1 2 3 4 5 6 7 8 9 @rollout_trace_op async def generate(self, request_id, *, prompt_ids: List[int], sampling_params: Dict[str, Any]) -\u003e List[int]: server = self._choose_server(request_id) output = await server.generate.remote( request_id=request_id, prompt_ids=prompt_ids, sampling_params=sampling_params, ) return output 根据 request_id 选择 server 异步调用 server 的生成接口，token-in-token-out 支持性能追踪 AgentLoopWorker AgentLoopWorker 负责接收数据，向下发给具体的 AgentLoop。虽然名字是 worker，但是\n从 ray 的角度来说，AgentLoopWorker 是有状态的，是 ray actor，而不是 ray worker 核心函数 generate 是层层套壳，调用其他类；例如 single_turn_agent_loop 和 tool_agent_loop 来 generate（当然这两个类的 generate 也是向下调用，下面会讲到） __init__\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @ray.remote class AgentLoopWorker: \"\"\"Agent loop worker takes a batch of messages and run each message in an agent loop.\"\"\" def __init__(self, config: DictConfig, server_handles: list[ray.actor.ActorHandle]): \"\"\"Initialize agent loop manager. Args: config (DictConfig): YAML config. server_handles (List[ray.actor.ActorHandle]): OpenAI compatible LLM server actor handles. \"\"\" self.config = config self.server_manager = AsyncLLMServerManager(config, server_handles) model_path = config.actor_rollout_ref.model.path self.model_name = \"/\".join(model_path.split(\"/\")[-2:]) local_path = copy_to_local(config.actor_rollout_ref.model.path) self.tokenizer = hf_tokenizer(local_path, trust_remote_code=True) trace_config = self.config.actor_rollout_ref.rollout.get(\"trace\", {}) RolloutTraceConfig.init( self.config.trainer.project_name, self.config.trainer.experiment_name, trace_config.get(\"backend\"), trace_config.get(\"token2text\", False), ) 上游传过来的 config 和 server_handles 作为参数来初始化 AsyncLLMServerManager，之后会把这个 self.server_manager 传给下游； 根据 config 的 config.actor_rollout_ref.model.path 设置 model_path, local_path, tokenizer 配置 RolloutTraceConfig 用于追踪 trajectories generate_sequences\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 async def generate_sequences(self, batch: DataProto) -\u003e DataProto: \"\"\"Generate sequences from agent loop. Args: batch (DataProto): Input batch. Returns: DataProto: Output batch. - prompts: [bsz, prompt_length], prompt token ids from dataset. - responses: [bsz, response_length], output token ids include response tokens from LLM generation and observation tokens from tool_calls. - response_mask: [bsz, response_length], 1 for LLM generated tokens, 0 for observation/padding tokens. - input_ids: [bsz, prompt_length + response_length], whole sequence token ids, including prompt tokens and response tokens. - attention_mask: [bsz, prompt_length + response_length], 0 for padding tokens, 1 for other tokens. - position_ids: [bsz, prompt_length + response_length], incremental position ids. For multi-turn conversations: responses: |\u003c- LLM generation -\u003e|\u003c- tool_calls -\u003e|\u003c- LLM generation -\u003e|\u003c- padding -\u003e| response_mask: | 1, 1, 1, ..., 1, 1 | 0, 0, .., 0, 0 | 1, 1, 1, ..., 1, 1 | 0, 0, ..., 0| \"\"\" config = self.config.actor_rollout_ref.rollout sampling_params = dict( temperature=config.temperature, top_p=config.top_p, repetition_penalty=1.0, ) # override sampling params for validation if batch.meta_info.get(\"validate\", False): sampling_params[\"top_p\"] = config.val_kwargs.top_p sampling_params[\"temperature\"] = config.val_kwargs.temperature # by default, we assume it's a single turn agent if \"agent_name\" not in batch.non_tensor_batch: batch.non_tensor_batch[\"agent_name\"] = np.array([\"single_turn_agent\"] * len(batch), dtype=object) tasks = [] agent_names = batch.non_tensor_batch[\"agent_name\"] raw_prompts = batch.non_tensor_batch[\"raw_prompt\"] if \"index\" in batch.non_tensor_batch: index = batch.non_tensor_batch[\"index\"] else: index = np.arange(len(raw_prompts)) trajectory_info = await get_trajectory_info( batch.meta_info.get(\"global_steps\", -1), index, batch.meta_info.get(\"validate\", False) ) for agent_name, messages, trajectory in zip(agent_names, raw_prompts, trajectory_info, strict=True): tasks.append( asyncio.create_task(self._run_agent_loop(agent_name, messages.tolist(), sampling_params, trajectory)) ) outputs = await asyncio.gather(*tasks) output = self._postprocess(outputs) return output 利用上游传来的 config，创建给下游使用的 sampling_params；对 validation batch 要用 validation 参数。 利用 batch 的 meta_info，获得 agent_name, raw_prompts, index。再用这个 meta_info 处理获得 trajectory_info；就是利用刚才的 index 来计算在每一个 step 每一个 prompt 被 rollout 的次数，然后存到一个 list 中获得整个 rollout 的 trace； 利用 agent_names, raw_prompts, trajectory_info 来并发执行 _run_agent_loop。 在 _run_agent_loop 函数内，就要进行相应 agent_name 的 agent_loop 实例化，以及调用 agent_loop 对应的 run 函数来 generate。 在 _postprocess 中，会根据前面计算出来的 output（被封装成了 AgentLoopOutput 格式）来进行后处理；padding，加入 mask，最后封装成一个 DataProto 返回。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 async def _run_agent_loop( self, agent_name: str, messages: list[dict[str, Any]], sampling_params: dict[str, Any], trajectory: dict[str, Any], ) -\u003e AgentLoopOutput: with rollout_trace_attr( step=trajectory[\"step\"], sample_index=trajectory[\"sample_index\"], rollout_n=trajectory[\"rollout_n\"], validate=trajectory[\"validate\"], name=\"agent_loop\", ): assert agent_name in _agent_loop_registry, ( f\"Agent loop {agent_name} not registered, registered agent loops: {_agent_loop_registry.keys()}\" ) agent_loop_config = _agent_loop_registry[agent_name] agent_loop = hydra.utils.instantiate( config=agent_loop_config, trainer_config=_DummyConfig(config=self.config), server_manager=self.server_manager, tokenizer=self.tokenizer, ) output = await agent_loop.run(messages, sampling_params) return output def _postprocess(self, inputs: list[AgentLoopOutput]) -\u003e DataProto: # NOTE: consistent with batch version of generate_sequences in vllm_rollout_spmd.py # prompts: left pad # responses: right pad # input_ids: prompt + response # attention_mask: [0,0,0,0,1,1,1,1, | 1,1,1,0,0,0,0,0] # position_ids: [0,0,0,0,0,1,2,3, | 4,5,6,7,8,9,10,11] # prompts self.tokenizer.padding_side = \"left\" outputs = self.tokenizer.pad( [{\"input_ids\": input.prompt_ids} for input in inputs], padding=\"max_length\", max_length=self.config.actor_rollout_ref.rollout.prompt_length, return_tensors=\"pt\", return_attention_mask=True, ) prompt_ids, prompt_attention_mask = outputs[\"input_ids\"], outputs[\"attention_mask\"] # responses self.tokenizer.padding_side = \"right\" outputs = self.tokenizer.pad( [{\"input_ids\": input.response_ids} for input in inputs], padding=\"max_length\", max_length=self.config.actor_rollout_ref.rollout.response_length, return_tensors=\"pt\", return_attention_mask=True, ) response_ids, response_attention_mask = outputs[\"input_ids\"], outputs[\"attention_mask\"] # response_mask outputs = self.tokenizer.pad( [{\"input_ids\": input.response_mask} for input in inputs], padding=\"max_length\", max_length=self.config.actor_rollout_ref.rollout.response_length, return_tensors=\"pt\", return_attention_mask=False, ) response_mask = outputs[\"input_ids\"] assert response_ids.shape == response_mask.shape, ( f\"mismatch in response_ids and response_mask shape: {response_ids.shape} vs {response_mask.shape}\" ) response_mask = response_mask * response_attention_mask input_ids = torch.cat([prompt_ids, response_ids], dim=1) attention_mask = torch.cat([prompt_attention_mask, response_attention_mask], dim=1) position_ids = (attention_mask.cumsum(dim=1) - 1) * attention_mask batch = TensorDict( { \"prompts\": prompt_ids, # [bsz, prompt_length] \"responses\": response_ids, # [bsz, response_length] \"response_mask\": response_mask, # [bsz, response_length] \"input_ids\": input_ids, # [bsz, prompt_length + response_length] \"attention_mask\": attention_mask, # [bsz, prompt_length + response_length] \"position_ids\": position_ids, # [bsz, prompt_length + response_length] }, batch_size=len(input_ids), ) num_turns = np.array([input.num_turns for input in inputs], dtype=np.int32) metrics = [input.metrics.model_dump() for input in inputs] return DataProto(batch=batch, non_tensor_batch={\"__num_turns__\": num_turns}, meta_info={\"metrics\": metrics}) AgentLoop 终于进入到了具体的 agent loop 当中，我们观察两种具体的 AgentLoop。\nSingleTurnAgentLoop 这个 agent_loop 是默认的单轮对话，处理简单的一问一答，不支持工具调用；最重要的自然是 run 函数：\n我们传入 agent_loop的 messages 其实是我们从 batch 里面获得的 raw_prompt，此处调用 apply_chat_template； 调用 server_manager 里面的 generate 函数来计算 response_ids； 计算 response_mask，并根据 response_length 截取，封装这些结果成 AgentLoopOutput，padding 在上层 AgentLoopManager 的 _postprocess 内做； 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class SingleTurnAgentLoop(AgentLoopBase): \"\"\"Naive agent loop that only do single turn chat completion.\"\"\" def __init__(self, config, server_manager, tokenizer): super().__init__(config, server_manager, tokenizer) self.prompt_length = config.actor_rollout_ref.rollout.prompt_length self.response_length = config.actor_rollout_ref.rollout.response_length async def run(self, messages: list[dict[str, Any]], sampling_params: dict[str, Any]) -\u003e AgentLoopOutput: metrics = {} request_id = uuid4().hex prompt_ids = await self.loop.run_in_executor( None, lambda: self.tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=True) ) with simple_timer(\"generate_sequences\", metrics): response_ids = await self.server_manager.generate( request_id=request_id, prompt_ids=prompt_ids, sampling_params=sampling_params ) response_mask = [1] * len(response_ids) output = AgentLoopOutput( prompt_ids=prompt_ids, response_ids=response_ids[: self.response_length], response_mask=response_mask[: self.response_length], num_turns=2, metrics=metrics, ) return output ToolAgentLoop 终于到了最核心的地方。ToolAgentLoop 支持多轮对话和工具调用。目前 ToolAgentLoop 可以完全覆盖 SGLangRollout 中基于 _async_rollout_a_request 实现的 tool call 管理。但状态数量和转移关系更加简单。也就是说， 先前的 multi-turn RL 的 tool 状态管理是在 SGLangRollout 内实现的，而 AgentLoop 提前将这层管理抽象了出来。\ninit_class\n下面只介绍一些关键参数的作用:\n**tool_response_truncate_side：**控制工具响应内容过长时的截断方式。 \"left\"：从左侧截断，保留开头部分 + “…(truncated)\"； \"right\"：从右侧截断，保留结尾部分，前面加 “(truncated)…\"； 其他值：从中间截断，保留开头和结尾部分，中间加 “…(truncated)…” tool_config_path：指定包含工具定义和配置信息的配置文件位置，用于初始化可用的工具列表，比如verl/examples/sglang_multiturn/config/tool_config/gsm8k_tool_config.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 tools: - class_name: \"verl.tools.gsm8k_tool.Gsm8kTool\" config: type: native tool_schema: type: \"function\" function: name: \"calc_gsm8k_reward\" description: \"A tool for calculating the reward of gsm8k. (1.0 if parsed answer is correct, 0.0 if parsed answer is incorrect or not correctly parsed)\" parameters: type: \"object\" properties: answer: type: \"string\" description: \"The model's answer to the GSM8K math problem, must be a digits\" required: [\"answer\"] tool_list, tool_schemas：通过 initialize_tools_from_config(tool_config_path) 函数从配置文件中解析并创建工具实例。\ntool_parser：通过设置类似 actor_rollout_ref.rollout.multi_turn.format=hermes这样的参数， 可以获取对应的 tool_parser；比如 HermesToolParser 就是提取 之间的内容，返回对应的 function_call（function_name 和 function_arguments）, 还有除开 tool_call 内容以外的 content。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 @classmethod def init_class(cls, config, tokenizer): if cls._class_initialized: return cls._class_initialized = True print(\"Performing class-level ToolAgentLoop initialization\") # Initialize tools from config file cls.tokenizer = tokenizer cls.max_user_turns = config.actor_rollout_ref.rollout.multi_turn.max_user_turns cls.max_assistant_turns = config.actor_rollout_ref.rollout.multi_turn.max_assistant_turns cls.max_parallel_calls = config.actor_rollout_ref.rollout.multi_turn.max_parallel_calls cls.max_tool_response_length = config.actor_rollout_ref.rollout.multi_turn.max_tool_response_length cls.tool_response_truncate_side = config.actor_rollout_ref.rollout.multi_turn.tool_response_truncate_side tool_config_path = config.actor_rollout_ref.rollout.multi_turn.tool_config_path tool_list = initialize_tools_from_config(tool_config_path) if tool_config_path else [] cls.tools = {tool.name: tool for tool in tool_list} cls.tool_schemas = [tool.tool_schema.model_dump(exclude_unset=True, exclude_none=True) for tool in tool_list] cls.tool_parser = cls.get_tool_parser(config.actor_rollout_ref.rollout.multi_turn.format) print(f\"Initialized tools: {cls.tools}\") cls.prompt_length = config.actor_rollout_ref.rollout.prompt_length cls.response_length = config.actor_rollout_ref.rollout.response_length cls.system_prompt = tokenizer.apply_chat_template([{}], add_generation_prompt=False, tokenize=True) run\n和 single_turn_agent_loop 一样，对 prompts apply_chat_template； 初始化 user_turns, assistant_turns，进入 multi-turn 的 loop 循环，直到退出: 向 server_manager 发送 prompt_ids，得到对应的 response_ids；将本轮返回的 response_ids append 到 prompt_ids 中，准备作为下一轮的输入，并且 assistant_turns += 1 处理边界条件，比如 prompts 过长，没有 tool call 了，或者超出了 max turns； 异步执行 _call_tool：从 response 中 extract 出 Function Call，接着 tool.execute(instance_id, tool_args) 获得相应的 tool_response, 然后截断返回即可。具体的 _call_tool 会在后文分析。 tool_responses 随后 apply_chat_template 得到 tool_response_ids，同样 append 到prompt_ids 内，然后 user_turns += 1，进入下一轮循环； 退出 tool agent loop 循环后，构造 AgentLoopOutput 注意 num_turns=user_turns+assistant_turns +1，因为 prompt 也算一次 user turn 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 @rollout_trace_op async def run(self, messages: list[dict[str, Any]], sampling_params: dict[str, Any]) -\u003e AgentLoopOutput: metrics = {} request_id = uuid4().hex prompt_ids = await self.loop.run_in_executor( None, lambda: self.tokenizer.apply_chat_template( messages, tools=self.tool_schemas, add_generation_prompt=True, tokenize=True ), ) response_mask = [] user_turns, assistant_turns = 0, 0 while True: with simple_timer(\"generate_sequences\", metrics): response_ids = await self.server_manager.generate( request_id=request_id, prompt_ids=prompt_ids, sampling_params=sampling_params ) prompt_ids += response_ids response_mask += [1] * len(response_ids) assistant_turns += 1 # reach max response length if len(response_mask) \u003e= self.response_length: break # reach max assistant turns if self.max_assistant_turns and assistant_turns \u003e= self.max_assistant_turns: break # reach max user turns if self.max_user_turns and user_turns \u003e= self.max_user_turns: break # no tool calls tool_calls = await self.tool_parser.extract_tool_calls(response_ids) if not tool_calls: break # call tools tasks = [] for tool_call in tool_calls[: self.max_parallel_calls]: tasks.append(self._call_tool(tool_call)) with simple_timer(\"tool_calls\", metrics): tool_responses = await asyncio.gather(*tasks) if any(isinstance(item, Exception) for item in tool_responses): break # append tool_response_ids tool_response_ids = await self.loop.run_in_executor( None, lambda messages=tool_responses: self.tokenizer.apply_chat_template( messages, add_generation_prompt=True, tokenize=True ), ) tool_response_ids = tool_response_ids[len(self.system_prompt) :] # NOTE: last turn should not be user turn, or the EOS token reward # can't be propagated to previous token in GAE. if len(response_mask) + len(tool_response_ids) \u003e= self.response_length: break prompt_ids += tool_response_ids response_mask += [0] * len(tool_response_ids) user_turns += 1 response_ids = prompt_ids[-len(response_mask) :] prompt_ids = prompt_ids[: len(prompt_ids) - len(response_mask)] output = AgentLoopOutput( prompt_ids=prompt_ids, response_ids=response_ids[: self.response_length], response_mask=response_mask[: self.response_length], num_turns=user_turns + assistant_turns + 1, metrics=metrics, ) return output call_tool\n基于 tool list 内的 tool 来调用工具，例如前面 config 中配置的 calc_gsm8k_reward，从 tool parser 得到 arguments 就可以代入运算得到相应的tool_response。如果 tool 调用成功，则会释放 tool 占用的资源,，最后tool_response根据 tool_response_truncate_side 来做相应的截断。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 async def _call_tool(self, tool_call: FunctionCall) -\u003e dict[str, str]: \"\"\"Call tool and return tool response.\"\"\" tool, instance_id = None, None try: # TODO: append malformed tool_call to the prompt: invalid function name or arguments tool_name = tool_call.name tool_args = json.loads(tool_call.arguments) tool = self.tools[tool_name] instance_id = await tool.create() tool_response, _, _ = await tool.execute(instance_id, tool_args) except Exception as e: logger.exception(f\"Error when executing tool: {e}\") return e finally: if tool and instance_id: await tool.release(instance_id) if len(tool_response) \u003e self.max_tool_response_length: if self.tool_response_truncate_side == \"left\": tool_response = tool_response[: self.max_tool_response_length] + \"...(truncated)\" elif self.tool_response_truncate_side == \"right\": tool_response = \"(truncated)...\" + tool_response[-self.max_tool_response_length :] else: length = self.max_tool_response_length // 2 tool_response = tool_response[:length] + \"...(truncated)...\" + tool_response[-length:] return { \"role\": \"tool\", \"content\": tool_response, } ","wordCount":"3051","inLanguage":"en","image":"https://pillumina.github.io/imgs/icon_head.png","datePublished":"2025-08-14T11:30:12+08:00","dateModified":"2025-08-14T11:30:12+08:00","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://pillumina.github.io/posts/aiinfra/09-verl-agentloop/"},"publisher":{"@type":"Organization","name":"CctoctoFX","logo":{"@type":"ImageObject","url":"https://pillumina.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://pillumina.github.io/ accesskey=h title="CctoctoFX (Alt + H)"><img src=https://pillumina.github.io/apple-touch-icon.png alt aria-label=logo height=30>CctoctoFX</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://pillumina.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://pillumina.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://pillumina.github.io/posts/aiinfra/ title="AI Infra"><span>AI Infra</span></a></li><li><a href=https://pillumina.github.io/posts/llmtheory/ title=Thoery><span>Thoery</span></a></li><li><a href=https://pillumina.github.io/posts/programming/ title=Programming><span>Programming</span></a></li><li><a href=https://pillumina.github.io/social/ title=Social><span>Social</span></a></li><li><a href=https://pillumina.github.io/open_courses/ title=Study><span>Study</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://pillumina.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://pillumina.github.io/posts/>Posts</a>&nbsp;»&nbsp;<a href=https://pillumina.github.io/posts/aiinfra/>AI Infra</a></div><h1 class="post-title entry-hint-parent">[VeRL] AgentLoop源码走读</h1><div class=post-meta><span title='2025-08-14 11:30:12 +0800 CST'>August 14, 2025</span>&nbsp;·&nbsp;15 min&nbsp;·&nbsp;3051 words&nbsp;·&nbsp;Me</div></header><div class="toc side left"><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#related-resources>Related Resources</a></li><li><a href=#使用-agentloop>使用 AgentLoop</a></li><li><a href=#调用总览>调用总览</a></li><li><a href=#agentloopmanager>AgentLoopManager</a><ul><li><a href=#核心-api>核心 API</a></li></ul></li><li><a href=#asyncsglangserver>AsyncSGLangServer</a><ul><li><a href=#核心-api-1>核心 API</a></li></ul></li><li><a href=#asyncllmservermanager>AsyncLLMServerManager</a></li><li><a href=#agentloopworker>AgentLoopWorker</a></li><li><a href=#agentloop>AgentLoop</a></li><li><a href=#singleturnagentloop>SingleTurnAgentLoop</a></li><li><a href=#toolagentloop>ToolAgentLoop</a></li></ul></nav></div></details></div><div class=post-content><p>最近 RL sys 圈子的吴锡斌老师在 verl 上设计了将 rollout 与 tool 调用解耦的 AgentLoop，实现了自由灵活的 mutli-turn RL。在每个 AgentLoop 内部，rollout engine 只对外提供一个 token-in-token-out 的接口，而 tool 调用则通过 <code>ToolAgentLoop</code> 来实现。我个人比较喜欢这样解耦的设计，同时，AgentLoop 的代码结构也比较清晰。我个人学习了一次整个代码后，觉着 AgentLoop 的设计甚是不错，但是 <code>ActorRolloutRefWorker</code> 的历史包袱还是很重。</p><p>本文简单分析了 agent loop 的源码，并给出了一些自己的看法。</p><p>如果我们把整个 <code>ActorRolloutRefWorker</code> 当做一个 <code>sgl.Engine</code> 的话，AgentLoop 里面包装的两层 <code>AsyncSGLangServer</code> 和 <code>AsyncLLMServerManager</code>。<code>AsyncSGLangServer</code> 相当于在 <code>sgl.Engine</code> 上包装了 <code>fastapi</code> 成了 server，而 <code>AsyncLLMServerManager</code> 是在 server 上包了一层 router 做 load balance，相当于 sglang 的 router。这两层设计都是合理的，主要麻烦的是 <code>ActorRolloutRefWorker</code>，层层调用，最后一共经过 7 个 class 才调到 <code>sgl.Engine</code>，最近 verl 团队也在致力于对这块 worker class 的重构，敬请期待。最后，<code>AgentLoopManager</code>，<code>AgentLoopWorker</code> 和 <code>AgentLoop</code> 这三层，我觉得 <code>AgentLoopWorker</code> 可能未必有必要，其他两层挺合理的。</p><h2 id=related-resources>Related Resources<a hidden class=anchor aria-hidden=true href=#related-resources>#</a></h2><p><strong>Script</strong></p><p><a href=https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/rlhf/verl/multi-turn/tool_examples/agent_loop.md>https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/rlhf/verl/multi-turn/tool_examples/agent_loop.md</a></p><p><strong>Related PR</strong></p><p><a href=https://github.com/volcengine/verl/pull/2124>https://github.com/volcengine/verl/pull/2124</a></p><p><strong>Design Docs</strong></p><p><a href=https://github.com/volcengine/verl/pull/2563>https://github.com/volcengine/verl/pull/2563</a></p><p><a href=https://github.com/volcengine/verl/pull/A2598>https://github.com/volcengine/verl/pull/A2598</a></p><p><strong>Commit we are looking at</strong></p><p><a href=https://github.com/volcengine/verl/tree/c5b189a1af496d0bc68320cd1d5bd7a1f1e3638a>https://github.com/volcengine/verl/tree/c5b189a1af496d0bc68320cd1d5bd7a1f1e3638a</a></p><h2 id=使用-agentloop>使用 AgentLoop<a hidden class=anchor aria-hidden=true href=#使用-agentloop>#</a></h2><p>安装 verl-sglang 的最新版本：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> ~
</span></span><span class=line><span class=cl>git clone https://github.com/volcengine/verl.git
</span></span><span class=line><span class=cl><span class=nb>cd</span> verl
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>python -m uv pip install wheel setuptools
</span></span><span class=line><span class=cl>python3 -m uv pip install -e <span class=s2>&#34;.[sglang]&#34;</span> --prerelease<span class=o>=</span>allow
</span></span><span class=line><span class=cl>python3 -m uv pip install -r ./requirements.txt --no-build-isolation
</span></span><span class=line><span class=cl>python3 -m uv pip install torch_memory_saver
</span></span></code></pre></td></tr></table></div></div><p>具体实现自己的 agent loop（见下文分析），然后配置 config 文件：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=w>    </span><span class=l>actor_rollout_ref.rollout.mode=async \</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=l>actor_rollout_ref.rollout.multi_turn.enable=true \</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=l>actor_rollout_ref.rollout.name=sglang \</span><span class=w>
</span></span></span></code></pre></td></tr></table></div></div><p>注意，不使用 <code>actor_rollout_ref.rollout.mode=async</code> 的话，会启用 SGLangRollout 本身管理的 mutli-turn 功能，在效果上和 AgentLoop 完全一致。</p><p>最后，在数据集构建过程中添加一个新的 <code>agent_name</code> 字段，比如我们在 <code>~/verl/examples/data_preprocess/gsm8k_multiturn_w_tool.py</code> 中追加 <code>"agent_name": "tool_agent"</code>：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>make_map_fn</span><span class=p>(</span><span class=n>split</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>def</span> <span class=nf>process_fn</span><span class=p>(</span><span class=n>example</span><span class=p>,</span> <span class=n>idx</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>question_raw</span> <span class=o>=</span> <span class=n>example</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=s2>&#34;question&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>question</span> <span class=o>=</span> <span class=n>question_raw</span> <span class=o>+</span> <span class=s2>&#34; &#34;</span> <span class=o>+</span> <span class=n>instruction_following</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>answer_raw</span> <span class=o>=</span> <span class=n>example</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=s2>&#34;answer&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>solution</span> <span class=o>=</span> <span class=n>extract_solution</span><span class=p>(</span><span class=n>answer_raw</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>data</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;data_source&#34;</span><span class=p>:</span> <span class=n>data_source</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=c1># new column for agent loop</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;agent_name&#34;</span><span class=p>:</span> <span class=s2>&#34;tool_agent&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;prompt&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>                    <span class=p>{</span>
</span></span><span class=line><span class=cl>                        <span class=c1>#...</span>
</span></span><span class=line><span class=cl>                    <span class=p>}</span>
</span></span><span class=line><span class=cl>                <span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=n>data</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>process_fn</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=调用总览>调用总览<a hidden class=anchor aria-hidden=true href=#调用总览>#</a></h2><p><code>main_ppo.py -> RayPPOTrainer(fit)-> AgentLoopManager(async) -> AgentLoopWorker -> AsyncLLMServerManager -> AsyncSGLangServer -> AsyncActorRolloutRefWorker -> SGLangRollout -> AsyncEngine -> sgl.Engine</code></p><ul><li><code>TaskRunner</code> 启动训练，调用 <code>RayPPOTrainer.fit()</code>。</li><li><code>RayPPOTrainer</code> 管理训练流程，调用 <code>AgentLoopManager.generate_sequences()</code> 开始层层向下调用，同时初始化 <code>AsyncActorRolloutRefWorker</code>。</li><li><code>AgentLoopManager</code> 初始化 dp 个 <code>AsyncSGLangServer</code>，随后，初始化 <code>num_rollout_workers</code> 个 <code>AgentLoopWorker</code>。</li><li>接着，每个 <code>AgentLoopWorker</code> 根据 <code>agent_name</code> 从预先注册好的 <code>_agent_loop_registry</code> 初始化自身管理的 <code>train_batch_size / num_rollout_workers</code> 个 <code>AgentLoop</code> 实例，对于 GRPO，<code>train_batch_size</code> 需要乘以 group size。用户可以依照自身需求注册新的 <code>AgentLoop</code>，目前通过 <code>ToolAgentLoop</code> 来完全覆盖了 <code>SGLangRollout</code> 中基于 <code>_req_level_generate_sequences</code> 实现的 tool call 管理。也就是说， 先前的 multi-turn RL 的 tool 状态管理是在 <code>SGLangRollout</code> 内实现的，而 <code>AgentLoop</code> 将这层管理抽象了出来，<code>SGLangRollout</code> 只是向上包装为 <code>AsyncSGLangServer</code> 来完成 token-in-token-out。</li><li><code>AgentLoop</code> 初始化后，管理 tool 调用的各种状态，并且根据 policy 的返回情况，向下层层调用 <code>AsyncLLMServerManager</code> -> <code>AsyncSGLangServer</code> -> <code>AsyncActorRolloutRefWorker</code> -> <code>SGLangRollout</code> -> <code>AsyncEngine</code> -> <code>sgl.Engine</code>，得到模型输出。 返回输出后，<code>AgentLoop</code>生命周期结束。</li><li><code>AgentLoopWorker</code>收集所有<code>AgentLoop</code>的返回值，上交给<code>AgentLoopManager</code>，等待下一次调用。</li><li><code>AgentLoopManager</code>收集所有<code>AgentLoopWorker</code>的返回值，返回。</li></ul><p><img loading=lazy src=https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/raw/main/rlhf/verl/multi-turn/imgs/agentLoop.png data-zoomable></p><h2 id=agentloopmanager>AgentLoopManager<a hidden class=anchor aria-hidden=true href=#agentloopmanager>#</a></h2><p>AgentLoop 的最顶层管理者，负责管理 AgentLoopWorker 以及 LLM servers 的生命周期。核心方法是<code>generate_sequences</code>：向下层层调用，得到 policy model 在给定的 agent loop 环境下的 trajectories。</p><h3 id=核心-api>核心 API<a hidden class=anchor aria-hidden=true href=#核心-api>#</a></h3><p>在 <code>RayPPOTrainer</code> 中被初始化：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>mode</span> <span class=o>==</span> <span class=s2>&#34;async&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=kn>from</span> <span class=nn>verl.experimental.agent_loop</span> <span class=kn>import</span> <span class=n>AgentLoopManager</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>async_rollout_mode</span> <span class=o>=</span> <span class=kc>True</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>async_rollout_manager</span> <span class=o>=</span> <span class=n>AgentLoopManager</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>config</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>worker_group</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>actor_rollout_wg</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>具体的初始化非常简洁：</p><p><strong><code>__init__</code></strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>config</span><span class=p>:</span> <span class=n>DictConfig</span><span class=p>,</span> <span class=n>worker_group</span><span class=p>:</span> <span class=n>RayWorkerGroup</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Initialize agent loop manager.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>        Args:
</span></span></span><span class=line><span class=cl><span class=s2>            config (DictConfig): trainer config.
</span></span></span><span class=line><span class=cl><span class=s2>            worker_group (RayWorkerGroup): ActorRolloutRef worker group.
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>config</span> <span class=o>=</span> <span class=n>config</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>worker_group</span> <span class=o>=</span> <span class=n>worker_group</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>_initialize_llm_servers</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>_init_agent_loop_workers</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Initially we&#39;re in sleep mode.</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>sleep</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><ul><li>传入 ActorRolloutRefWOrker 对应的 worker group，在<code>_initialize_llm_servers</code>里用来查找对应的 RolloutWorker；</li><li>初始化 llm server 和 agent loop workers；</li></ul><p><strong><code>_initialize_llm_servers</code></strong></p><ul><li>计算 dp size：<code>self.rollout_dp_size = self.worker_group.world_size // self.rollout_tp_size</code></li><li>通过<code>async_server_class(rollout_backend=self.config.actor_rollout_ref.rollout.name)</code>获取服务器类，如 <code>Async``SGLang``Server</code>，作为和下层的 <code>sgl.Engine</code> 通信的转接层。</li><li>用 ray 初始化 dp size 个 server，为每个 dp rank 创建 server 实例。</li><li>通过<code>ray.get(server.get_server_address.remote())</code>获取并记录每个服务器的地址</li><li>调用<code>ray.get([server.init_engine.remote() for server in self.async_llm_servers])</code>；server 从 ray 通过前缀查询，在已经初始化好的 ray actor 中拿到自己对应的所有 SGLang engine。</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=k>def</span> <span class=nf>_initialize_llm_servers</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># 计算 dp size</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>rollout_tp_size</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>tensor_model_parallel_size</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>rollout_dp_size</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>worker_group</span><span class=o>.</span><span class=n>world_size</span> <span class=o>//</span> <span class=bp>self</span><span class=o>.</span><span class=n>rollout_tp_size</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 获取 worker 信息用于节点亲和性调度</span>
</span></span><span class=line><span class=cl>    <span class=n>register_center</span> <span class=o>=</span> <span class=n>ray</span><span class=o>.</span><span class=n>get_actor</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>worker_group</span><span class=o>.</span><span class=n>name_prefix</span><span class=si>}</span><span class=s2>_register_center&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>workers_info</span> <span class=o>=</span> <span class=n>ray</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>register_center</span><span class=o>.</span><span class=n>get_worker_info</span><span class=o>.</span><span class=n>remote</span><span class=p>())</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=nb>len</span><span class=p>(</span><span class=n>workers_info</span><span class=p>)</span> <span class=o>==</span> <span class=bp>self</span><span class=o>.</span><span class=n>worker_group</span><span class=o>.</span><span class=n>world_size</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>async_llm_servers</span> <span class=o>=</span> <span class=p>[</span><span class=kc>None</span><span class=p>]</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>rollout_dp_size</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>server_addresses</span> <span class=o>=</span> <span class=p>[</span><span class=kc>None</span><span class=p>]</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>rollout_dp_size</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 根据 config 拿到对应的 server, e.g., AsyncSGLangServer</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>agent</span><span class=o>.</span><span class=n>custom_async_server</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>server_class</span> <span class=o>=</span> <span class=n>async_server_class</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>rollout_backend</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>rollout_backend_module</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>agent</span><span class=o>.</span><span class=n>custom_async_server</span><span class=o>.</span><span class=n>path</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>rollout_backend_class</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>agent</span><span class=o>.</span><span class=n>custom_async_server</span><span class=o>.</span><span class=n>name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>server_class</span> <span class=o>=</span> <span class=n>async_server_class</span><span class=p>(</span><span class=n>rollout_backend</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 用 ray 初始化 dp rank 个 AsyncServer</span>
</span></span><span class=line><span class=cl>    <span class=n>unready_dp_ranks</span> <span class=o>=</span> <span class=nb>set</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>rollout_dp_size</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=k>while</span> <span class=nb>len</span><span class=p>(</span><span class=n>unready_dp_ranks</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>servers</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=n>rollout_dp_rank</span><span class=p>:</span> <span class=n>server_class</span><span class=o>.</span><span class=n>options</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=c1># 确保 AsyncServer 与对应的工作器在同一节点</span>
</span></span><span class=line><span class=cl>                <span class=n>scheduling_strategy</span><span class=o>=</span><span class=n>ray</span><span class=o>.</span><span class=n>util</span><span class=o>.</span><span class=n>scheduling_strategies</span><span class=o>.</span><span class=n>NodeAffinitySchedulingStrategy</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                    <span class=n>node_id</span><span class=o>=</span><span class=n>workers_info</span><span class=p>[</span><span class=n>rollout_dp_rank</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>rollout_tp_size</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                    <span class=n>soft</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=n>name</span><span class=o>=</span><span class=sa>f</span><span class=s2>&#34;async_llm_server_</span><span class=si>{</span><span class=n>rollout_dp_rank</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span><span class=o>.</span><span class=n>remote</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>rollout_dp_size</span><span class=p>,</span> <span class=n>rollout_dp_rank</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>worker_group</span><span class=o>.</span><span class=n>name_prefix</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>rollout_dp_rank</span> <span class=ow>in</span> <span class=n>unready_dp_ranks</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 记录 server 地址</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>rollout_dp_rank</span><span class=p>,</span> <span class=n>server</span> <span class=ow>in</span> <span class=n>servers</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>address</span> <span class=o>=</span> <span class=n>ray</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>server</span><span class=o>.</span><span class=n>get_server_address</span><span class=o>.</span><span class=n>remote</span><span class=p>())</span>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>server_addresses</span><span class=p>[</span><span class=n>rollout_dp_rank</span><span class=p>]</span> <span class=o>=</span> <span class=n>address</span>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>async_llm_servers</span><span class=p>[</span><span class=n>rollout_dp_rank</span><span class=p>]</span> <span class=o>=</span> <span class=n>server</span>
</span></span><span class=line><span class=cl>                <span class=n>unready_dp_ranks</span><span class=o>.</span><span class=n>remove</span><span class=p>(</span><span class=n>rollout_dp_rank</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>except</span> <span class=ne>Exception</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>ray</span><span class=o>.</span><span class=n>kill</span><span class=p>(</span><span class=n>server</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;rollout server </span><span class=si>{</span><span class=n>rollout_dp_rank</span><span class=si>}</span><span class=s2> failed, maybe address already in use, restarting...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 初始化 server，这个初始化是 server 从 ray 中拿到自己 dp 对应的所有 worker</span>
</span></span><span class=line><span class=cl>        <span class=n>ray</span><span class=o>.</span><span class=n>get</span><span class=p>([</span><span class=n>server</span><span class=o>.</span><span class=n>init_engine</span><span class=o>.</span><span class=n>remote</span><span class=p>()</span> <span class=k>for</span> <span class=n>server</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>async_llm_servers</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><p><strong><code>_init_agent_loop_workers</code></strong></p><p>在 ray 上初始化 <code>rollout.agent.num_workers</code> 个 <code>AgentLoopWorker</code>：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=k>def</span> <span class=nf>_init_agent_loop_workers</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>agent_loop_workers</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>agent</span><span class=o>.</span><span class=n>num_workers</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>agent_loop_workers</span><span class=o>.</span><span class=n>append</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>AgentLoopWorker</span><span class=o>.</span><span class=n>options</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>name</span><span class=o>=</span><span class=sa>f</span><span class=s2>&#34;agent_loop_worker_</span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span><span class=o>.</span><span class=n>remote</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>async_llm_servers</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p><strong><code>generate_sequences</code></strong></p><ul><li>如果配置了<code>free_cache_engine</code>，先调用<code>self.wake_up()</code></li><li><code>chunkes = prompts.chunk(len(self.agent_loop_workers))</code> 将输入批次按 AgentLoopWorker 数量分块。</li><li>每个 agentLoopWorker 处理自身的 chunk，通过<code>ray.get([worker.generate_sequences.remote(chunk) for ...])</code>并行执行并得到结果；</li><li>处理完成后调用<code>self.sleep()</code>让 server 进入睡眠状态以释放显存</li><li>计算生成序列和工具调用的性能指标</li><li>合并所有 <code>A``gentLoopWorker</code> 的输出并返回</li></ul><p>Code link [<a href=https://github.com/volcengine/verl/blob/c5b189a1af496d0bc68320cd1d5bd7a1f1e3638a/verl/experimental/agent_loop/agent_loop.py#L486>here</a>]</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=k>def</span> <span class=nf>generate_sequences</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>prompts</span><span class=p>:</span> <span class=n>DataProto</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>DataProto</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>free_cache_engine</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>wake_up</span><span class=p>()</span>  <span class=c1># 唤醒所有 LLM 服务器</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>chunkes</span> <span class=o>=</span> <span class=n>prompts</span><span class=o>.</span><span class=n>chunk</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>agent_loop_workers</span><span class=p>))</span>  <span class=c1># 按 worker 数量分块</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>outputs</span> <span class=o>=</span> <span class=n>ray</span><span class=o>.</span><span class=n>get</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=n>worker</span><span class=o>.</span><span class=n>generate_sequences</span><span class=o>.</span><span class=n>remote</span><span class=p>(</span><span class=n>chunk</span><span class=p>)</span> <span class=k>for</span> <span class=n>worker</span><span class=p>,</span> <span class=n>chunk</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>agent_loop_workers</span><span class=p>,</span> <span class=n>chunkes</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>  <span class=c1># 并行分发到各个 AgentLoopWorker</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>output</span> <span class=o>=</span> <span class=n>DataProto</span><span class=o>.</span><span class=n>concat</span><span class=p>(</span><span class=n>outputs</span><span class=p>)</span>  <span class=c1># 聚合所有 worker 的输出</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>free_cache_engine</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>sleep</span><span class=p>()</span>  <span class=c1># 让服务器进入睡眠状态，释放显存</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 计算性能指标</span>
</span></span><span class=line><span class=cl>    <span class=n>metrics</span> <span class=o>=</span> <span class=p>[</span><span class=n>output</span><span class=o>.</span><span class=n>meta_info</span><span class=p>[</span><span class=s2>&#34;metrics&#34;</span><span class=p>]</span> <span class=k>for</span> <span class=n>output</span> <span class=ow>in</span> <span class=n>outputs</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>timing</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_performance_metrics</span><span class=p>(</span><span class=n>metrics</span><span class=p>,</span> <span class=n>output</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>output</span><span class=o>.</span><span class=n>meta_info</span> <span class=o>=</span> <span class=p>{</span><span class=s2>&#34;timing&#34;</span><span class=p>:</span> <span class=n>timing</span><span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>output</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=asyncsglangserver>AsyncSGLangServer<a hidden class=anchor aria-hidden=true href=#asyncsglangserver>#</a></h2><p>基于 SGLang 的异步服务器实现，继承自<code>AsyncServerBase</code>。作为 Ray 远程 actor 运行，负责将收到的请求转发给下层的 SGLang Engine。出于 SGLang 的设计，调用 <code>generate</code> 的时候只需要对 master worker（verl 的 inference tp 0）调用即可。</p><h3 id=核心-api-1>核心 API<a hidden class=anchor aria-hidden=true href=#核心-api-1>#</a></h3><p><strong><code>init_engine</code></strong></p><p>异步初始化 SGLang 引擎：</p><ul><li>通过<code>ray.util.list_named_actors</code>查找所有匹配的 actors；</li><li>根据命名规则 <code>self.wg_prefix + "WorkerDict_"</code> 解析 actor 名称；</li><li>根据 dp_rank 和 tp_size 分配 actor，确定 master worker（tp rank 0）</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=k>async</span> <span class=k>def</span> <span class=nf>init_engine</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>workers</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># avoid init twice</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span>
</span></span><span class=line><span class=cl>    <span class=n>all_actors</span> <span class=o>=</span> <span class=n>ray</span><span class=o>.</span><span class=n>util</span><span class=o>.</span><span class=n>list_named_actors</span><span class=p>(</span><span class=n>all_namespaces</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>matched_actors</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=n>actor</span> <span class=k>for</span> <span class=n>actor</span> <span class=ow>in</span> <span class=n>all_actors</span> <span class=k>if</span> <span class=n>actor</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;name&#34;</span><span class=p>,</span> <span class=kc>None</span><span class=p>)</span><span class=o>.</span><span class=n>startswith</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>wg_prefix</span> <span class=o>+</span> <span class=s2>&#34;WorkerDict_&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>gpu_per_node</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=nb>set</span><span class=p>([</span><span class=n>actor</span><span class=p>[</span><span class=s2>&#34;name&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s2>&#34;:&#34;</span><span class=p>)[</span><span class=mi>1</span><span class=p>]</span> <span class=k>for</span> <span class=n>actor</span> <span class=ow>in</span> <span class=n>matched_actors</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>    <span class=c1># total gpu num</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=nb>len</span><span class=p>(</span><span class=n>matched_actors</span><span class=p>)</span> <span class=o>==</span> <span class=bp>self</span><span class=o>.</span><span class=n>_dp_size</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>_tp_size</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>matched_actor</span> <span class=ow>in</span> <span class=n>matched_actors</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>fields</span> <span class=o>=</span> <span class=n>matched_actor</span><span class=p>[</span><span class=s2>&#34;name&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s2>&#34;:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>assert</span> <span class=nb>len</span><span class=p>(</span><span class=n>fields</span><span class=p>)</span> <span class=o>==</span> <span class=mi>2</span><span class=p>,</span> <span class=sa>f</span><span class=s2>&#34;invalid actor name: </span><span class=si>{</span><span class=n>matched_actor</span><span class=p>[</span><span class=s1>&#39;name&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>pg_index</span><span class=p>,</span> <span class=n>local_rank</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>fields</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s2>&#34;_&#34;</span><span class=p>)[</span><span class=o>-</span><span class=mi>1</span><span class=p>]),</span> <span class=nb>int</span><span class=p>(</span><span class=n>fields</span><span class=p>[</span><span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>current_global_rank</span> <span class=o>=</span> <span class=n>gpu_per_node</span> <span class=o>*</span> <span class=n>pg_index</span> <span class=o>+</span> <span class=n>local_rank</span>
</span></span><span class=line><span class=cl>        <span class=n>worker_dp_rank</span> <span class=o>=</span> <span class=n>current_global_rank</span> <span class=o>//</span> <span class=bp>self</span><span class=o>.</span><span class=n>_tp_size</span>
</span></span><span class=line><span class=cl>        <span class=n>worker_tp_rank</span> <span class=o>=</span> <span class=n>current_global_rank</span> <span class=o>%</span> <span class=bp>self</span><span class=o>.</span><span class=n>_tp_size</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>worker_dp_rank</span> <span class=o>==</span> <span class=bp>self</span><span class=o>.</span><span class=n>_dp_rank</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>worker</span> <span class=o>=</span> <span class=n>ray</span><span class=o>.</span><span class=n>get_actor</span><span class=p>(</span><span class=o>**</span><span class=n>matched_actor</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>workers</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>worker</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>worker_tp_rank</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>master_worker</span> <span class=o>=</span> <span class=n>worker</span>
</span></span></code></pre></td></tr></table></div></div><p><strong><code>chat_completion</code></strong></p><p>处理 <code>chat_completion</code> 请求：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=k>async</span> <span class=k>def</span> <span class=nf>chat_completion</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>raw_request</span><span class=p>:</span> <span class=n>Request</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>request</span> <span class=o>=</span> <span class=k>await</span> <span class=n>raw_request</span><span class=o>.</span><span class=n>json</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>output_future</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>master_worker</span><span class=o>.</span><span class=n>chat_completion</span><span class=o>.</span><span class=n>remote</span><span class=p>(</span><span class=n>request</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=n>outputs</span><span class=p>]</span> <span class=o>=</span> <span class=k>await</span> <span class=n>asyncio</span><span class=o>.</span><span class=n>gather</span><span class=p>(</span><span class=n>output_future</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>JSONResponse</span><span class=p>(</span><span class=n>outputs</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><ul><li>将请求转发给 master worker 处理</li><li>返回 JSON 格式的响应</li></ul><p><strong><code>generate</code></strong></p><p>Token in token out 来获得 SGLang Engine 的 inference 结果：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=k>async</span> <span class=k>def</span> <span class=nf>generate</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>prompt_ids</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=nb>int</span><span class=p>],</span> <span class=n>sampling_params</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span> <span class=n>request_id</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>List</span><span class=p>[</span><span class=nb>int</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=k>await</span> <span class=bp>self</span><span class=o>.</span><span class=n>master_worker</span><span class=o>.</span><span class=n>generate</span><span class=o>.</span><span class=n>remote</span><span class=p>(</span><span class=n>prompt_ids</span><span class=p>,</span> <span class=n>sampling_params</span><span class=p>,</span> <span class=n>request_id</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><ul><li>直接调用 master worker 的生成方法</li><li>支持自定义采样参数</li></ul><h2 id=asyncllmservermanager>AsyncLLMServerManager<a hidden class=anchor aria-hidden=true href=#asyncllmservermanager>#</a></h2><p>管理多个 OpenAI 兼容的 LLM 服务器 (例如 <code>Async``SGLang``Server</code>)，提供负载均衡和会话粘性功能。支持最少请求负载均衡算法，确保多轮对话发送到同一服务器以实现自动前缀缓存。可以认为就是简单的 router/load balancer 层。</p><p><strong>初始化</strong></p><ul><li>配置服务器句柄列表，随机打乱顺序</li><li>初始化最少请求负载均衡器：<code>self.weighted_serveres = [[0, (hash(server), server)] for server in server_handles]</code></li><li>创建 LRU 缓存：<code>self.request_id_to_server = LRUCache(maxsize=max_cache_size)</code>用于 request_id 到服务器的映射</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>config</span><span class=p>:</span> <span class=n>DictConfig</span><span class=p>,</span> <span class=n>server_handles</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=n>ray</span><span class=o>.</span><span class=n>actor</span><span class=o>.</span><span class=n>ActorHandle</span><span class=p>],</span> <span class=n>max_cache_size</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>10000</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Initialize the AsyncLLMServerManager.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>        Args:
</span></span></span><span class=line><span class=cl><span class=s2>            config (DictConfig): YAML config.
</span></span></span><span class=line><span class=cl><span class=s2>            server_handles (List[ray.actor.ActorHandle]): OpenAI compatible LLM server actor handles.
</span></span></span><span class=line><span class=cl><span class=s2>            max_cache_size (int, optional): max cache size for request_id to server mapping. Defaults to 10000.
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>config</span> <span class=o>=</span> <span class=n>config</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>server_handles</span> <span class=o>=</span> <span class=n>server_handles</span>
</span></span><span class=line><span class=cl>        <span class=n>random</span><span class=o>.</span><span class=n>shuffle</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>server_handles</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Least requests load balancing</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>weighted_serveres</span> <span class=o>=</span> <span class=p>[[</span><span class=mi>0</span><span class=p>,</span> <span class=p>(</span><span class=nb>hash</span><span class=p>(</span><span class=n>server</span><span class=p>),</span> <span class=n>server</span><span class=p>)]</span> <span class=k>for</span> <span class=n>server</span> <span class=ow>in</span> <span class=n>server_handles</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>heapq</span><span class=o>.</span><span class=n>heapify</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>weighted_serveres</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># LRU cache to map request_id to server</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>request_id_to_server</span> <span class=o>=</span> <span class=n>LRUCache</span><span class=p>(</span><span class=n>maxsize</span><span class=o>=</span><span class=n>max_cache_size</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p><strong><code>_choose_server</code></strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=k>def</span> <span class=nf>_choose_server</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>request_id</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>ray</span><span class=o>.</span><span class=n>actor</span><span class=o>.</span><span class=n>ActorHandle</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>request_id</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>request_id_to_server</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>request_id_to_server</span><span class=p>[</span><span class=n>request_id</span><span class=p>]</span>  <span class=c1># 会话粘性</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>server</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>weighted_serveres</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=mi>1</span><span class=p>][</span><span class=mi>1</span><span class=p>]</span>  <span class=c1># 最少请求的服务器</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>weighted_serveres</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=mi>0</span><span class=p>]</span> <span class=o>+=</span> <span class=mi>1</span>  <span class=c1># 增加请求计数</span>
</span></span><span class=line><span class=cl>    <span class=n>heapq</span><span class=o>.</span><span class=n>heapreplace</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>weighted_serveres</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>weighted_serveres</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>request_id_to_server</span><span class=p>[</span><span class=n>request_id</span><span class=p>]</span> <span class=o>=</span> <span class=n>server</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>server</span>
</span></span></code></pre></td></tr></table></div></div><ul><li><strong>会话粘性</strong>：相同 <code>request_id</code> 发送给同一 <code>server</code></li><li><strong>最少请求</strong>：新请求分配给当前负载最轻的 <code>server</code></li><li><strong>动态更新</strong>：使用堆结构维护服务器负载状态</li></ul><p><strong><code>generate</code></strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=nd>@rollout_trace_op</span>
</span></span><span class=line><span class=cl><span class=k>async</span> <span class=k>def</span> <span class=nf>generate</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>request_id</span><span class=p>,</span> <span class=o>*</span><span class=p>,</span> <span class=n>prompt_ids</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=nb>int</span><span class=p>],</span> <span class=n>sampling_params</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>])</span> <span class=o>-&gt;</span> <span class=n>List</span><span class=p>[</span><span class=nb>int</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=n>server</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_choose_server</span><span class=p>(</span><span class=n>request_id</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>output</span> <span class=o>=</span> <span class=k>await</span> <span class=n>server</span><span class=o>.</span><span class=n>generate</span><span class=o>.</span><span class=n>remote</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>request_id</span><span class=o>=</span><span class=n>request_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>prompt_ids</span><span class=o>=</span><span class=n>prompt_ids</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>sampling_params</span><span class=o>=</span><span class=n>sampling_params</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>output</span>
</span></span></code></pre></td></tr></table></div></div><ul><li>根据 <code>request_id</code> 选择 <code>server</code></li><li>异步调用 server 的生成接口，token-in-token-out</li><li>支持性能追踪</li></ul><h2 id=agentloopworker>AgentLoopWorker<a hidden class=anchor aria-hidden=true href=#agentloopworker>#</a></h2><p><code>AgentLoopWorker</code> 负责接收数据，向下发给具体的 <code>AgentLoop</code>。虽然名字是 worker，但是</p><ol><li>从 ray 的角度来说，<code>AgentLoopWorker</code> 是有状态的，是 ray actor，而不是 ray worker</li><li>核心函数 <code>generate</code> 是层层套壳，调用其他类；例如 <code>single_turn_agent_loop</code> 和 <code>tool_agent_loop</code> 来 <code>generate</code>（当然这两个类的 <code>generate</code> 也是向下调用，下面会讲到）</li></ol><p><strong><code>__init__</code></strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=nd>@ray.remote</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>AgentLoopWorker</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Agent loop worker takes a batch of messages and run each message in an agent loop.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>config</span><span class=p>:</span> <span class=n>DictConfig</span><span class=p>,</span> <span class=n>server_handles</span><span class=p>:</span> <span class=nb>list</span><span class=p>[</span><span class=n>ray</span><span class=o>.</span><span class=n>actor</span><span class=o>.</span><span class=n>ActorHandle</span><span class=p>]):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Initialize agent loop manager.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>        Args:
</span></span></span><span class=line><span class=cl><span class=s2>            config (DictConfig): YAML config.
</span></span></span><span class=line><span class=cl><span class=s2>            server_handles (List[ray.actor.ActorHandle]): OpenAI compatible LLM server actor handles.
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>config</span> <span class=o>=</span> <span class=n>config</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>server_manager</span> <span class=o>=</span> <span class=n>AsyncLLMServerManager</span><span class=p>(</span><span class=n>config</span><span class=p>,</span> <span class=n>server_handles</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>model_path</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>path</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>model_name</span> <span class=o>=</span> <span class=s2>&#34;/&#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>model_path</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s2>&#34;/&#34;</span><span class=p>)[</span><span class=o>-</span><span class=mi>2</span><span class=p>:])</span>
</span></span><span class=line><span class=cl>        <span class=n>local_path</span> <span class=o>=</span> <span class=n>copy_to_local</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span> <span class=o>=</span> <span class=n>hf_tokenizer</span><span class=p>(</span><span class=n>local_path</span><span class=p>,</span> <span class=n>trust_remote_code</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>trace_config</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;trace&#34;</span><span class=p>,</span> <span class=p>{})</span>
</span></span><span class=line><span class=cl>        <span class=n>RolloutTraceConfig</span><span class=o>.</span><span class=n>init</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>project_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>experiment_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>trace_config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;backend&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>trace_config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;token2text&#34;</span><span class=p>,</span> <span class=kc>False</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><ul><li>上游传过来的 <code>config</code> 和 <code>server_handles</code> 作为参数来初始化 <code>AsyncLLMServerManager</code>，之后会把这个 <code>self.server_manager</code> 传给下游；</li><li>根据 <code>config</code> 的 <code>config</code><strong><code>.</code></strong><code>actor_rollout_ref</code><strong><code>.</code></strong><code>model</code><strong><code>.</code></strong><code>path</code> 设置 <code>model_path, local_path, tokenizer</code></li><li>配置 <code>RolloutTraceConfig</code> 用于追踪 trajectories</li></ul><p><strong><code>generate_sequences</code></strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=k>async</span> <span class=k>def</span> <span class=nf>generate_sequences</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>:</span> <span class=n>DataProto</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>DataProto</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Generate sequences from agent loop.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        batch (DataProto): Input batch.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        DataProto: Output batch.
</span></span></span><span class=line><span class=cl><span class=s2>        - prompts: [bsz, prompt_length], prompt token ids from dataset.
</span></span></span><span class=line><span class=cl><span class=s2>        - responses: [bsz, response_length], output token ids include response tokens
</span></span></span><span class=line><span class=cl><span class=s2>          from LLM generation and observation tokens from tool_calls.
</span></span></span><span class=line><span class=cl><span class=s2>        - response_mask: [bsz, response_length], 1 for LLM generated tokens, 0 for observation/padding tokens.
</span></span></span><span class=line><span class=cl><span class=s2>        - input_ids: [bsz, prompt_length + response_length], whole sequence token ids, including prompt tokens
</span></span></span><span class=line><span class=cl><span class=s2>          and response tokens.
</span></span></span><span class=line><span class=cl><span class=s2>        - attention_mask: [bsz, prompt_length + response_length], 0 for padding tokens, 1 for other tokens.
</span></span></span><span class=line><span class=cl><span class=s2>        - position_ids: [bsz, prompt_length + response_length], incremental position ids.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>        For multi-turn conversations:
</span></span></span><span class=line><span class=cl><span class=s2>        responses:     |&lt;- LLM generation -&gt;|&lt;- tool_calls -&gt;|&lt;- LLM generation -&gt;|&lt;- padding -&gt;|
</span></span></span><span class=line><span class=cl><span class=s2>        response_mask: | 1, 1, 1, ..., 1, 1 | 0, 0, .., 0, 0 | 1, 1, 1, ..., 1, 1 | 0, 0, ..., 0|
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>config</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span>
</span></span><span class=line><span class=cl>    <span class=n>sampling_params</span> <span class=o>=</span> <span class=nb>dict</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>temperature</span><span class=o>=</span><span class=n>config</span><span class=o>.</span><span class=n>temperature</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>top_p</span><span class=o>=</span><span class=n>config</span><span class=o>.</span><span class=n>top_p</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>repetition_penalty</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># override sampling params for validation</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>batch</span><span class=o>.</span><span class=n>meta_info</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;validate&#34;</span><span class=p>,</span> <span class=kc>False</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>sampling_params</span><span class=p>[</span><span class=s2>&#34;top_p&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>val_kwargs</span><span class=o>.</span><span class=n>top_p</span>
</span></span><span class=line><span class=cl>        <span class=n>sampling_params</span><span class=p>[</span><span class=s2>&#34;temperature&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>val_kwargs</span><span class=o>.</span><span class=n>temperature</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># by default, we assume it&#39;s a single turn agent</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=s2>&#34;agent_name&#34;</span> <span class=ow>not</span> <span class=ow>in</span> <span class=n>batch</span><span class=o>.</span><span class=n>non_tensor_batch</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>batch</span><span class=o>.</span><span class=n>non_tensor_batch</span><span class=p>[</span><span class=s2>&#34;agent_name&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=s2>&#34;single_turn_agent&#34;</span><span class=p>]</span> <span class=o>*</span> <span class=nb>len</span><span class=p>(</span><span class=n>batch</span><span class=p>),</span> <span class=n>dtype</span><span class=o>=</span><span class=nb>object</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>tasks</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>agent_names</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>non_tensor_batch</span><span class=p>[</span><span class=s2>&#34;agent_name&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>raw_prompts</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>non_tensor_batch</span><span class=p>[</span><span class=s2>&#34;raw_prompt&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=s2>&#34;index&#34;</span> <span class=ow>in</span> <span class=n>batch</span><span class=o>.</span><span class=n>non_tensor_batch</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>index</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>non_tensor_batch</span><span class=p>[</span><span class=s2>&#34;index&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>index</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>raw_prompts</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>trajectory_info</span> <span class=o>=</span> <span class=k>await</span> <span class=n>get_trajectory_info</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>batch</span><span class=o>.</span><span class=n>meta_info</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;global_steps&#34;</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>),</span> <span class=n>index</span><span class=p>,</span> <span class=n>batch</span><span class=o>.</span><span class=n>meta_info</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;validate&#34;</span><span class=p>,</span> <span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>agent_name</span><span class=p>,</span> <span class=n>messages</span><span class=p>,</span> <span class=n>trajectory</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>agent_names</span><span class=p>,</span> <span class=n>raw_prompts</span><span class=p>,</span> <span class=n>trajectory_info</span><span class=p>,</span> <span class=n>strict</span><span class=o>=</span><span class=kc>True</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>tasks</span><span class=o>.</span><span class=n>append</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>asyncio</span><span class=o>.</span><span class=n>create_task</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_run_agent_loop</span><span class=p>(</span><span class=n>agent_name</span><span class=p>,</span> <span class=n>messages</span><span class=o>.</span><span class=n>tolist</span><span class=p>(),</span> <span class=n>sampling_params</span><span class=p>,</span> <span class=n>trajectory</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>outputs</span> <span class=o>=</span> <span class=k>await</span> <span class=n>asyncio</span><span class=o>.</span><span class=n>gather</span><span class=p>(</span><span class=o>*</span><span class=n>tasks</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_postprocess</span><span class=p>(</span><span class=n>outputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>output</span>
</span></span></code></pre></td></tr></table></div></div><ul><li>利用上游传来的 <code>config</code>，创建给下游使用的 <code>sampling_params</code>；对 validation batch 要用 validation 参数。</li><li>利用 batch 的 <code>meta_info</code>，获得 <code>agent_name, raw_prompts, index</code>。再用这个 <code>meta_info</code> 处理获得 <code>trajectory_info</code>；就是利用刚才的 index 来计算在每一个 step 每一个 prompt 被 rollout 的次数，然后存到一个 list 中获得整个 rollout 的 trace；</li><li>利用 <code>agent_names, raw_prompts, trajectory_info</code> 来并发执行 <code>_run_agent_loop</code>。</li><li>在 <code>_run_agent_loop</code> 函数内，就要进行相应 <code>agent_name</code> 的 <code>agent_loop</code> 实例化，以及调用 <code>agent_loop</code> 对应的 run 函数来 generate。</li><li>在 <code>_postprocess</code> 中，会根据前面计算出来的 output（被封装成了 <code>AgentLoopOutput</code> 格式）来进行后处理；padding，加入 mask，最后封装成一个 <code>DataProto</code> 返回。</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span><span class=lnt>72
</span><span class=lnt>73
</span><span class=lnt>74
</span><span class=lnt>75
</span><span class=lnt>76
</span><span class=lnt>77
</span><span class=lnt>78
</span><span class=lnt>79
</span><span class=lnt>80
</span><span class=lnt>81
</span><span class=lnt>82
</span><span class=lnt>83
</span><span class=lnt>84
</span><span class=lnt>85
</span><span class=lnt>86
</span><span class=lnt>87
</span><span class=lnt>88
</span><span class=lnt>89
</span><span class=lnt>90
</span><span class=lnt>91
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=k>async</span> <span class=k>def</span> <span class=nf>_run_agent_loop</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>agent_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>messages</span><span class=p>:</span> <span class=nb>list</span><span class=p>[</span><span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]],</span>
</span></span><span class=line><span class=cl>    <span class=n>sampling_params</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>trajectory</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span>
</span></span><span class=line><span class=cl><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>AgentLoopOutput</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>rollout_trace_attr</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>step</span><span class=o>=</span><span class=n>trajectory</span><span class=p>[</span><span class=s2>&#34;step&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>sample_index</span><span class=o>=</span><span class=n>trajectory</span><span class=p>[</span><span class=s2>&#34;sample_index&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>rollout_n</span><span class=o>=</span><span class=n>trajectory</span><span class=p>[</span><span class=s2>&#34;rollout_n&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>validate</span><span class=o>=</span><span class=n>trajectory</span><span class=p>[</span><span class=s2>&#34;validate&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>name</span><span class=o>=</span><span class=s2>&#34;agent_loop&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>assert</span> <span class=n>agent_name</span> <span class=ow>in</span> <span class=n>_agent_loop_registry</span><span class=p>,</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=sa>f</span><span class=s2>&#34;Agent loop </span><span class=si>{</span><span class=n>agent_name</span><span class=si>}</span><span class=s2> not registered, registered agent loops: </span><span class=si>{</span><span class=n>_agent_loop_registry</span><span class=o>.</span><span class=n>keys</span><span class=p>()</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>agent_loop_config</span> <span class=o>=</span> <span class=n>_agent_loop_registry</span><span class=p>[</span><span class=n>agent_name</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>agent_loop</span> <span class=o>=</span> <span class=n>hydra</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>instantiate</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>config</span><span class=o>=</span><span class=n>agent_loop_config</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>trainer_config</span><span class=o>=</span><span class=n>_DummyConfig</span><span class=p>(</span><span class=n>config</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>server_manager</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>server_manager</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>tokenizer</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>output</span> <span class=o>=</span> <span class=k>await</span> <span class=n>agent_loop</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>messages</span><span class=p>,</span> <span class=n>sampling_params</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>output</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>_postprocess</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>inputs</span><span class=p>:</span> <span class=nb>list</span><span class=p>[</span><span class=n>AgentLoopOutput</span><span class=p>])</span> <span class=o>-&gt;</span> <span class=n>DataProto</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># NOTE: consistent with batch version of generate_sequences in vllm_rollout_spmd.py</span>
</span></span><span class=line><span class=cl>    <span class=c1># prompts: left pad</span>
</span></span><span class=line><span class=cl>    <span class=c1># responses: right pad</span>
</span></span><span class=line><span class=cl>    <span class=c1># input_ids: prompt + response</span>
</span></span><span class=line><span class=cl>    <span class=c1># attention_mask: [0,0,0,0,1,1,1,1, | 1,1,1,0,0,0,0,0]</span>
</span></span><span class=line><span class=cl>    <span class=c1># position_ids:   [0,0,0,0,0,1,2,3, | 4,5,6,7,8,9,10,11]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># prompts</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>padding_side</span> <span class=o>=</span> <span class=s2>&#34;left&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>outputs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>pad</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=p>[{</span><span class=s2>&#34;input_ids&#34;</span><span class=p>:</span> <span class=nb>input</span><span class=o>.</span><span class=n>prompt_ids</span><span class=p>}</span> <span class=k>for</span> <span class=nb>input</span> <span class=ow>in</span> <span class=n>inputs</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>padding</span><span class=o>=</span><span class=s2>&#34;max_length&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>max_length</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>prompt_length</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>return_attention_mask</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>prompt_ids</span><span class=p>,</span> <span class=n>prompt_attention_mask</span> <span class=o>=</span> <span class=n>outputs</span><span class=p>[</span><span class=s2>&#34;input_ids&#34;</span><span class=p>],</span> <span class=n>outputs</span><span class=p>[</span><span class=s2>&#34;attention_mask&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># responses</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>padding_side</span> <span class=o>=</span> <span class=s2>&#34;right&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>outputs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>pad</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=p>[{</span><span class=s2>&#34;input_ids&#34;</span><span class=p>:</span> <span class=nb>input</span><span class=o>.</span><span class=n>response_ids</span><span class=p>}</span> <span class=k>for</span> <span class=nb>input</span> <span class=ow>in</span> <span class=n>inputs</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>padding</span><span class=o>=</span><span class=s2>&#34;max_length&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>max_length</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>response_length</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>return_attention_mask</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>response_ids</span><span class=p>,</span> <span class=n>response_attention_mask</span> <span class=o>=</span> <span class=n>outputs</span><span class=p>[</span><span class=s2>&#34;input_ids&#34;</span><span class=p>],</span> <span class=n>outputs</span><span class=p>[</span><span class=s2>&#34;attention_mask&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># response_mask</span>
</span></span><span class=line><span class=cl>    <span class=n>outputs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>pad</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=p>[{</span><span class=s2>&#34;input_ids&#34;</span><span class=p>:</span> <span class=nb>input</span><span class=o>.</span><span class=n>response_mask</span><span class=p>}</span> <span class=k>for</span> <span class=nb>input</span> <span class=ow>in</span> <span class=n>inputs</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>padding</span><span class=o>=</span><span class=s2>&#34;max_length&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>max_length</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>response_length</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>return_attention_mask</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>response_mask</span> <span class=o>=</span> <span class=n>outputs</span><span class=p>[</span><span class=s2>&#34;input_ids&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=n>response_ids</span><span class=o>.</span><span class=n>shape</span> <span class=o>==</span> <span class=n>response_mask</span><span class=o>.</span><span class=n>shape</span><span class=p>,</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=sa>f</span><span class=s2>&#34;mismatch in response_ids and response_mask shape: </span><span class=si>{</span><span class=n>response_ids</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2> vs </span><span class=si>{</span><span class=n>response_mask</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>response_mask</span> <span class=o>=</span> <span class=n>response_mask</span> <span class=o>*</span> <span class=n>response_attention_mask</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>input_ids</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>prompt_ids</span><span class=p>,</span> <span class=n>response_ids</span><span class=p>],</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>attention_mask</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>prompt_attention_mask</span><span class=p>,</span> <span class=n>response_attention_mask</span><span class=p>],</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>position_ids</span> <span class=o>=</span> <span class=p>(</span><span class=n>attention_mask</span><span class=o>.</span><span class=n>cumsum</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)</span> <span class=o>*</span> <span class=n>attention_mask</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>batch</span> <span class=o>=</span> <span class=n>TensorDict</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;prompts&#34;</span><span class=p>:</span> <span class=n>prompt_ids</span><span class=p>,</span>  <span class=c1># [bsz, prompt_length]</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;responses&#34;</span><span class=p>:</span> <span class=n>response_ids</span><span class=p>,</span>  <span class=c1># [bsz, response_length]</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;response_mask&#34;</span><span class=p>:</span> <span class=n>response_mask</span><span class=p>,</span>  <span class=c1># [bsz, response_length]</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;input_ids&#34;</span><span class=p>:</span> <span class=n>input_ids</span><span class=p>,</span>  <span class=c1># [bsz, prompt_length + response_length]</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;attention_mask&#34;</span><span class=p>:</span> <span class=n>attention_mask</span><span class=p>,</span>  <span class=c1># [bsz, prompt_length + response_length]</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;position_ids&#34;</span><span class=p>:</span> <span class=n>position_ids</span><span class=p>,</span>  <span class=c1># [bsz, prompt_length + response_length]</span>
</span></span><span class=line><span class=cl>        <span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=n>batch_size</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>input_ids</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>num_turns</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=nb>input</span><span class=o>.</span><span class=n>num_turns</span> <span class=k>for</span> <span class=nb>input</span> <span class=ow>in</span> <span class=n>inputs</span><span class=p>],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>int32</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>metrics</span> <span class=o>=</span> <span class=p>[</span><span class=nb>input</span><span class=o>.</span><span class=n>metrics</span><span class=o>.</span><span class=n>model_dump</span><span class=p>()</span> <span class=k>for</span> <span class=nb>input</span> <span class=ow>in</span> <span class=n>inputs</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>DataProto</span><span class=p>(</span><span class=n>batch</span><span class=o>=</span><span class=n>batch</span><span class=p>,</span> <span class=n>non_tensor_batch</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;__num_turns__&#34;</span><span class=p>:</span> <span class=n>num_turns</span><span class=p>},</span> <span class=n>meta_info</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;metrics&#34;</span><span class=p>:</span> <span class=n>metrics</span><span class=p>})</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=agentloop>AgentLoop<a hidden class=anchor aria-hidden=true href=#agentloop>#</a></h2><p>终于进入到了具体的 agent loop 当中，我们观察两种具体的 AgentLoop。</p><h2 id=singleturnagentloop>SingleTurnAgentLoop<a hidden class=anchor aria-hidden=true href=#singleturnagentloop>#</a></h2><p>这个 <code>agent_loop</code> 是默认的单轮对话，处理简单的一问一答，不支持工具调用；最重要的自然是 <code>run</code> 函数：</p><ol><li>我们传入 <code>agent_loop</code>的 <code>messages</code> 其实是我们从 <code>batch</code> 里面获得的 <code>raw_prompt</code>，此处调用 <code>apply_chat_template</code>；</li><li>调用 <code>server_manager</code> 里面的 <code>generate</code> 函数来计算 <code>response_ids</code>；</li><li>计算 <code>response_mask</code>，并根据 <code>response_length</code> 截取，封装这些结果成 <code>AgentLoopOutput</code>，padding 在上层 <code>AgentLoopManager</code> 的 <code>_postprocess</code> 内做；</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=k>class</span> <span class=nc>SingleTurnAgentLoop</span><span class=p>(</span><span class=n>AgentLoopBase</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Naive agent loop that only do single turn chat completion.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>config</span><span class=p>,</span> <span class=n>server_manager</span><span class=p>,</span> <span class=n>tokenizer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=n>config</span><span class=p>,</span> <span class=n>server_manager</span><span class=p>,</span> <span class=n>tokenizer</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>prompt_length</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>prompt_length</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>response_length</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>response_length</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>async</span> <span class=k>def</span> <span class=nf>run</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>messages</span><span class=p>:</span> <span class=nb>list</span><span class=p>[</span><span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]],</span> <span class=n>sampling_params</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>])</span> <span class=o>-&gt;</span> <span class=n>AgentLoopOutput</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>metrics</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>        <span class=n>request_id</span> <span class=o>=</span> <span class=n>uuid4</span><span class=p>()</span><span class=o>.</span><span class=n>hex</span>
</span></span><span class=line><span class=cl>        <span class=n>prompt_ids</span> <span class=o>=</span> <span class=k>await</span> <span class=bp>self</span><span class=o>.</span><span class=n>loop</span><span class=o>.</span><span class=n>run_in_executor</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=kc>None</span><span class=p>,</span> <span class=k>lambda</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>apply_chat_template</span><span class=p>(</span><span class=n>messages</span><span class=p>,</span> <span class=n>add_generation_prompt</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>tokenize</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>simple_timer</span><span class=p>(</span><span class=s2>&#34;generate_sequences&#34;</span><span class=p>,</span> <span class=n>metrics</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>response_ids</span> <span class=o>=</span> <span class=k>await</span> <span class=bp>self</span><span class=o>.</span><span class=n>server_manager</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>request_id</span><span class=o>=</span><span class=n>request_id</span><span class=p>,</span> <span class=n>prompt_ids</span><span class=o>=</span><span class=n>prompt_ids</span><span class=p>,</span> <span class=n>sampling_params</span><span class=o>=</span><span class=n>sampling_params</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>response_mask</span> <span class=o>=</span> <span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>*</span> <span class=nb>len</span><span class=p>(</span><span class=n>response_ids</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>output</span> <span class=o>=</span> <span class=n>AgentLoopOutput</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>prompt_ids</span><span class=o>=</span><span class=n>prompt_ids</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>response_ids</span><span class=o>=</span><span class=n>response_ids</span><span class=p>[:</span> <span class=bp>self</span><span class=o>.</span><span class=n>response_length</span><span class=p>],</span>
</span></span><span class=line><span class=cl>            <span class=n>response_mask</span><span class=o>=</span><span class=n>response_mask</span><span class=p>[:</span> <span class=bp>self</span><span class=o>.</span><span class=n>response_length</span><span class=p>],</span>
</span></span><span class=line><span class=cl>            <span class=n>num_turns</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>metrics</span><span class=o>=</span><span class=n>metrics</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>output</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=toolagentloop>ToolAgentLoop<a hidden class=anchor aria-hidden=true href=#toolagentloop>#</a></h2><p>终于到了最核心的地方。<code>ToolAgentLoop</code> 支持多轮对话和工具调用。目前 <code>ToolAgentLoop</code> 可以完全覆盖 <code>SGLangRollout</code> 中基于 <code>_async_rollout_a_request</code> 实现的 <a href=https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/rlhf/verl/multi-turn/code-walk-through/readme-2.md#_async_rollout_a_request>tool call 管理</a>。但状态数量和转移关系更加简单。也就是说， 先前的 multi-turn RL 的 tool 状态管理是在 <code>SGLangRollout</code> 内实现的，而 <code>AgentLoop</code> 提前将这层管理抽象了出来。</p><p><strong><code>init_class</code></strong></p><p>下面只介绍一些关键参数的作用:</p><ol><li>**<code>tool_response_truncate_side</code>：**控制工具响应内容过长时的截断方式。<ul><li><code>"left"</code>：从左侧截断，保留开头部分 + &ldquo;&mldr;(truncated)"；</li><li><code>"right"</code>：从右侧截断，保留结尾部分，前面加 &ldquo;(truncated)&mldr;"；</li><li>其他值：从中间截断，保留开头和结尾部分，中间加 &ldquo;&mldr;(truncated)&mldr;&rdquo;</li></ul></li><li><strong><code>tool_config_path</code></strong>：指定包含工具定义和配置信息的配置文件位置，用于初始化可用的工具列表，比如<code>verl/examples/sglang_multiturn/config/tool_config/gsm8k_tool_config.yaml</code></li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-YAML data-lang=YAML><span class=line><span class=cl><span class=nt>tools</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>class_name</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;verl.tools.gsm8k_tool.Gsm8kTool&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>config</span><span class=p>:</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>native</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>tool_schema</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;function&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>function</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;calc_gsm8k_reward&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>description</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;A tool for calculating the reward of gsm8k. (1.0 if parsed answer is correct, 0.0 if parsed answer is incorrect or not correctly parsed)&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>parameters</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;object&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>properties</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>answer</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;string&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span><span class=nt>description</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;The model&#39;s answer to the GSM8K math problem, must be a digits&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>required</span><span class=p>:</span><span class=w> </span><span class=p>[</span><span class=s2>&#34;answer&#34;</span><span class=p>]</span><span class=w>
</span></span></span></code></pre></td></tr></table></div></div><p><strong><code>tool_list</code></strong>, <strong><code>tool_schemas</code></strong>：通过 <code>initialize_tools_from_config(tool_config_path)</code> 函数从配置文件中解析并创建工具实例。</p><p><strong><code>tool_parser</code></strong>：通过设置类似 <code>actor_rollout_ref.rollout.multi_turn.format=hermes</code>这样的参数， 可以获取对应的 <code>tool_parser</code>；比如 <code>HermesToolParser</code> 就是提取 <code>&lt;tool_call>&lt;/tool_call></code> 之间的内容，返回对应的 <code>function_call</code>（<code>function_name</code> 和 <code>function_arguments</code>）, 还有除开 <code>tool_call</code> 内容以外的 <code>content</code>。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=nd>@classmethod</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>init_class</span><span class=p>(</span><span class=bp>cls</span><span class=p>,</span> <span class=n>config</span><span class=p>,</span> <span class=n>tokenizer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>cls</span><span class=o>.</span><span class=n>_class_initialized</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span>
</span></span><span class=line><span class=cl>    <span class=bp>cls</span><span class=o>.</span><span class=n>_class_initialized</span> <span class=o>=</span> <span class=kc>True</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Performing class-level ToolAgentLoop initialization&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Initialize tools from config file</span>
</span></span><span class=line><span class=cl>    <span class=bp>cls</span><span class=o>.</span><span class=n>tokenizer</span> <span class=o>=</span> <span class=n>tokenizer</span>
</span></span><span class=line><span class=cl>    <span class=bp>cls</span><span class=o>.</span><span class=n>max_user_turns</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>multi_turn</span><span class=o>.</span><span class=n>max_user_turns</span>
</span></span><span class=line><span class=cl>    <span class=bp>cls</span><span class=o>.</span><span class=n>max_assistant_turns</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>multi_turn</span><span class=o>.</span><span class=n>max_assistant_turns</span>
</span></span><span class=line><span class=cl>    <span class=bp>cls</span><span class=o>.</span><span class=n>max_parallel_calls</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>multi_turn</span><span class=o>.</span><span class=n>max_parallel_calls</span>
</span></span><span class=line><span class=cl>    <span class=bp>cls</span><span class=o>.</span><span class=n>max_tool_response_length</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>multi_turn</span><span class=o>.</span><span class=n>max_tool_response_length</span>
</span></span><span class=line><span class=cl>    <span class=bp>cls</span><span class=o>.</span><span class=n>tool_response_truncate_side</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>multi_turn</span><span class=o>.</span><span class=n>tool_response_truncate_side</span>
</span></span><span class=line><span class=cl>    <span class=n>tool_config_path</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>multi_turn</span><span class=o>.</span><span class=n>tool_config_path</span>
</span></span><span class=line><span class=cl>    <span class=n>tool_list</span> <span class=o>=</span> <span class=n>initialize_tools_from_config</span><span class=p>(</span><span class=n>tool_config_path</span><span class=p>)</span> <span class=k>if</span> <span class=n>tool_config_path</span> <span class=k>else</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=bp>cls</span><span class=o>.</span><span class=n>tools</span> <span class=o>=</span> <span class=p>{</span><span class=n>tool</span><span class=o>.</span><span class=n>name</span><span class=p>:</span> <span class=n>tool</span> <span class=k>for</span> <span class=n>tool</span> <span class=ow>in</span> <span class=n>tool_list</span><span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=bp>cls</span><span class=o>.</span><span class=n>tool_schemas</span> <span class=o>=</span> <span class=p>[</span><span class=n>tool</span><span class=o>.</span><span class=n>tool_schema</span><span class=o>.</span><span class=n>model_dump</span><span class=p>(</span><span class=n>exclude_unset</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>exclude_none</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span> <span class=k>for</span> <span class=n>tool</span> <span class=ow>in</span> <span class=n>tool_list</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=bp>cls</span><span class=o>.</span><span class=n>tool_parser</span> <span class=o>=</span> <span class=bp>cls</span><span class=o>.</span><span class=n>get_tool_parser</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>multi_turn</span><span class=o>.</span><span class=n>format</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Initialized tools: </span><span class=si>{</span><span class=bp>cls</span><span class=o>.</span><span class=n>tools</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=bp>cls</span><span class=o>.</span><span class=n>prompt_length</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>prompt_length</span>
</span></span><span class=line><span class=cl>    <span class=bp>cls</span><span class=o>.</span><span class=n>response_length</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>response_length</span>
</span></span><span class=line><span class=cl>    <span class=bp>cls</span><span class=o>.</span><span class=n>system_prompt</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>apply_chat_template</span><span class=p>([{}],</span> <span class=n>add_generation_prompt</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>tokenize</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p><strong><code>run</code></strong></p><ul><li>和 <code>single_turn_agent_loop</code> 一样，对 prompts <code>apply_chat_template</code>；</li><li>初始化 <code>user_turns, assistant_turns</code>，进入 multi-turn 的 loop 循环，直到退出:<ul><li>向 <code>server_manager</code> 发送 <code>prompt_ids</code>，得到对应的 <code>response_ids</code>；将本轮返回的 <code>response_ids</code> append 到 <code>prompt_ids</code> 中，准备作为下一轮的输入，并且 <code>assistant_turns += 1</code></li><li>处理边界条件，比如 prompts 过长，没有 tool call 了，或者超出了 max turns；</li><li>异步执行 <code>_call_tool</code>：从 response 中 extract 出 Function Call，接着 <code>tool</code><strong><code>.</code></strong><code>execute(instance_id</code><strong><code>,</code></strong><code> tool_args)</code> 获得相应的 <code>tool_response</code>, 然后截断返回即可。具体的 <code>_call_tool</code> 会在后文分析。</li><li><code>tool_responses</code> 随后 <code>apply_chat_template</code> 得到 <code>tool_response_ids</code>，同样 append 到<code>prompt_ids</code> 内，然后 <code>user_turns += 1</code>，进入下一轮循环；</li></ul></li><li>退出 tool agent loop 循环后，构造 <code>AgentLoopOutput</code> 注意 num_turns=user_turns+assistant_turns +1，因为 prompt 也算一次 user turn</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span><span class=lnt>72
</span><span class=lnt>73
</span><span class=lnt>74
</span><span class=lnt>75
</span><span class=lnt>76
</span><span class=lnt>77
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=nd>@rollout_trace_op</span>
</span></span><span class=line><span class=cl><span class=k>async</span> <span class=k>def</span> <span class=nf>run</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>messages</span><span class=p>:</span> <span class=nb>list</span><span class=p>[</span><span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]],</span> <span class=n>sampling_params</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>])</span> <span class=o>-&gt;</span> <span class=n>AgentLoopOutput</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>metrics</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>    <span class=n>request_id</span> <span class=o>=</span> <span class=n>uuid4</span><span class=p>()</span><span class=o>.</span><span class=n>hex</span>
</span></span><span class=line><span class=cl>    <span class=n>prompt_ids</span> <span class=o>=</span> <span class=k>await</span> <span class=bp>self</span><span class=o>.</span><span class=n>loop</span><span class=o>.</span><span class=n>run_in_executor</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=k>lambda</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>apply_chat_template</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>messages</span><span class=p>,</span> <span class=n>tools</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>tool_schemas</span><span class=p>,</span> <span class=n>add_generation_prompt</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>tokenize</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl>        <span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>response_mask</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>user_turns</span><span class=p>,</span> <span class=n>assistant_turns</span> <span class=o>=</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=k>while</span> <span class=kc>True</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>simple_timer</span><span class=p>(</span><span class=s2>&#34;generate_sequences&#34;</span><span class=p>,</span> <span class=n>metrics</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>response_ids</span> <span class=o>=</span> <span class=k>await</span> <span class=bp>self</span><span class=o>.</span><span class=n>server_manager</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>request_id</span><span class=o>=</span><span class=n>request_id</span><span class=p>,</span> <span class=n>prompt_ids</span><span class=o>=</span><span class=n>prompt_ids</span><span class=p>,</span> <span class=n>sampling_params</span><span class=o>=</span><span class=n>sampling_params</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>prompt_ids</span> <span class=o>+=</span> <span class=n>response_ids</span>
</span></span><span class=line><span class=cl>        <span class=n>response_mask</span> <span class=o>+=</span> <span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>*</span> <span class=nb>len</span><span class=p>(</span><span class=n>response_ids</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>assistant_turns</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># reach max response length</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>response_mask</span><span class=p>)</span> <span class=o>&gt;=</span> <span class=bp>self</span><span class=o>.</span><span class=n>response_length</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>break</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># reach max assistant turns</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>max_assistant_turns</span> <span class=ow>and</span> <span class=n>assistant_turns</span> <span class=o>&gt;=</span> <span class=bp>self</span><span class=o>.</span><span class=n>max_assistant_turns</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>break</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># reach max user turns</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>max_user_turns</span> <span class=ow>and</span> <span class=n>user_turns</span> <span class=o>&gt;=</span> <span class=bp>self</span><span class=o>.</span><span class=n>max_user_turns</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>break</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># no tool calls</span>
</span></span><span class=line><span class=cl>        <span class=n>tool_calls</span> <span class=o>=</span> <span class=k>await</span> <span class=bp>self</span><span class=o>.</span><span class=n>tool_parser</span><span class=o>.</span><span class=n>extract_tool_calls</span><span class=p>(</span><span class=n>response_ids</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=ow>not</span> <span class=n>tool_calls</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>break</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># call tools</span>
</span></span><span class=line><span class=cl>        <span class=n>tasks</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>tool_call</span> <span class=ow>in</span> <span class=n>tool_calls</span><span class=p>[:</span> <span class=bp>self</span><span class=o>.</span><span class=n>max_parallel_calls</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>            <span class=n>tasks</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_call_tool</span><span class=p>(</span><span class=n>tool_call</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>simple_timer</span><span class=p>(</span><span class=s2>&#34;tool_calls&#34;</span><span class=p>,</span> <span class=n>metrics</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>tool_responses</span> <span class=o>=</span> <span class=k>await</span> <span class=n>asyncio</span><span class=o>.</span><span class=n>gather</span><span class=p>(</span><span class=o>*</span><span class=n>tasks</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>any</span><span class=p>(</span><span class=nb>isinstance</span><span class=p>(</span><span class=n>item</span><span class=p>,</span> <span class=ne>Exception</span><span class=p>)</span> <span class=k>for</span> <span class=n>item</span> <span class=ow>in</span> <span class=n>tool_responses</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=k>break</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># append tool_response_ids</span>
</span></span><span class=line><span class=cl>        <span class=n>tool_response_ids</span> <span class=o>=</span> <span class=k>await</span> <span class=bp>self</span><span class=o>.</span><span class=n>loop</span><span class=o>.</span><span class=n>run_in_executor</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=k>lambda</span> <span class=n>messages</span><span class=o>=</span><span class=n>tool_responses</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>apply_chat_template</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>messages</span><span class=p>,</span> <span class=n>add_generation_prompt</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>tokenize</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl>            <span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>tool_response_ids</span> <span class=o>=</span> <span class=n>tool_response_ids</span><span class=p>[</span><span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>system_prompt</span><span class=p>)</span> <span class=p>:]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># NOTE: last turn should not be user turn, or the EOS token reward</span>
</span></span><span class=line><span class=cl>        <span class=c1># can&#39;t be propagated to previous token in GAE.</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>response_mask</span><span class=p>)</span> <span class=o>+</span> <span class=nb>len</span><span class=p>(</span><span class=n>tool_response_ids</span><span class=p>)</span> <span class=o>&gt;=</span> <span class=bp>self</span><span class=o>.</span><span class=n>response_length</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>break</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>prompt_ids</span> <span class=o>+=</span> <span class=n>tool_response_ids</span>
</span></span><span class=line><span class=cl>        <span class=n>response_mask</span> <span class=o>+=</span> <span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=nb>len</span><span class=p>(</span><span class=n>tool_response_ids</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>user_turns</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>response_ids</span> <span class=o>=</span> <span class=n>prompt_ids</span><span class=p>[</span><span class=o>-</span><span class=nb>len</span><span class=p>(</span><span class=n>response_mask</span><span class=p>)</span> <span class=p>:]</span>
</span></span><span class=line><span class=cl>    <span class=n>prompt_ids</span> <span class=o>=</span> <span class=n>prompt_ids</span><span class=p>[:</span> <span class=nb>len</span><span class=p>(</span><span class=n>prompt_ids</span><span class=p>)</span> <span class=o>-</span> <span class=nb>len</span><span class=p>(</span><span class=n>response_mask</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>output</span> <span class=o>=</span> <span class=n>AgentLoopOutput</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>prompt_ids</span><span class=o>=</span><span class=n>prompt_ids</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>response_ids</span><span class=o>=</span><span class=n>response_ids</span><span class=p>[:</span> <span class=bp>self</span><span class=o>.</span><span class=n>response_length</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>response_mask</span><span class=o>=</span><span class=n>response_mask</span><span class=p>[:</span> <span class=bp>self</span><span class=o>.</span><span class=n>response_length</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>num_turns</span><span class=o>=</span><span class=n>user_turns</span> <span class=o>+</span> <span class=n>assistant_turns</span> <span class=o>+</span> <span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>metrics</span><span class=o>=</span><span class=n>metrics</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>output</span>
</span></span></code></pre></td></tr></table></div></div><p><strong><code>call_tool</code></strong></p><p>基于 tool list 内的 tool 来调用工具，例如前面 config 中配置的 <code>calc_gsm8k_reward</code>，从 tool parser 得到 arguments 就可以代入运算得到相应的<code>tool_response</code>。如果 tool 调用成功，则会释放 tool 占用的资源,，最后<code>tool_response</code>根据 <code>tool_response_truncate_side</code> 来做相应的截断。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Python data-lang=Python><span class=line><span class=cl><span class=k>async</span> <span class=k>def</span> <span class=nf>_call_tool</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>tool_call</span><span class=p>:</span> <span class=n>FunctionCall</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=nb>str</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Call tool and return tool response.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>tool</span><span class=p>,</span> <span class=n>instance_id</span> <span class=o>=</span> <span class=kc>None</span><span class=p>,</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>    <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># TODO: append malformed tool_call to the prompt: invalid function name or arguments</span>
</span></span><span class=line><span class=cl>        <span class=n>tool_name</span> <span class=o>=</span> <span class=n>tool_call</span><span class=o>.</span><span class=n>name</span>
</span></span><span class=line><span class=cl>        <span class=n>tool_args</span> <span class=o>=</span> <span class=n>json</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>tool_call</span><span class=o>.</span><span class=n>arguments</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>tool</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>tools</span><span class=p>[</span><span class=n>tool_name</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>instance_id</span> <span class=o>=</span> <span class=k>await</span> <span class=n>tool</span><span class=o>.</span><span class=n>create</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>tool_response</span><span class=p>,</span> <span class=n>_</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=k>await</span> <span class=n>tool</span><span class=o>.</span><span class=n>execute</span><span class=p>(</span><span class=n>instance_id</span><span class=p>,</span> <span class=n>tool_args</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>logger</span><span class=o>.</span><span class=n>exception</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Error when executing tool: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>e</span>
</span></span><span class=line><span class=cl>    <span class=k>finally</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>tool</span> <span class=ow>and</span> <span class=n>instance_id</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>await</span> <span class=n>tool</span><span class=o>.</span><span class=n>release</span><span class=p>(</span><span class=n>instance_id</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>tool_response</span><span class=p>)</span> <span class=o>&gt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>max_tool_response_length</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>tool_response_truncate_side</span> <span class=o>==</span> <span class=s2>&#34;left&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>tool_response</span> <span class=o>=</span> <span class=n>tool_response</span><span class=p>[:</span> <span class=bp>self</span><span class=o>.</span><span class=n>max_tool_response_length</span><span class=p>]</span> <span class=o>+</span> <span class=s2>&#34;...(truncated)&#34;</span>
</span></span><span class=line><span class=cl>        <span class=k>elif</span> <span class=bp>self</span><span class=o>.</span><span class=n>tool_response_truncate_side</span> <span class=o>==</span> <span class=s2>&#34;right&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>tool_response</span> <span class=o>=</span> <span class=s2>&#34;(truncated)...&#34;</span> <span class=o>+</span> <span class=n>tool_response</span><span class=p>[</span><span class=o>-</span><span class=bp>self</span><span class=o>.</span><span class=n>max_tool_response_length</span> <span class=p>:]</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>length</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>max_tool_response_length</span> <span class=o>//</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl>            <span class=n>tool_response</span> <span class=o>=</span> <span class=n>tool_response</span><span class=p>[:</span><span class=n>length</span><span class=p>]</span> <span class=o>+</span> <span class=s2>&#34;...(truncated)...&#34;</span> <span class=o>+</span> <span class=n>tool_response</span><span class=p>[</span><span class=o>-</span><span class=n>length</span><span class=p>:]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;tool&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=n>tool_response</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://pillumina.github.io/tags/framework/>Framework</a></li><li><a href=https://pillumina.github.io/tags/verl/>Verl</a></li><li><a href=https://pillumina.github.io/tags/sglang/>Sglang</a></li></ul><nav class=paginav><a class=prev href=https://pillumina.github.io/posts/aiinfra/10-verl-dataproto/><span class=title>« Prev</span><br><span>[VeRL] DataProto介绍</span>
</a><a class=next href=https://pillumina.github.io/posts/aiinfra/05-verl-params/><span class=title>Next »</span><br><span>[VeRL] 参数速览</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share [VeRL] AgentLoop源码走读 on x" href="https://x.com/intent/tweet/?text=%5bVeRL%5d%20AgentLoop%e6%ba%90%e7%a0%81%e8%b5%b0%e8%af%bb&amp;url=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f09-verl-agentloop%2f&amp;hashtags=framework%2cverl%2csglang"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [VeRL] AgentLoop源码走读 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f09-verl-agentloop%2f&amp;title=%5bVeRL%5d%20AgentLoop%e6%ba%90%e7%a0%81%e8%b5%b0%e8%af%bb&amp;summary=%5bVeRL%5d%20AgentLoop%e6%ba%90%e7%a0%81%e8%b5%b0%e8%af%bb&amp;source=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f09-verl-agentloop%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [VeRL] AgentLoop源码走读 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f09-verl-agentloop%2f&title=%5bVeRL%5d%20AgentLoop%e6%ba%90%e7%a0%81%e8%b5%b0%e8%af%bb"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [VeRL] AgentLoop源码走读 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f09-verl-agentloop%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [VeRL] AgentLoop源码走读 on whatsapp" href="https://api.whatsapp.com/send?text=%5bVeRL%5d%20AgentLoop%e6%ba%90%e7%a0%81%e8%b5%b0%e8%af%bb%20-%20https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f09-verl-agentloop%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [VeRL] AgentLoop源码走读 on telegram" href="https://telegram.me/share/url?text=%5bVeRL%5d%20AgentLoop%e6%ba%90%e7%a0%81%e8%b5%b0%e8%af%bb&amp;url=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f09-verl-agentloop%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [VeRL] AgentLoop源码走读 on ycombinator" href="https://news.ycombinator.com/submitlink?t=%5bVeRL%5d%20AgentLoop%e6%ba%90%e7%a0%81%e8%b5%b0%e8%af%bb&u=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f09-verl-agentloop%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul><div class=related-posts><div class=related-series><h3>同系列文章</h3><ul><li><a href=/posts/aiinfra/10-verl-dataproto/>[VeRL] DataProto介绍</a>
<span class=meta>2025-08-25
· 17 min read</span></li><li><a href=/posts/aiinfra/05-verl-params/>[VeRL] 参数速览</a>
<span class=meta>2025-08-14
· 6 min read</span></li><li><a href=/posts/aiinfra/08-verl-multiturn-2/>[VeRL] Multi-Turn RL训练源码走读（2）</a>
<span class=meta>2025-08-03
· 27 min read</span></li><li><a href=/posts/aiinfra/07-verl-multiturn-1/>[VeRL] Multi-Turn RL训练源码走读（1）</a>
<span class=meta>2025-08-03
· 27 min read</span></li></ul></div><div class=related-tags><h3>相关文章</h3><ul><li><a href=/posts/aiinfra/10-verl-dataproto/>[VeRL] DataProto介绍</a>
<span class=meta>2025-08-25
· 17 min read
· Tags: framework, verl</span></li><li><a href=/posts/aiinfra/05-verl-params/>[VeRL] 参数速览</a>
<span class=meta>2025-08-14
· 6 min read
· Tags: framework, verl</span></li><li><a href=/posts/aiinfra/06-sglang-backend/>[SGLang] 后端代码速览</a>
<span class=meta>2025-08-13
· 5 min read
· Tags: inference, sglang</span></li><li><a href=/posts/aiinfra/02-slime/>[RL4LLM] 异步RL框架: Slime</a>
<span class=meta>2025-08-07
· 15 min read
· Tags: framework, LLM, RL</span></li></ul></div></div></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://pillumina.github.io/>CctoctoFX</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg></a><div class=reading-progress-bar></div><script src=https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js></script><script>document.addEventListener("DOMContentLoaded",function(){const t=document.querySelector(".reading-progress-bar");if(!t)return;const n=document.querySelector(".post-single");if(!n)return;function s(){const e=n.getBoundingClientRect(),s=e.height,o=window.innerHeight,i=window.scrollY||window.pageYOffset,a=i/(s-o)*100;t.style.width=`${Math.min(100,Math.max(0,a))}%`}let e=!1;window.addEventListener("scroll",function(){e||(window.requestAnimationFrame(function(){s(),e=!1}),e=!0)}),s()}),document.addEventListener("DOMContentLoaded",function(){mediumZoom("article img:not(.nozoom)",{margin:24,background:"var(--theme)",scrollOffset:0})})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>