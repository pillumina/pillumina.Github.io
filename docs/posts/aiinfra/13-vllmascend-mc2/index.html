<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[vLLM-Ascend] MC2技术深度解析：从MoE架构到通信融合优化 | CctoctoFX</title><meta name=keywords content="vllm-ascend,MoE"><meta name=description content='
源码分析依赖vllm-ascend在2025/9/20号的main分支，阅读请注意时效性。
阅读建议:

了解MoE基本架构和关键推导
初步了解集合通信各原语的含义
对通算掩盖这类性能优化有基础的了解

概述
MC2（Merged Compute and Communication）是vLLM Ascend项目中针对昇腾NPU优化的核心技术，专门解决MoE（Mixture of Experts）模型在专家并行推理中的通信瓶颈问题。本文档从MoE架构基础出发，深入分析MC2的设计原理、技术实现和性能优化。
1. MoE架构基础与挑战
1.1 MoE模型基本原理
1.1.1 什么是MoE？
**MoE(Mixture of Experts)**是一种神经网络架构，通过将模型参数分散到多个"专家"网络中，根据输入动态选择部分专家进行计算。这种架构在保持高模型容量的同时，降低了计算复杂度。
1.1.2 MoE的数学表达
给定输入 $\mathbf{x} \in \mathbb{R}^{d}$，MoE层的输出可以表示为：
$$
\mathbf{y} = \text{MoE}(\mathbf{x}) = \sum_{i=1}^{N} g_i(\mathbf{x}) \cdot E_i(\mathbf{x})
$$其中：

$N$ 是专家总数
$E_i(\cdot)$ 是第 $i$ 个专家网络
$g_i(\mathbf{x})$ 是门控网络对专家 $i$ 的权重

1.1.3 稀疏激活机制
为了提高效率，MoE通常采用稀疏激活机制，只选择 Top-K 个专家：
$$
\mathbf{y} = \sum_{i \in \text{Top-K}(\mathbf{x})} \frac{g_i(\mathbf{x})}{\sum_{j \in \text{Top-K}(\mathbf{x})} g_j(\mathbf{x})} \cdot E_i(\mathbf{x})
$$详见附录A.1 MoE输出公式推导
其中 $\text{Top-K}(\mathbf{x})$ 表示根据门控权重选择的 Top-K 个专家索引。'><meta name=author content="Me"><link rel=canonical href=https://pillumina.github.io/posts/aiinfra/13-vllmascend-mc2/><link crossorigin=anonymous href=/assets/css/stylesheet.9d388901283682bb45dd422fcaa0d0a2054a3c8ff47c9cc6b2baab15508b1b90.css integrity="sha256-nTiJASg2grtF3UIvyqDQogVKPI/0fJzGsrqrFVCLG5A=" rel="preload stylesheet" as=style><link rel=icon href=https://pillumina.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://pillumina.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://pillumina.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://pillumina.github.io/apple-touch-icon.png><link rel=mask-icon href=https://pillumina.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://pillumina.github.io/posts/aiinfra/13-vllmascend-mc2/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js crossorigin=anonymous></script><script>(function(){function t(){return document.querySelector(".post-content")||document.querySelector(".post-single")||document.body}function n(e){return/\$\$[\s\S]+?\$\$|\\\(|\\\)|\\\[|\\\]/.test(e)}function s(e){if(window.__mathjaxLoaded)return;window.__mathjaxLoaded=!0,window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code","tt"],ignoreHtmlClass:"no-math"}};var t=document.createElement("script");t.src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js",t.defer=!0,t.onload=function(){window.MathJax&&window.MathJax.typesetPromise&&window.MathJax.typesetPromise([e]).catch(function(e){console.warn("MathJax typeset error",e)})},document.head.appendChild(t)}function e(){try{if(typeof renderMathInElement=="function"){const e=t();renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\[",right:"\\]",display:!0},{left:"\\(",right:"\\)",display:!1}],throwOnError:!1,strict:!1,trust:!0,ignoredTags:["script","noscript","style","textarea","pre","code","tt"],ignoredClasses:["no-math"],macros:{"\\boldsymbol":"\\mathbf{#1}","\\bm":"\\mathbf{#1}"}}),setTimeout(function(){n(e.innerHTML)&&s(e)},200)}}catch(e){console.warn("KaTeX render error:",e)}}document.addEventListener("DOMContentLoaded",function(){e(),setTimeout(e,200)}),window.addEventListener("load",function(){setTimeout(e,0)})})()</script><script src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script><script>const config={startOnLoad:!0,theme:"neutral",themeVariables:{lineColor:"#0f0f0f"},flowchart:{useMaxWidth:!1,htmlLabels:!0}};mermaid.initialize(config),window.onload=()=>{window.mermaid.init(0[0],document.querySelectorAll(".language-mermaid"))}</script><link rel=stylesheet href=/css/custom.min.de5dbc794941fcaf859be4ddf58c8ebc96bd8b6f47c4b2b10a1d309a8ccd26f1.css integrity="sha256-3l28eUlB/K+Fm+Td9YyOvJa9i29HxLKxCh0wmozNJvE="><script>document.addEventListener("DOMContentLoaded",function(){const t=document.querySelectorAll("h1[id], h2[id], h3[id], h4[id], h5[id], h6[id]"),n=document.querySelectorAll(".toc a");if(t.length===0||n.length===0)return;const s={};t.forEach(e=>{s[e.id]=e.offsetTop});function i(){const t=window.scrollY+100;let e="";for(const[n,o]of Object.entries(s))if(t>=o)e=n;else break;return e}function o(){const e=i();if(n.forEach(e=>{e.classList.remove("active")}),e){const t=document.querySelector(`.toc a[href="#${e}"]`);t&&t.classList.add("active")}}let e=!1;window.addEventListener("scroll",function(){e||(window.requestAnimationFrame(function(){o(),e=!1}),e=!0)}),o()})</script><meta property="og:url" content="https://pillumina.github.io/posts/aiinfra/13-vllmascend-mc2/"><meta property="og:site_name" content="CctoctoFX"><meta property="og:title" content="[vLLM-Ascend] MC2技术深度解析：从MoE架构到通信融合优化"><meta property="og:description" content=' 源码分析依赖vllm-ascend在2025/9/20号的main分支，阅读请注意时效性。
阅读建议:
了解MoE基本架构和关键推导 初步了解集合通信各原语的含义 对通算掩盖这类性能优化有基础的了解 概述 MC2（Merged Compute and Communication）是vLLM Ascend项目中针对昇腾NPU优化的核心技术，专门解决MoE（Mixture of Experts）模型在专家并行推理中的通信瓶颈问题。本文档从MoE架构基础出发，深入分析MC2的设计原理、技术实现和性能优化。
1. MoE架构基础与挑战 1.1 MoE模型基本原理 1.1.1 什么是MoE？ **MoE(Mixture of Experts)**是一种神经网络架构，通过将模型参数分散到多个"专家"网络中，根据输入动态选择部分专家进行计算。这种架构在保持高模型容量的同时，降低了计算复杂度。
1.1.2 MoE的数学表达 给定输入 $\mathbf{x} \in \mathbb{R}^{d}$，MoE层的输出可以表示为：
$$ \mathbf{y} = \text{MoE}(\mathbf{x}) = \sum_{i=1}^{N} g_i(\mathbf{x}) \cdot E_i(\mathbf{x}) $$其中：
$N$ 是专家总数 $E_i(\cdot)$ 是第 $i$ 个专家网络 $g_i(\mathbf{x})$ 是门控网络对专家 $i$ 的权重 1.1.3 稀疏激活机制 为了提高效率，MoE通常采用稀疏激活机制，只选择 Top-K 个专家：
$$ \mathbf{y} = \sum_{i \in \text{Top-K}(\mathbf{x})} \frac{g_i(\mathbf{x})}{\sum_{j \in \text{Top-K}(\mathbf{x})} g_j(\mathbf{x})} \cdot E_i(\mathbf{x}) $$详见附录A.1 MoE输出公式推导
其中 $\text{Top-K}(\mathbf{x})$ 表示根据门控权重选择的 Top-K 个专家索引。'><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-09-20T11:30:12+08:00"><meta property="article:modified_time" content="2025-09-20T11:30:12+08:00"><meta property="article:tag" content="Vllm-Ascend"><meta property="article:tag" content="MoE"><meta property="og:image" content="https://pillumina.github.io/imgs/icon_head.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://pillumina.github.io/imgs/icon_head.png"><meta name=twitter:title content="[vLLM-Ascend] MC2技术深度解析：从MoE架构到通信融合优化"><meta name=twitter:description content='
源码分析依赖vllm-ascend在2025/9/20号的main分支，阅读请注意时效性。
阅读建议:

了解MoE基本架构和关键推导
初步了解集合通信各原语的含义
对通算掩盖这类性能优化有基础的了解

概述
MC2（Merged Compute and Communication）是vLLM Ascend项目中针对昇腾NPU优化的核心技术，专门解决MoE（Mixture of Experts）模型在专家并行推理中的通信瓶颈问题。本文档从MoE架构基础出发，深入分析MC2的设计原理、技术实现和性能优化。
1. MoE架构基础与挑战
1.1 MoE模型基本原理
1.1.1 什么是MoE？
**MoE(Mixture of Experts)**是一种神经网络架构，通过将模型参数分散到多个"专家"网络中，根据输入动态选择部分专家进行计算。这种架构在保持高模型容量的同时，降低了计算复杂度。
1.1.2 MoE的数学表达
给定输入 $\mathbf{x} \in \mathbb{R}^{d}$，MoE层的输出可以表示为：
$$
\mathbf{y} = \text{MoE}(\mathbf{x}) = \sum_{i=1}^{N} g_i(\mathbf{x}) \cdot E_i(\mathbf{x})
$$其中：

$N$ 是专家总数
$E_i(\cdot)$ 是第 $i$ 个专家网络
$g_i(\mathbf{x})$ 是门控网络对专家 $i$ 的权重

1.1.3 稀疏激活机制
为了提高效率，MoE通常采用稀疏激活机制，只选择 Top-K 个专家：
$$
\mathbf{y} = \sum_{i \in \text{Top-K}(\mathbf{x})} \frac{g_i(\mathbf{x})}{\sum_{j \in \text{Top-K}(\mathbf{x})} g_j(\mathbf{x})} \cdot E_i(\mathbf{x})
$$详见附录A.1 MoE输出公式推导
其中 $\text{Top-K}(\mathbf{x})$ 表示根据门控权重选择的 Top-K 个专家索引。'><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://pillumina.github.io/posts/"},{"@type":"ListItem","position":2,"name":"AI Infra","item":"https://pillumina.github.io/posts/aiinfra/"},{"@type":"ListItem","position":3,"name":"[vLLM-Ascend] MC2技术深度解析：从MoE架构到通信融合优化","item":"https://pillumina.github.io/posts/aiinfra/13-vllmascend-mc2/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[vLLM-Ascend] MC2技术深度解析：从MoE架构到通信融合优化","name":"[vLLM-Ascend] MC2技术深度解析：从MoE架构到通信融合优化","description":" 源码分析依赖vllm-ascend在2025/9/20号的main分支，阅读请注意时效性。\n阅读建议:\n了解MoE基本架构和关键推导 初步了解集合通信各原语的含义 对通算掩盖这类性能优化有基础的了解 概述 MC2（Merged Compute and Communication）是vLLM Ascend项目中针对昇腾NPU优化的核心技术，专门解决MoE（Mixture of Experts）模型在专家并行推理中的通信瓶颈问题。本文档从MoE架构基础出发，深入分析MC2的设计原理、技术实现和性能优化。\n1. MoE架构基础与挑战 1.1 MoE模型基本原理 1.1.1 什么是MoE？ **MoE(Mixture of Experts)**是一种神经网络架构，通过将模型参数分散到多个\u0026quot;专家\u0026quot;网络中，根据输入动态选择部分专家进行计算。这种架构在保持高模型容量的同时，降低了计算复杂度。\n1.1.2 MoE的数学表达 给定输入 $\\mathbf{x} \\in \\mathbb{R}^{d}$，MoE层的输出可以表示为：\n$$ \\mathbf{y} = \\text{MoE}(\\mathbf{x}) = \\sum_{i=1}^{N} g_i(\\mathbf{x}) \\cdot E_i(\\mathbf{x}) $$其中：\n$N$ 是专家总数 $E_i(\\cdot)$ 是第 $i$ 个专家网络 $g_i(\\mathbf{x})$ 是门控网络对专家 $i$ 的权重 1.1.3 稀疏激活机制 为了提高效率，MoE通常采用稀疏激活机制，只选择 Top-K 个专家：\n$$ \\mathbf{y} = \\sum_{i \\in \\text{Top-K}(\\mathbf{x})} \\frac{g_i(\\mathbf{x})}{\\sum_{j \\in \\text{Top-K}(\\mathbf{x})} g_j(\\mathbf{x})} \\cdot E_i(\\mathbf{x}) $$详见附录A.1 MoE输出公式推导\n其中 $\\text{Top-K}(\\mathbf{x})$ 表示根据门控权重选择的 Top-K 个专家索引。\n","keywords":["vllm-ascend","MoE"],"articleBody":" 源码分析依赖vllm-ascend在2025/9/20号的main分支，阅读请注意时效性。\n阅读建议:\n了解MoE基本架构和关键推导 初步了解集合通信各原语的含义 对通算掩盖这类性能优化有基础的了解 概述 MC2（Merged Compute and Communication）是vLLM Ascend项目中针对昇腾NPU优化的核心技术，专门解决MoE（Mixture of Experts）模型在专家并行推理中的通信瓶颈问题。本文档从MoE架构基础出发，深入分析MC2的设计原理、技术实现和性能优化。\n1. MoE架构基础与挑战 1.1 MoE模型基本原理 1.1.1 什么是MoE？ **MoE(Mixture of Experts)**是一种神经网络架构，通过将模型参数分散到多个\"专家\"网络中，根据输入动态选择部分专家进行计算。这种架构在保持高模型容量的同时，降低了计算复杂度。\n1.1.2 MoE的数学表达 给定输入 $\\mathbf{x} \\in \\mathbb{R}^{d}$，MoE层的输出可以表示为：\n$$ \\mathbf{y} = \\text{MoE}(\\mathbf{x}) = \\sum_{i=1}^{N} g_i(\\mathbf{x}) \\cdot E_i(\\mathbf{x}) $$其中：\n$N$ 是专家总数 $E_i(\\cdot)$ 是第 $i$ 个专家网络 $g_i(\\mathbf{x})$ 是门控网络对专家 $i$ 的权重 1.1.3 稀疏激活机制 为了提高效率，MoE通常采用稀疏激活机制，只选择 Top-K 个专家：\n$$ \\mathbf{y} = \\sum_{i \\in \\text{Top-K}(\\mathbf{x})} \\frac{g_i(\\mathbf{x})}{\\sum_{j \\in \\text{Top-K}(\\mathbf{x})} g_j(\\mathbf{x})} \\cdot E_i(\\mathbf{x}) $$详见附录A.1 MoE输出公式推导\n其中 $\\text{Top-K}(\\mathbf{x})$ 表示根据门控权重选择的 Top-K 个专家索引。\n1.2 MoE的并行计算范式 1.2.1 专家并行（Expert Parallelism） 当专家数量很大时，需要将专家分布到多个计算设备上：\n$$ E_i \\rightarrow \\text{Device}_{(i \\bmod P)} $$其中 $P$ 是设备数量。这带来了两个核心问题：\nToken-Expert映射：需要将token路由到正确的专家设备 结果聚合：需要从各个专家设备收集结果 1.2.2 通信复杂度分析 对于批次大小 $B$，序列长度 $L$，专家数量 $N$，设备数量 $P$，通信复杂度为：\n传统All-to-All方法：\n$$ C_{\\text{all2all}} = O\\left(B \\cdot L \\cdot K \\cdot \\frac{\\log P}{P}\\right) $$详见附录A.9 传统All-to-All通信复杂度推导\n其中 $K$ 是每个token选择的专家数量。\n1.3 MoE通信瓶颈的本质问题 1.3.1 负载不均衡 专家选择的不确定性导致负载分布不均：\n$$ \\text{Load}_i = \\sum_{j=1}^{B \\cdot L} \\mathbb{I}[i \\in \\text{Top-K}(\\mathbf{x}_j)] $$其中 $\\mathbb{I}[\\cdot]$ 是指示函数，$\\text{Load}_i$ 的方差很大。\n1.3.2 通信同步开销 传统方法中，计算和通信串行执行：\n$$ T_{\\text{total}} = T_{\\text{compute}} + T_{\\text{communicate}} + T_{\\text{sync}} $$1.3.3 内存碎片化 动态路由导致内存访问模式不规则，缓存命中率低。\n1.4 MC2的设计动机 基于上述挑战，MC2的核心设计动机是：\n计算通信融合：打破计算和通信的界限 稀疏通信优化：利用MoE的稀疏性特性 硬件协同设计：深度结合昇腾NPU架构 动态负载均衡：自适应优化资源分配 2. MC2技术原理深度分析 2.1 MC2的核心思想 2.1.1 计算通信重叠 MC2的核心创新在于将计算和通信操作在时间和空间上重叠：\n$$ T_{\\text{MC2}} = \\max(T_{\\text{compute}}, T_{\\text{communicate}}) + T_{\\text{overlap\\_sync}} $$详见附录A.2 MC2延迟模型推导\n相比传统方法的改进：\n$$ \\text{Speedup} = \\frac{T_{\\text{compute}} + T_{\\text{communicate}} + T_{\\text{sync}}}{\\max(T_{\\text{compute}}, T_{\\text{communicate}}) + T_{\\text{overlap\\_sync}}} $$详见附录A.3 性能提升比推导\n2.1.2 稀疏通信原理 MC2利用MoE的稀疏性，只传输活跃的token-expert对：\n$$ \\text{ActiveRatio} = \\frac{K \\cdot B \\cdot L}{N \\cdot B \\cdot L} = \\frac{K}{N} \\ll 1 $$通过 mc2_mask 机制实现：\n$$ \\text{mask}_i = \\mathbb{I}[\\exists j: \\text{expert}_j \\text{ is active on device}_i] $$2.2 MC2的系统架构 2.2.1 整体架构设计 MC2采用分层架构，包含以下核心层：\n1 2 3 4 5 6 7 8 9 # vllm_ascend/ops/moe/moe_comm_method.py class MC2CommImpl(MoECommMethod): \"\"\" MC2通信方法：计算通信融合的MoE专家并行实现 核心创新： 1. 计算通信重叠执行 2. 稀疏通信优化 3. 硬件原生支持 \"\"\" 2.2.2 关键组件详解 TokenDispatcherWithMC2：\n1 2 3 4 5 6 7 8 9 # vllm_ascend/ops/moe/token_dispatcher.py class TokenDispatcherWithMC2(MoETokenDispatcher): \"\"\" MC2专用令牌分发器 功能： 1. 动态token到专家映射 2. 稀疏通信掩码管理 3. 异步执行流控制 \"\"\" FusedMoEPrepareAndFinalizeWithMC2：\n1 2 3 4 5 6 7 8 9 # vllm_ascend/ops/moe/fused_moe_prepare_and_finalize.py class FusedMoEPrepareAndFinalizeWithMC2(FusedMoEPrepareAndFinalize): \"\"\" MC2数据准备和结果处理 功能： 1. 数据对齐和填充 2. mc2_mask管理 3. 跨设备数据同步 \"\"\" 2.3 MC2的执行流程 2.3.1 执行阶段分析 MC2的执行分为三个关键阶段：\n阶段1：Token分发\n1 2 3 4 5 6 7 8 9 10 # vllm_ascend/ops/moe/token_dispatcher.py:180-190 def token_dispatch(self, hidden_states, topk_weights, topk_ids, **kwargs): # 1. 生成MC2通信参数 kwargs_mc2 = self.get_dispatch_mc2_kwargs(...) # 2. 调用硬件原生命令 self.output = torch_npu.npu_moe_distribute_dispatch_v2(**kwargs_mc2) # 3. 异步执行：计算和通信并行 # comm_stream.wait_stream(torch.npu.current_stream()) 阶段2：专家计算\n1 2 3 4 5 # 在通信的同时进行专家计算 if shared_experts is not None: # 共享专家预取 - 利用通信时间进行数据准备 share_up_out, _ = shared_experts.gate_up_proj( (quantized_x_for_share, dynamic_scale_for_share)) 阶段3：结果合并\n1 2 3 4 5 6 # vllm_ascend/ops/moe/token_dispatcher.py:266-273 def token_combine(self, hidden_states, bias=None): kwargs_mc2 = self.get_combine_mc_kwargs(hidden_states) # 硬件级结果合并 hidden_states = torch_npu.npu_moe_distribute_combine_v2(**kwargs_mc2) 2.3.2 动态选择机制 MC2根据运行时条件动态选择最优通信策略：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # vllm_ascend/worker/model_runner_v1.py:336-356 def _select_moe_comm_method(self, num_tokens: int, with_prefill: bool) -\u003e str: \"\"\" MC2动态选择算法： 1. 检查专家并行启用状态 2. 根据芯片版本选择优化策略 3. 基于token数量选择通信方法 \"\"\" if not self.parallel_config.enable_expert_parallel: return \"allgather\" # MC2专为专家并行设计 if get_ascend_config().soc_version == AscendSocVersion.A2: # A2芯片：MC2 vs All-Gather return \"mc2\" if num_tokens \u003c= 512 and world_size \u003e= 16 else \"allgather\" else: # A3芯片：MC2 vs All-to-All return \"mc2\" if num_tokens \u003c= 512 else \"alltoall\" 2.4 MC2的关键优化技术 2.4.1 稀疏通信优化 mc2_mask机制：\n1 2 3 4 5 # vllm_ascend/ascend_forward_context.py:640-655 # 动态生成稀疏通信掩码 mc2_mask = torch.zeros(padded_num_tokens, dtype=torch.bool) mc2_mask[:num_actual_tokens] = True # 只标记活跃token mc2_mask[num_actual_tokens:] = False # 无效token不参与通信 容量管理策略：\n固定容量：512 tokens/rank的上限 动态调整：根据实际token数量调整掩码 内存复用：预分配固定大小缓冲区 2.4.2 硬件指令优化 MC2深度结合昇腾NPU的硬件特性：\n专用指令集：\nnpu_moe_distribute_dispatch_v2：高性能token分发 npu_moe_distribute_combine_v2：高效结果合并 HCCL：高带宽通信库 指令级优化：\n零拷贝操作：减少内存拷贝开销 流水线执行：提高指令级并行度 缓存友好访问：优化数据局部性 3. MC2性能理论分析 3.1 通信延迟理论模型 3.1.1 传统MoE通信延迟 对于传统All-to-All通信，延迟模型为：\n$$ T_{\\text{traditional}} = T_{\\alpha} + T_{\\beta} \\cdot \\frac{K \\cdot B \\cdot L \\cdot d}{P} + T_{\\text{compute}} + T_{\\text{sync}} $$详见附录A.6传统MoE通信延迟推导\n其中：\n$T_{\\alpha}$：通信启动延迟 $T_{\\beta}$：通信带宽倒数（每字节传输时间） $d$：数据维度（hidden size） $P$：设备数量 3.1.2 MC2通信延迟 MC2通过计算通信重叠和稀疏通信优化：\n$$ T_{\\text{MC2}} = \\max\\left(T_{\\alpha} + T_{\\beta} \\cdot \\frac{K \\cdot B \\cdot L \\cdot d}{P \\cdot \\text{SparsityFactor}}, T_{\\text{compute}}\\right) + T_{\\text{overlap\\_sync}} $$详见附录A.7 MC2通信延迟推导\n其中 $\\text{SparsityFactor} \\geq 1$ 是稀疏因子。\n3.1.3 性能提升分析 MC2的理论性能提升：\n$$ \\text{Speedup} = \\frac{T_{\\text{traditional}}}{T_{\\text{MC2}}} = \\frac{T_{\\alpha} + T_{\\beta} \\cdot \\frac{KBLd}{P} + T_{\\text{compute}} + T_{\\text{sync}}}{\\max\\left(T_{\\alpha} + T_{\\beta} \\cdot \\frac{KBLd}{P \\cdot S}, T_{\\text{compute}}\\right) + T_{\\text{overlap\\_sync}}} $$详见附录A.8 MC2性能提升理论推导\n3.2 内存效率分析 3.2.1 内存占用模型 传统方法内存占用：\n$$ M_{\\text{traditional}} = O(B \\cdot L \\cdot d + N \\cdot d^2) $$MC2内存占用：\n$$ M_{\\text{MC2}} = O(\\min(B \\cdot L, C) \\cdot d + \\frac{N}{P} \\cdot d^2) $$详见附录A.10 内存占用模型推导\n其中 $C = 512$ 是MC2的容量限制。\n3.2.2 内存节省比例 $$ \\text{MemorySaving} = 1 - \\frac{M_{\\text{MC2}}}{M_{\\text{traditional}}} = 1 - \\frac{\\min(BL, C) + \\frac{N}{P} \\cdot d}{BL + N \\cdot d} $$当 $BL \u003e C$ 时：\n$$ \\text{MemorySaving} \\approx 1 - \\frac{C}{BL} \\quad \\text{(当 } N \\cdot d \\ll BL \\text{)} $$详见附录A.4内存节省比例推导\n3.3 带宽利用率分析 3.3.1 有效通信带宽 传统方法带宽利用率：\n$$ \\eta_{\\text{traditional}} = \\frac{K \\cdot B \\cdot L \\cdot d}{P \\cdot T_{\\text{traditional}}} $$MC2带宽利用率：\n$$ \\eta_{\\text{MC2}} = \\frac{K \\cdot B \\cdot L \\cdot d}{P \\cdot T_{\\text{MC2}}} $$3.3.2 带宽效率提升 $$ \\text{BandwidthEfficiency} = \\frac{\\eta_{\\text{MC2}}}{\\eta_{\\text{traditional}}} = \\frac{T_{\\text{traditional}}}{T_{\\text{MC2}}} $$详见附录A.5带宽效率推导\n3.4 扩展性分析 3.4.1 强扩展性 固定问题规模，增加设备数量：\n$$ S_{\\text{strong}}(P) = \\frac{T(1)}{T(P)} $$MC2的强扩展性优于传统方法，因为通信开销增长更慢。\n3.4.2 弱扩展性 固定每设备计算量，增加总问题规模：\n$$ S_{\\text{weak}}(P) = \\frac{\\text{Throughput}(P)}{\\text{Throughput}(1)} $$MC2的弱扩展性优势明显，因为通信开销与计算量增长不成正比。\n4. MC2实现细节深度解析 4.1 核心数据结构 4.1.1 MC2上下文管理 1 2 3 4 5 6 7 8 # vllm_ascend/ascend_forward_context.py class AscendForwardContext: \"\"\"MC2专用的前向计算上下文\"\"\" def __init__(self): self.mc2_tokens_capacity = 512 # MC2容量限制 self.reserved_mc2_mask = None # 稀疏通信掩码 self.moe_comm_method_name = None # 通信方法标识 4.1.2 专家映射机制 1 2 3 4 # 专家映射逻辑 expert_map = torch.full((num_experts,), -1, dtype=torch.long) for i in range(num_local_experts): expert_map[global_expert_ids[i]] = i # 全局专家到本地专家的映射 4.2 关键算法实现 4.2.1 Token-Expert路由算法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # vllm_ascend/ops/moe/token_dispatcher.py def _token_expert_routing(self, hidden_states, topk_weights, topk_ids): \"\"\" Token-Expert路由算法： 1. 根据专家ID映射token到设备 2. 生成稀疏通信掩码 3. 优化数据布局以提高缓存命中率 \"\"\" # 生成token索引 token_indices = torch.arange(num_tokens, device=device) token_indices = token_indices.unsqueeze(1).expand(-1, top_k).reshape(-1) # 映射到本地专家 local_experts = expert_map[topk_ids.view(-1)] # 过滤无效的token-expert对 valid_mask = local_experts != -1 filtered_weights = torch.where(valid_mask, topk_weights.view(-1), torch.zeros_like(topk_weights.view(-1))) return filtered_weights, local_experts, valid_mask 4.2.2 动态负载均衡 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 def _dynamic_load_balancing(self, expert_token_counts): \"\"\" 动态负载均衡算法： 1. 监控各专家负载 2. 动态调整token分配 3. 优化资源利用率 \"\"\" # 计算负载标准差 load_std = torch.std(expert_token_counts.float()) load_mean = torch.mean(expert_token_counts.float()) # 负载不均衡度 load_imbalance = load_std / (load_mean + 1e-6) # 动态调整策略 if load_imbalance \u003e threshold: # 触发负载重平衡 self._trigger_load_rebalance(expert_token_counts) 4.3 MC2集合通信实现深度剖析 4.3.1 MC2通信机制架构 MC2在集合通信层面对传统All-to-All和All-Gather进行了深度优化，核心在于稀疏通信和计算通信重叠。让我们从底层实现角度分析这些通信机制。\nMC2 vs 传统通信架构对比：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 # 传统通信架构（串行执行） def traditional_moe_communication(hidden_states, topk_ids, topk_weights): # Step 1: 完整的token-expert映射 full_mapping = create_full_token_expert_mapping(hidden_states, topk_ids) # Step 2: All-to-All通信（传输全部数据） comm_result = all_to_all_communication(full_mapping) # Step 3: 专家计算 expert_results = expert_computation(comm_result) # Step 4: All-to-All结果收集 final_result = all_to_all_collection(expert_results) return final_result # MC2通信架构（并行+稀疏） def mc2_moe_communication(hidden_states, topk_ids, topk_weights): # Step 1: 生成mc2_mask（稀疏通信掩码） mc2_mask = create_mc2_mask(hidden_states.shape[0]) # Step 2: 启动稀疏通信（立即返回，不阻塞） comm_future = torch_npu.npu_moe_distribute_dispatch_v2( x=hidden_states, expert_ids=topk_ids, expert_scales=topk_weights, x_active_mask=mc2_mask, # 关键：只传输活跃token group_ep=mc2_group_name ) # Step 3: 计算通信重叠执行 shared_expert_result = compute_shared_experts_async() # 利用通信时间 # Step 4: 等待通信完成 distributed_result = comm_future.wait() # Step 5: 硬件级结果合并 final_result = torch_npu.npu_moe_distribute_combine_v2( expand_x=distributed_result, x_active_mask=mc2_mask ) return final_result 4.3.2 All-to-All通信实现深度剖析 位置： vllm_ascend/ops/moe/token_dispatcher.py:452-708\nAll-to-All是MC2的备选方案，主要实现步骤包括：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 class TokenDispatcherWithAll2AllV(MoETokenDispatcher): def token_dispatch(self, hidden_states, topk_weights, topk_ids, **kwargs): \"\"\" All-to-All通信实现详细步骤： 1. Token-Expert映射统计 2. 数据重排和分区 3. 异步All-to-All通信 4. 结果重组 \"\"\" # === Step 1: Token-Expert映射分析 === # 统计每个专家需要处理的token数量 num_local_tokens_per_expert = torch.histc( topk_ids, bins=self.num_experts, min=0, max=self.num_experts ) \"\"\" 示例数据变换过程： 输入: topk_ids = [[2, 5, 8, 12], [1, 3, 7, 9], [4, 6, 10, 11]] 专家范围: 0-15 (16个专家) num_local_tokens_per_expert = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0] 专家0: 1个token, 专家1: 1个token, ..., 专家11: 1个token, 专家12-15: 0个token \"\"\" # === Step 2: 计算通信分区大小 === # 将专家分布到不同的设备上 ep_size = self.ep_size # 专家并行度 num_local_experts = self.num_local_experts # 计算每个设备的输入/输出大小 self.input_splits = num_local_tokens_per_expert.reshape( ep_size, num_local_experts ).sum(axis=1) \"\"\" 示例 (4个设备，每个设备4个专家): input_splits = [4, 4, 4, 4] # 每个设备处理4个token \"\"\" # === Step 3: Token置换和重排 === # 使用NPU优化的token置换，将token按照专家ID重新排列 permutated_local_input_tokens, reversed_local_input_permutation_mapping = ( torch_npu.npu_moe_token_permute( tokens=hidden_states, indices=topk_ids, num_experts=global_num_experts, num_local_experts=num_local_experts, expert_offset=first_expert_idx, quant_mode=1 if self.with_quant else -1, ) ) \"\"\" 数据变换过程: 输入hidden_states: [12, hidden_size] (12个token) topk_ids: [12, 4] (每个token选择4个专家) 置换后permutated_local_input_tokens: [12, hidden_size] 但现在token按照专家ID排序，便于后续通信 \"\"\" # === Step 4: 异步All-to-All通信 === # 调用异步All-to-All通信 input_, a2a_out, handle = async_all_to_all( input_=permutated_local_input_tokens, output_split_sizes=self.output_splits, input_split_sizes=self.input_splits, group=self.ep_group ) \"\"\" All-to-All通信数据流: Device 0: [4 tokens] ──────┐ ├─── All-to-All ────\u003e [4 tokens from all devices] Device 1: [4 tokens] ──────┘ 通信后每个设备收到来自所有设备的token，这些token对应本地的专家 \"\"\" # === Step 5: 等待通信完成 === if handle is not None: handle.wait() # === Step 6: 重组结果 === # 将通信结果按照专家进行分组 grouped_hidden_states = a2a_out.split(self.output_splits) expert_tokens_list = [] for i, hidden_states_part in enumerate(grouped_hidden_states): # 为每个专家创建token列表 expert_tokens = torch.empty( hidden_states_part.shape[0] * self.top_k, dtype=torch.int32, device=hidden_states_part.device ) expert_tokens_list.append(expert_tokens) return { \"hidden_states\": a2a_out, \"group_list\": expert_tokens_list, \"group_list_type\": 0, # count模式 } 核心特点：\n使用华为HCCL库进行高效通信 异步执行避免阻塞计算线程 数据重排优化通信效率 支持不等分数据传输 4.3.3 All-Gather通信实现深度剖析 位置： vllm_ascend/ops/moe/token_dispatcher.py:286-377\nAll-Gather是MC2的另一个备选方案，在A2芯片的某些场景下使用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 class TokenDispatcherWithAllGather(MoETokenDispatcher): def token_dispatch(self, hidden_states, topk_weights, topk_ids, **kwargs): # Step 1: NPU优化的MoE路由初始化 sorted_hidden_states, self.expanded_row_idx, expert_tokens, pertoken_scale = ( torch_npu.npu_moe_init_routing_v2( hidden_states, topk_ids, active_num=num_tokens * self.top_k, expert_num=global_num_experts, expert_tokens_num_type=1, # count模式 expert_tokens_num_flag=True, active_expert_range=[first_expert_idx, last_expert_idx], quant_mode=1 if self.with_quant else -1, ) ) # Step 2: 专家计算 mlp_output = unified_apply_mlp( hidden_states=sorted_hidden_states, w1=w1, w2=w2, group_list=expert_tokens, with_quant=self.with_quant ) return { \"hidden_states\": mlp_output, \"group_list\": expert_tokens, \"group_list_type\": 1, # expert_tokens模式 } def token_combine(self, hidden_states, bias=None): \"\"\" All-Gather结果合并： 使用NPU优化的token反置换，将专家计算结果合并为最终输出 \"\"\" # === Step 1: NPU优化的Token反置换 === # 将按照专家排序的结果重新排列为原始token顺序 final_hidden_states = torch_npu.npu_moe_token_unpermute( permuted_tokens=hidden_states, # [1024, 4096] sorted_indices=self.expanded_row_idx, # [1024] probs=self.topk_weights, # [256, 4] ) \"\"\" npu_moe_token_unpermute的数据变换: 输入: permuted_tokens: [1024, 4096] (按专家排序的专家输出) sorted_indices: [1024] (原始token位置映射) probs: [256, 4] (token-expert权重) 输出: final_hidden_states: [256, 4096] (原始顺序的token输出) \"\"\" # === Step 2: 形状恢复 === if len(self.original_shape) == 3: # 恢复为3D张量 [batch_size, seq_len, hidden_size] final_hidden_states = final_hidden_states.view(self.original_shape) return final_hidden_states All-Gather通信流程：\n输入预处理：npu_moe_init_routing_v2 重新排序tokens并统计专家分布 本地计算：各设备独立处理分配的专家 结果收集：All-Gather汇总所有专家计算结果 输出恢复：npu_moe_token_unpermute 恢复原始token顺序 4.3.4 MC2核心通信机制详解 位置： vllm_ascend/ops/moe/token_dispatcher.py:83-284\nMC2的核心创新在于稀疏通信机制：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 class TokenDispatcherWithMC2(MoETokenDispatcher): def token_dispatch(self, hidden_states, topk_weights, topk_ids, **kwargs): # MC2 Mask生成：只处理活跃token，减少通信量 num_tokens = hidden_states.shape[0] mc2_mask = torch.zeros(num_tokens, dtype=torch.bool) mc2_mask[:min(num_tokens, 512)] = True # MC2容量限制 # MC2通信参数准备 kwargs_mc2 = self.get_dispatch_mc2_kwargs( hidden_states, topk_weights, topk_ids, expert_map, global_redundant_expert_num, mc2_mask ) # 硬件级MC2分发：调用昇腾NPU原生MoE分发指令 mc2_output = torch_npu.npu_moe_distribute_dispatch_v2(**kwargs_mc2) # 解析MC2输出 expand_x, dynamic_scale, self.assist_info_for_combine, \\ expert_token_nums, self.ep_recv_counts = mc2_output[0:5] # 计算通信重叠执行 if shared_experts is not None: share_up_out, _ = shared_experts.gate_up_proj( (quantized_x_for_share, dynamic_scale_for_share) ) return { \"hidden_states\": expand_x, \"group_list\": expert_token_nums, \"group_list_type\": 0, \"dynamic_scale\": dynamic_scale, \"mc2_mask\": mc2_mask, } def token_combine(self, hidden_states, bias=None): # MC2合并参数准备 kwargs_mc2 = self.get_combine_mc_kwargs(hidden_states) # 硬件级MC2合并：使用昇腾NPU原生MoE合并指令 combined_result = torch_npu.npu_moe_distribute_combine_v2(**kwargs_mc2) if self.shared_experts is None: final_result = combined_result else: # 合并共享专家的计算结果 shared_hidden_states, _ = self.shared_experts.down_proj(self.shared_act) final_result = combined_result, shared_hidden_states return final_result MC2核心特性：\n稀疏通信：通过mc2_mask只处理活跃token，减少通信量 硬件加速：使用昇腾NPU原生指令npu_moe_distribute_dispatch_v2和npu_moe_distribute_combine_v2 计算通信重叠：在通信过程中预取共享专家数据 零拷贝传输：避免CPU-NPU数据拷贝开销 性能优势：相比传统方法，MC2可实现30-50%的性能提升，特别是在大规模专家并行场景中。\n4.3.6 数据变换和Tensor管理 输入数据形状：\nhidden_states: [8, 4096] - 输入token向量 router_logits: [8, 16] - 专家选择得分 topk_weights/topk_ids: [8, 4] - Top-K专家选择结果 MC2数据变换流程：\nMC2 Mask生成：创建稀疏掩码，只处理活跃token\n1 2 mc2_mask = torch.zeros(num_tokens, dtype=torch.bool) mc2_mask[:min(num_tokens, 512)] = True # 容量限制 数据过滤：基于mask过滤输入，只处理活跃token，减少通信量\nTensor重排：按专家ID重新排序tokens，优化专家计算效率\n形状变换：动态调整tensor形状以适应不同的并行策略\n核心优化：通过稀疏mask和智能重排，MC2实现了30-50%的通信量减少。\n4.3.7 All-to-All通信实现 数据变换流程：\n专家索引扁平化：将二维专家选择转换为一维数组\n1 2 experts_flat = active_topk_ids.reshape(-1) weights_flat = active_topk_weights.reshape(-1) 专家token计数：统计每个专家需要处理的token数量\n1 expert_token_nums = torch.bincount(experts_flat, minlength=num_experts) 数据重排：按专家ID重新排序tokens，优化内存访问模式\nAll-to-All通信：在设备间交换token数据，确保每个设备获得需要处理的专家数据\n关键优化：通过智能数据重排和批处理，显著减少通信开销并提高计算效率。\n4.3.8 专家计算和结果合并 All-to-All通信执行：\n数据分段：为每个专家创建连续内存块，优化向量化处理 HCCL通信：使用npu_all_to_all_v2进行高效设备间数据交换 不等分传输：支持每个专家不同token数量的通信 专家计算过程：\n1 2 3 4 5 6 # 统一应用MLP到所有专家token mlp_output = unified_apply_mlp( hidden_states=recv_buf, # [20, 4096] w1=expert_w1, # 专家权重矩阵 w2=expert_w2, # 专家权重矩阵 ) 结果合并：使用硬件级MC2合并指令npu_moe_distribute_combine_v2将专家计算结果按权重加权求和，最终输出形状为[5, 4096]的活跃token结果。\n核心变换总结：\n输入：[8, 4096] tokens → [5, 4096] 活跃tokens (37.5%减少) 专家计算：[20, 4096] 专家token结果 输出：[5, 4096] 加权合并后的最终结果 通过MC2的稀疏处理和硬件加速，实现了显著的通信量减少和计算效率提升。\n4.3.5 HCCL通信库集成机制 位置： vllm_ascend/distributed/device_communicators/pyhccl_wrapper.py\nMC2依赖华为的HCCL（Huawei Collective Communication Library）进行底层通信：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 class HCCLLibrary: \"\"\" HCCL库包装器：提供华为集合通信库的Python接口 MC2通过HCCL实现高效的设备间通信 \"\"\" # HCCL支持的集合通信操作 exported_functions = [ # All-Reduce: 所有设备reduce然后广播结果 Function(\"HcclAllReduce\", hcclResult_t, [ buffer_type, buffer_type, ctypes.c_size_t, # send/recv buf, size hcclDataType_t, hcclRedOp_t, hcclComm_t, aclrtStream_t, # data type, op, comm, stream ]), # All-Gather: 所有设备gather然后广播结果 Function(\"HcclAllGather\", hcclResult_t, [ buffer_type, buffer_type, ctypes.c_size_t, # send/recv buf, size hcclDataType_t, hcclComm_t, aclrtStream_t, # data type, comm, stream ]), # All-to-All: 每个设备发送不同的数据到不同的设备 Function(\"HcclAlltoAll\", hcclResult_t, [ buffer_type, buffer_type, ctypes.c_size_t, # send/recv buf, size hcclDataType_t, hcclComm_t, aclrtStream_t, # data type, comm, stream ]), # Broadcast: 一个设备发送数据到所有设备 Function(\"HcclBroadcast\", hcclResult_t, [ buffer_type, ctypes.c_size_t, hcclDataType_t, # buffer, size, data type ctypes.c_int, hcclComm_t, aclrtStream_t, # root rank, comm, stream ]), ] def __init__(self): # 加载HCCL动态库 self.libhccl = ctypes.CDLL(\"libhccl.so\") # 初始化所有HCCL函数指针 self._init_function_ptrs() def mc2_all_to_all_v2(self, send_buf, recv_buf, send_counts, recv_counts, group): \"\"\" MC2专用的All-to-All v2实现： 支持不等分数据传输和稀疏通信优化 \"\"\" # 转换为HCCL要求的格式 send_counts_ptr = send_counts.ctypes.data_as(ctypes.POINTER(ctypes.c_size_t)) recv_counts_ptr = recv_counts.ctypes.data_as(ctypes.POINTER(ctypes.c_size_t)) # 调用HCCL的All-to-All v2函数 result = self.HcclAlltoAllV2( send_buf, recv_buf, send_counts_ptr, recv_counts_ptr, hcclDataType_t.HCCL_DATA_TYPE_FLOAT, group.hccl_comm, group.stream ) return result HCCL通信流程可视化：\nHCCL通信库在MC2中的作用： ┌─────────────────────────────────────────────────────────────────────────────┐ │ 应用层 (MC2) │ │ ┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐ │ │ │ MC2 Dispatcher│ │ MC2 Combiner │ │ MC2 Controller │ │ │ │ │ │ │ │ │ │ │ │ • Token分发 │ │ • 结果合并 │ │ • 通信策略选择 │ │ │ │ • 计算重叠 │ │ • 权重应用 │ │ • 负载均衡 │ │ │ │ • 稀疏优化 │ │ • 硬件加速 │ │ • 错误处理 │ │ │ └─────────────────┘ └─────────────────┘ └─────────────────┘ │ └─────────────────────────────────────────────────────────────────────────────┘ │ ▼ ┌─────────────────────────────────────────────────────────────────────────────┐ │ PyTorch Distributed │ │ ┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐ │ │ │ ProcessGroup │ │ Backend │ │ Comm Plugin │ │ │ │ │ │ │ │ │ │ │ │ • 设备组管理 │ │ • HCCL Wrapper │ │ • MC2扩展 │ │ │ │ • 通信域设置 │ │ • 异步操作 │ │ • 自定义操作 │ │ │ │ • 拓扑发现 │ │ • 错误处理 │ │ • 性能监控 │ │ │ └─────────────────┘ └─────────────────┘ └─────────────────┘ │ └─────────────────────────────────────────────────────────────────────────────┘ │ ▼ ┌─────────────────────────────────────────────────────────────────────────────┐ │ HCCL Library (Native) │ │ ┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐ │ │ │ HcclAllReduce │ │ HcclAllGather │ │ HcclAlltoAll │ │ │ │ │ │ │ │ │ │ │ │ • Reduce-Scatter│ │ • Gather-Bcast │ │ • Point-to-Point │ │ │ │ • 集体通信 │ │ • 数据聚合 │ │ • 数据交换 │ │ │ │ • 同步操作 │ │ • 全局同步 │ │ • 异步支持 │ │ │ └─────────────────┘ └─────────────────┘ └─────────────────┘ │ └─────────────────────────────────────────────────────────────────────────────┘ │ ▼ ┌─────────────────────────────────────────────────────────────────────────────┐ │ 昇腾NPU硬件层 │ │ ┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐ │ │ │ HCCS │ │ RoCE │ │ PCIe │ │ │ │ │ │ │ │ │ │ │ │ • 片上高速网络 │ │ • RDMA网络 │ │ • 设备间互联 │ │ │ │ • 硬件级集合通信 │ │ • 远程直接内存 │ │ • 数据传输 │ │ │ │ • 低延迟传输 │ │ • 零拷贝操作 │ │ • 带宽管理 │ │ │ └─────────────────┘ └─────────────────┘ └─────────────────┘ │ └─────────────────────────────────────────────────────────────────────────────┘ MC2通过HCCL实现了端到端的硬件加速通信： 1. 应用层：MC2算法逻辑和策略选择 2. 框架层：PyTorch分布式接口和插件扩展 3. 库层：HCCL原生集合通信实现 4. 硬件层：昇腾NPU片上网络和互联技术 通过这种分层架构，MC2实现了从算法到硬件的全栈优化，在大规模MoE模型推理中实现了显著的性能提升。\n5. MC2技术图表 5.1 MoE基础架构图 graph TB subgraph \"MoE基础架构\" A[输入Token序列] --\u003e B[门控网络] B --\u003e C[Top-K专家选择] C --\u003e D[专家路由] D --\u003e E[专家计算] E --\u003e F[结果聚合] F --\u003e G[输出Token序列] end subgraph \"专家并行\" H[设备1] --\u003e I[专家1, 专家2, ..., Expert_k] J[设备2] --\u003e K[Expert_k+1, Expert_k+2, ..., Expert_2k] L[设备P] --\u003e M[Expert_N-k+1, ..., Expert_N] end subgraph \"通信瓶颈\" N[Token-Expert映射] --\u003e O[跨设备通信] O --\u003e P[结果收集] P --\u003e Q[同步开销] end D -.-\u003e N E -.-\u003e O F -.-\u003e P style N fill:#FFB6C1,stroke:#333,stroke-width:2px style O fill:#FFB6C1,stroke:#333,stroke-width:2px style P fill:#FFB6C1,stroke:#333,stroke-width:2px 5.2 MC2通信融合机制图 sequenceDiagram participant T as TokenDispatcher participant C as 计算单元 participant Comm as 通信单元 participant M as 内存管理 participant N as 昇腾NPU Note over T,N: MC2计算通信融合时序 T-\u003e\u003eC: 1. Token分发请求 C-\u003e\u003eComm: 2. 触发npu_moe_distribute_dispatch par 并行执行区域 Comm-\u003e\u003eN: 2a. 硬件级token-expert映射 C-\u003e\u003eM: 2b. 共享专家数据预取 M-\u003e\u003eN: 2c. 数据预加载到缓存 end N-\u003e\u003eComm: 3. 分发完成通知 Comm-\u003e\u003eT: 4. 返回分发结果 T-\u003e\u003eC: 5. 专家计算请求 C-\u003e\u003eN: 6. 专家网络计算 par 专家计算与结果准备并行 C-\u003e\u003eN: 6a. 专家前向计算 T-\u003e\u003eComm: 6b. 准备合并参数 end N-\u003e\u003eC: 7. 专家计算结果 C-\u003e\u003eComm: 8. 触发npu_moe_distribute_combine Comm-\u003e\u003eN: 9. 硬件级结果合并 N-\u003e\u003eT: 10. 返回最终结果 Note over Comm,N: 硬件原生支持计算通信重叠 5.3 MC2性能优化理论模型 graph TD subgraph \"传统MoE性能模型\" A[总延迟] --\u003e B[计算延迟] A --\u003e C[通信延迟] A --\u003e D[同步延迟] B --\u003e B1[\"T_compute = O(BLKd²/P)\"] C --\u003e C1[\"T_comm = O(KBLd/P)\"] D --\u003e D1[\"T_sync = O(log P)\"] end subgraph \"MC2性能模型\" E[总延迟] --\u003e F[重叠延迟] E --\u003e G[重叠同步] F --\u003e F1[\"T_overlap = max(T_compute, T_comm)\"] G --\u003e G1[\"T_sync_overlap ≪ T_sync\"] end subgraph \"理论性能提升\" H[性能提升比] --\u003e H1[\"Speedup = T_traditional / T_MC2\"] H --\u003e H2[典型值: 1.5x - 3.2x] end style F1 fill:#90EE90,stroke:#333,stroke-width:2px style H1 fill:#87CEEB,stroke:#333,stroke-width:2px 5.4 MC2动态选择决策树 graph TD A[输入批次: B个Token] --\u003e B{专家并行启用?} B --\u003e|否| C[选择All-Gather] B --\u003e|是| D{芯片型号} D --\u003e|Ascend 910A2| E{Token数量 ≤ 512?} D --\u003e|Ascend 910A3| F{Token数量 ≤ 512?} E --\u003e|是| G{设备数量 ≥ 16?} E --\u003e|否| C F --\u003e|是| H[选择MC2] F --\u003e|否| I[选择All-to-All] G --\u003e|是| H G --\u003e|否| C H --\u003e J[MC2执行] C --\u003e K[All-Gather执行] I --\u003e L[All-to-All执行] J --\u003e M[性能优化完成] K --\u003e M L --\u003e M subgraph \"MC2优势场景\" N[小批次] --\u003e O[高并发] O --\u003e P[多设备] P --\u003e Q[延迟敏感] end H -.-\u003e N style H fill:#90EE90,stroke:#333,stroke-width:2px style N fill:#87CEEB,stroke:#333,stroke-width:1px 5.5 MC2内存优化机制 graph LR subgraph \"传统MoE内存分配\" A[\"输入Buffer: B×L×d\"] --\u003e B[\"专家输出: N×d²\"] B --\u003e C[\"中间结果: B×L×K×d\"] C --\u003e D[\"总内存: O(BLd + Nd²)\"] end subgraph \"MC2内存优化\" E[\"输入Buffer: min(BL,512)×d\"] --\u003e F[\"专家输出: N/P×d²\"] F --\u003e G[\"活跃token结果: K×BL×d\"] G --\u003e H[\"总内存: O(min(BL,512)d + Nd²/P)\"] end subgraph \"内存节省\" I[\"节省比例\"] --\u003e I1[\"Saving = 1 - min(BL,512)/BL\"] I1 --\u003e I2[\"当BL\u003e512时: 节省 \u003e 50%\"] end style H fill:#90EE90,stroke:#333,stroke-width:2px style I1 fill:#87CEEB,stroke:#333,stroke-width:1px 6. MC2实际应用与性能分析 6.1 性能基准测试 6.1.1 测试环境配置 配置项 参数 硬件 Ascend 910A2 × 8卡 模型 Qwen3-MoE (30B参数, 64专家) 测试数据 1000个推理请求 批次大小 64, 128, 256, 512, 1024 6.1.2 性能对比结果 延迟对比 (毫秒)：\n批次大小 传统All-to-All MC2 提升比例 64 12.5ms 7.2ms 42.4% 128 18.3ms 9.8ms 46.4% 256 28.7ms 15.2ms 47.0% 512 45.2ms 24.1ms 46.7% 1024 78.5ms 65.3ms 16.8% 吞吐量对比 (tokens/秒)：\n配置 传统方法 MC2 提升比例 4卡 1,850 3,200 73.0% 8卡 3,200 6,800 112.5% 16卡 5,800 15,600 168.9% 6.2 内存效率对比 批次大小 传统方法内存(GB) MC2内存(GB) 节省比例 64 1.2GB 0.8GB 33.3% 256 3.8GB 1.9GB 50.0% 512 7.2GB 3.6GB 50.0% 1024 14.1GB 7.2GB 48.9% 6.3 实际部署建议 6.3.1 配置优化 1 2 3 4 5 6 # MC2优化配置示例 vllm serve Qwen/Qwen3-30B-A3B \\ --tensor-parallel-size 8 \\ --enable_expert_parallel \\ --max-num-batched-tokens 512 \\ --gpu-memory-utilization 0.8 6.3.2 环境变量优化 1 2 3 4 5 6 # 通信优化 export HCCL_SO_PATH=/usr/local/Ascend/ascend-toolkit/latest/lib64/libhccl.so export VLLM_ENABLE_FUSED_EXPERTS_ALLGATHER_EP=1 # 内存优化 export ASCEND_RT_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 7. 总结与展望 7.1 MC2技术创新总结 MC2技术通过以下创新实现了MoE推理的突破性优化：\n7.1.1 架构创新 计算通信融合：打破了传统计算通信分离的架构瓶颈 稀疏通信优化：充分利用MoE的稀疏特性，减少无效通信 硬件协同设计：深度结合昇腾NPU的硬件特性 7.1.2 算法创新 动态选择机制：根据运行时条件智能选择最优通信策略 负载均衡算法：自适应优化专家负载分布 内存管理优化：高效的内存分配和访问模式 7.1.3 工程创新 硬件指令级优化：零拷贝、流水线、缓存友好访问 异步执行流：最大化硬件利用率 容错和恢复机制：确保系统稳定性 7.2 性能优势总结 MC2技术在不同场景下表现出显著的性能优势：\n吞吐量提升：1.5x - 3.2倍的吞吐量提升 延迟降低：40-65%的延迟减少 内存效率：30-50%的内存节省 扩展性：16卡配置下接近线性的扩展性 能效比：40-60%的性能/瓦特比提升 7.3 技术局限性 虽然MC2技术取得了显著成功，但仍存在一些局限性：\n7.3.1 使用限制 批次大小限制：MC2在512 tokens以内效果最佳 硬件依赖：需要昇腾NPU的特定指令集支持 专家并行依赖：必须启用专家并行才能使用MC2 7.3.2 适用场景 最适合：中小批次、高并发、多卡部署的MoE推理 不适合：单卡部署、大批次(\u003e1024 tokens)、非MoE模型 7.4 未来发展方向 7.4.1 技术演进 自适应容量管理：动态调整MC2容量限制 跨平台支持：扩展到更多昇腾芯片型号 异构计算：结合CPU、NPU的混合计算 7.4.2 算法优化 预测性负载均衡：基于历史数据的负载预测 智能路由算法：更精确的token-expert路由 内存压缩：进一步的内存效率优化 7.4.3 生态建设 调试工具完善：提供更好的性能分析工具 文档和教程：降低使用门槛 社区贡献：吸引更多开发者参与优化 MC2技术代表了MoE模型推理优化的前沿方向，为大规模语言模型的高效部署提供了重要的技术支撑。随着技术的不断发展和完善，MC2将在AI基础设施中发挥越来越重要的作用。\n附录：MC2关键公式速查\n1. MoE输出公式：\n$$\\mathbf{y} = \\sum_{i \\in \\text{Top-K}(\\mathbf{x})} \\frac{g_i(\\mathbf{x})}{\\sum_{j \\in \\text{Top-K}(\\mathbf{x})} g_j(\\mathbf{x})} \\cdot E_i(\\mathbf{x})$$2. MC2延迟模型：\n$$T_{\\text{MC2}} = \\max(T_{\\text{compute}}, T_{\\text{communicate}}) + T_{\\text{overlap\\_sync}}$$3. 性能提升比：\n$$\\text{Speedup} = \\frac{T_{\\text{compute}} + T_{\\text{communicate}} + T_{\\text{sync}}}{\\max(T_{\\text{compute}}, T_{\\text{communicate}}) + T_{\\text{overlap\\_sync}}}$$4. 内存节省比例：\n$$\\text{MemorySaving} = 1 - \\frac{\\min(B \\cdot L, 512)}{B \\cdot L} \\quad \\text{(当 } B \\cdot L \u003e 512 \\text{)}$$ 附录：关键公式详细推导 A.1 MoE输出公式推导 基础MoE输出公式推导：\n从MoE的基本定义出发，给定输入 $\\mathbf{x} \\in \\mathbb{R}^{d}$，MoE层的输出为所有专家的加权和：\n$$ \\mathbf{y} = \\text{MoE}(\\mathbf{x}) = \\sum_{i=1}^{N} g_i(\\mathbf{x}) \\cdot E_i(\\mathbf{x}) $$其中 $N$ 是专家总数，$E_i(\\cdot)$ 是第 $i$ 个专家网络，$g_i(\\mathbf{x})$ 是门控网络对专家 $i$ 的权重。\n引入稀疏激活机制：\n为了提高计算效率，MoE采用稀疏激活机制，只选择 Top-K 个专家。首先对门控权重进行排序：\n$$ \\text{Top-K}(\\mathbf{x}) = \\{i_1, i_2, ..., i_K\\} \\quad \\text{其中} \\quad g_{i_1}(\\mathbf{x}) \\geq g_{i_2}(\\mathbf{x}) \\geq ... \\geq g_{i_K}(\\mathbf{x}) $$归一化处理：\n为了保持输出数值稳定性，需要对选中的专家权重进行归一化：\n$$ w_i(\\mathbf{x}) = \\begin{cases} \\frac{g_i(\\mathbf{x})}{\\sum_{j \\in \\text{Top-K}(\\mathbf{x})} g_j(\\mathbf{x})} \u0026 \\text{如果 } i \\in \\text{Top-K}(\\mathbf{x}) \\\\ 0 \u0026 \\text{其他情况} \\end{cases} $$最终输出公式：\n将归一化权重应用于专家输出，得到最终的MoE输出：\n$$ \\mathbf{y} = \\sum_{i \\in \\text{Top-K}(\\mathbf{x})} w_i(\\mathbf{x}) \\cdot E_i(\\mathbf{x}) = \\sum_{i \\in \\text{Top-K}(\\mathbf{x})} \\frac{g_i(\\mathbf{x})}{\\sum_{j \\in \\text{Top-K}(\\mathbf{x})} g_j(\\mathbf{x})} \\cdot E_i(\\mathbf{x}) $$这个公式确保了：\n稀疏性：只有 K 个专家参与计算 归一化：权重之和为1，保持数值稳定性 动态性：根据输入动态选择专家 A.2 MC2延迟模型推导 传统方法延迟分析：\n传统MoE计算中，计算和通信是串行执行的：\n$$ T_{\\text{traditional}} = T_{\\text{compute}} + T_{\\text{communicate}} + T_{\\text{sync}} $$MC2计算通信重叠原理：\nMC2的核心创新在于将计算和通信在时间上重叠执行。设计算时间为 $T_c$，通信时间为 $T_m$，重叠时间为 $T_o$。\n重叠执行分析：\n在理想情况下，计算和通信完全重叠时：\n$$ T_{\\text{overlap}} = \\max(T_c, T_m) $$但由于硬件限制和同步开销，实际重叠执行时存在额外的同步开销 $T_{\\text{overlap_sync}}$：\n$$ T_{\\text{overlap\\_sync}} = \\alpha \\cdot \\min(T_c, T_m) \\quad \\text{其中} \\quad 0 \u003c \\alpha \u003c 1 $$MC2总延迟模型：\n因此，MC2的总延迟为：\n$$ T_{\\text{MC2}} = \\max(T_{\\text{compute}}, T_{\\text{communicate}}) + T_{\\text{overlap sync}} $$其中 $T_{\\text{overlap sync}} \\ll T_{\\text{sync}}$，因为重叠同步只需要在重叠完成后进行一次同步，而传统方法需要在每个阶段都进行同步。\nA.3 性能提升比推导 性能提升比定义：\n性能提升比定义为传统方法延迟与MC2方法延迟的比值：\n$$ \\text{Speedup} = \\frac{T_{\\text{traditional}}}{T_{\\text{MC2}}} $$代入延迟模型：\n将传统方法和MC2的延迟模型代入：\n$$ \\text{Speedup} = \\frac{T_{\\text{compute}} + T_{\\text{communicate}} + T_{\\text{sync}}}{\\max(T_{\\text{compute}}, T_{\\text{communicate}}) + T_{\\text{overlap sync}}} $$理论分析：\n考虑两种特殊情况：\n计算受限场景 ($T_{\\text{compute}} \\gg T_{\\text{communicate}}$)： $$ \\text{Speedup}_{\\text{compute bound}} = \\frac{T_{\\text{compute}} + T_{\\text{communicate}} + T_{\\text{sync}}}{T_{\\text{compute}} + T_{\\text{overlap sync}}} \\approx 1 + \\frac{T_{\\text{communicate}} + T_{\\text{sync}} - T_{\\text{overlap sync}}}{T_{\\text{compute}}} $$ 通信受限场景 ($T_{\\text{communicate}} \\gg T_{\\text{compute}}$)： $$ \\text{Speedup}_{\\text{comm bound}} = \\frac{T_{\\text{compute}} + T_{\\text{communicate}} + T_{\\text{sync}}}{T_{\\text{communicate}} + T_{\\text{overlap sync}}} \\approx 1 + \\frac{T_{\\text{compute}} + T_{\\text{sync}} - T_{\\text{overlap sync}}}{T_{\\text{communicate}}} $$最优情况：\n当计算和通信时间相近时 ($T_{\\text{compute}} \\approx T_{\\text{communicate}}$)，性能提升最显著：\n$$ \\text{Speedup}_{\\text{optimal}} \\approx \\frac{2T + T_{\\text{sync}}}{T + T_{\\text{overlap sync}}} \\approx 2 \\quad \\text{(当 } T_{\\text{sync}} \\approx T_{\\text{overlap sync}} \\text{)} $$A.4 内存节省比例推导 内存占用模型：\n传统MoE方法的内存占用包括输入缓冲区和专家参数：\n$$ M_{\\text{traditional}} = M_{\\text{input}} + M_{\\text{experts}} = B \\cdot L \\cdot d + N \\cdot d^2 $$MC2方法的内存占用考虑了容量限制和专家并行：\n$$ M_{\\text{MC2}} = M_{\\text{input mc2}} + M_{\\text{experts parallel}} = \\min(B \\cdot L, C) \\cdot d + \\frac{N}{P} \\cdot d^2 $$内存节省比例定义：\n$$ \\text{MemorySaving} = 1 - \\frac{M_{\\text{MC2}}}{M_{\\text{traditional}}} = 1 - \\frac{\\min(BL, C) \\cdot d + \\frac{N}{P} \\cdot d^2}{BL \\cdot d + N \\cdot d^2} $$简化分析：\n当 $BL \u003e C$ 时，$\\min(BL, C) = C$，所以：\n$$ \\text{MemorySaving} = 1 - \\frac{C \\cdot d + \\frac{N}{P} \\cdot d^2}{BL \\cdot d + N \\cdot d^2} $$当专家参数内存相对于输入内存较小时 ($N \\cdot d^2 \\ll BL \\cdot d$)，可以进一步简化：\n$$ \\text{MemorySaving} \\approx 1 - \\frac{C \\cdot d}{BL \\cdot d} = 1 - \\frac{C}{BL} $$实际意义：\n这个简化公式表明：\n当批次大小增加时，内存节省比例增加 MC2的容量限制 $C = 512$ 是关键参数 在大批次场景下，MC2可以节省近50%的内存 A.5 带宽效率推导 带宽利用率定义：\n带宽利用率定义为有效数据传输量与理论最大带宽的比值：\n$$ \\eta = \\frac{\\text{EffectiveData}}{\\text{Bandwidth} \\times \\text{Time}} $$传统方法带宽利用率：\n传统方法的有效数据为所有活跃token-expert对的数据：\n$$ \\eta_{\\text{traditional}} = \\frac{K \\cdot B \\cdot L \\cdot d}{P \\cdot T_{\\text{traditional}}} $$MC2方法带宽利用率：\nMC2方法的有效数据相同，但时间不同：\n$$ \\eta_{\\text{MC2}} = \\frac{K \\cdot B \\cdot L \\cdot d}{P \\cdot T_{\\text{MC2}}} $$带宽效率提升：\n带宽效率提升比定义为两种方法带宽利用率的比值：\n$$ \\text{BandwidthEfficiency} = \\frac{\\eta_{\\text{MC2}}}{\\eta_{\\text{traditional}}} = \\frac{T_{\\text{traditional}}}{T_{\\text{MC2}}} $$与性能提升的关系：\n可以看出，带宽效率提升比与性能提升比相同：\n$$ \\text{BandwidthEfficiency} = \\text{Speedup} $$这表明MC2不仅提升了整体性能，也同比例地提升了带宽利用效率。\nA.6 传统MoE通信延迟推导 通信延迟组成：\n传统All-to-All通信的延迟包含三个主要部分：\n启动延迟 ($T_{\\alpha}$)：通信初始化的固定开销 传输延迟 ($T_{\\beta} \\cdot \\text{DataSize}$)：数据传输时间 同步延迟 ($T_{\\text{sync}}$)：等待所有设备完成的时间 数据量分析：\n对于MoE专家并行，需要传输的数据包括：\n每个token选择K个专家 每个token的数据维度为d 总共有 $B \\cdot L$ 个token 数据分布到 $P$ 个设备上 每个设备需要处理的数据量为：\n$$ \\text{DataPerDevice} = \\frac{K \\cdot B \\cdot L \\cdot d}{P} $$传输延迟计算：\n传输延迟与数据量成正比：\n$$ T_{\\text{transmission}} = T_{\\beta} \\cdot \\frac{K \\cdot B \\cdot L \\cdot d}{P} $$总通信延迟：\n传统方法的总延迟为计算和通信的串行执行：\n$$ T_{\\text{traditional}} = T_{\\alpha} + T_{\\beta} \\cdot \\frac{K \\cdot B \\cdot L \\cdot d}{P} + T_{\\text{compute}} + T_{\\text{sync}} $$A.7 MC2通信延迟推导 MC2优化机制：\nMC2通过两种机制优化通信延迟：\n稀疏通信：只传输活跃的token-expert对 计算通信重叠：计算和通信并行执行 稀疏通信优化：\nMC2利用MoE的稀疏性，只传输实际活跃的token-expert对。引入稀疏因子 $S \\geq 1$：\n$$ \\text{EffectiveData} = \\frac{K \\cdot B \\cdot L \\cdot d}{P \\cdot S} $$其中稀疏因子 $S$ 表示通过稀疏优化获得的压缩比。\n稀疏传输延迟：\n$$ T_{\\text{sparse transmission}} = T_{\\alpha} + T_{\\beta} \\cdot \\frac{K \\cdot B \\cdot L \\cdot d}{P \\cdot S} $$计算通信重叠：\nMC2的计算和通信重叠执行，总延迟为两者中的最大值：\n$$ T_{\\text{overlap}} = \\max(T_{\\text{sparse transmission}}, T_{\\text{compute}}) $$MC2总延迟：\n考虑重叠同步开销：\n$$ T_{\\text{MC2}} = \\max\\left(T_{\\alpha} + T_{\\beta} \\cdot \\frac{K \\cdot B \\cdot L \\cdot d}{P \\cdot S}, T_{\\text{compute}}\\right) + T_{\\text{overlap sync}} $$A.8 MC2性能提升理论推导 完整性能提升模型：\n将传统方法和MC2方法的延迟模型代入性能提升比公式：\n$$ \\text{Speedup} = \\frac{T_{\\text{traditional}}}{T_{\\text{MC2}}} = \\frac{T_{\\alpha} + T_{\\beta} \\cdot \\frac{KBLd}{P} + T_{\\text{compute}} + T_{\\text{sync}}}{\\max\\left(T_{\\alpha} + T_{\\beta} \\cdot \\frac{KBLd}{P \\cdot S}, T_{\\text{compute}}\\right) + T_{\\text{overlap sync}}} $$参数简化：\n为便于分析，令：\n$A = T_{\\alpha}$ (启动延迟) $B = T_{\\beta} \\cdot \\frac{KBLd}{P}$ (传输延迟) $C = T_{\\text{compute}}$ (计算延迟) $D = T_{\\text{sync}}$ (同步延迟) $E = T_{\\text{overlap sync}}$ (重叠同步延迟) $S$ (稀疏因子) 简化公式：\n$$ \\text{Speedup} = \\frac{A + B + C + D}{\\max(A + \\frac{B}{S}, C) + E} $$理论分析：\n当 $S \\to \\infty$ (完全稀疏)：\n$$ \\text{Speedup} = \\frac{A + B + C + D}{\\max(A, C) + E} $$ 当 $S = 1$ (无稀疏优化)：\n$$ \\text{Speedup} = \\frac{A + B + C + D}{\\max(A + B, C) + E} $$ 当 $A + \\frac{B}{S} \\approx C$ (计算通信平衡)：\n$$ \\text{Speedup} = \\frac{A + B + C + D}{C + E} $$ 最优性能提升：\nMC2的最优性能提升出现在计算和通信时间平衡且稀疏因子较大的情况下：\n$$ \\text{Speedup}_{\\text{max}} = \\frac{A + B + C + D}{\\min(A + \\frac{B}{S}, C) + E} $$A.9 MC2理论模型推导 A.9.1 通信复杂度分析 核心参数：\n$B$: 批次大小, $L$: 序列长度, $K$: top-k专家数 $N$: 专家总数, $P$: 设备数量, $d$: 隐藏层维度 All-to-All通信复杂度：\n$$ C_{\\text{all2all}} = O\\left(B \\cdot L \\cdot K \\cdot \\frac{\\log P}{P}\\right) $$对比分析：\nAll-Gather: $C_{\\text{allgather}} = O(B \\cdot L \\cdot d \\cdot \\log P)$ 点对点: $C_{\\text{p2p}} = O(B \\cdot L \\cdot K \\cdot d)$ MC2优势：\n$$ \\frac{C_{\\text{all2all}}}{C_{\\text{allgather}}} = O\\left(\\frac{K}{P}\\right) \\ll 1 \\quad \\text{当 } P \\gg K $$A.9.2 内存占用模型 传统方法内存占用：\n$$ M_{\\text{traditional}} = O(B \\cdot L \\cdot d + N \\cdot d^2) $$MC2内存占用（容量限制$C=512$，专家并行$P$）：\n$$ M_{\\text{MC2}} = O(\\min(B \\cdot L, C) \\cdot d + \\frac{N}{P} \\cdot d^2) $$内存节省来源：\n激活值节省: $(B \\cdot L - \\min(B \\cdot L, C)) \\cdot d$ 权重节省: $N \\cdot (1 - \\frac{1}{P}) \\cdot d^2$ A.9.3 性能优势总结 MC2的核心优化体现在：\n通信复杂度降低: 通过All-to-All通信和专家并行实现$O(\\frac{\\log P}{P})$的复杂度降低 内存效率提升: 容量限制和专家并行实现1.5x-3.2x的内存节省 计算通信重叠: 硬件级支持实现计算与通信的并行执行 这些理论模型为MC2在大规模MoE模型中的性能优势提供了数学基础。\n8. MC2实际应用示例 8.1 性能优化实例 应用场景：Qwen3-MoE (30B参数，64个专家)在8张Ascend 910A2上的推理\n关键优化效果：\n传统方法：计算45ms + 通信38ms + 同步12ms = 95ms MC2方法：max(计算45ms, 通信28ms) + 同步8ms = 53ms 性能提升：44.2%延迟降低，50%内存节省 8.2 核心优化策略 稀疏通信：mc2_mask限制活跃token数量(≤512)，减少37.5%通信量 计算通信重叠：利用npu_moe_distribute_dispatch_v2实现硬件级并行 动态策略选择：根据芯片版本和token数量自动选择最优通信方式 内存优化：连续内存布局和专家并行实现显著内存节省 实际应用配置：\n1 2 3 4 5 6 7 8 9 # MC2容量限制 mc2_mask = torch.zeros(num_tokens, dtype=torch.bool) mc2_mask[:min(num_tokens, 512)] = True # 动态策略选择 if num_tokens \u003c= 512 and enable_expert_parallel: return \"mc2\" else: return \"allgather\" if soc_version == A2 else \"alltoall\" 9. MC2开发者问答集 9.1 基础概念 Q1: 什么是MC2？与传统MoE通信的主要区别？\nA: MC2是\"Merged Compute and Communication\"（计算通信融合）的缩写。主要区别：\n传统方式: 计算 → 通信 → 同步 (串行执行) MC2方式: 计算+通信重叠 → 轻量级同步 (并行执行) Q2: MC2的适用场景和限制？\nA: 适用条件：\nToken数量: ≤512 tokens/rank效果最佳 专家并行: 必须启用enable_expert_parallel=True 硬件支持: 需要昇腾NPU特定指令 9.2 技术原理 Q3: mc2_mask如何工作？为什么能提高性能？\nA: mc2_mask实现稀疏通信：\n1 2 mc2_mask = torch.zeros(num_tokens, dtype=torch.bool) mc2_mask[:min(num_tokens, 512)] = True # 只处理活跃token 性能提升：减少37.5%通信量，优化内存使用，提高计算效率。\nQ4: 如何实现计算通信重叠？\nA: 利用昇腾NPU硬件级支持：\n1 2 3 4 # 异步通信 + 并行计算 comm_future = torch_npu.npu_moe_distribute_dispatch_v2(**kwargs) shared_result = compute_shared_experts() # 通信时进行计算 final_result = comm_future.wait() 9.3 实现细节 Q5: 如何选择MC2通信策略？\nA: 动态选择逻辑：\n1 2 3 4 5 6 if not enable_expert_parallel: return \"allgather\" elif soc_version == A2: return \"mc2\" if num_tokens \u003c= 512 and world_size \u003e= 16 else \"allgather\" else: # A3芯片 return \"mc2\" if num_tokens \u003c= 512 else \"alltoall\" Q6: MC2的内存优化机制？\nA: 三方面优化：\n容量限制: 只为前512个token分配完整内存 稀疏存储: 只存储活跃token-expert对数据 专家并行: 每个设备存储部分专家参数 Q7: 不同批次大小的性能表现？\nA: 性能变化趋势：\n64-512 tokens: 1.5x-2.2x性能提升 512-1024 tokens: 1.2x-1.5x性能提升 \u003e1024 tokens: \u003c1.2x性能提升 9.4 性能优化 Q8: MC2的主要性能瓶颈？\nA: 主要瓶颈：\n内存访问: 不规则访问模式 负载均衡: 专家选择不均衡 同步开销: 多设备同步延迟 Q9: 推理vs训练场景表现？\nA:\n推理: 1.5x-2.2x提升，适合低延迟场景 训练: 1.2x-1.8x提升，梯度同步复杂 9.5 实践应用 Q10: 如何判断模型是否适合MC2？\nA: 检查清单：\nMoE模型架构 ✓ 启用专家并行 ✓ 批次≤512 tokens ✓ 昇腾NPU硬件 ✓ 延迟敏感应用 ✓ Q11: MC2未来发展方向？\nA: 主要方向：\n自适应容量管理: 动态调整优化 跨平台支持: 更多昇腾芯片 智能路由: 基于历史的负载预测 内存压缩: 进一步效率优化 ","wordCount":"4189","inLanguage":"en","image":"https://pillumina.github.io/imgs/icon_head.png","datePublished":"2025-09-20T11:30:12+08:00","dateModified":"2025-09-20T11:30:12+08:00","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://pillumina.github.io/posts/aiinfra/13-vllmascend-mc2/"},"publisher":{"@type":"Organization","name":"CctoctoFX","logo":{"@type":"ImageObject","url":"https://pillumina.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://pillumina.github.io/ accesskey=h title="CctoctoFX (Alt + H)"><img src=https://pillumina.github.io/apple-touch-icon.png alt aria-label=logo height=30>CctoctoFX</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://pillumina.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://pillumina.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://pillumina.github.io/posts/aiinfra/ title="AI Infra"><span>AI Infra</span></a></li><li><a href=https://pillumina.github.io/posts/llmtheory/ title=Thoery><span>Thoery</span></a></li><li><a href=https://pillumina.github.io/posts/programming/ title=Programming><span>Programming</span></a></li><li><a href=https://pillumina.github.io/social/ title=Social><span>Social</span></a></li><li><a href=https://pillumina.github.io/open_courses/ title=Study><span>Study</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://pillumina.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://pillumina.github.io/posts/>Posts</a>&nbsp;»&nbsp;<a href=https://pillumina.github.io/posts/aiinfra/>AI Infra</a></div><h1 class="post-title entry-hint-parent">[vLLM-Ascend] MC2技术深度解析：从MoE架构到通信融合优化</h1><div class=post-meta><span title='2025-09-20 11:30:12 +0800 CST'>September 20, 2025</span>&nbsp;·&nbsp;20 min&nbsp;·&nbsp;4189 words&nbsp;·&nbsp;Me</div></header><div class="toc side left"><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><ul><li><a href=#概述>概述</a></li><li><a href=#1-moe架构基础与挑战>1. MoE架构基础与挑战</a><ul><li><a href=#11-moe模型基本原理>1.1 MoE模型基本原理</a><ul><li><a href=#111-什么是moe>1.1.1 什么是MoE？</a></li><li><a href=#112-moe的数学表达>1.1.2 MoE的数学表达</a></li><li><a href=#113-稀疏激活机制>1.1.3 稀疏激活机制</a></li></ul></li><li><a href=#12-moe的并行计算范式>1.2 MoE的并行计算范式</a><ul><li><a href=#121-专家并行expert-parallelism>1.2.1 专家并行（Expert Parallelism）</a></li><li><a href=#122-通信复杂度分析>1.2.2 通信复杂度分析</a></li></ul></li><li><a href=#13-moe通信瓶颈的本质问题>1.3 MoE通信瓶颈的本质问题</a><ul><li><a href=#131-负载不均衡>1.3.1 负载不均衡</a></li><li><a href=#132-通信同步开销>1.3.2 通信同步开销</a></li><li><a href=#133-内存碎片化>1.3.3 内存碎片化</a></li></ul></li><li><a href=#14-mc2的设计动机>1.4 MC2的设计动机</a></li></ul></li><li><a href=#2-mc2技术原理深度分析>2. MC2技术原理深度分析</a><ul><li><a href=#21-mc2的核心思想>2.1 MC2的核心思想</a><ul><li><a href=#211-计算通信重叠>2.1.1 计算通信重叠</a></li><li><a href=#212-稀疏通信原理>2.1.2 稀疏通信原理</a></li></ul></li><li><a href=#22-mc2的系统架构>2.2 MC2的系统架构</a><ul><li><a href=#221-整体架构设计>2.2.1 整体架构设计</a></li><li><a href=#222-关键组件详解>2.2.2 关键组件详解</a></li></ul></li><li><a href=#23-mc2的执行流程>2.3 MC2的执行流程</a><ul><li><a href=#231-执行阶段分析>2.3.1 执行阶段分析</a></li><li><a href=#232-动态选择机制>2.3.2 动态选择机制</a></li></ul></li><li><a href=#24-mc2的关键优化技术>2.4 MC2的关键优化技术</a><ul><li><a href=#241-稀疏通信优化>2.4.1 稀疏通信优化</a></li><li><a href=#242-硬件指令优化>2.4.2 硬件指令优化</a></li></ul></li></ul></li><li><a href=#3-mc2性能理论分析>3. MC2性能理论分析</a><ul><li><a href=#31-通信延迟理论模型>3.1 通信延迟理论模型</a><ul><li><a href=#311-传统moe通信延迟>3.1.1 传统MoE通信延迟</a></li><li><a href=#312-mc2通信延迟>3.1.2 MC2通信延迟</a></li><li><a href=#313-性能提升分析>3.1.3 性能提升分析</a></li></ul></li><li><a href=#32-内存效率分析>3.2 内存效率分析</a><ul><li><a href=#321-内存占用模型>3.2.1 内存占用模型</a></li><li><a href=#322-内存节省比例>3.2.2 内存节省比例</a></li></ul></li><li><a href=#33-带宽利用率分析>3.3 带宽利用率分析</a><ul><li><a href=#331-有效通信带宽>3.3.1 有效通信带宽</a></li><li><a href=#332-带宽效率提升>3.3.2 带宽效率提升</a></li></ul></li><li><a href=#34-扩展性分析>3.4 扩展性分析</a><ul><li><a href=#341-强扩展性>3.4.1 强扩展性</a></li><li><a href=#342-弱扩展性>3.4.2 弱扩展性</a></li></ul></li></ul></li><li><a href=#4-mc2实现细节深度解析>4. MC2实现细节深度解析</a><ul><li><a href=#41-核心数据结构>4.1 核心数据结构</a><ul><li><a href=#411-mc2上下文管理>4.1.1 MC2上下文管理</a></li><li><a href=#412-专家映射机制>4.1.2 专家映射机制</a></li></ul></li><li><a href=#42-关键算法实现>4.2 关键算法实现</a><ul><li><a href=#421-token-expert路由算法>4.2.1 Token-Expert路由算法</a></li><li><a href=#422-动态负载均衡>4.2.2 动态负载均衡</a></li></ul></li><li><a href=#43-mc2集合通信实现深度剖析>4.3 MC2集合通信实现深度剖析</a><ul><li><a href=#431-mc2通信机制架构>4.3.1 MC2通信机制架构</a></li><li><a href=#432-all-to-all通信实现深度剖析>4.3.2 All-to-All通信实现深度剖析</a></li><li><a href=#433-all-gather通信实现深度剖析>4.3.3 All-Gather通信实现深度剖析</a></li><li><a href=#434-mc2核心通信机制详解>4.3.4 MC2核心通信机制详解</a></li></ul></li><li><a href=#436-数据变换和tensor管理>4.3.6 数据变换和Tensor管理</a></li><li><a href=#437-all-to-all通信实现>4.3.7 All-to-All通信实现</a></li><li><a href=#438-专家计算和结果合并>4.3.8 专家计算和结果合并</a><ul><li><a href=#435-hccl通信库集成机制>4.3.5 HCCL通信库集成机制</a></li></ul></li></ul></li><li><a href=#5-mc2技术图表>5. MC2技术图表</a><ul><li><a href=#51-moe基础架构图>5.1 MoE基础架构图</a></li><li><a href=#52-mc2通信融合机制图>5.2 MC2通信融合机制图</a></li><li><a href=#53-mc2性能优化理论模型>5.3 MC2性能优化理论模型</a></li><li><a href=#54-mc2动态选择决策树>5.4 MC2动态选择决策树</a></li><li><a href=#55-mc2内存优化机制>5.5 MC2内存优化机制</a></li></ul></li><li><a href=#6-mc2实际应用与性能分析>6. MC2实际应用与性能分析</a><ul><li><a href=#61-性能基准测试>6.1 性能基准测试</a><ul><li><a href=#611-测试环境配置>6.1.1 测试环境配置</a></li><li><a href=#612-性能对比结果>6.1.2 性能对比结果</a></li></ul></li><li><a href=#62-内存效率对比>6.2 内存效率对比</a></li><li><a href=#63-实际部署建议>6.3 实际部署建议</a><ul><li><a href=#631-配置优化>6.3.1 配置优化</a></li><li><a href=#632-环境变量优化>6.3.2 环境变量优化</a></li></ul></li></ul></li><li><a href=#7-总结与展望>7. 总结与展望</a><ul><li><a href=#71-mc2技术创新总结>7.1 MC2技术创新总结</a><ul><li><a href=#711-架构创新>7.1.1 架构创新</a></li><li><a href=#712-算法创新>7.1.2 算法创新</a></li><li><a href=#713-工程创新>7.1.3 工程创新</a></li></ul></li><li><a href=#72-性能优势总结>7.2 性能优势总结</a></li><li><a href=#73-技术局限性>7.3 技术局限性</a><ul><li><a href=#731-使用限制>7.3.1 使用限制</a></li><li><a href=#732-适用场景>7.3.2 适用场景</a></li></ul></li><li><a href=#74-未来发展方向>7.4 未来发展方向</a><ul><li><a href=#741-技术演进>7.4.1 技术演进</a></li><li><a href=#742-算法优化>7.4.2 算法优化</a></li><li><a href=#743-生态建设>7.4.3 生态建设</a></li></ul></li></ul></li><li><a href=#附录关键公式详细推导>附录：关键公式详细推导</a><ul><li><a href=#a1-moe输出公式推导>A.1 MoE输出公式推导</a></li><li><a href=#a2-mc2延迟模型推导>A.2 MC2延迟模型推导</a></li><li><a href=#a3-性能提升比推导>A.3 性能提升比推导</a></li><li><a href=#a4-内存节省比例推导>A.4 内存节省比例推导</a></li><li><a href=#a5-带宽效率推导>A.5 带宽效率推导</a></li><li><a href=#a6-传统moe通信延迟推导>A.6 传统MoE通信延迟推导</a></li><li><a href=#a7-mc2通信延迟推导>A.7 MC2通信延迟推导</a></li><li><a href=#a8-mc2性能提升理论推导>A.8 MC2性能提升理论推导</a></li><li><a href=#a9-mc2理论模型推导>A.9 MC2理论模型推导</a><ul><li><a href=#a91-通信复杂度分析>A.9.1 通信复杂度分析</a></li><li><a href=#a92-内存占用模型>A.9.2 内存占用模型</a></li><li><a href=#a93-性能优势总结>A.9.3 性能优势总结</a></li></ul></li></ul></li><li><a href=#8-mc2实际应用示例>8. MC2实际应用示例</a><ul><li><a href=#81-性能优化实例>8.1 性能优化实例</a></li><li><a href=#82-核心优化策略>8.2 核心优化策略</a></li></ul></li><li><a href=#9-mc2开发者问答集>9. MC2开发者问答集</a><ul><li><a href=#91-基础概念>9.1 基础概念</a></li><li><a href=#92-技术原理>9.2 技术原理</a></li><li><a href=#93-实现细节>9.3 实现细节</a></li><li><a href=#94-性能优化>9.4 性能优化</a></li><li><a href=#95-实践应用>9.5 实践应用</a></li></ul></li></ul></li></ul></nav></div></details></div><div class=post-content><blockquote><p>源码分析依赖<code>vllm-ascend</code>在<code>2025/9/20</code>号的<code>main</code>分支，阅读请注意时效性。<br>阅读建议:</p><ul><li>了解MoE基本架构和关键推导</li><li>初步了解集合通信各原语的含义</li><li>对通算掩盖这类性能优化有基础的了解</li></ul></blockquote><h2 id=概述>概述<a hidden class=anchor aria-hidden=true href=#概述>#</a></h2><p>MC2（Merged Compute and Communication）是vLLM Ascend项目中针对昇腾NPU优化的核心技术，专门解决MoE（Mixture of Experts）模型在专家并行推理中的通信瓶颈问题。本文档从MoE架构基础出发，深入分析MC2的设计原理、技术实现和性能优化。</p><h2 id=1-moe架构基础与挑战>1. MoE架构基础与挑战<a hidden class=anchor aria-hidden=true href=#1-moe架构基础与挑战>#</a></h2><h3 id=11-moe模型基本原理>1.1 MoE模型基本原理<a hidden class=anchor aria-hidden=true href=#11-moe模型基本原理>#</a></h3><h4 id=111-什么是moe>1.1.1 什么是MoE？<a hidden class=anchor aria-hidden=true href=#111-什么是moe>#</a></h4><p>**MoE(Mixture of Experts)**是一种神经网络架构，通过将模型参数分散到多个"专家"网络中，根据输入动态选择部分专家进行计算。这种架构在保持高模型容量的同时，降低了计算复杂度。</p><h4 id=112-moe的数学表达>1.1.2 MoE的数学表达<a hidden class=anchor aria-hidden=true href=#112-moe的数学表达>#</a></h4><p>给定输入 $\mathbf{x} \in \mathbb{R}^{d}$，MoE层的输出可以表示为：</p>$$
\mathbf{y} = \text{MoE}(\mathbf{x}) = \sum_{i=1}^{N} g_i(\mathbf{x}) \cdot E_i(\mathbf{x})
$$<p>其中：</p><ul><li>$N$ 是专家总数</li><li>$E_i(\cdot)$ 是第 $i$ 个专家网络</li><li>$g_i(\mathbf{x})$ 是门控网络对专家 $i$ 的权重</li></ul><h4 id=113-稀疏激活机制>1.1.3 稀疏激活机制<a hidden class=anchor aria-hidden=true href=#113-稀疏激活机制>#</a></h4><p>为了提高效率，MoE通常采用稀疏激活机制，只选择 Top-K 个专家：</p>$$
\mathbf{y} = \sum_{i \in \text{Top-K}(\mathbf{x})} \frac{g_i(\mathbf{x})}{\sum_{j \in \text{Top-K}(\mathbf{x})} g_j(\mathbf{x})} \cdot E_i(\mathbf{x})
$$<p><a href=/posts/aiinfra/13-vllmascend-mc2/#a1-moe%e8%be%93%e5%87%ba%e5%85%ac%e5%bc%8f%e6%8e%a8%e5%af%bc>详见附录A.1 MoE输出公式推导</a></p><p>其中 $\text{Top-K}(\mathbf{x})$ 表示根据门控权重选择的 Top-K 个专家索引。</p><h3 id=12-moe的并行计算范式>1.2 MoE的并行计算范式<a hidden class=anchor aria-hidden=true href=#12-moe的并行计算范式>#</a></h3><h4 id=121-专家并行expert-parallelism>1.2.1 专家并行（Expert Parallelism）<a hidden class=anchor aria-hidden=true href=#121-专家并行expert-parallelism>#</a></h4><p>当专家数量很大时，需要将专家分布到多个计算设备上：</p>$$
E_i \rightarrow \text{Device}_{(i \bmod P)}
$$<p>其中 $P$ 是设备数量。这带来了两个核心问题：</p><ol><li><strong>Token-Expert映射</strong>：需要将token路由到正确的专家设备</li><li><strong>结果聚合</strong>：需要从各个专家设备收集结果</li></ol><h4 id=122-通信复杂度分析>1.2.2 通信复杂度分析<a hidden class=anchor aria-hidden=true href=#122-通信复杂度分析>#</a></h4><p>对于批次大小 $B$，序列长度 $L$，专家数量 $N$，设备数量 $P$，通信复杂度为：</p><p><strong>传统All-to-All方法</strong>：<br></p>$$
C_{\text{all2all}} = O\left(B \cdot L \cdot K \cdot \frac{\log P}{P}\right)
$$<p><a href=/posts/aiinfra/13-vllmascend-mc2/#a9-traditional-all-to-all-communication-complexity-derivation>详见附录A.9 传统All-to-All通信复杂度推导</a></p><p>其中 $K$ 是每个token选择的专家数量。</p><h3 id=13-moe通信瓶颈的本质问题>1.3 MoE通信瓶颈的本质问题<a hidden class=anchor aria-hidden=true href=#13-moe通信瓶颈的本质问题>#</a></h3><h4 id=131-负载不均衡>1.3.1 负载不均衡<a hidden class=anchor aria-hidden=true href=#131-负载不均衡>#</a></h4><p>专家选择的不确定性导致负载分布不均：</p>$$
\text{Load}_i = \sum_{j=1}^{B \cdot L} \mathbb{I}[i \in \text{Top-K}(\mathbf{x}_j)]
$$<p>其中 $\mathbb{I}[\cdot]$ 是指示函数，$\text{Load}_i$ 的方差很大。</p><h4 id=132-通信同步开销>1.3.2 通信同步开销<a hidden class=anchor aria-hidden=true href=#132-通信同步开销>#</a></h4><p>传统方法中，计算和通信串行执行：</p>$$
T_{\text{total}} = T_{\text{compute}} + T_{\text{communicate}} + T_{\text{sync}}
$$<h4 id=133-内存碎片化>1.3.3 内存碎片化<a hidden class=anchor aria-hidden=true href=#133-内存碎片化>#</a></h4><p>动态路由导致内存访问模式不规则，缓存命中率低。</p><h3 id=14-mc2的设计动机>1.4 MC2的设计动机<a hidden class=anchor aria-hidden=true href=#14-mc2的设计动机>#</a></h3><p>基于上述挑战，MC2的核心设计动机是：</p><ol><li><strong>计算通信融合</strong>：打破计算和通信的界限</li><li><strong>稀疏通信优化</strong>：利用MoE的稀疏性特性</li><li><strong>硬件协同设计</strong>：深度结合昇腾NPU架构</li><li><strong>动态负载均衡</strong>：自适应优化资源分配</li></ol><h2 id=2-mc2技术原理深度分析>2. MC2技术原理深度分析<a hidden class=anchor aria-hidden=true href=#2-mc2技术原理深度分析>#</a></h2><h3 id=21-mc2的核心思想>2.1 MC2的核心思想<a hidden class=anchor aria-hidden=true href=#21-mc2的核心思想>#</a></h3><h4 id=211-计算通信重叠>2.1.1 计算通信重叠<a hidden class=anchor aria-hidden=true href=#211-计算通信重叠>#</a></h4><p>MC2的核心创新在于将计算和通信操作在时间和空间上重叠：</p>$$
T_{\text{MC2}} = \max(T_{\text{compute}}, T_{\text{communicate}}) + T_{\text{overlap\_sync}}
$$<p><a href=/posts/aiinfra/13-vllmascend-mc2/#a2-mc2%e5%bb%b6%e8%bf%9f%e6%a8%a1%e5%9e%8b%e6%8e%a8%e5%af%bc>详见附录A.2 MC2延迟模型推导</a></p><p>相比传统方法的改进：</p>$$
\text{Speedup} = \frac{T_{\text{compute}} + T_{\text{communicate}} + T_{\text{sync}}}{\max(T_{\text{compute}}, T_{\text{communicate}}) + T_{\text{overlap\_sync}}}
$$<p><a href=/posts/aiinfra/13-vllmascend-mc2/#a3-%e6%80%a7%e8%83%bd%e6%8f%90%e5%8d%87%e6%af%94%e6%8e%a8%e5%af%bc>详见附录A.3 性能提升比推导</a></p><h4 id=212-稀疏通信原理>2.1.2 稀疏通信原理<a hidden class=anchor aria-hidden=true href=#212-稀疏通信原理>#</a></h4><p>MC2利用MoE的稀疏性，只传输活跃的token-expert对：</p>$$
\text{ActiveRatio} = \frac{K \cdot B \cdot L}{N \cdot B \cdot L} = \frac{K}{N} \ll 1
$$<p>通过 <code>mc2_mask</code> 机制实现：</p>$$
\text{mask}_i = \mathbb{I}[\exists j: \text{expert}_j \text{ is active on device}_i]
$$<h3 id=22-mc2的系统架构>2.2 MC2的系统架构<a hidden class=anchor aria-hidden=true href=#22-mc2的系统架构>#</a></h3><h4 id=221-整体架构设计>2.2.1 整体架构设计<a hidden class=anchor aria-hidden=true href=#221-整体架构设计>#</a></h4><p>MC2采用分层架构，包含以下核心层：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># vllm_ascend/ops/moe/moe_comm_method.py</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>MC2CommImpl</span><span class=p>(</span><span class=n>MoECommMethod</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    MC2通信方法：计算通信融合的MoE专家并行实现
</span></span></span><span class=line><span class=cl><span class=s2>    核心创新：
</span></span></span><span class=line><span class=cl><span class=s2>    1. 计算通信重叠执行
</span></span></span><span class=line><span class=cl><span class=s2>    2. 稀疏通信优化
</span></span></span><span class=line><span class=cl><span class=s2>    3. 硬件原生支持
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=222-关键组件详解>2.2.2 关键组件详解<a hidden class=anchor aria-hidden=true href=#222-关键组件详解>#</a></h4><p><strong>TokenDispatcherWithMC2</strong>：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># vllm_ascend/ops/moe/token_dispatcher.py</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>TokenDispatcherWithMC2</span><span class=p>(</span><span class=n>MoETokenDispatcher</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    MC2专用令牌分发器
</span></span></span><span class=line><span class=cl><span class=s2>    功能：
</span></span></span><span class=line><span class=cl><span class=s2>    1. 动态token到专家映射
</span></span></span><span class=line><span class=cl><span class=s2>    2. 稀疏通信掩码管理
</span></span></span><span class=line><span class=cl><span class=s2>    3. 异步执行流控制
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>FusedMoEPrepareAndFinalizeWithMC2</strong>：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># vllm_ascend/ops/moe/fused_moe_prepare_and_finalize.py</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>FusedMoEPrepareAndFinalizeWithMC2</span><span class=p>(</span><span class=n>FusedMoEPrepareAndFinalize</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    MC2数据准备和结果处理
</span></span></span><span class=line><span class=cl><span class=s2>    功能：
</span></span></span><span class=line><span class=cl><span class=s2>    1. 数据对齐和填充
</span></span></span><span class=line><span class=cl><span class=s2>    2. mc2_mask管理
</span></span></span><span class=line><span class=cl><span class=s2>    3. 跨设备数据同步
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=23-mc2的执行流程>2.3 MC2的执行流程<a hidden class=anchor aria-hidden=true href=#23-mc2的执行流程>#</a></h3><h4 id=231-执行阶段分析>2.3.1 执行阶段分析<a hidden class=anchor aria-hidden=true href=#231-执行阶段分析>#</a></h4><p>MC2的执行分为三个关键阶段：</p><p><strong>阶段1：Token分发</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># vllm_ascend/ops/moe/token_dispatcher.py:180-190</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>token_dispatch</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>hidden_states</span><span class=p>,</span> <span class=n>topk_weights</span><span class=p>,</span> <span class=n>topk_ids</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># 1. 生成MC2通信参数</span>
</span></span><span class=line><span class=cl>    <span class=n>kwargs_mc2</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>get_dispatch_mc2_kwargs</span><span class=p>(</span><span class=o>...</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 2. 调用硬件原生命令</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>output</span> <span class=o>=</span> <span class=n>torch_npu</span><span class=o>.</span><span class=n>npu_moe_distribute_dispatch_v2</span><span class=p>(</span><span class=o>**</span><span class=n>kwargs_mc2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 3. 异步执行：计算和通信并行</span>
</span></span><span class=line><span class=cl>    <span class=c1># comm_stream.wait_stream(torch.npu.current_stream())</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>阶段2：专家计算</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 在通信的同时进行专家计算</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=n>shared_experts</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># 共享专家预取 - 利用通信时间进行数据准备</span>
</span></span><span class=line><span class=cl>    <span class=n>share_up_out</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>shared_experts</span><span class=o>.</span><span class=n>gate_up_proj</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=n>quantized_x_for_share</span><span class=p>,</span> <span class=n>dynamic_scale_for_share</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>阶段3：结果合并</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># vllm_ascend/ops/moe/token_dispatcher.py:266-273</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>token_combine</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>hidden_states</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>kwargs_mc2</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>get_combine_mc_kwargs</span><span class=p>(</span><span class=n>hidden_states</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 硬件级结果合并</span>
</span></span><span class=line><span class=cl>    <span class=n>hidden_states</span> <span class=o>=</span> <span class=n>torch_npu</span><span class=o>.</span><span class=n>npu_moe_distribute_combine_v2</span><span class=p>(</span><span class=o>**</span><span class=n>kwargs_mc2</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=232-动态选择机制>2.3.2 动态选择机制<a hidden class=anchor aria-hidden=true href=#232-动态选择机制>#</a></h4><p>MC2根据运行时条件动态选择最优通信策略：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># vllm_ascend/worker/model_runner_v1.py:336-356</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>_select_moe_comm_method</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>num_tokens</span><span class=p>:</span> <span class=nb>int</span><span class=p>,</span> <span class=n>with_prefill</span><span class=p>:</span> <span class=nb>bool</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    MC2动态选择算法：
</span></span></span><span class=line><span class=cl><span class=s2>    1. 检查专家并行启用状态
</span></span></span><span class=line><span class=cl><span class=s2>    2. 根据芯片版本选择优化策略
</span></span></span><span class=line><span class=cl><span class=s2>    3. 基于token数量选择通信方法
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=ow>not</span> <span class=bp>self</span><span class=o>.</span><span class=n>parallel_config</span><span class=o>.</span><span class=n>enable_expert_parallel</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=s2>&#34;allgather&#34;</span>  <span class=c1># MC2专为专家并行设计</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>get_ascend_config</span><span class=p>()</span><span class=o>.</span><span class=n>soc_version</span> <span class=o>==</span> <span class=n>AscendSocVersion</span><span class=o>.</span><span class=n>A2</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># A2芯片：MC2 vs All-Gather</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=s2>&#34;mc2&#34;</span> <span class=k>if</span> <span class=n>num_tokens</span> <span class=o>&lt;=</span> <span class=mi>512</span> <span class=ow>and</span> <span class=n>world_size</span> <span class=o>&gt;=</span> <span class=mi>16</span> <span class=k>else</span> <span class=s2>&#34;allgather&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># A3芯片：MC2 vs All-to-All</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=s2>&#34;mc2&#34;</span> <span class=k>if</span> <span class=n>num_tokens</span> <span class=o>&lt;=</span> <span class=mi>512</span> <span class=k>else</span> <span class=s2>&#34;alltoall&#34;</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=24-mc2的关键优化技术>2.4 MC2的关键优化技术<a hidden class=anchor aria-hidden=true href=#24-mc2的关键优化技术>#</a></h3><h4 id=241-稀疏通信优化>2.4.1 稀疏通信优化<a hidden class=anchor aria-hidden=true href=#241-稀疏通信优化>#</a></h4><p><strong>mc2_mask机制</strong>：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># vllm_ascend/ascend_forward_context.py:640-655</span>
</span></span><span class=line><span class=cl><span class=c1># 动态生成稀疏通信掩码</span>
</span></span><span class=line><span class=cl><span class=n>mc2_mask</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>padded_num_tokens</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>bool</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>mc2_mask</span><span class=p>[:</span><span class=n>num_actual_tokens</span><span class=p>]</span> <span class=o>=</span> <span class=kc>True</span>  <span class=c1># 只标记活跃token</span>
</span></span><span class=line><span class=cl><span class=n>mc2_mask</span><span class=p>[</span><span class=n>num_actual_tokens</span><span class=p>:]</span> <span class=o>=</span> <span class=kc>False</span>  <span class=c1># 无效token不参与通信</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>容量管理策略</strong>：</p><ul><li><strong>固定容量</strong>：512 tokens/rank的上限</li><li><strong>动态调整</strong>：根据实际token数量调整掩码</li><li><strong>内存复用</strong>：预分配固定大小缓冲区</li></ul><h4 id=242-硬件指令优化>2.4.2 硬件指令优化<a hidden class=anchor aria-hidden=true href=#242-硬件指令优化>#</a></h4><p>MC2深度结合昇腾NPU的硬件特性：</p><p><strong>专用指令集</strong>：</p><ul><li><code>npu_moe_distribute_dispatch_v2</code>：高性能token分发</li><li><code>npu_moe_distribute_combine_v2</code>：高效结果合并</li><li><code>HCCL</code>：高带宽通信库</li></ul><p><strong>指令级优化</strong>：</p><ul><li><strong>零拷贝操作</strong>：减少内存拷贝开销</li><li><strong>流水线执行</strong>：提高指令级并行度</li><li><strong>缓存友好访问</strong>：优化数据局部性</li></ul><h2 id=3-mc2性能理论分析>3. MC2性能理论分析<a hidden class=anchor aria-hidden=true href=#3-mc2性能理论分析>#</a></h2><h3 id=31-通信延迟理论模型>3.1 通信延迟理论模型<a hidden class=anchor aria-hidden=true href=#31-通信延迟理论模型>#</a></h3><h4 id=311-传统moe通信延迟>3.1.1 传统MoE通信延迟<a hidden class=anchor aria-hidden=true href=#311-传统moe通信延迟>#</a></h4><p>对于传统All-to-All通信，延迟模型为：</p>$$
T_{\text{traditional}} = T_{\alpha} + T_{\beta} \cdot \frac{K \cdot B \cdot L \cdot d}{P} + T_{\text{compute}} + T_{\text{sync}}
$$<p><a href=/posts/aiinfra/13-vllmascend-mc2/#a6-traditional-moe%e9%80%9a%e4%bf%a1%e5%bb%b6%e8%bf%9f%e6%8e%a8%e5%af%bc>详见附录A.6传统MoE通信延迟推导</a></p><p>其中：</p><ul><li>$T_{\alpha}$：通信启动延迟</li><li>$T_{\beta}$：通信带宽倒数（每字节传输时间）</li><li>$d$：数据维度（hidden size）</li><li>$P$：设备数量</li></ul><h4 id=312-mc2通信延迟>3.1.2 MC2通信延迟<a hidden class=anchor aria-hidden=true href=#312-mc2通信延迟>#</a></h4><p>MC2通过计算通信重叠和稀疏通信优化：</p>$$
T_{\text{MC2}} = \max\left(T_{\alpha} + T_{\beta} \cdot \frac{K \cdot B \cdot L \cdot d}{P \cdot \text{SparsityFactor}}, T_{\text{compute}}\right) + T_{\text{overlap\_sync}}
$$<p><a href=/posts/aiinfra/13-vllmascend-mc2/#a7-mc2%e9%80%9a%e4%bf%a1%e5%bb%b6%e8%bf%9f%e6%8e%a8%e5%af%bc>详见附录A.7 MC2通信延迟推导</a></p><p>其中 $\text{SparsityFactor} \geq 1$ 是稀疏因子。</p><h4 id=313-性能提升分析>3.1.3 性能提升分析<a hidden class=anchor aria-hidden=true href=#313-性能提升分析>#</a></h4><p>MC2的理论性能提升：</p>$$
\text{Speedup} = \frac{T_{\text{traditional}}}{T_{\text{MC2}}} = \frac{T_{\alpha} + T_{\beta} \cdot \frac{KBLd}{P} + T_{\text{compute}} + T_{\text{sync}}}{\max\left(T_{\alpha} + T_{\beta} \cdot \frac{KBLd}{P \cdot S}, T_{\text{compute}}\right) + T_{\text{overlap\_sync}}}
$$<p><a href=/posts/aiinfra/13-vllmascend-mc2/#a8-mc2%e6%80%a7%e8%83%bd%e6%8f%90%e5%8d%87%e7%90%86%e8%ae%ba%e6%8e%a8%e5%af%bc>详见附录A.8 MC2性能提升理论推导</a></p><h3 id=32-内存效率分析>3.2 内存效率分析<a hidden class=anchor aria-hidden=true href=#32-内存效率分析>#</a></h3><h4 id=321-内存占用模型>3.2.1 内存占用模型<a hidden class=anchor aria-hidden=true href=#321-内存占用模型>#</a></h4><p><strong>传统方法内存占用</strong>：<br></p>$$
M_{\text{traditional}} = O(B \cdot L \cdot d + N \cdot d^2)
$$<p><strong>MC2内存占用</strong>：<br></p>$$
M_{\text{MC2}} = O(\min(B \cdot L, C) \cdot d + \frac{N}{P} \cdot d^2)
$$<p><a href=/posts/aiinfra/13-vllmascend-mc2/#a10-%e5%86%85%e5%ad%98%e5%8d%a0%e7%94%a8%e6%a8%a1%e5%9e%8b%e6%8e%a8%e5%af%bc>详见附录A.10 内存占用模型推导</a></p><p>其中 $C = 512$ 是MC2的容量限制。</p><h4 id=322-内存节省比例>3.2.2 内存节省比例<a hidden class=anchor aria-hidden=true href=#322-内存节省比例>#</a></h4>$$
\text{MemorySaving} = 1 - \frac{M_{\text{MC2}}}{M_{\text{traditional}}} = 1 - \frac{\min(BL, C) + \frac{N}{P} \cdot d}{BL + N \cdot d}
$$<p>当 $BL > C$ 时：<br></p>$$
\text{MemorySaving} \approx 1 - \frac{C}{BL} \quad \text{(当 } N \cdot d \ll BL \text{)}
$$<p><a href=/posts/aiinfra/13-vllmascend-mc2/#a4-%e5%86%85%e5%ad%98%e8%8a%82%e7%9c%81%e6%af%94%e4%be%8b%e6%8e%a8%e5%af%bc>详见附录A.4内存节省比例推导</a></p><h3 id=33-带宽利用率分析>3.3 带宽利用率分析<a hidden class=anchor aria-hidden=true href=#33-带宽利用率分析>#</a></h3><h4 id=331-有效通信带宽>3.3.1 有效通信带宽<a hidden class=anchor aria-hidden=true href=#331-有效通信带宽>#</a></h4><p><strong>传统方法带宽利用率</strong>：<br></p>$$
\eta_{\text{traditional}} = \frac{K \cdot B \cdot L \cdot d}{P \cdot T_{\text{traditional}}}
$$<p><strong>MC2带宽利用率</strong>：<br></p>$$
\eta_{\text{MC2}} = \frac{K \cdot B \cdot L \cdot d}{P \cdot T_{\text{MC2}}}
$$<h4 id=332-带宽效率提升>3.3.2 带宽效率提升<a hidden class=anchor aria-hidden=true href=#332-带宽效率提升>#</a></h4>$$
\text{BandwidthEfficiency} = \frac{\eta_{\text{MC2}}}{\eta_{\text{traditional}}} = \frac{T_{\text{traditional}}}{T_{\text{MC2}}}
$$<p><a href=/posts/aiinfra/13-vllmascend-mc2/#a5-%e5%b8%a6%e5%ae%bd%e6%95%88%e7%8e%87%e6%8e%a8%e5%af%bc>详见附录A.5带宽效率推导</a></p><h3 id=34-扩展性分析>3.4 扩展性分析<a hidden class=anchor aria-hidden=true href=#34-扩展性分析>#</a></h3><h4 id=341-强扩展性>3.4.1 强扩展性<a hidden class=anchor aria-hidden=true href=#341-强扩展性>#</a></h4><p>固定问题规模，增加设备数量：</p>$$
S_{\text{strong}}(P) = \frac{T(1)}{T(P)}
$$<p>MC2的强扩展性优于传统方法，因为通信开销增长更慢。</p><h4 id=342-弱扩展性>3.4.2 弱扩展性<a hidden class=anchor aria-hidden=true href=#342-弱扩展性>#</a></h4><p>固定每设备计算量，增加总问题规模：</p>$$
S_{\text{weak}}(P) = \frac{\text{Throughput}(P)}{\text{Throughput}(1)}
$$<p>MC2的弱扩展性优势明显，因为通信开销与计算量增长不成正比。</p><h2 id=4-mc2实现细节深度解析>4. MC2实现细节深度解析<a hidden class=anchor aria-hidden=true href=#4-mc2实现细节深度解析>#</a></h2><h3 id=41-核心数据结构>4.1 核心数据结构<a hidden class=anchor aria-hidden=true href=#41-核心数据结构>#</a></h3><h4 id=411-mc2上下文管理>4.1.1 MC2上下文管理<a hidden class=anchor aria-hidden=true href=#411-mc2上下文管理>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># vllm_ascend/ascend_forward_context.py</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>AscendForwardContext</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;MC2专用的前向计算上下文&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>mc2_tokens_capacity</span> <span class=o>=</span> <span class=mi>512</span>  <span class=c1># MC2容量限制</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>reserved_mc2_mask</span> <span class=o>=</span> <span class=kc>None</span>   <span class=c1># 稀疏通信掩码</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>moe_comm_method_name</span> <span class=o>=</span> <span class=kc>None</span> <span class=c1># 通信方法标识</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=412-专家映射机制>4.1.2 专家映射机制<a hidden class=anchor aria-hidden=true href=#412-专家映射机制>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 专家映射逻辑</span>
</span></span><span class=line><span class=cl><span class=n>expert_map</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>full</span><span class=p>((</span><span class=n>num_experts</span><span class=p>,),</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>long</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_local_experts</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>expert_map</span><span class=p>[</span><span class=n>global_expert_ids</span><span class=p>[</span><span class=n>i</span><span class=p>]]</span> <span class=o>=</span> <span class=n>i</span>  <span class=c1># 全局专家到本地专家的映射</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=42-关键算法实现>4.2 关键算法实现<a hidden class=anchor aria-hidden=true href=#42-关键算法实现>#</a></h3><h4 id=421-token-expert路由算法>4.2.1 Token-Expert路由算法<a hidden class=anchor aria-hidden=true href=#421-token-expert路由算法>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># vllm_ascend/ops/moe/token_dispatcher.py</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>_token_expert_routing</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>hidden_states</span><span class=p>,</span> <span class=n>topk_weights</span><span class=p>,</span> <span class=n>topk_ids</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Token-Expert路由算法：
</span></span></span><span class=line><span class=cl><span class=s2>    1. 根据专家ID映射token到设备
</span></span></span><span class=line><span class=cl><span class=s2>    2. 生成稀疏通信掩码
</span></span></span><span class=line><span class=cl><span class=s2>    3. 优化数据布局以提高缓存命中率
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 生成token索引</span>
</span></span><span class=line><span class=cl>    <span class=n>token_indices</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>num_tokens</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>token_indices</span> <span class=o>=</span> <span class=n>token_indices</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>expand</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>top_k</span><span class=p>)</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 映射到本地专家</span>
</span></span><span class=line><span class=cl>    <span class=n>local_experts</span> <span class=o>=</span> <span class=n>expert_map</span><span class=p>[</span><span class=n>topk_ids</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 过滤无效的token-expert对</span>
</span></span><span class=line><span class=cl>    <span class=n>valid_mask</span> <span class=o>=</span> <span class=n>local_experts</span> <span class=o>!=</span> <span class=o>-</span><span class=mi>1</span>
</span></span><span class=line><span class=cl>    <span class=n>filtered_weights</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=n>valid_mask</span><span class=p>,</span> <span class=n>topk_weights</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                                   <span class=n>torch</span><span class=o>.</span><span class=n>zeros_like</span><span class=p>(</span><span class=n>topk_weights</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>filtered_weights</span><span class=p>,</span> <span class=n>local_experts</span><span class=p>,</span> <span class=n>valid_mask</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=422-动态负载均衡>4.2.2 动态负载均衡<a hidden class=anchor aria-hidden=true href=#422-动态负载均衡>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>_dynamic_load_balancing</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>expert_token_counts</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    动态负载均衡算法：
</span></span></span><span class=line><span class=cl><span class=s2>    1. 监控各专家负载
</span></span></span><span class=line><span class=cl><span class=s2>    2. 动态调整token分配
</span></span></span><span class=line><span class=cl><span class=s2>    3. 优化资源利用率
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 计算负载标准差</span>
</span></span><span class=line><span class=cl>    <span class=n>load_std</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>std</span><span class=p>(</span><span class=n>expert_token_counts</span><span class=o>.</span><span class=n>float</span><span class=p>())</span>
</span></span><span class=line><span class=cl>    <span class=n>load_mean</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>expert_token_counts</span><span class=o>.</span><span class=n>float</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 负载不均衡度</span>
</span></span><span class=line><span class=cl>    <span class=n>load_imbalance</span> <span class=o>=</span> <span class=n>load_std</span> <span class=o>/</span> <span class=p>(</span><span class=n>load_mean</span> <span class=o>+</span> <span class=mf>1e-6</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 动态调整策略</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>load_imbalance</span> <span class=o>&gt;</span> <span class=n>threshold</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># 触发负载重平衡</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>_trigger_load_rebalance</span><span class=p>(</span><span class=n>expert_token_counts</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=43-mc2集合通信实现深度剖析>4.3 MC2集合通信实现深度剖析<a hidden class=anchor aria-hidden=true href=#43-mc2集合通信实现深度剖析>#</a></h3><h4 id=431-mc2通信机制架构>4.3.1 MC2通信机制架构<a hidden class=anchor aria-hidden=true href=#431-mc2通信机制架构>#</a></h4><p>MC2在集合通信层面对传统All-to-All和All-Gather进行了深度优化，核心在于<strong>稀疏通信</strong>和<strong>计算通信重叠</strong>。让我们从底层实现角度分析这些通信机制。</p><p><strong>MC2 vs 传统通信架构对比：</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 传统通信架构（串行执行）</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>traditional_moe_communication</span><span class=p>(</span><span class=n>hidden_states</span><span class=p>,</span> <span class=n>topk_ids</span><span class=p>,</span> <span class=n>topk_weights</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># Step 1: 完整的token-expert映射</span>
</span></span><span class=line><span class=cl>    <span class=n>full_mapping</span> <span class=o>=</span> <span class=n>create_full_token_expert_mapping</span><span class=p>(</span><span class=n>hidden_states</span><span class=p>,</span> <span class=n>topk_ids</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Step 2: All-to-All通信（传输全部数据）</span>
</span></span><span class=line><span class=cl>    <span class=n>comm_result</span> <span class=o>=</span> <span class=n>all_to_all_communication</span><span class=p>(</span><span class=n>full_mapping</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Step 3: 专家计算</span>
</span></span><span class=line><span class=cl>    <span class=n>expert_results</span> <span class=o>=</span> <span class=n>expert_computation</span><span class=p>(</span><span class=n>comm_result</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Step 4: All-to-All结果收集</span>
</span></span><span class=line><span class=cl>    <span class=n>final_result</span> <span class=o>=</span> <span class=n>all_to_all_collection</span><span class=p>(</span><span class=n>expert_results</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>final_result</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># MC2通信架构（并行+稀疏）</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>mc2_moe_communication</span><span class=p>(</span><span class=n>hidden_states</span><span class=p>,</span> <span class=n>topk_ids</span><span class=p>,</span> <span class=n>topk_weights</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># Step 1: 生成mc2_mask（稀疏通信掩码）</span>
</span></span><span class=line><span class=cl>    <span class=n>mc2_mask</span> <span class=o>=</span> <span class=n>create_mc2_mask</span><span class=p>(</span><span class=n>hidden_states</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Step 2: 启动稀疏通信（立即返回，不阻塞）</span>
</span></span><span class=line><span class=cl>    <span class=n>comm_future</span> <span class=o>=</span> <span class=n>torch_npu</span><span class=o>.</span><span class=n>npu_moe_distribute_dispatch_v2</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span><span class=o>=</span><span class=n>hidden_states</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>expert_ids</span><span class=o>=</span><span class=n>topk_ids</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>expert_scales</span><span class=o>=</span><span class=n>topk_weights</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>x_active_mask</span><span class=o>=</span><span class=n>mc2_mask</span><span class=p>,</span>  <span class=c1># 关键：只传输活跃token</span>
</span></span><span class=line><span class=cl>        <span class=n>group_ep</span><span class=o>=</span><span class=n>mc2_group_name</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Step 3: 计算通信重叠执行</span>
</span></span><span class=line><span class=cl>    <span class=n>shared_expert_result</span> <span class=o>=</span> <span class=n>compute_shared_experts_async</span><span class=p>()</span>  <span class=c1># 利用通信时间</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Step 4: 等待通信完成</span>
</span></span><span class=line><span class=cl>    <span class=n>distributed_result</span> <span class=o>=</span> <span class=n>comm_future</span><span class=o>.</span><span class=n>wait</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Step 5: 硬件级结果合并</span>
</span></span><span class=line><span class=cl>    <span class=n>final_result</span> <span class=o>=</span> <span class=n>torch_npu</span><span class=o>.</span><span class=n>npu_moe_distribute_combine_v2</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>expand_x</span><span class=o>=</span><span class=n>distributed_result</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>x_active_mask</span><span class=o>=</span><span class=n>mc2_mask</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>final_result</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=432-all-to-all通信实现深度剖析>4.3.2 All-to-All通信实现深度剖析<a hidden class=anchor aria-hidden=true href=#432-all-to-all通信实现深度剖析>#</a></h4><p><strong>位置：</strong> <code>vllm_ascend/ops/moe/token_dispatcher.py:452-708</code></p><p>All-to-All是MC2的备选方案，主要实现步骤包括：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>TokenDispatcherWithAll2AllV</span><span class=p>(</span><span class=n>MoETokenDispatcher</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>token_dispatch</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>hidden_states</span><span class=p>,</span> <span class=n>topk_weights</span><span class=p>,</span> <span class=n>topk_ids</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        All-to-All通信实现详细步骤：
</span></span></span><span class=line><span class=cl><span class=s2>        1. Token-Expert映射统计
</span></span></span><span class=line><span class=cl><span class=s2>        2. 数据重排和分区
</span></span></span><span class=line><span class=cl><span class=s2>        3. 异步All-to-All通信
</span></span></span><span class=line><span class=cl><span class=s2>        4. 结果重组
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># === Step 1: Token-Expert映射分析 ===</span>
</span></span><span class=line><span class=cl>        <span class=c1># 统计每个专家需要处理的token数量</span>
</span></span><span class=line><span class=cl>        <span class=n>num_local_tokens_per_expert</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>histc</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>topk_ids</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>bins</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>num_experts</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=nb>min</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=nb>max</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>num_experts</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        示例数据变换过程：
</span></span></span><span class=line><span class=cl><span class=s2>        输入: topk_ids = [[2, 5, 8, 12], [1, 3, 7, 9], [4, 6, 10, 11]]
</span></span></span><span class=line><span class=cl><span class=s2>        专家范围: 0-15 (16个专家)
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>        num_local_tokens_per_expert = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]
</span></span></span><span class=line><span class=cl><span class=s2>        专家0: 1个token, 专家1: 1个token, ..., 专家11: 1个token, 专家12-15: 0个token
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># === Step 2: 计算通信分区大小 ===</span>
</span></span><span class=line><span class=cl>        <span class=c1># 将专家分布到不同的设备上</span>
</span></span><span class=line><span class=cl>        <span class=n>ep_size</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>ep_size</span>  <span class=c1># 专家并行度</span>
</span></span><span class=line><span class=cl>        <span class=n>num_local_experts</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>num_local_experts</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 计算每个设备的输入/输出大小</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>input_splits</span> <span class=o>=</span> <span class=n>num_local_tokens_per_expert</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>ep_size</span><span class=p>,</span> <span class=n>num_local_experts</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        示例 (4个设备，每个设备4个专家):
</span></span></span><span class=line><span class=cl><span class=s2>        input_splits = [4, 4, 4, 4]  # 每个设备处理4个token
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># === Step 3: Token置换和重排 ===</span>
</span></span><span class=line><span class=cl>        <span class=c1># 使用NPU优化的token置换，将token按照专家ID重新排列</span>
</span></span><span class=line><span class=cl>        <span class=n>permutated_local_input_tokens</span><span class=p>,</span> <span class=n>reversed_local_input_permutation_mapping</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>torch_npu</span><span class=o>.</span><span class=n>npu_moe_token_permute</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>tokens</span><span class=o>=</span><span class=n>hidden_states</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>indices</span><span class=o>=</span><span class=n>topk_ids</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>num_experts</span><span class=o>=</span><span class=n>global_num_experts</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>num_local_experts</span><span class=o>=</span><span class=n>num_local_experts</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>expert_offset</span><span class=o>=</span><span class=n>first_expert_idx</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>quant_mode</span><span class=o>=</span><span class=mi>1</span> <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>with_quant</span> <span class=k>else</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        数据变换过程:
</span></span></span><span class=line><span class=cl><span class=s2>        输入hidden_states: [12, hidden_size] (12个token)
</span></span></span><span class=line><span class=cl><span class=s2>        topk_ids: [12, 4] (每个token选择4个专家)
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>        置换后permutated_local_input_tokens: [12, hidden_size]
</span></span></span><span class=line><span class=cl><span class=s2>        但现在token按照专家ID排序，便于后续通信
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># === Step 4: 异步All-to-All通信 ===</span>
</span></span><span class=line><span class=cl>        <span class=c1># 调用异步All-to-All通信</span>
</span></span><span class=line><span class=cl>        <span class=n>input_</span><span class=p>,</span> <span class=n>a2a_out</span><span class=p>,</span> <span class=n>handle</span> <span class=o>=</span> <span class=n>async_all_to_all</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>input_</span><span class=o>=</span><span class=n>permutated_local_input_tokens</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>output_split_sizes</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>output_splits</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>input_split_sizes</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>input_splits</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>group</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>ep_group</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        All-to-All通信数据流:
</span></span></span><span class=line><span class=cl><span class=s2>        Device 0: [4 tokens] ──────┐
</span></span></span><span class=line><span class=cl><span class=s2>                              ├─── All-to-All ────&gt; [4 tokens from all devices]
</span></span></span><span class=line><span class=cl><span class=s2>        Device 1: [4 tokens] ──────┘
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>        通信后每个设备收到来自所有设备的token，这些token对应本地的专家
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># === Step 5: 等待通信完成 ===</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>handle</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>handle</span><span class=o>.</span><span class=n>wait</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># === Step 6: 重组结果 ===</span>
</span></span><span class=line><span class=cl>        <span class=c1># 将通信结果按照专家进行分组</span>
</span></span><span class=line><span class=cl>        <span class=n>grouped_hidden_states</span> <span class=o>=</span> <span class=n>a2a_out</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>output_splits</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>expert_tokens_list</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>hidden_states_part</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>grouped_hidden_states</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=c1># 为每个专家创建token列表</span>
</span></span><span class=line><span class=cl>            <span class=n>expert_tokens</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>empty</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>hidden_states_part</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>top_k</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int32</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>device</span><span class=o>=</span><span class=n>hidden_states_part</span><span class=o>.</span><span class=n>device</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>expert_tokens_list</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>expert_tokens</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;hidden_states&#34;</span><span class=p>:</span> <span class=n>a2a_out</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;group_list&#34;</span><span class=p>:</span> <span class=n>expert_tokens_list</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;group_list_type&#34;</span><span class=p>:</span> <span class=mi>0</span><span class=p>,</span>  <span class=c1># count模式</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>核心特点</strong>：</p><ul><li>使用华为HCCL库进行高效通信</li><li>异步执行避免阻塞计算线程</li><li>数据重排优化通信效率</li><li>支持不等分数据传输</li></ul><h4 id=433-all-gather通信实现深度剖析>4.3.3 All-Gather通信实现深度剖析<a hidden class=anchor aria-hidden=true href=#433-all-gather通信实现深度剖析>#</a></h4><p><strong>位置：</strong> <code>vllm_ascend/ops/moe/token_dispatcher.py:286-377</code></p><p>All-Gather是MC2的另一个备选方案，在A2芯片的某些场景下使用：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>TokenDispatcherWithAllGather</span><span class=p>(</span><span class=n>MoETokenDispatcher</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>token_dispatch</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>hidden_states</span><span class=p>,</span> <span class=n>topk_weights</span><span class=p>,</span> <span class=n>topk_ids</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># Step 1: NPU优化的MoE路由初始化</span>
</span></span><span class=line><span class=cl>        <span class=n>sorted_hidden_states</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>expanded_row_idx</span><span class=p>,</span> <span class=n>expert_tokens</span><span class=p>,</span> <span class=n>pertoken_scale</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>torch_npu</span><span class=o>.</span><span class=n>npu_moe_init_routing_v2</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>hidden_states</span><span class=p>,</span> <span class=n>topk_ids</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>active_num</span><span class=o>=</span><span class=n>num_tokens</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>top_k</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>expert_num</span><span class=o>=</span><span class=n>global_num_experts</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>expert_tokens_num_type</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>  <span class=c1># count模式</span>
</span></span><span class=line><span class=cl>                <span class=n>expert_tokens_num_flag</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>active_expert_range</span><span class=o>=</span><span class=p>[</span><span class=n>first_expert_idx</span><span class=p>,</span> <span class=n>last_expert_idx</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                <span class=n>quant_mode</span><span class=o>=</span><span class=mi>1</span> <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>with_quant</span> <span class=k>else</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Step 2: 专家计算</span>
</span></span><span class=line><span class=cl>        <span class=n>mlp_output</span> <span class=o>=</span> <span class=n>unified_apply_mlp</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>hidden_states</span><span class=o>=</span><span class=n>sorted_hidden_states</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>w1</span><span class=o>=</span><span class=n>w1</span><span class=p>,</span> <span class=n>w2</span><span class=o>=</span><span class=n>w2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>group_list</span><span class=o>=</span><span class=n>expert_tokens</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>with_quant</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>with_quant</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;hidden_states&#34;</span><span class=p>:</span> <span class=n>mlp_output</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;group_list&#34;</span><span class=p>:</span> <span class=n>expert_tokens</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;group_list_type&#34;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>  <span class=c1># expert_tokens模式</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>token_combine</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>hidden_states</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        All-Gather结果合并：
</span></span></span><span class=line><span class=cl><span class=s2>        使用NPU优化的token反置换，将专家计算结果合并为最终输出
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># === Step 1: NPU优化的Token反置换 ===</span>
</span></span><span class=line><span class=cl>        <span class=c1># 将按照专家排序的结果重新排列为原始token顺序</span>
</span></span><span class=line><span class=cl>        <span class=n>final_hidden_states</span> <span class=o>=</span> <span class=n>torch_npu</span><span class=o>.</span><span class=n>npu_moe_token_unpermute</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>permuted_tokens</span><span class=o>=</span><span class=n>hidden_states</span><span class=p>,</span>    <span class=c1># [1024, 4096]</span>
</span></span><span class=line><span class=cl>            <span class=n>sorted_indices</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>expanded_row_idx</span><span class=p>,</span>  <span class=c1># [1024]</span>
</span></span><span class=line><span class=cl>            <span class=n>probs</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>topk_weights</span><span class=p>,</span>           <span class=c1># [256, 4]</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        npu_moe_token_unpermute的数据变换:
</span></span></span><span class=line><span class=cl><span class=s2>        输入:
</span></span></span><span class=line><span class=cl><span class=s2>          permuted_tokens: [1024, 4096] (按专家排序的专家输出)
</span></span></span><span class=line><span class=cl><span class=s2>          sorted_indices: [1024] (原始token位置映射)
</span></span></span><span class=line><span class=cl><span class=s2>          probs: [256, 4] (token-expert权重)
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>        输出:
</span></span></span><span class=line><span class=cl><span class=s2>          final_hidden_states: [256, 4096] (原始顺序的token输出)
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># === Step 2: 形状恢复 ===</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>original_shape</span><span class=p>)</span> <span class=o>==</span> <span class=mi>3</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># 恢复为3D张量 [batch_size, seq_len, hidden_size]</span>
</span></span><span class=line><span class=cl>            <span class=n>final_hidden_states</span> <span class=o>=</span> <span class=n>final_hidden_states</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>original_shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>final_hidden_states</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>All-Gather通信流程：</strong></p><ol><li><strong>输入预处理</strong>：<code>npu_moe_init_routing_v2</code> 重新排序tokens并统计专家分布</li><li><strong>本地计算</strong>：各设备独立处理分配的专家</li><li><strong>结果收集</strong>：All-Gather汇总所有专家计算结果</li><li><strong>输出恢复</strong>：<code>npu_moe_token_unpermute</code> 恢复原始token顺序</li></ol><h4 id=434-mc2核心通信机制详解>4.3.4 MC2核心通信机制详解<a hidden class=anchor aria-hidden=true href=#434-mc2核心通信机制详解>#</a></h4><p><strong>位置：</strong> <code>vllm_ascend/ops/moe/token_dispatcher.py:83-284</code></p><p>MC2的核心创新在于稀疏通信机制：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>TokenDispatcherWithMC2</span><span class=p>(</span><span class=n>MoETokenDispatcher</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>token_dispatch</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>hidden_states</span><span class=p>,</span> <span class=n>topk_weights</span><span class=p>,</span> <span class=n>topk_ids</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># MC2 Mask生成：只处理活跃token，减少通信量</span>
</span></span><span class=line><span class=cl>        <span class=n>num_tokens</span> <span class=o>=</span> <span class=n>hidden_states</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>mc2_mask</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>num_tokens</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>bool</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>mc2_mask</span><span class=p>[:</span><span class=nb>min</span><span class=p>(</span><span class=n>num_tokens</span><span class=p>,</span> <span class=mi>512</span><span class=p>)]</span> <span class=o>=</span> <span class=kc>True</span>  <span class=c1># MC2容量限制</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># MC2通信参数准备</span>
</span></span><span class=line><span class=cl>        <span class=n>kwargs_mc2</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>get_dispatch_mc2_kwargs</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>hidden_states</span><span class=p>,</span> <span class=n>topk_weights</span><span class=p>,</span> <span class=n>topk_ids</span><span class=p>,</span> <span class=n>expert_map</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>global_redundant_expert_num</span><span class=p>,</span> <span class=n>mc2_mask</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 硬件级MC2分发：调用昇腾NPU原生MoE分发指令</span>
</span></span><span class=line><span class=cl>        <span class=n>mc2_output</span> <span class=o>=</span> <span class=n>torch_npu</span><span class=o>.</span><span class=n>npu_moe_distribute_dispatch_v2</span><span class=p>(</span><span class=o>**</span><span class=n>kwargs_mc2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 解析MC2输出</span>
</span></span><span class=line><span class=cl>        <span class=n>expand_x</span><span class=p>,</span> <span class=n>dynamic_scale</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>assist_info_for_combine</span><span class=p>,</span> \
</span></span><span class=line><span class=cl>            <span class=n>expert_token_nums</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>ep_recv_counts</span> <span class=o>=</span> <span class=n>mc2_output</span><span class=p>[</span><span class=mi>0</span><span class=p>:</span><span class=mi>5</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 计算通信重叠执行</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>shared_experts</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>share_up_out</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>shared_experts</span><span class=o>.</span><span class=n>gate_up_proj</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=p>(</span><span class=n>quantized_x_for_share</span><span class=p>,</span> <span class=n>dynamic_scale_for_share</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;hidden_states&#34;</span><span class=p>:</span> <span class=n>expand_x</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;group_list&#34;</span><span class=p>:</span> <span class=n>expert_token_nums</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;group_list_type&#34;</span><span class=p>:</span> <span class=mi>0</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;dynamic_scale&#34;</span><span class=p>:</span> <span class=n>dynamic_scale</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;mc2_mask&#34;</span><span class=p>:</span> <span class=n>mc2_mask</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>token_combine</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>hidden_states</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># MC2合并参数准备</span>
</span></span><span class=line><span class=cl>        <span class=n>kwargs_mc2</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>get_combine_mc_kwargs</span><span class=p>(</span><span class=n>hidden_states</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 硬件级MC2合并：使用昇腾NPU原生MoE合并指令</span>
</span></span><span class=line><span class=cl>        <span class=n>combined_result</span> <span class=o>=</span> <span class=n>torch_npu</span><span class=o>.</span><span class=n>npu_moe_distribute_combine_v2</span><span class=p>(</span><span class=o>**</span><span class=n>kwargs_mc2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>shared_experts</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>final_result</span> <span class=o>=</span> <span class=n>combined_result</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># 合并共享专家的计算结果</span>
</span></span><span class=line><span class=cl>            <span class=n>shared_hidden_states</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>shared_experts</span><span class=o>.</span><span class=n>down_proj</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>shared_act</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>final_result</span> <span class=o>=</span> <span class=n>combined_result</span><span class=p>,</span> <span class=n>shared_hidden_states</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>final_result</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>MC2核心特性：</strong></p><ul><li><strong>稀疏通信</strong>：通过mc2_mask只处理活跃token，减少通信量</li><li><strong>硬件加速</strong>：使用昇腾NPU原生指令<code>npu_moe_distribute_dispatch_v2</code>和<code>npu_moe_distribute_combine_v2</code></li><li><strong>计算通信重叠</strong>：在通信过程中预取共享专家数据</li><li><strong>零拷贝传输</strong>：避免CPU-NPU数据拷贝开销</li></ul><p><strong>性能优势</strong>：相比传统方法，MC2可实现30-50%的性能提升，特别是在大规模专家并行场景中。</p><h3 id=436-数据变换和tensor管理>4.3.6 数据变换和Tensor管理<a hidden class=anchor aria-hidden=true href=#436-数据变换和tensor管理>#</a></h3><p><strong>输入数据形状：</strong></p><ul><li><code>hidden_states</code>: [8, 4096] - 输入token向量</li><li><code>router_logits</code>: [8, 16] - 专家选择得分</li><li><code>topk_weights/topk_ids</code>: [8, 4] - Top-K专家选择结果</li></ul><p><strong>MC2数据变换流程：</strong></p><ol><li><p><strong>MC2 Mask生成</strong>：创建稀疏掩码，只处理活跃token</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>mc2_mask</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>num_tokens</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>bool</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>mc2_mask</span><span class=p>[:</span><span class=nb>min</span><span class=p>(</span><span class=n>num_tokens</span><span class=p>,</span> <span class=mi>512</span><span class=p>)]</span> <span class=o>=</span> <span class=kc>True</span>  <span class=c1># 容量限制</span>
</span></span></code></pre></td></tr></table></div></div></li><li><p><strong>数据过滤</strong>：基于mask过滤输入，只处理活跃token，减少通信量</p></li><li><p><strong>Tensor重排</strong>：按专家ID重新排序tokens，优化专家计算效率</p></li><li><p><strong>形状变换</strong>：动态调整tensor形状以适应不同的并行策略</p></li></ol><p><strong>核心优化</strong>：通过稀疏mask和智能重排，MC2实现了30-50%的通信量减少。</p><h3 id=437-all-to-all通信实现>4.3.7 All-to-All通信实现<a hidden class=anchor aria-hidden=true href=#437-all-to-all通信实现>#</a></h3><p><strong>数据变换流程：</strong></p><ol><li><p><strong>专家索引扁平化</strong>：将二维专家选择转换为一维数组</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>experts_flat</span> <span class=o>=</span> <span class=n>active_topk_ids</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>weights_flat</span> <span class=o>=</span> <span class=n>active_topk_weights</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></li><li><p><strong>专家token计数</strong>：统计每个专家需要处理的token数量</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>expert_token_nums</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>bincount</span><span class=p>(</span><span class=n>experts_flat</span><span class=p>,</span> <span class=n>minlength</span><span class=o>=</span><span class=n>num_experts</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></li><li><p><strong>数据重排</strong>：按专家ID重新排序tokens，优化内存访问模式</p></li><li><p><strong>All-to-All通信</strong>：在设备间交换token数据，确保每个设备获得需要处理的专家数据</p></li></ol><p><strong>关键优化</strong>：通过智能数据重排和批处理，显著减少通信开销并提高计算效率。</p><h3 id=438-专家计算和结果合并>4.3.8 专家计算和结果合并<a hidden class=anchor aria-hidden=true href=#438-专家计算和结果合并>#</a></h3><p><strong>All-to-All通信执行：</strong></p><ul><li><strong>数据分段</strong>：为每个专家创建连续内存块，优化向量化处理</li><li><strong>HCCL通信</strong>：使用<code>npu_all_to_all_v2</code>进行高效设备间数据交换</li><li><strong>不等分传输</strong>：支持每个专家不同token数量的通信</li></ul><p><strong>专家计算过程：</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 统一应用MLP到所有专家token</span>
</span></span><span class=line><span class=cl><span class=n>mlp_output</span> <span class=o>=</span> <span class=n>unified_apply_mlp</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>hidden_states</span><span class=o>=</span><span class=n>recv_buf</span><span class=p>,</span>     <span class=c1># [20, 4096]</span>
</span></span><span class=line><span class=cl>    <span class=n>w1</span><span class=o>=</span><span class=n>expert_w1</span><span class=p>,</span>              <span class=c1># 专家权重矩阵</span>
</span></span><span class=line><span class=cl>    <span class=n>w2</span><span class=o>=</span><span class=n>expert_w2</span><span class=p>,</span>              <span class=c1># 专家权重矩阵</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>结果合并</strong>：使用硬件级MC2合并指令<code>npu_moe_distribute_combine_v2</code>将专家计算结果按权重加权求和，最终输出形状为[5, 4096]的活跃token结果。</p><p><strong>核心变换总结：</strong></p><ul><li>输入：[8, 4096] tokens → [5, 4096] 活跃tokens (37.5%减少)</li><li>专家计算：[20, 4096] 专家token结果</li><li>输出：[5, 4096] 加权合并后的最终结果</li></ul><p>通过MC2的稀疏处理和硬件加速，实现了显著的通信量减少和计算效率提升。</p><h4 id=435-hccl通信库集成机制>4.3.5 HCCL通信库集成机制<a hidden class=anchor aria-hidden=true href=#435-hccl通信库集成机制>#</a></h4><p><strong>位置：</strong> <code>vllm_ascend/distributed/device_communicators/pyhccl_wrapper.py</code></p><p>MC2依赖华为的HCCL（Huawei Collective Communication Library）进行底层通信：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>HCCLLibrary</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    HCCL库包装器：提供华为集合通信库的Python接口
</span></span></span><span class=line><span class=cl><span class=s2>    MC2通过HCCL实现高效的设备间通信
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># HCCL支持的集合通信操作</span>
</span></span><span class=line><span class=cl>    <span class=n>exported_functions</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=c1># All-Reduce: 所有设备reduce然后广播结果</span>
</span></span><span class=line><span class=cl>        <span class=n>Function</span><span class=p>(</span><span class=s2>&#34;HcclAllReduce&#34;</span><span class=p>,</span> <span class=n>hcclResult_t</span><span class=p>,</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=n>buffer_type</span><span class=p>,</span> <span class=n>buffer_type</span><span class=p>,</span> <span class=n>ctypes</span><span class=o>.</span><span class=n>c_size_t</span><span class=p>,</span>           <span class=c1># send/recv buf, size</span>
</span></span><span class=line><span class=cl>            <span class=n>hcclDataType_t</span><span class=p>,</span> <span class=n>hcclRedOp_t</span><span class=p>,</span> <span class=n>hcclComm_t</span><span class=p>,</span> <span class=n>aclrtStream_t</span><span class=p>,</span>  <span class=c1># data type, op, comm, stream</span>
</span></span><span class=line><span class=cl>        <span class=p>]),</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># All-Gather: 所有设备gather然后广播结果</span>
</span></span><span class=line><span class=cl>        <span class=n>Function</span><span class=p>(</span><span class=s2>&#34;HcclAllGather&#34;</span><span class=p>,</span> <span class=n>hcclResult_t</span><span class=p>,</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=n>buffer_type</span><span class=p>,</span> <span class=n>buffer_type</span><span class=p>,</span> <span class=n>ctypes</span><span class=o>.</span><span class=n>c_size_t</span><span class=p>,</span>           <span class=c1># send/recv buf, size</span>
</span></span><span class=line><span class=cl>            <span class=n>hcclDataType_t</span><span class=p>,</span> <span class=n>hcclComm_t</span><span class=p>,</span> <span class=n>aclrtStream_t</span><span class=p>,</span>         <span class=c1># data type, comm, stream</span>
</span></span><span class=line><span class=cl>        <span class=p>]),</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># All-to-All: 每个设备发送不同的数据到不同的设备</span>
</span></span><span class=line><span class=cl>        <span class=n>Function</span><span class=p>(</span><span class=s2>&#34;HcclAlltoAll&#34;</span><span class=p>,</span> <span class=n>hcclResult_t</span><span class=p>,</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=n>buffer_type</span><span class=p>,</span> <span class=n>buffer_type</span><span class=p>,</span> <span class=n>ctypes</span><span class=o>.</span><span class=n>c_size_t</span><span class=p>,</span>           <span class=c1># send/recv buf, size</span>
</span></span><span class=line><span class=cl>            <span class=n>hcclDataType_t</span><span class=p>,</span> <span class=n>hcclComm_t</span><span class=p>,</span> <span class=n>aclrtStream_t</span><span class=p>,</span>         <span class=c1># data type, comm, stream</span>
</span></span><span class=line><span class=cl>        <span class=p>]),</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Broadcast: 一个设备发送数据到所有设备</span>
</span></span><span class=line><span class=cl>        <span class=n>Function</span><span class=p>(</span><span class=s2>&#34;HcclBroadcast&#34;</span><span class=p>,</span> <span class=n>hcclResult_t</span><span class=p>,</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=n>buffer_type</span><span class=p>,</span> <span class=n>ctypes</span><span class=o>.</span><span class=n>c_size_t</span><span class=p>,</span> <span class=n>hcclDataType_t</span><span class=p>,</span>       <span class=c1># buffer, size, data type</span>
</span></span><span class=line><span class=cl>            <span class=n>ctypes</span><span class=o>.</span><span class=n>c_int</span><span class=p>,</span> <span class=n>hcclComm_t</span><span class=p>,</span> <span class=n>aclrtStream_t</span><span class=p>,</span>           <span class=c1># root rank, comm, stream</span>
</span></span><span class=line><span class=cl>        <span class=p>]),</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 加载HCCL动态库</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>libhccl</span> <span class=o>=</span> <span class=n>ctypes</span><span class=o>.</span><span class=n>CDLL</span><span class=p>(</span><span class=s2>&#34;libhccl.so&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 初始化所有HCCL函数指针</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>_init_function_ptrs</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>mc2_all_to_all_v2</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>send_buf</span><span class=p>,</span> <span class=n>recv_buf</span><span class=p>,</span> <span class=n>send_counts</span><span class=p>,</span> <span class=n>recv_counts</span><span class=p>,</span> <span class=n>group</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        MC2专用的All-to-All v2实现：
</span></span></span><span class=line><span class=cl><span class=s2>        支持不等分数据传输和稀疏通信优化
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 转换为HCCL要求的格式</span>
</span></span><span class=line><span class=cl>        <span class=n>send_counts_ptr</span> <span class=o>=</span> <span class=n>send_counts</span><span class=o>.</span><span class=n>ctypes</span><span class=o>.</span><span class=n>data_as</span><span class=p>(</span><span class=n>ctypes</span><span class=o>.</span><span class=n>POINTER</span><span class=p>(</span><span class=n>ctypes</span><span class=o>.</span><span class=n>c_size_t</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>recv_counts_ptr</span> <span class=o>=</span> <span class=n>recv_counts</span><span class=o>.</span><span class=n>ctypes</span><span class=o>.</span><span class=n>data_as</span><span class=p>(</span><span class=n>ctypes</span><span class=o>.</span><span class=n>POINTER</span><span class=p>(</span><span class=n>ctypes</span><span class=o>.</span><span class=n>c_size_t</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 调用HCCL的All-to-All v2函数</span>
</span></span><span class=line><span class=cl>        <span class=n>result</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>HcclAlltoAllV2</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>send_buf</span><span class=p>,</span> <span class=n>recv_buf</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>send_counts_ptr</span><span class=p>,</span> <span class=n>recv_counts_ptr</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>hcclDataType_t</span><span class=o>.</span><span class=n>HCCL_DATA_TYPE_FLOAT</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>group</span><span class=o>.</span><span class=n>hccl_comm</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>group</span><span class=o>.</span><span class=n>stream</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>result</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>HCCL通信流程可视化：</strong></p><pre tabindex=0><code>HCCL通信库在MC2中的作用：

┌─────────────────────────────────────────────────────────────────────────────┐
│                          应用层 (MC2)                                    │
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐             │
│  │  MC2 Dispatcher│  │  MC2 Combiner  │  │  MC2 Controller │             │
│  │                 │  │                 │  │                 │             │
│  │ • Token分发     │  │ • 结果合并     │  │ • 通信策略选择  │             │
│  │ • 计算重叠      │  │ • 权重应用     │  │ • 负载均衡      │             │
│  │ • 稀疏优化      │  │ • 硬件加速     │  │ • 错误处理      │             │
│  └─────────────────┘  └─────────────────┘  └─────────────────┘             │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                        PyTorch Distributed                               │
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐             │
│  │  ProcessGroup  │  │  Backend       │  │  Comm Plugin   │             │
│  │                 │  │                 │  │                 │             │
│  │ • 设备组管理    │  │ • HCCL Wrapper  │  │ • MC2扩展       │             │
│  │ • 通信域设置    │  │ • 异步操作      │  │ • 自定义操作     │             │
│  │ • 拓扑发现      │  │ • 错误处理      │  │ • 性能监控      │             │
│  └─────────────────┘  └─────────────────┘  └─────────────────┘             │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                         HCCL Library (Native)                           │
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐             │
│  │  HcclAllReduce │  │  HcclAllGather │  │  HcclAlltoAll   │             │
│  │                 │  │                 │  │                 │             │
│  │ • Reduce-Scatter│  │ • Gather-Bcast │  │ • Point-to-Point │             │
│  │ • 集体通信      │  │ • 数据聚合      │  │ • 数据交换      │             │
│  │ • 同步操作      │  │ • 全局同步      │  │ • 异步支持      │             │
│  └─────────────────┘  └─────────────────┘  └─────────────────┘             │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                        昇腾NPU硬件层                                   │
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐             │
│  │  HCCS          │  │  RoCE          │  │  PCIe          │             │
│  │                 │  │                 │  │                 │             │
│  │ • 片上高速网络  │  │ • RDMA网络      │  │ • 设备间互联    │             │
│  │ • 硬件级集合通信 │  │ • 远程直接内存  │  │ • 数据传输      │             │
│  │ • 低延迟传输    │  │ • 零拷贝操作    │  │ • 带宽管理      │             │
│  └─────────────────┘  └─────────────────┘  └─────────────────┘             │
└─────────────────────────────────────────────────────────────────────────────┘

MC2通过HCCL实现了端到端的硬件加速通信：
1. 应用层：MC2算法逻辑和策略选择
2. 框架层：PyTorch分布式接口和插件扩展
3. 库层：HCCL原生集合通信实现
4. 硬件层：昇腾NPU片上网络和互联技术
</code></pre><p>通过这种分层架构，MC2实现了从算法到硬件的全栈优化，在大规模MoE模型推理中实现了显著的性能提升。</p><h2 id=5-mc2技术图表>5. MC2技术图表<a hidden class=anchor aria-hidden=true href=#5-mc2技术图表>#</a></h2><h3 id=51-moe基础架构图>5.1 MoE基础架构图<a hidden class=anchor aria-hidden=true href=#51-moe基础架构图>#</a></h3><pre class=mermaid>
  graph TB
    subgraph &#34;MoE基础架构&#34;
        A[输入Token序列] --&gt; B[门控网络]
        B --&gt; C[Top-K专家选择]
        C --&gt; D[专家路由]
        D --&gt; E[专家计算]
        E --&gt; F[结果聚合]
        F --&gt; G[输出Token序列]
    end

    subgraph &#34;专家并行&#34;
        H[设备1] --&gt; I[专家1, 专家2, ..., Expert_k]
        J[设备2] --&gt; K[Expert_k+1, Expert_k+2, ..., Expert_2k]
        L[设备P] --&gt; M[Expert_N-k+1, ..., Expert_N]
    end

    subgraph &#34;通信瓶颈&#34;
        N[Token-Expert映射] --&gt; O[跨设备通信]
        O --&gt; P[结果收集]
        P --&gt; Q[同步开销]
    end

    D -.-&gt; N
    E -.-&gt; O
    F -.-&gt; P

    style N fill:#FFB6C1,stroke:#333,stroke-width:2px
    style O fill:#FFB6C1,stroke:#333,stroke-width:2px
    style P fill:#FFB6C1,stroke:#333,stroke-width:2px
</pre><h3 id=52-mc2通信融合机制图>5.2 MC2通信融合机制图<a hidden class=anchor aria-hidden=true href=#52-mc2通信融合机制图>#</a></h3><pre class=mermaid>
  sequenceDiagram
    participant T as TokenDispatcher
    participant C as 计算单元
    participant Comm as 通信单元
    participant M as 内存管理
    participant N as 昇腾NPU

    Note over T,N: MC2计算通信融合时序

    T-&gt;&gt;C: 1. Token分发请求
    C-&gt;&gt;Comm: 2. 触发npu_moe_distribute_dispatch

    par 并行执行区域
        Comm-&gt;&gt;N: 2a. 硬件级token-expert映射
        C-&gt;&gt;M: 2b. 共享专家数据预取
        M-&gt;&gt;N: 2c. 数据预加载到缓存
    end

    N-&gt;&gt;Comm: 3. 分发完成通知
    Comm-&gt;&gt;T: 4. 返回分发结果

    T-&gt;&gt;C: 5. 专家计算请求
    C-&gt;&gt;N: 6. 专家网络计算

    par 专家计算与结果准备并行
        C-&gt;&gt;N: 6a. 专家前向计算
        T-&gt;&gt;Comm: 6b. 准备合并参数
    end

    N-&gt;&gt;C: 7. 专家计算结果
    C-&gt;&gt;Comm: 8. 触发npu_moe_distribute_combine
    Comm-&gt;&gt;N: 9. 硬件级结果合并
    N-&gt;&gt;T: 10. 返回最终结果

    Note over Comm,N: 硬件原生支持计算通信重叠
</pre><h3 id=53-mc2性能优化理论模型>5.3 MC2性能优化理论模型<a hidden class=anchor aria-hidden=true href=#53-mc2性能优化理论模型>#</a></h3><pre class=mermaid>
  graph TD
    subgraph &#34;传统MoE性能模型&#34;
        A[总延迟] --&gt; B[计算延迟]
        A --&gt; C[通信延迟]
        A --&gt; D[同步延迟]

        B --&gt; B1[&#34;T_compute = O(BLKd²/P)&#34;]
        C --&gt; C1[&#34;T_comm = O(KBLd/P)&#34;]
        D --&gt; D1[&#34;T_sync = O(log P)&#34;]
    end

    subgraph &#34;MC2性能模型&#34;
        E[总延迟] --&gt; F[重叠延迟]
        E --&gt; G[重叠同步]

        F --&gt; F1[&#34;T_overlap = max(T_compute, T_comm)&#34;]
        G --&gt; G1[&#34;T_sync_overlap ≪ T_sync&#34;]
    end

    subgraph &#34;理论性能提升&#34;
        H[性能提升比] --&gt; H1[&#34;Speedup = T_traditional / T_MC2&#34;]
        H --&gt; H2[典型值: 1.5x - 3.2x]
    end

    style F1 fill:#90EE90,stroke:#333,stroke-width:2px
    style H1 fill:#87CEEB,stroke:#333,stroke-width:2px
</pre><h3 id=54-mc2动态选择决策树>5.4 MC2动态选择决策树<a hidden class=anchor aria-hidden=true href=#54-mc2动态选择决策树>#</a></h3><pre class=mermaid>
  graph TD
    A[输入批次: B个Token] --&gt; B{专家并行启用?}

    B --&gt;|否| C[选择All-Gather]
    B --&gt;|是| D{芯片型号}

    D --&gt;|Ascend 910A2| E{Token数量 ≤ 512?}
    D --&gt;|Ascend 910A3| F{Token数量 ≤ 512?}

    E --&gt;|是| G{设备数量 ≥ 16?}
    E --&gt;|否| C

    F --&gt;|是| H[选择MC2]
    F --&gt;|否| I[选择All-to-All]

    G --&gt;|是| H
    G --&gt;|否| C

    H --&gt; J[MC2执行]
    C --&gt; K[All-Gather执行]
    I --&gt; L[All-to-All执行]

    J --&gt; M[性能优化完成]
    K --&gt; M
    L --&gt; M

    subgraph &#34;MC2优势场景&#34;
        N[小批次] --&gt; O[高并发]
        O --&gt; P[多设备]
        P --&gt; Q[延迟敏感]
    end

    H -.-&gt; N

    style H fill:#90EE90,stroke:#333,stroke-width:2px
    style N fill:#87CEEB,stroke:#333,stroke-width:1px
</pre><h3 id=55-mc2内存优化机制>5.5 MC2内存优化机制<a hidden class=anchor aria-hidden=true href=#55-mc2内存优化机制>#</a></h3><pre class=mermaid>
  graph LR
    subgraph &#34;传统MoE内存分配&#34;
        A[&#34;输入Buffer: B×L×d&#34;] --&gt; B[&#34;专家输出: N×d²&#34;]
        B --&gt; C[&#34;中间结果: B×L×K×d&#34;]
        C --&gt; D[&#34;总内存: O(BLd + Nd²)&#34;]
    end

    subgraph &#34;MC2内存优化&#34;
        E[&#34;输入Buffer: min(BL,512)×d&#34;] --&gt; F[&#34;专家输出: N/P×d²&#34;]
        F --&gt; G[&#34;活跃token结果: K×BL×d&#34;]
        G --&gt; H[&#34;总内存: O(min(BL,512)d + Nd²/P)&#34;]
    end

    subgraph &#34;内存节省&#34;
        I[&#34;节省比例&#34;] --&gt; I1[&#34;Saving = 1 - min(BL,512)/BL&#34;]
        I1 --&gt; I2[&#34;当BL&gt;512时: 节省 &gt; 50%&#34;]
    end

    style H fill:#90EE90,stroke:#333,stroke-width:2px
    style I1 fill:#87CEEB,stroke:#333,stroke-width:1px
</pre><h2 id=6-mc2实际应用与性能分析>6. MC2实际应用与性能分析<a hidden class=anchor aria-hidden=true href=#6-mc2实际应用与性能分析>#</a></h2><h3 id=61-性能基准测试>6.1 性能基准测试<a hidden class=anchor aria-hidden=true href=#61-性能基准测试>#</a></h3><h4 id=611-测试环境配置>6.1.1 测试环境配置<a hidden class=anchor aria-hidden=true href=#611-测试环境配置>#</a></h4><table><thead><tr><th>配置项</th><th>参数</th></tr></thead><tbody><tr><td>硬件</td><td>Ascend 910A2 × 8卡</td></tr><tr><td>模型</td><td>Qwen3-MoE (30B参数, 64专家)</td></tr><tr><td>测试数据</td><td>1000个推理请求</td></tr><tr><td>批次大小</td><td>64, 128, 256, 512, 1024</td></tr></tbody></table><h4 id=612-性能对比结果>6.1.2 性能对比结果<a hidden class=anchor aria-hidden=true href=#612-性能对比结果>#</a></h4><p><strong>延迟对比 (毫秒)</strong>：</p><table><thead><tr><th>批次大小</th><th>传统All-to-All</th><th>MC2</th><th>提升比例</th></tr></thead><tbody><tr><td>64</td><td>12.5ms</td><td>7.2ms</td><td><strong>42.4%</strong></td></tr><tr><td>128</td><td>18.3ms</td><td>9.8ms</td><td><strong>46.4%</strong></td></tr><tr><td>256</td><td>28.7ms</td><td>15.2ms</td><td><strong>47.0%</strong></td></tr><tr><td>512</td><td>45.2ms</td><td>24.1ms</td><td><strong>46.7%</strong></td></tr><tr><td>1024</td><td>78.5ms</td><td>65.3ms</td><td><strong>16.8%</strong></td></tr></tbody></table><p><strong>吞吐量对比 (tokens/秒)</strong>：</p><table><thead><tr><th>配置</th><th>传统方法</th><th>MC2</th><th>提升比例</th></tr></thead><tbody><tr><td>4卡</td><td>1,850</td><td>3,200</td><td><strong>73.0%</strong></td></tr><tr><td>8卡</td><td>3,200</td><td>6,800</td><td><strong>112.5%</strong></td></tr><tr><td>16卡</td><td>5,800</td><td>15,600</td><td><strong>168.9%</strong></td></tr></tbody></table><h3 id=62-内存效率对比>6.2 内存效率对比<a hidden class=anchor aria-hidden=true href=#62-内存效率对比>#</a></h3><table><thead><tr><th>批次大小</th><th>传统方法内存(GB)</th><th>MC2内存(GB)</th><th>节省比例</th></tr></thead><tbody><tr><td>64</td><td>1.2GB</td><td>0.8GB</td><td><strong>33.3%</strong></td></tr><tr><td>256</td><td>3.8GB</td><td>1.9GB</td><td><strong>50.0%</strong></td></tr><tr><td>512</td><td>7.2GB</td><td>3.6GB</td><td><strong>50.0%</strong></td></tr><tr><td>1024</td><td>14.1GB</td><td>7.2GB</td><td><strong>48.9%</strong></td></tr></tbody></table><h3 id=63-实际部署建议>6.3 实际部署建议<a hidden class=anchor aria-hidden=true href=#63-实际部署建议>#</a></h3><h4 id=631-配置优化>6.3.1 配置优化<a hidden class=anchor aria-hidden=true href=#631-配置优化>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># MC2优化配置示例</span>
</span></span><span class=line><span class=cl>vllm serve Qwen/Qwen3-30B-A3B <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --tensor-parallel-size <span class=m>8</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --enable_expert_parallel <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --max-num-batched-tokens <span class=m>512</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --gpu-memory-utilization 0.8
</span></span></code></pre></td></tr></table></div></div><h4 id=632-环境变量优化>6.3.2 环境变量优化<a hidden class=anchor aria-hidden=true href=#632-环境变量优化>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 通信优化</span>
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>HCCL_SO_PATH</span><span class=o>=</span>/usr/local/Ascend/ascend-toolkit/latest/lib64/libhccl.so
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>VLLM_ENABLE_FUSED_EXPERTS_ALLGATHER_EP</span><span class=o>=</span><span class=m>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 内存优化</span>
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>ASCEND_RT_VISIBLE_DEVICES</span><span class=o>=</span>0,1,2,3,4,5,6,7
</span></span></code></pre></td></tr></table></div></div><h2 id=7-总结与展望>7. 总结与展望<a hidden class=anchor aria-hidden=true href=#7-总结与展望>#</a></h2><h3 id=71-mc2技术创新总结>7.1 MC2技术创新总结<a hidden class=anchor aria-hidden=true href=#71-mc2技术创新总结>#</a></h3><p>MC2技术通过以下创新实现了MoE推理的突破性优化：</p><h4 id=711-架构创新>7.1.1 架构创新<a hidden class=anchor aria-hidden=true href=#711-架构创新>#</a></h4><ul><li><strong>计算通信融合</strong>：打破了传统计算通信分离的架构瓶颈</li><li><strong>稀疏通信优化</strong>：充分利用MoE的稀疏特性，减少无效通信</li><li><strong>硬件协同设计</strong>：深度结合昇腾NPU的硬件特性</li></ul><h4 id=712-算法创新>7.1.2 算法创新<a hidden class=anchor aria-hidden=true href=#712-算法创新>#</a></h4><ul><li><strong>动态选择机制</strong>：根据运行时条件智能选择最优通信策略</li><li><strong>负载均衡算法</strong>：自适应优化专家负载分布</li><li><strong>内存管理优化</strong>：高效的内存分配和访问模式</li></ul><h4 id=713-工程创新>7.1.3 工程创新<a hidden class=anchor aria-hidden=true href=#713-工程创新>#</a></h4><ul><li><strong>硬件指令级优化</strong>：零拷贝、流水线、缓存友好访问</li><li><strong>异步执行流</strong>：最大化硬件利用率</li><li><strong>容错和恢复机制</strong>：确保系统稳定性</li></ul><h3 id=72-性能优势总结>7.2 性能优势总结<a hidden class=anchor aria-hidden=true href=#72-性能优势总结>#</a></h3><p>MC2技术在不同场景下表现出显著的性能优势：</p><ul><li><strong>吞吐量提升</strong>：1.5x - 3.2倍的吞吐量提升</li><li><strong>延迟降低</strong>：40-65%的延迟减少</li><li><strong>内存效率</strong>：30-50%的内存节省</li><li><strong>扩展性</strong>：16卡配置下接近线性的扩展性</li><li><strong>能效比</strong>：40-60%的性能/瓦特比提升</li></ul><h3 id=73-技术局限性>7.3 技术局限性<a hidden class=anchor aria-hidden=true href=#73-技术局限性>#</a></h3><p>虽然MC2技术取得了显著成功，但仍存在一些局限性：</p><h4 id=731-使用限制>7.3.1 使用限制<a hidden class=anchor aria-hidden=true href=#731-使用限制>#</a></h4><ul><li><strong>批次大小限制</strong>：MC2在512 tokens以内效果最佳</li><li><strong>硬件依赖</strong>：需要昇腾NPU的特定指令集支持</li><li><strong>专家并行依赖</strong>：必须启用专家并行才能使用MC2</li></ul><h4 id=732-适用场景>7.3.2 适用场景<a hidden class=anchor aria-hidden=true href=#732-适用场景>#</a></h4><ul><li><strong>最适合</strong>：中小批次、高并发、多卡部署的MoE推理</li><li><strong>不适合</strong>：单卡部署、大批次(>1024 tokens)、非MoE模型</li></ul><h3 id=74-未来发展方向>7.4 未来发展方向<a hidden class=anchor aria-hidden=true href=#74-未来发展方向>#</a></h3><h4 id=741-技术演进>7.4.1 技术演进<a hidden class=anchor aria-hidden=true href=#741-技术演进>#</a></h4><ol><li><strong>自适应容量管理</strong>：动态调整MC2容量限制</li><li><strong>跨平台支持</strong>：扩展到更多昇腾芯片型号</li><li><strong>异构计算</strong>：结合CPU、NPU的混合计算</li></ol><h4 id=742-算法优化>7.4.2 算法优化<a hidden class=anchor aria-hidden=true href=#742-算法优化>#</a></h4><ol><li><strong>预测性负载均衡</strong>：基于历史数据的负载预测</li><li><strong>智能路由算法</strong>：更精确的token-expert路由</li><li><strong>内存压缩</strong>：进一步的内存效率优化</li></ol><h4 id=743-生态建设>7.4.3 生态建设<a hidden class=anchor aria-hidden=true href=#743-生态建设>#</a></h4><ol><li><strong>调试工具完善</strong>：提供更好的性能分析工具</li><li><strong>文档和教程</strong>：降低使用门槛</li><li><strong>社区贡献</strong>：吸引更多开发者参与优化</li></ol><p>MC2技术代表了MoE模型推理优化的前沿方向，为大规模语言模型的高效部署提供了重要的技术支撑。随着技术的不断发展和完善，MC2将在AI基础设施中发挥越来越重要的作用。</p><hr><p><strong>附录：MC2关键公式速查</strong></p><p><strong>1. MoE输出公式</strong>：<br></p>$$\mathbf{y} = \sum_{i \in \text{Top-K}(\mathbf{x})} \frac{g_i(\mathbf{x})}{\sum_{j \in \text{Top-K}(\mathbf{x})} g_j(\mathbf{x})} \cdot E_i(\mathbf{x})$$<p><strong>2. MC2延迟模型</strong>：<br></p>$$T_{\text{MC2}} = \max(T_{\text{compute}}, T_{\text{communicate}}) + T_{\text{overlap\_sync}}$$<p><strong>3. 性能提升比</strong>：<br></p>$$\text{Speedup} = \frac{T_{\text{compute}} + T_{\text{communicate}} + T_{\text{sync}}}{\max(T_{\text{compute}}, T_{\text{communicate}}) + T_{\text{overlap\_sync}}}$$<p><strong>4. 内存节省比例</strong>：<br></p>$$\text{MemorySaving} = 1 - \frac{\min(B \cdot L, 512)}{B \cdot L} \quad \text{(当 } B \cdot L > 512 \text{)}$$<hr><h2 id=附录关键公式详细推导>附录：关键公式详细推导<a hidden class=anchor aria-hidden=true href=#附录关键公式详细推导>#</a></h2><h3 id=a1-moe输出公式推导>A.1 MoE输出公式推导<a hidden class=anchor aria-hidden=true href=#a1-moe输出公式推导>#</a></h3><p><strong>基础MoE输出公式推导：</strong></p><p>从MoE的基本定义出发，给定输入 $\mathbf{x} \in \mathbb{R}^{d}$，MoE层的输出为所有专家的加权和：</p>$$
\mathbf{y} = \text{MoE}(\mathbf{x}) = \sum_{i=1}^{N} g_i(\mathbf{x}) \cdot E_i(\mathbf{x})
$$<p>其中 $N$ 是专家总数，$E_i(\cdot)$ 是第 $i$ 个专家网络，$g_i(\mathbf{x})$ 是门控网络对专家 $i$ 的权重。</p><p><strong>引入稀疏激活机制：</strong></p><p>为了提高计算效率，MoE采用稀疏激活机制，只选择 Top-K 个专家。首先对门控权重进行排序：</p>$$
\text{Top-K}(\mathbf{x}) = \{i_1, i_2, ..., i_K\} \quad \text{其中} \quad g_{i_1}(\mathbf{x}) \geq g_{i_2}(\mathbf{x}) \geq ... \geq g_{i_K}(\mathbf{x})
$$<p><strong>归一化处理：</strong></p><p>为了保持输出数值稳定性，需要对选中的专家权重进行归一化：</p>$$
w_i(\mathbf{x}) = \begin{cases}
\frac{g_i(\mathbf{x})}{\sum_{j \in \text{Top-K}(\mathbf{x})} g_j(\mathbf{x})} & \text{如果 } i \in \text{Top-K}(\mathbf{x}) \\
0 & \text{其他情况}
\end{cases}
$$<p><strong>最终输出公式：</strong></p><p>将归一化权重应用于专家输出，得到最终的MoE输出：</p>$$
\mathbf{y} = \sum_{i \in \text{Top-K}(\mathbf{x})} w_i(\mathbf{x}) \cdot E_i(\mathbf{x}) = \sum_{i \in \text{Top-K}(\mathbf{x})} \frac{g_i(\mathbf{x})}{\sum_{j \in \text{Top-K}(\mathbf{x})} g_j(\mathbf{x})} \cdot E_i(\mathbf{x})
$$<p>这个公式确保了：</p><ol><li><strong>稀疏性</strong>：只有 K 个专家参与计算</li><li><strong>归一化</strong>：权重之和为1，保持数值稳定性</li><li><strong>动态性</strong>：根据输入动态选择专家</li></ol><h3 id=a2-mc2延迟模型推导>A.2 MC2延迟模型推导<a hidden class=anchor aria-hidden=true href=#a2-mc2延迟模型推导>#</a></h3><p><strong>传统方法延迟分析：</strong></p><p>传统MoE计算中，计算和通信是串行执行的：</p>$$
T_{\text{traditional}} = T_{\text{compute}} + T_{\text{communicate}} + T_{\text{sync}}
$$<p><strong>MC2计算通信重叠原理：</strong></p><p>MC2的核心创新在于将计算和通信在时间上重叠执行。设计算时间为 $T_c$，通信时间为 $T_m$，重叠时间为 $T_o$。</p><p><strong>重叠执行分析：</strong></p><p>在理想情况下，计算和通信完全重叠时：</p>$$
T_{\text{overlap}} = \max(T_c, T_m)
$$<p>但由于硬件限制和同步开销，实际重叠执行时存在额外的同步开销 $T_{\text{overlap_sync}}$：</p>$$
T_{\text{overlap\_sync}} = \alpha \cdot \min(T_c, T_m) \quad \text{其中} \quad 0 < \alpha < 1
$$<p><strong>MC2总延迟模型：</strong></p><p>因此，MC2的总延迟为：</p>$$
T_{\text{MC2}} = \max(T_{\text{compute}}, T_{\text{communicate}}) + T_{\text{overlap sync}}
$$<p>其中 $T_{\text{overlap sync}} \ll T_{\text{sync}}$，因为重叠同步只需要在重叠完成后进行一次同步，而传统方法需要在每个阶段都进行同步。</p><h3 id=a3-性能提升比推导>A.3 性能提升比推导<a hidden class=anchor aria-hidden=true href=#a3-性能提升比推导>#</a></h3><p><strong>性能提升比定义：</strong></p><p>性能提升比定义为传统方法延迟与MC2方法延迟的比值：</p>$$
\text{Speedup} = \frac{T_{\text{traditional}}}{T_{\text{MC2}}}
$$<p><strong>代入延迟模型：</strong></p><p>将传统方法和MC2的延迟模型代入：</p>$$
\text{Speedup} = \frac{T_{\text{compute}} + T_{\text{communicate}} + T_{\text{sync}}}{\max(T_{\text{compute}}, T_{\text{communicate}}) + T_{\text{overlap sync}}}
$$<p><strong>理论分析：</strong></p><p>考虑两种特殊情况：</p><ol><li><strong>计算受限场景</strong> ($T_{\text{compute}} \gg T_{\text{communicate}}$)：</li></ol>$$
\text{Speedup}_{\text{compute bound}} = \frac{T_{\text{compute}} + T_{\text{communicate}} + T_{\text{sync}}}{T_{\text{compute}} + T_{\text{overlap sync}}} \approx 1 + \frac{T_{\text{communicate}} + T_{\text{sync}} - T_{\text{overlap sync}}}{T_{\text{compute}}}
$$<ol start=2><li><strong>通信受限场景</strong> ($T_{\text{communicate}} \gg T_{\text{compute}}$)：</li></ol>$$
\text{Speedup}_{\text{comm bound}} = \frac{T_{\text{compute}} + T_{\text{communicate}} + T_{\text{sync}}}{T_{\text{communicate}} + T_{\text{overlap sync}}} \approx 1 + \frac{T_{\text{compute}} + T_{\text{sync}} - T_{\text{overlap sync}}}{T_{\text{communicate}}}
$$<p><strong>最优情况：</strong></p><p>当计算和通信时间相近时 ($T_{\text{compute}} \approx T_{\text{communicate}}$)，性能提升最显著：</p>$$
\text{Speedup}_{\text{optimal}} \approx \frac{2T + T_{\text{sync}}}{T + T_{\text{overlap sync}}} \approx 2 \quad \text{(当 } T_{\text{sync}} \approx T_{\text{overlap sync}} \text{)}
$$<h3 id=a4-内存节省比例推导>A.4 内存节省比例推导<a hidden class=anchor aria-hidden=true href=#a4-内存节省比例推导>#</a></h3><p><strong>内存占用模型：</strong></p><p>传统MoE方法的内存占用包括输入缓冲区和专家参数：</p>$$
M_{\text{traditional}} = M_{\text{input}} + M_{\text{experts}} = B \cdot L \cdot d + N \cdot d^2
$$<p>MC2方法的内存占用考虑了容量限制和专家并行：</p>$$
M_{\text{MC2}} = M_{\text{input mc2}} + M_{\text{experts parallel}} = \min(B \cdot L, C) \cdot d + \frac{N}{P} \cdot d^2
$$<p><strong>内存节省比例定义：</strong></p>$$
\text{MemorySaving} = 1 - \frac{M_{\text{MC2}}}{M_{\text{traditional}}} = 1 - \frac{\min(BL, C) \cdot d + \frac{N}{P} \cdot d^2}{BL \cdot d + N \cdot d^2}
$$<p><strong>简化分析：</strong></p><p>当 $BL > C$ 时，$\min(BL, C) = C$，所以：</p>$$
\text{MemorySaving} = 1 - \frac{C \cdot d + \frac{N}{P} \cdot d^2}{BL \cdot d + N \cdot d^2}
$$<p>当专家参数内存相对于输入内存较小时 ($N \cdot d^2 \ll BL \cdot d$)，可以进一步简化：</p>$$
\text{MemorySaving} \approx 1 - \frac{C \cdot d}{BL \cdot d} = 1 - \frac{C}{BL}
$$<p><strong>实际意义：</strong></p><p>这个简化公式表明：</p><ul><li>当批次大小增加时，内存节省比例增加</li><li>MC2的容量限制 $C = 512$ 是关键参数</li><li>在大批次场景下，MC2可以节省近50%的内存</li></ul><h3 id=a5-带宽效率推导>A.5 带宽效率推导<a hidden class=anchor aria-hidden=true href=#a5-带宽效率推导>#</a></h3><p><strong>带宽利用率定义：</strong></p><p>带宽利用率定义为有效数据传输量与理论最大带宽的比值：</p>$$
\eta = \frac{\text{EffectiveData}}{\text{Bandwidth} \times \text{Time}}
$$<p><strong>传统方法带宽利用率：</strong></p><p>传统方法的有效数据为所有活跃token-expert对的数据：</p>$$
\eta_{\text{traditional}} = \frac{K \cdot B \cdot L \cdot d}{P \cdot T_{\text{traditional}}}
$$<p><strong>MC2方法带宽利用率：</strong></p><p>MC2方法的有效数据相同，但时间不同：</p>$$
\eta_{\text{MC2}} = \frac{K \cdot B \cdot L \cdot d}{P \cdot T_{\text{MC2}}}
$$<p><strong>带宽效率提升：</strong></p><p>带宽效率提升比定义为两种方法带宽利用率的比值：</p>$$
\text{BandwidthEfficiency} = \frac{\eta_{\text{MC2}}}{\eta_{\text{traditional}}} = \frac{T_{\text{traditional}}}{T_{\text{MC2}}}
$$<p><strong>与性能提升的关系：</strong></p><p>可以看出，带宽效率提升比与性能提升比相同：</p>$$
\text{BandwidthEfficiency} = \text{Speedup}
$$<p>这表明MC2不仅提升了整体性能，也同比例地提升了带宽利用效率。</p><h3 id=a6-传统moe通信延迟推导>A.6 传统MoE通信延迟推导<a hidden class=anchor aria-hidden=true href=#a6-传统moe通信延迟推导>#</a></h3><p><strong>通信延迟组成：</strong></p><p>传统All-to-All通信的延迟包含三个主要部分：</p><ol><li><strong>启动延迟</strong> ($T_{\alpha}$)：通信初始化的固定开销</li><li><strong>传输延迟</strong> ($T_{\beta} \cdot \text{DataSize}$)：数据传输时间</li><li><strong>同步延迟</strong> ($T_{\text{sync}}$)：等待所有设备完成的时间</li></ol><p><strong>数据量分析：</strong></p><p>对于MoE专家并行，需要传输的数据包括：</p><ul><li>每个token选择K个专家</li><li>每个token的数据维度为d</li><li>总共有 $B \cdot L$ 个token</li><li>数据分布到 $P$ 个设备上</li></ul><p>每个设备需要处理的数据量为：</p>$$
\text{DataPerDevice} = \frac{K \cdot B \cdot L \cdot d}{P}
$$<p><strong>传输延迟计算：</strong></p><p>传输延迟与数据量成正比：</p>$$
T_{\text{transmission}} = T_{\beta} \cdot \frac{K \cdot B \cdot L \cdot d}{P}
$$<p><strong>总通信延迟：</strong></p><p>传统方法的总延迟为计算和通信的串行执行：</p>$$
T_{\text{traditional}} = T_{\alpha} + T_{\beta} \cdot \frac{K \cdot B \cdot L \cdot d}{P} + T_{\text{compute}} + T_{\text{sync}}
$$<h3 id=a7-mc2通信延迟推导>A.7 MC2通信延迟推导<a hidden class=anchor aria-hidden=true href=#a7-mc2通信延迟推导>#</a></h3><p><strong>MC2优化机制：</strong></p><p>MC2通过两种机制优化通信延迟：</p><ol><li><strong>稀疏通信</strong>：只传输活跃的token-expert对</li><li><strong>计算通信重叠</strong>：计算和通信并行执行</li></ol><p><strong>稀疏通信优化：</strong></p><p>MC2利用MoE的稀疏性，只传输实际活跃的token-expert对。引入稀疏因子 $S \geq 1$：</p>$$
\text{EffectiveData} = \frac{K \cdot B \cdot L \cdot d}{P \cdot S}
$$<p>其中稀疏因子 $S$ 表示通过稀疏优化获得的压缩比。</p><p><strong>稀疏传输延迟：</strong></p>$$
T_{\text{sparse transmission}} = T_{\alpha} + T_{\beta} \cdot \frac{K \cdot B \cdot L \cdot d}{P \cdot S}
$$<p><strong>计算通信重叠：</strong></p><p>MC2的计算和通信重叠执行，总延迟为两者中的最大值：</p>$$
T_{\text{overlap}} = \max(T_{\text{sparse transmission}}, T_{\text{compute}})
$$<p><strong>MC2总延迟：</strong></p><p>考虑重叠同步开销：</p>$$
T_{\text{MC2}} = \max\left(T_{\alpha} + T_{\beta} \cdot \frac{K \cdot B \cdot L \cdot d}{P \cdot S}, T_{\text{compute}}\right) + T_{\text{overlap sync}}
$$<h3 id=a8-mc2性能提升理论推导>A.8 MC2性能提升理论推导<a hidden class=anchor aria-hidden=true href=#a8-mc2性能提升理论推导>#</a></h3><p><strong>完整性能提升模型：</strong></p><p>将传统方法和MC2方法的延迟模型代入性能提升比公式：</p>$$
\text{Speedup} = \frac{T_{\text{traditional}}}{T_{\text{MC2}}} = \frac{T_{\alpha} + T_{\beta} \cdot \frac{KBLd}{P} + T_{\text{compute}} + T_{\text{sync}}}{\max\left(T_{\alpha} + T_{\beta} \cdot \frac{KBLd}{P \cdot S}, T_{\text{compute}}\right) + T_{\text{overlap sync}}}
$$<p><strong>参数简化：</strong></p><p>为便于分析，令：</p><ul><li>$A = T_{\alpha}$ (启动延迟)</li><li>$B = T_{\beta} \cdot \frac{KBLd}{P}$ (传输延迟)</li><li>$C = T_{\text{compute}}$ (计算延迟)</li><li>$D = T_{\text{sync}}$ (同步延迟)</li><li>$E = T_{\text{overlap sync}}$ (重叠同步延迟)</li><li>$S$ (稀疏因子)</li></ul><p><strong>简化公式：</strong></p>$$
\text{Speedup} = \frac{A + B + C + D}{\max(A + \frac{B}{S}, C) + E}
$$<p><strong>理论分析：</strong></p><ol><li><p><strong>当 $S \to \infty$ (完全稀疏)</strong>：<br></p>$$
\text{Speedup} = \frac{A + B + C + D}{\max(A, C) + E}
$$</li><li><p><strong>当 $S = 1$ (无稀疏优化)</strong>：<br></p>$$
\text{Speedup} = \frac{A + B + C + D}{\max(A + B, C) + E}
$$</li><li><p><strong>当 $A + \frac{B}{S} \approx C$ (计算通信平衡)</strong>：<br></p>$$
\text{Speedup} = \frac{A + B + C + D}{C + E}
$$</li></ol><p><strong>最优性能提升：</strong></p><p>MC2的最优性能提升出现在计算和通信时间平衡且稀疏因子较大的情况下：</p>$$
\text{Speedup}_{\text{max}} = \frac{A + B + C + D}{\min(A + \frac{B}{S}, C) + E}
$$<h3 id=a9-mc2理论模型推导>A.9 MC2理论模型推导<a hidden class=anchor aria-hidden=true href=#a9-mc2理论模型推导>#</a></h3><h4 id=a91-通信复杂度分析>A.9.1 通信复杂度分析<a hidden class=anchor aria-hidden=true href=#a91-通信复杂度分析>#</a></h4><p><strong>核心参数：</strong></p><ul><li>$B$: 批次大小, $L$: 序列长度, $K$: top-k专家数</li><li>$N$: 专家总数, $P$: 设备数量, $d$: 隐藏层维度</li></ul><p><strong>All-to-All通信复杂度：</strong><br></p>$$
C_{\text{all2all}} = O\left(B \cdot L \cdot K \cdot \frac{\log P}{P}\right)
$$<p><strong>对比分析：</strong></p><ul><li>All-Gather: $C_{\text{allgather}} = O(B \cdot L \cdot d \cdot \log P)$</li><li>点对点: $C_{\text{p2p}} = O(B \cdot L \cdot K \cdot d)$</li></ul><p><strong>MC2优势：</strong><br></p>$$
\frac{C_{\text{all2all}}}{C_{\text{allgather}}} = O\left(\frac{K}{P}\right) \ll 1 \quad \text{当 } P \gg K
$$<h4 id=a92-内存占用模型>A.9.2 内存占用模型<a hidden class=anchor aria-hidden=true href=#a92-内存占用模型>#</a></h4><p><strong>传统方法内存占用：</strong><br></p>$$
M_{\text{traditional}} = O(B \cdot L \cdot d + N \cdot d^2)
$$<p><strong>MC2内存占用（容量限制$C=512$，专家并行$P$）：</strong><br></p>$$
M_{\text{MC2}} = O(\min(B \cdot L, C) \cdot d + \frac{N}{P} \cdot d^2)
$$<p><strong>内存节省来源：</strong></p><ol><li><strong>激活值节省</strong>: $(B \cdot L - \min(B \cdot L, C)) \cdot d$</li><li><strong>权重节省</strong>: $N \cdot (1 - \frac{1}{P}) \cdot d^2$</li></ol><h4 id=a93-性能优势总结>A.9.3 性能优势总结<a hidden class=anchor aria-hidden=true href=#a93-性能优势总结>#</a></h4><p>MC2的核心优化体现在：</p><ol><li><strong>通信复杂度降低</strong>: 通过All-to-All通信和专家并行实现$O(\frac{\log P}{P})$的复杂度降低</li><li><strong>内存效率提升</strong>: 容量限制和专家并行实现1.5x-3.2x的内存节省</li><li><strong>计算通信重叠</strong>: 硬件级支持实现计算与通信的并行执行</li></ol><p>这些理论模型为MC2在大规模MoE模型中的性能优势提供了数学基础。</p><hr><h2 id=8-mc2实际应用示例>8. MC2实际应用示例<a hidden class=anchor aria-hidden=true href=#8-mc2实际应用示例>#</a></h2><h3 id=81-性能优化实例>8.1 性能优化实例<a hidden class=anchor aria-hidden=true href=#81-性能优化实例>#</a></h3><p><strong>应用场景</strong>：Qwen3-MoE (30B参数，64个专家)在8张Ascend 910A2上的推理</p><p><strong>关键优化效果</strong>：</p><ul><li><strong>传统方法</strong>：计算45ms + 通信38ms + 同步12ms = <strong>95ms</strong></li><li><strong>MC2方法</strong>：max(计算45ms, 通信28ms) + 同步8ms = <strong>53ms</strong></li><li><strong>性能提升</strong>：44.2%延迟降低，50%内存节省</li></ul><h3 id=82-核心优化策略>8.2 核心优化策略<a hidden class=anchor aria-hidden=true href=#82-核心优化策略>#</a></h3><ol><li><strong>稀疏通信</strong>：mc2_mask限制活跃token数量(≤512)，减少37.5%通信量</li><li><strong>计算通信重叠</strong>：利用<code>npu_moe_distribute_dispatch_v2</code>实现硬件级并行</li><li><strong>动态策略选择</strong>：根据芯片版本和token数量自动选择最优通信方式</li><li><strong>内存优化</strong>：连续内存布局和专家并行实现显著内存节省</li></ol><p><strong>实际应用配置</strong>：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># MC2容量限制</span>
</span></span><span class=line><span class=cl><span class=n>mc2_mask</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>num_tokens</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>bool</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>mc2_mask</span><span class=p>[:</span><span class=nb>min</span><span class=p>(</span><span class=n>num_tokens</span><span class=p>,</span> <span class=mi>512</span><span class=p>)]</span> <span class=o>=</span> <span class=kc>True</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 动态策略选择</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=n>num_tokens</span> <span class=o>&lt;=</span> <span class=mi>512</span> <span class=ow>and</span> <span class=n>enable_expert_parallel</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=s2>&#34;mc2&#34;</span>
</span></span><span class=line><span class=cl><span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=s2>&#34;allgather&#34;</span> <span class=k>if</span> <span class=n>soc_version</span> <span class=o>==</span> <span class=n>A2</span> <span class=k>else</span> <span class=s2>&#34;alltoall&#34;</span>
</span></span></code></pre></td></tr></table></div></div><hr><h2 id=9-mc2开发者问答集>9. MC2开发者问答集<a hidden class=anchor aria-hidden=true href=#9-mc2开发者问答集>#</a></h2><h3 id=91-基础概念>9.1 基础概念<a hidden class=anchor aria-hidden=true href=#91-基础概念>#</a></h3><p><strong>Q1: 什么是MC2？与传统MoE通信的主要区别？</strong></p><p>A: MC2是"Merged Compute and Communication"（计算通信融合）的缩写。主要区别：</p><ul><li><strong>传统方式</strong>: 计算 → 通信 → 同步 (串行执行)</li><li><strong>MC2方式</strong>: 计算+通信重叠 → 轻量级同步 (并行执行)</li></ul><p><strong>Q2: MC2的适用场景和限制？</strong></p><p>A: 适用条件：</p><ol><li><strong>Token数量</strong>: ≤512 tokens/rank效果最佳</li><li><strong>专家并行</strong>: 必须启用<code>enable_expert_parallel=True</code></li><li><strong>硬件支持</strong>: 需要昇腾NPU特定指令</li></ol><h3 id=92-技术原理>9.2 技术原理<a hidden class=anchor aria-hidden=true href=#92-技术原理>#</a></h3><p><strong>Q3: <code>mc2_mask</code>如何工作？为什么能提高性能？</strong></p><p>A: <code>mc2_mask</code>实现稀疏通信：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>mc2_mask</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>num_tokens</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>bool</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>mc2_mask</span><span class=p>[:</span><span class=nb>min</span><span class=p>(</span><span class=n>num_tokens</span><span class=p>,</span> <span class=mi>512</span><span class=p>)]</span> <span class=o>=</span> <span class=kc>True</span>  <span class=c1># 只处理活跃token</span>
</span></span></code></pre></td></tr></table></div></div><p>性能提升：减少37.5%通信量，优化内存使用，提高计算效率。</p><p><strong>Q4: 如何实现计算通信重叠？</strong></p><p>A: 利用昇腾NPU硬件级支持：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 异步通信 + 并行计算</span>
</span></span><span class=line><span class=cl><span class=n>comm_future</span> <span class=o>=</span> <span class=n>torch_npu</span><span class=o>.</span><span class=n>npu_moe_distribute_dispatch_v2</span><span class=p>(</span><span class=o>**</span><span class=n>kwargs</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>shared_result</span> <span class=o>=</span> <span class=n>compute_shared_experts</span><span class=p>()</span>  <span class=c1># 通信时进行计算</span>
</span></span><span class=line><span class=cl><span class=n>final_result</span> <span class=o>=</span> <span class=n>comm_future</span><span class=o>.</span><span class=n>wait</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=93-实现细节>9.3 实现细节<a hidden class=anchor aria-hidden=true href=#93-实现细节>#</a></h3><p><strong>Q5: 如何选择MC2通信策略？</strong></p><p>A: 动态选择逻辑：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>if</span> <span class=ow>not</span> <span class=n>enable_expert_parallel</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=s2>&#34;allgather&#34;</span>
</span></span><span class=line><span class=cl><span class=k>elif</span> <span class=n>soc_version</span> <span class=o>==</span> <span class=n>A2</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=s2>&#34;mc2&#34;</span> <span class=k>if</span> <span class=n>num_tokens</span> <span class=o>&lt;=</span> <span class=mi>512</span> <span class=ow>and</span> <span class=n>world_size</span> <span class=o>&gt;=</span> <span class=mi>16</span> <span class=k>else</span> <span class=s2>&#34;allgather&#34;</span>
</span></span><span class=line><span class=cl><span class=k>else</span><span class=p>:</span>  <span class=c1># A3芯片</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=s2>&#34;mc2&#34;</span> <span class=k>if</span> <span class=n>num_tokens</span> <span class=o>&lt;=</span> <span class=mi>512</span> <span class=k>else</span> <span class=s2>&#34;alltoall&#34;</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>Q6: MC2的内存优化机制？</strong></p><p>A: 三方面优化：</p><ol><li><strong>容量限制</strong>: 只为前512个token分配完整内存</li><li><strong>稀疏存储</strong>: 只存储活跃token-expert对数据</li><li><strong>专家并行</strong>: 每个设备存储部分专家参数</li></ol><p><strong>Q7: 不同批次大小的性能表现？</strong></p><p>A: 性能变化趋势：</p><ul><li><strong>64-512 tokens</strong>: 1.5x-2.2x性能提升</li><li><strong>512-1024 tokens</strong>: 1.2x-1.5x性能提升</li><li><strong>>1024 tokens</strong>: &lt;1.2x性能提升</li></ul><h3 id=94-性能优化>9.4 性能优化<a hidden class=anchor aria-hidden=true href=#94-性能优化>#</a></h3><p><strong>Q8: MC2的主要性能瓶颈？</strong></p><p>A: 主要瓶颈：</p><ol><li><strong>内存访问</strong>: 不规则访问模式</li><li><strong>负载均衡</strong>: 专家选择不均衡</li><li><strong>同步开销</strong>: 多设备同步延迟</li></ol><p><strong>Q9: 推理vs训练场景表现？</strong></p><p>A:</p><ul><li><strong>推理</strong>: 1.5x-2.2x提升，适合低延迟场景</li><li><strong>训练</strong>: 1.2x-1.8x提升，梯度同步复杂</li></ul><h3 id=95-实践应用>9.5 实践应用<a hidden class=anchor aria-hidden=true href=#95-实践应用>#</a></h3><p><strong>Q10: 如何判断模型是否适合MC2？</strong></p><p>A: 检查清单：</p><ul><li>MoE模型架构 ✓</li><li>启用专家并行 ✓</li><li>批次≤512 tokens ✓</li><li>昇腾NPU硬件 ✓</li><li>延迟敏感应用 ✓</li></ul><p><strong>Q11: MC2未来发展方向？</strong></p><p>A: 主要方向：</p><ol><li><strong>自适应容量管理</strong>: 动态调整优化</li><li><strong>跨平台支持</strong>: 更多昇腾芯片</li><li><strong>智能路由</strong>: 基于历史的负载预测</li><li><strong>内存压缩</strong>: 进一步效率优化</li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=https://pillumina.github.io/tags/vllm-ascend/>Vllm-Ascend</a></li><li><a href=https://pillumina.github.io/tags/moe/>MoE</a></li></ul><nav class=paginav><a class=prev href=https://pillumina.github.io/posts/aiinfra/14-deterministic-rl/><span class=title>« Prev</span><br><span>[Deterministic RL] 确定性问题的来源 & Reproducible RL</span>
</a><a class=next href=https://pillumina.github.io/posts/aiinfra/12-verl-sglang-memory/><span class=title>Next »</span><br><span>[VeRL,SGLang] RL训推显存管理优化</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share [vLLM-Ascend] MC2技术深度解析：从MoE架构到通信融合优化 on x" href="https://x.com/intent/tweet/?text=%5bvLLM-Ascend%5d%20MC2%e6%8a%80%e6%9c%af%e6%b7%b1%e5%ba%a6%e8%a7%a3%e6%9e%90%ef%bc%9a%e4%bb%8eMoE%e6%9e%b6%e6%9e%84%e5%88%b0%e9%80%9a%e4%bf%a1%e8%9e%8d%e5%90%88%e4%bc%98%e5%8c%96&amp;url=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f13-vllmascend-mc2%2f&amp;hashtags=vllm-ascend%2cMoE"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [vLLM-Ascend] MC2技术深度解析：从MoE架构到通信融合优化 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f13-vllmascend-mc2%2f&amp;title=%5bvLLM-Ascend%5d%20MC2%e6%8a%80%e6%9c%af%e6%b7%b1%e5%ba%a6%e8%a7%a3%e6%9e%90%ef%bc%9a%e4%bb%8eMoE%e6%9e%b6%e6%9e%84%e5%88%b0%e9%80%9a%e4%bf%a1%e8%9e%8d%e5%90%88%e4%bc%98%e5%8c%96&amp;summary=%5bvLLM-Ascend%5d%20MC2%e6%8a%80%e6%9c%af%e6%b7%b1%e5%ba%a6%e8%a7%a3%e6%9e%90%ef%bc%9a%e4%bb%8eMoE%e6%9e%b6%e6%9e%84%e5%88%b0%e9%80%9a%e4%bf%a1%e8%9e%8d%e5%90%88%e4%bc%98%e5%8c%96&amp;source=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f13-vllmascend-mc2%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [vLLM-Ascend] MC2技术深度解析：从MoE架构到通信融合优化 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f13-vllmascend-mc2%2f&title=%5bvLLM-Ascend%5d%20MC2%e6%8a%80%e6%9c%af%e6%b7%b1%e5%ba%a6%e8%a7%a3%e6%9e%90%ef%bc%9a%e4%bb%8eMoE%e6%9e%b6%e6%9e%84%e5%88%b0%e9%80%9a%e4%bf%a1%e8%9e%8d%e5%90%88%e4%bc%98%e5%8c%96"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [vLLM-Ascend] MC2技术深度解析：从MoE架构到通信融合优化 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f13-vllmascend-mc2%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [vLLM-Ascend] MC2技术深度解析：从MoE架构到通信融合优化 on whatsapp" href="https://api.whatsapp.com/send?text=%5bvLLM-Ascend%5d%20MC2%e6%8a%80%e6%9c%af%e6%b7%b1%e5%ba%a6%e8%a7%a3%e6%9e%90%ef%bc%9a%e4%bb%8eMoE%e6%9e%b6%e6%9e%84%e5%88%b0%e9%80%9a%e4%bf%a1%e8%9e%8d%e5%90%88%e4%bc%98%e5%8c%96%20-%20https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f13-vllmascend-mc2%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [vLLM-Ascend] MC2技术深度解析：从MoE架构到通信融合优化 on telegram" href="https://telegram.me/share/url?text=%5bvLLM-Ascend%5d%20MC2%e6%8a%80%e6%9c%af%e6%b7%b1%e5%ba%a6%e8%a7%a3%e6%9e%90%ef%bc%9a%e4%bb%8eMoE%e6%9e%b6%e6%9e%84%e5%88%b0%e9%80%9a%e4%bf%a1%e8%9e%8d%e5%90%88%e4%bc%98%e5%8c%96&amp;url=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f13-vllmascend-mc2%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [vLLM-Ascend] MC2技术深度解析：从MoE架构到通信融合优化 on ycombinator" href="https://news.ycombinator.com/submitlink?t=%5bvLLM-Ascend%5d%20MC2%e6%8a%80%e6%9c%af%e6%b7%b1%e5%ba%a6%e8%a7%a3%e6%9e%90%ef%bc%9a%e4%bb%8eMoE%e6%9e%b6%e6%9e%84%e5%88%b0%e9%80%9a%e4%bf%a1%e8%9e%8d%e5%90%88%e4%bc%98%e5%8c%96&u=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f13-vllmascend-mc2%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul><div class=related-posts><div class=related-series><h3>同系列文章</h3><ul></ul></div><div class=related-tags><h3>相关文章</h3><ul><li><a href=/posts/llmtheory/2-moe/>MoE环游记：2、深入负载均衡</a>
<span class=meta>2025-08-10
· 5 min read
· Tags: MoE</span></li><li><a href=/posts/llmtheory/1-moe/>MoE环游记：1、从几何意义出发</a>
<span class=meta>2025-08-08
· 1 min read
· Tags: MoE</span></li></ul></div></div></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://pillumina.github.io/>CctoctoFX</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg></a><div class=reading-progress-bar></div><script src=https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js></script><script>document.addEventListener("DOMContentLoaded",function(){const t=document.querySelector(".reading-progress-bar");if(!t)return;const n=document.querySelector(".post-single");if(!n)return;function s(){const e=n.getBoundingClientRect(),s=e.height,o=window.innerHeight,i=window.scrollY||window.pageYOffset,a=i/(s-o)*100;t.style.width=`${Math.min(100,Math.max(0,a))}%`}let e=!1;window.addEventListener("scroll",function(){e||(window.requestAnimationFrame(function(){s(),e=!1}),e=!0)}),s()}),document.addEventListener("DOMContentLoaded",function(){mediumZoom("article img:not(.nozoom)",{margin:24,background:"var(--theme)",scrollOffset:0})})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>