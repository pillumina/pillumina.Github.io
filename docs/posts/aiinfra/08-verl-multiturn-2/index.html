<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[VeRL] Multi-Turn RL训练源码走读（2） | CctoctoFX</title><meta name=keywords content="framework,verl,sglang"><meta name=description content='
在 Part 1 中，我们介绍了 verl 的初始化过程，我们进一步介绍 verl 的训练过程，包括rollout部分、make experience部分以及training部分。
在 GRPO 中，单个 step 包含四个阶段：load data -> rollout -> make experience -> update model。区别于前一节的详述，本节会使用伪代码结合源码的方式进行阐述。

  flowchart LR
subgraph W2["Initialize"]
WP[Process Data] --> A
direction TB D1[Data Prepare] --> A
A[TaskRunner] --> B1[RayPPOTrainer]
B1 --> Workers

    subgraph Workers["Workers"]
        direction TB
                WA[ActorRolloutWorker] --> WD[FSDP Engine]
        WB[CriticWorker] --> WD
        WC[RewardModelWorker] --> WD
        WD --> WE[SGLang Engine]
    end
    
    Workers --> C1[Hybrid Engine]
end 

subgraph W3["Train Loop"]
    direction TB
    E[DataLoader] --> RolloutBox
    
    subgraph RolloutBox["Rollout"]
        F1[Prepare Data] --> F2[SGLang Async Rollout]
        F2 --> F3[Multi-turn Chat Process]
    end
    
    RolloutBox --> ExpBox
    
    subgraph ExpBox["Make Experience"]
        G1[Recompute Log Probs] --> G2[Compute Reward]
        G2 --> G3[Compute Advantage]
    end
    
    ExpBox --> UpdateBox
    
    subgraph UpdateBox["Train The Model"]
        H1[Load FSDP Model Weight] --> H2[Compute Gradient]
        H2 --> H3[Weights Update]
        H3 --> H4[Sync Weights]
    end
    
    UpdateBox --> E
end

W2 --> W3


数据加载与预处理
verl 通过 DataProto 和 RLHFDataset 来实现数据处理。具体来说，在 main_ppo.py 中，我们观察这个函数：'><meta name=author content="Me"><link rel=canonical href=https://pillumina.github.io/posts/aiinfra/08-verl-multiturn-2/><link crossorigin=anonymous href=/assets/css/stylesheet.9d388901283682bb45dd422fcaa0d0a2054a3c8ff47c9cc6b2baab15508b1b90.css integrity="sha256-nTiJASg2grtF3UIvyqDQogVKPI/0fJzGsrqrFVCLG5A=" rel="preload stylesheet" as=style><link rel=icon href=https://pillumina.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://pillumina.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://pillumina.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://pillumina.github.io/apple-touch-icon.png><link rel=mask-icon href=https://pillumina.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://pillumina.github.io/posts/aiinfra/08-verl-multiturn-2/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js crossorigin=anonymous></script><script>(function(){function t(){return document.querySelector(".post-content")||document.querySelector(".post-single")||document.body}function n(e){return/\$\$[\s\S]+?\$\$|\\\(|\\\)|\\\[|\\\]/.test(e)}function s(e){if(window.__mathjaxLoaded)return;window.__mathjaxLoaded=!0,window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code","tt"],ignoreHtmlClass:"no-math"}};var t=document.createElement("script");t.src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js",t.defer=!0,t.onload=function(){window.MathJax&&window.MathJax.typesetPromise&&window.MathJax.typesetPromise([e]).catch(function(e){console.warn("MathJax typeset error",e)})},document.head.appendChild(t)}function e(){try{if(typeof renderMathInElement=="function"){const e=t();renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\[",right:"\\]",display:!0},{left:"\\(",right:"\\)",display:!1}],throwOnError:!1,strict:!1,trust:!0,ignoredTags:["script","noscript","style","textarea","pre","code","tt"],ignoredClasses:["no-math"],macros:{"\\boldsymbol":"\\mathbf{#1}","\\bm":"\\mathbf{#1}"}}),setTimeout(function(){n(e.innerHTML)&&s(e)},200)}}catch(e){console.warn("KaTeX render error:",e)}}document.addEventListener("DOMContentLoaded",function(){e(),setTimeout(e,200)}),window.addEventListener("load",function(){setTimeout(e,0)})})()</script><script src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script><script>const config={startOnLoad:!0,theme:"neutral",themeVariables:{lineColor:"#0f0f0f"},flowchart:{useMaxWidth:!1,htmlLabels:!0}};mermaid.initialize(config),window.onload=()=>{window.mermaid.init(0[0],document.querySelectorAll(".language-mermaid"))}</script><link rel=stylesheet href=/css/custom.min.bda7229c4269a242639e058fb11a4782f02f8d77071ba16609befee67cc41c49.css integrity="sha256-vacinEJpokJjngWPsRpHgvAvjXcHG6FmCb7+5nzEHEk="><script>document.addEventListener("DOMContentLoaded",function(){const t=document.querySelectorAll("h1[id], h2[id], h3[id], h4[id], h5[id], h6[id]"),n=document.querySelectorAll(".toc a");if(t.length===0||n.length===0)return;const s={};t.forEach(e=>{s[e.id]=e.offsetTop});function i(){const t=window.scrollY+100;let e="";for(const[n,o]of Object.entries(s))if(t>=o)e=n;else break;return e}function o(){const e=i();if(n.forEach(e=>{e.classList.remove("active")}),e){const t=document.querySelector(`.toc a[href="#${e}"]`);t&&t.classList.add("active")}}let e=!1;window.addEventListener("scroll",function(){e||(window.requestAnimationFrame(function(){o(),e=!1}),e=!0)}),o()})</script><meta property="og:url" content="https://pillumina.github.io/posts/aiinfra/08-verl-multiturn-2/"><meta property="og:site_name" content="CctoctoFX"><meta property="og:title" content="[VeRL] Multi-Turn RL训练源码走读（2）"><meta property="og:description" content=' 在 Part 1 中，我们介绍了 verl 的初始化过程，我们进一步介绍 verl 的训练过程，包括rollout部分、make experience部分以及training部分。
在 GRPO 中，单个 step 包含四个阶段：load data -> rollout -> make experience -> update model。区别于前一节的详述，本节会使用伪代码结合源码的方式进行阐述。
flowchart LR subgraph W2["Initialize"] WP[Process Data] --> A direction TB D1[Data Prepare] --> A A[TaskRunner] --> B1[RayPPOTrainer] B1 --> Workers subgraph Workers["Workers"] direction TB WA[ActorRolloutWorker] --> WD[FSDP Engine] WB[CriticWorker] --> WD WC[RewardModelWorker] --> WD WD --> WE[SGLang Engine] end Workers --> C1[Hybrid Engine] end subgraph W3["Train Loop"] direction TB E[DataLoader] --> RolloutBox subgraph RolloutBox["Rollout"] F1[Prepare Data] --> F2[SGLang Async Rollout] F2 --> F3[Multi-turn Chat Process] end RolloutBox --> ExpBox subgraph ExpBox["Make Experience"] G1[Recompute Log Probs] --> G2[Compute Reward] G2 --> G3[Compute Advantage] end ExpBox --> UpdateBox subgraph UpdateBox["Train The Model"] H1[Load FSDP Model Weight] --> H2[Compute Gradient] H2 --> H3[Weights Update] H3 --> H4[Sync Weights] end UpdateBox --> E end W2 --> W3 数据加载与预处理 verl 通过 DataProto 和 RLHFDataset 来实现数据处理。具体来说，在 main_ppo.py 中，我们观察这个函数：'><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-08-03T17:30:12+08:00"><meta property="article:modified_time" content="2025-08-03T17:30:12+08:00"><meta property="article:tag" content="Framework"><meta property="article:tag" content="Verl"><meta property="article:tag" content="Sglang"><meta property="og:image" content="https://pillumina.github.io/imgs/icon_head.png"><meta property="og:see_also" content="https://pillumina.github.io/posts/aiinfra/10-verl-dataproto/"><meta property="og:see_also" content="https://pillumina.github.io/posts/aiinfra/09-verl-agentloop/"><meta property="og:see_also" content="https://pillumina.github.io/posts/aiinfra/05-verl-params/"><meta property="og:see_also" content="https://pillumina.github.io/posts/aiinfra/07-verl-multiturn-1/"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://pillumina.github.io/imgs/icon_head.png"><meta name=twitter:title content="[VeRL] Multi-Turn RL训练源码走读（2）"><meta name=twitter:description content='
在 Part 1 中，我们介绍了 verl 的初始化过程，我们进一步介绍 verl 的训练过程，包括rollout部分、make experience部分以及training部分。
在 GRPO 中，单个 step 包含四个阶段：load data -> rollout -> make experience -> update model。区别于前一节的详述，本节会使用伪代码结合源码的方式进行阐述。

  flowchart LR
subgraph W2["Initialize"]
WP[Process Data] --> A
direction TB D1[Data Prepare] --> A
A[TaskRunner] --> B1[RayPPOTrainer]
B1 --> Workers

    subgraph Workers["Workers"]
        direction TB
                WA[ActorRolloutWorker] --> WD[FSDP Engine]
        WB[CriticWorker] --> WD
        WC[RewardModelWorker] --> WD
        WD --> WE[SGLang Engine]
    end
    
    Workers --> C1[Hybrid Engine]
end 

subgraph W3["Train Loop"]
    direction TB
    E[DataLoader] --> RolloutBox
    
    subgraph RolloutBox["Rollout"]
        F1[Prepare Data] --> F2[SGLang Async Rollout]
        F2 --> F3[Multi-turn Chat Process]
    end
    
    RolloutBox --> ExpBox
    
    subgraph ExpBox["Make Experience"]
        G1[Recompute Log Probs] --> G2[Compute Reward]
        G2 --> G3[Compute Advantage]
    end
    
    ExpBox --> UpdateBox
    
    subgraph UpdateBox["Train The Model"]
        H1[Load FSDP Model Weight] --> H2[Compute Gradient]
        H2 --> H3[Weights Update]
        H3 --> H4[Sync Weights]
    end
    
    UpdateBox --> E
end

W2 --> W3


数据加载与预处理
verl 通过 DataProto 和 RLHFDataset 来实现数据处理。具体来说，在 main_ppo.py 中，我们观察这个函数：'><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://pillumina.github.io/posts/"},{"@type":"ListItem","position":2,"name":"AI Infra","item":"https://pillumina.github.io/posts/aiinfra/"},{"@type":"ListItem","position":3,"name":"[VeRL] Multi-Turn RL训练源码走读（2）","item":"https://pillumina.github.io/posts/aiinfra/08-verl-multiturn-2/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[VeRL] Multi-Turn RL训练源码走读（2）","name":"[VeRL] Multi-Turn RL训练源码走读（2）","description":" 在 Part 1 中，我们介绍了 verl 的初始化过程，我们进一步介绍 verl 的训练过程，包括rollout部分、make experience部分以及training部分。\n在 GRPO 中，单个 step 包含四个阶段：load data -\u0026gt; rollout -\u0026gt; make experience -\u0026gt; update model。区别于前一节的详述，本节会使用伪代码结合源码的方式进行阐述。\nflowchart LR subgraph W2[\u0026#34;Initialize\u0026#34;] WP[Process Data] --\u0026gt; A direction TB D1[Data Prepare] --\u0026gt; A A[TaskRunner] --\u0026gt; B1[RayPPOTrainer] B1 --\u0026gt; Workers subgraph Workers[\u0026#34;Workers\u0026#34;] direction TB WA[ActorRolloutWorker] --\u0026gt; WD[FSDP Engine] WB[CriticWorker] --\u0026gt; WD WC[RewardModelWorker] --\u0026gt; WD WD --\u0026gt; WE[SGLang Engine] end Workers --\u0026gt; C1[Hybrid Engine] end subgraph W3[\u0026#34;Train Loop\u0026#34;] direction TB E[DataLoader] --\u0026gt; RolloutBox subgraph RolloutBox[\u0026#34;Rollout\u0026#34;] F1[Prepare Data] --\u0026gt; F2[SGLang Async Rollout] F2 --\u0026gt; F3[Multi-turn Chat Process] end RolloutBox --\u0026gt; ExpBox subgraph ExpBox[\u0026#34;Make Experience\u0026#34;] G1[Recompute Log Probs] --\u0026gt; G2[Compute Reward] G2 --\u0026gt; G3[Compute Advantage] end ExpBox --\u0026gt; UpdateBox subgraph UpdateBox[\u0026#34;Train The Model\u0026#34;] H1[Load FSDP Model Weight] --\u0026gt; H2[Compute Gradient] H2 --\u0026gt; H3[Weights Update] H3 --\u0026gt; H4[Sync Weights] end UpdateBox --\u0026gt; E end W2 --\u0026gt; W3 数据加载与预处理 verl 通过 DataProto 和 RLHFDataset 来实现数据处理。具体来说，在 main_ppo.py 中，我们观察这个函数：\n","keywords":["framework","verl","sglang"],"articleBody":" 在 Part 1 中，我们介绍了 verl 的初始化过程，我们进一步介绍 verl 的训练过程，包括rollout部分、make experience部分以及training部分。\n在 GRPO 中，单个 step 包含四个阶段：load data -\u003e rollout -\u003e make experience -\u003e update model。区别于前一节的详述，本节会使用伪代码结合源码的方式进行阐述。\nflowchart LR subgraph W2[\"Initialize\"] WP[Process Data] --\u003e A direction TB D1[Data Prepare] --\u003e A A[TaskRunner] --\u003e B1[RayPPOTrainer] B1 --\u003e Workers subgraph Workers[\"Workers\"] direction TB WA[ActorRolloutWorker] --\u003e WD[FSDP Engine] WB[CriticWorker] --\u003e WD WC[RewardModelWorker] --\u003e WD WD --\u003e WE[SGLang Engine] end Workers --\u003e C1[Hybrid Engine] end subgraph W3[\"Train Loop\"] direction TB E[DataLoader] --\u003e RolloutBox subgraph RolloutBox[\"Rollout\"] F1[Prepare Data] --\u003e F2[SGLang Async Rollout] F2 --\u003e F3[Multi-turn Chat Process] end RolloutBox --\u003e ExpBox subgraph ExpBox[\"Make Experience\"] G1[Recompute Log Probs] --\u003e G2[Compute Reward] G2 --\u003e G3[Compute Advantage] end ExpBox --\u003e UpdateBox subgraph UpdateBox[\"Train The Model\"] H1[Load FSDP Model Weight] --\u003e H2[Compute Gradient] H2 --\u003e H3[Weights Update] H3 --\u003e H4[Sync Weights] end UpdateBox --\u003e E end W2 --\u003e W3 数据加载与预处理 verl 通过 DataProto 和 RLHFDataset 来实现数据处理。具体来说，在 main_ppo.py 中，我们观察这个函数：\ncreate_rl_dataset 源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def create_rl_dataset(data_paths, data_config, tokenizer, processor): \"\"\"Create a dataset. Arguments: data_paths: List of paths to data files. data_config: The data config. tokenizer (Tokenizer): The tokenizer. processor (Processor): The processor. Returns: dataset (Dataset): The dataset. \"\"\" from torch.utils.data import Dataset from verl.utils.dataset.rl_dataset import RLHFDataset # Check if a custom dataset class is specified in the data configuration # and if the path to the custom class is provided if \"custom_cls\" in data_config and data_config.custom_cls.get(\"path\", None) is not None: from verl.utils.import_utils import load_extern_type # Dynamically load the custom dataset class dataset_cls = load_extern_type(data_config.custom_cls.path, data_config.custom_cls.name) # Verify that the custom dataset class inherits from torch.utils.data.Dataset if not issubclass(dataset_cls, Dataset): raise TypeError(f\"The custom dataset class '{data_config.custom_cls.name}' from '{data_config.custom_cls.path}' must inherit from torch.utils.data.Dataset\") else: # Use the default RLHFDataset class if no custom class is specified dataset_cls = RLHFDataset print(f\"Using dataset class: {dataset_cls.__name__}\") # Instantiate the dataset using the determined dataset class dataset = dataset_cls( data_files=data_paths, tokenizer=tokenizer, processor=processor, config=data_config, ) return dataset 非常典型，创造一个了 RLHFDataset 实例，并返回。而具体的 RLHFDataset 实现如下：\nRLHFDataset 实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 class RLHFDataset(Dataset): \"\"\" Load and preprocess RLHF data from Parquet files. - Caches files locally. - Reads into a HuggingFace Dataset and tokenizes prompts. - Optionally handles images/videos via a ProcessorMixin. - Filters prompts over a max length. - Supports resuming from checkpoints. Args: data_files (str or list): Path(s) to Parquet file(s). tokenizer (PreTrainedTokenizer): For the tokenization of text to token IDs. config (DictConfig): Options like cache_dir, prompt_key, max_prompt_length, truncation, etc. processor (ProcessorMixin, optional): Multimodal preprocessor for images/videos. \"\"\" def __init__( self, data_files: Union[str, List[str]], tokenizer: PreTrainedTokenizer, config: DictConfig, processor: Optional[ProcessorMixin] = None, ): if not isinstance(data_files, (List, ListConfig)): data_files = [data_files] self.data_files = copy.deepcopy(data_files) self.original_data_files = copy.deepcopy(data_files) # use for resume self.tokenizer = tokenizer self.processor = processor self.config = config self.cache_dir = os.path.expanduser(config.get(\"cache_dir\", \"~/.cache/verl/rlhf\")) self.prompt_key = config.get(\"prompt_key\", \"prompt\") self.image_key = config.get(\"image_key\", \"images\") self.video_key = config.get(\"video_key\", \"videos\") self.max_prompt_length = config.get(\"max_prompt_length\", 1024) self.return_raw_chat = config.get(\"return_raw_chat\", False) self.return_full_prompt = config.get(\"return_full_prompt\", False) self.truncation = config.get(\"truncation\", \"error\") self.filter_overlong_prompts = config.get(\"filter_overlong_prompts\", True) self.num_workers = config.get(\"filter_overlong_prompts_workers\", max(1, os.cpu_count() // 4)) self.num_workers = min(self.num_workers, os.cpu_count()) self.use_shm = config.get(\"use_shm\", False) self.chat_template_func = config.get(\"chat_template_func\", None) self.need_tools_kwargs = config.get(\"need_tools_kwargs\", False) self.filter_prompts = config.get(\"filter_prompts\", True) self.serialize_dataset = False self._download() self._read_files_and_tokenize() def _download(self, use_origin_parquet=False): from verl.utils.fs import copy_to_local data_files = self.data_files if not use_origin_parquet else self.original_data_files for i, parquet_file in enumerate(data_files): self.data_files[i] = copy_to_local(src=parquet_file, cache_dir=self.cache_dir, use_shm=self.use_shm) def _read_files_and_tokenize(self): dataframes = [] for parquet_file in self.data_files: # read parquet files and cache dataframe = datasets.load_dataset(\"parquet\", data_files=parquet_file)[\"train\"] dataframes.append(dataframe) self.dataframe: datasets.Dataset = datasets.concatenate_datasets(dataframes) print(f\"dataset len: {len(self.dataframe)}\") # filter out too long prompts if self.filter_overlong_prompts: tokenizer = self.tokenizer processor = self.processor prompt_key = self.prompt_key image_key = self.image_key video_key = self.video_key if processor is not None: from verl.utils.dataset.vision_utils import process_image, process_video def doc2len(doc) -\u003e int: messages = self._build_messages(doc) raw_prompt = self.processor.apply_chat_template(messages, add_generation_prompt=True, tokenize=False) images = [process_image(image) for image in messages.pop(image_key)] if image_key in messages else None videos = [process_video(video) for video in messages.pop(video_key)] if video_key in messages else None return len(processor(text=[raw_prompt], images=images, videos=videos)[\"input_ids\"][0]) else: def doc2len(doc) -\u003e int: return len(tokenizer.apply_chat_template(doc[prompt_key], add_generation_prompt=True)) self.dataframe = self.dataframe.filter( lambda doc: doc2len(doc) \u003c= self.max_prompt_length, num_proc=self.num_workers, desc=f\"Filtering prompts longer than {self.max_prompt_length} tokens\", ) print(f\"filter dataset len: {len(self.dataframe)}\") def resume_dataset_state(self): self.serialize_dataset = not hasattr(self, \"original_data_files\") # resume dataframe if not it's serialized in data.pt if not self.serialize_dataset: self._download(use_origin_parquet=True) # download and resume from original parquet files self._read_files_and_tokenize() else: print(r\"old dataloader ckpt file is used, please train from scratch for better ckpt performance\") def __len__(self): return len(self.dataframe) def _build_messages(self, example: dict): messages: list = example.pop(self.prompt_key) if self.image_key in example or self.video_key in example: for message in messages: content = message[\"content\"] content_list = [] segments = re.split(\"(|)\", content) segments = [item for item in segments if item != \"\"] for segment in segments: if segment == \"\": content_list.append({\"type\": \"image\"}) elif segment == \"\": content_list.append({\"type\": \"video\"}) else: content_list.append({\"type\": \"text\", \"text\": segment}) message[\"content\"] = content_list return messages def __getitem__(self, item): \"\"\" Note that we also return the raw_input_ids so that it can be combined with other chat template \"\"\" row_dict: dict = self.dataframe[item] messages = self._build_messages(row_dict) model_inputs = {} if self.processor is not None: from verl.utils.dataset.vision_utils import process_image, process_video raw_prompt = self.processor.apply_chat_template(messages, add_generation_prompt=True, tokenize=False) multi_modal_data = {} images = None if self.image_key in row_dict and row_dict.get(self.image_key, None) is not None: images = [process_image(image) for image in row_dict.pop(self.image_key)] multi_modal_data[\"image\"] = images videos = None if self.video_key in row_dict and row_dict.get(self.video_key, None) is not None: videos = [process_video(video) for video in row_dict.pop(self.video_key)] multi_modal_data[\"video\"] = [video.numpy() for video in videos] model_inputs = self.processor(text=[raw_prompt], images=images, videos=videos, return_tensors=\"pt\") input_ids = model_inputs.pop(\"input_ids\") attention_mask = model_inputs.pop(\"attention_mask\") if \"second_per_grid_ts\" in model_inputs: model_inputs.pop(\"second_per_grid_ts\") # There's a trap here, multi_modal_inputs has to be a dict, not BatchFeature row_dict[\"multi_modal_data\"] = multi_modal_data row_dict[\"multi_modal_inputs\"] = dict(model_inputs) # second_per_grid_ts isn't used for training, just for mrope row_dict[\"multi_modal_inputs\"].pop(\"second_per_grid_ts\", None) else: raw_prompt = self.tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False) model_inputs = self.tokenizer(raw_prompt, return_tensors=\"pt\", add_special_tokens=False) input_ids = model_inputs.pop(\"input_ids\") attention_mask = model_inputs.pop(\"attention_mask\") input_ids, attention_mask = verl_F.postprocess_data( input_ids=input_ids, attention_mask=attention_mask, max_length=self.max_prompt_length, pad_token_id=self.tokenizer.pad_token_id, left_pad=True, truncation=self.truncation, ) if self.processor is not None and \"Qwen2VLImageProcessor\" in self.processor.image_processor.__class__.__name__: from verl.models.transformers.qwen2_vl import get_rope_index position_ids = [ get_rope_index( self.processor, input_ids=input_ids[0], image_grid_thw=model_inputs.get(\"image_grid_thw\"), video_grid_thw=model_inputs.get(\"video_grid_thw\"), second_per_grid_ts=model_inputs.get(\"second_per_grid_ts\"), attention_mask=attention_mask[0], ) ] # (1, 3, seq_len) else: position_ids = compute_position_id_with_mask(attention_mask) row_dict[\"input_ids\"] = input_ids[0] row_dict[\"attention_mask\"] = attention_mask[0] row_dict[\"position_ids\"] = position_ids[0] raw_prompt_ids = self.tokenizer.encode(raw_prompt, add_special_tokens=False) if len(raw_prompt_ids) \u003e self.max_prompt_length: if self.truncation == \"left\": raw_prompt_ids = raw_prompt_ids[-self.max_prompt_length :] elif self.truncation == \"right\": raw_prompt_ids = raw_prompt_ids[: self.max_prompt_length] elif self.truncation == \"middle\": left_half = self.max_prompt_length // 2 right_half = self.max_prompt_length - left_half raw_prompt_ids = raw_prompt_ids[:left_half] + raw_prompt_ids[-right_half:] elif self.truncation == \"error\": raise RuntimeError(f\"Prompt length {len(raw_prompt_ids)} is longer than {self.max_prompt_length}.\") row_dict[\"raw_prompt_ids\"] = raw_prompt_ids # encode prompts without chat template if self.return_raw_chat: row_dict[\"raw_prompt\"] = messages # get prompts with chat template if self.return_full_prompt: row_dict[\"full_prompts\"] = raw_prompt # array of strings # add index for each prompt index = row_dict.get(\"extra_info\", {}).get(\"index\", 0) tools_kwargs = row_dict.get(\"extra_info\", {}).get(\"tools_kwargs\", {}) need_tools_kwargs = row_dict.get(\"extra_info\", {}).get(\"need_tools_kwargs\", self.need_tools_kwargs) if need_tools_kwargs and not tools_kwargs: logger.warning(\"tools_kwargs is empty for index {}, data source: {}\", index, row_dict[\"data_source\"]) row_dict[\"index\"] = index row_dict[\"tools_kwargs\"] = tools_kwargs return row_dict def __getstate__(self): if not self.serialize_dataset: state = self.__dict__.copy() if \"dataframe\" in state: del state[\"dataframe\"] return state return self.__dict__.copy() 支持从远程存储下载 Parquet 文件到本地缓存，支持共享内存加速文件访问，自动管理文件路径，支持检查点恢复。 使用 HuggingFace datasets 库读取 Parquet 文件，支持多个数据文件的合并，自动处理数据格式转换。 根据最大长度过滤过长的 prompts，支持多进程并行处理，可配置的过滤策略。 支持图像和视频的多模态输入，解析 和 标签，将多模态内容转换为结构化格式。 添加 chat template 来格式化对话，将文本转换为 token IDs，生成 attn mask 和 position ids。 padding 到指定长度，支持多种截断策略（left, right, middle, error），生成位置编码。 支持训练中断后的恢复，可以从原始文件重新构建数据集，兼容序列化/反序列化。 返回包含以下关键字段的字典：input_ids, attention_mask, position_ids, raw_prompt_ids, multi_modal_data, multi_modal_inputs, index, tools_kwargs。 这里最重要的一个参数是 tools_kwargs，用于为不同的 tools 提供配置参数。它的结构如下：\n1 2 3 4 5 6 7 8 tools_kwargs = { \"tool_name\": { \"create_kwargs\": {...}, # 工具创建时的参数 \"execute_kwargs\": {...}, # 工具执行时的参数（可选） \"calc_reward_kwargs\": {...}, # 计算奖励时的参数（可选） \"release_kwargs\": {...}, # 释放资源时的参数（可选） } } 比如 Search-R1 的 tools_kwargs 如下：\n1 2 3 4 5 6 7 8 9 tools_kwargs = { \"search-r1\": { \"create_kwargs\": { \"ground_truth\": ground_truth, \"question\": question, \"data_source\": data_source_tagged } } } 具体这些参数是如何调用了一个 tool，我们会留在后续部分继续介绍。\n训练入口 RayPPOTrainer.fit() 创建 Tracking 日志记录器，设置全局步数，加载检查点，并在训练前进行验证。 使用 tqdm 创建进度条，显示训练进度，并设置初始步数。 遍历配置的总 epoch 数和数据加载器，每个 train batch 更新多步。 从 batch 中分离出用于 rollout 的数据（input_ids, attention_mask, position_ids 等），保留其他数据用于后续处理。 调用 ActorRolloutWorker 生成序列，并记录生成时间。 处理 REMAX 基线（如果使用）：生成确定性基线序列，计算基线奖励，用于 REMAX 优势估计器。 为每个样本分配唯一 ID，重复数据以对齐多次采样，计算响应掩码，并可选地进行批次平衡。 根据配置使用奖励模型或自定义奖励函数计算 token 级别的奖励分数，支持同步和异步计算。 使用 megatron 基于训练开始前的 policy 重新计算 behaviour policy 的 log probabilities，用于重要性采样，同时计算熵值。（原因在 part 1讲过） 使用 reference policy 计算 log probs，用于 KL 散度计算。 使用 Critic 网络计算状态价值，用于优势函数估计。 根据配置的优势估计器（GAE、GRPO、REMAX 等）计算优势函数，支持 KL 惩罚。 使用计算出的优势函数更新 Critic 网络参数。 在 Critic 预热完成后，使用 PPO 损失函数更新 Actor 网络参数。 将生成的序列、输入、输出和分数保存到指定目录。 根据配置的频率执行验证，计算验证指标并记录。 根据配置的频率保存模型检查点。 收集训练指标、时序指标和吞吐量指标，并记录到日志系统。 更新进度条，递增全局步数，并在达到总训练步数时结束训练。 根据配置在特定步数启用/禁用性能分析，用于调试和优化。 RayPPOTrainer.fit() 源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 def fit(self): \"\"\" The training loop of PPO. The driver process only need to call the compute functions of the worker group through RPC to construct the PPO dataflow. The light-weight advantage computation is done on the driver process. \"\"\" from omegaconf import OmegaConf from verl.utils.tracking import Tracking logger = Tracking( project_name=self.config.trainer.project_name, experiment_name=self.config.trainer.experiment_name, default_backend=self.config.trainer.logger, config=OmegaConf.to_container(self.config, resolve=True), ) self.global_steps = 0 # load checkpoint before doing anything self._load_checkpoint() # perform validation before training # currently, we only support validation using the reward_function. if self.val_reward_fn is not None and self.config.trainer.get(\"val_before_train\", True): val_metrics = self._validate() assert val_metrics, f\"{val_metrics=}\" pprint(f\"Initial validation metrics: {val_metrics}\") logger.log(data=val_metrics, step=self.global_steps) if self.config.trainer.get(\"val_only\", False): return # add tqdm progress_bar = tqdm(total=self.total_training_steps, initial=self.global_steps, desc=\"Training Progress\") # we start from step 1 self.global_steps += 1 last_val_metrics = None for epoch in range(self.config.trainer.total_epochs): for batch_dict in self.train_dataloader: do_profile = self.global_steps in self.config.trainer.profile_steps if self.config.trainer.profile_steps is not None else False if do_profile: self.actor_rollout_wg.start_profile() if self.use_reference_policy: self.ref_policy_wg.start_profile() if self.use_critic: self.critic_wg.start_profile() if self.use_rm: self.rm_wg.start_profile() metrics = {} timing_raw = {} batch: DataProto = DataProto.from_single_dict(batch_dict) # pop those keys for generation batch_keys_to_pop = [\"input_ids\", \"attention_mask\", \"position_ids\"] non_tensor_batch_keys_to_pop = [\"raw_prompt_ids\"] if \"multi_modal_data\" in batch.non_tensor_batch: non_tensor_batch_keys_to_pop.append(\"multi_modal_data\") if \"raw_prompt\" in batch.non_tensor_batch: non_tensor_batch_keys_to_pop.append(\"raw_prompt\") if \"tools_kwargs\" in batch.non_tensor_batch: non_tensor_batch_keys_to_pop.append(\"tools_kwargs\") gen_batch = batch.pop( batch_keys=batch_keys_to_pop, non_tensor_batch_keys=non_tensor_batch_keys_to_pop, ) is_last_step = self.global_steps \u003e= self.total_training_steps with marked_timer(\"step\", timing_raw): # generate a batch with marked_timer(\"gen\", timing_raw, color=\"red\"): if not self.async_rollout_mode: gen_batch_output = self.actor_rollout_wg.generate_sequences(gen_batch) else: self.async_rollout_manager.wake_up() gen_batch_output = self.async_rollout_manager.generate_sequences(gen_batch) self.async_rollout_manager.sleep() timing_raw.update(gen_batch_output.meta_info[\"timing\"]) gen_batch_output.meta_info.pop(\"timing\", None) if self.config.algorithm.adv_estimator == AdvantageEstimator.REMAX: with marked_timer(\"gen_max\", timing_raw, color=\"purple\"): gen_baseline_batch = deepcopy(gen_batch) gen_baseline_batch.meta_info[\"do_sample\"] = False gen_baseline_output = self.actor_rollout_wg.generate_sequences(gen_baseline_batch) batch = batch.union(gen_baseline_output) reward_baseline_tensor = self.reward_fn(batch) reward_baseline_tensor = reward_baseline_tensor.sum(dim=-1) batch.pop(batch_keys=list(gen_baseline_output.batch.keys())) batch.batch[\"reward_baselines\"] = reward_baseline_tensor del gen_baseline_batch, gen_baseline_output batch.non_tensor_batch[\"uid\"] = np.array([str(uuid.uuid4()) for _ in range(len(batch.batch))], dtype=object) # repeat to align with repeated responses in rollout batch = batch.repeat(repeat_times=self.config.actor_rollout_ref.rollout.n, interleave=True) batch = batch.union(gen_batch_output) batch.batch[\"response_mask\"] = compute_response_mask(batch) # Balance the number of valid tokens across DP ranks. # NOTE: This usually changes the order of data in the `batch`, # which won't affect the advantage calculation (since it's based on uid), # but might affect the loss calculation (due to the change of mini-batching). # TODO: Decouple the DP balancing and mini-batching. if self.config.trainer.balance_batch: self._balance_batch(batch, metrics=metrics) # compute global_valid tokens batch.meta_info[\"global_token_num\"] = torch.sum(batch.batch[\"attention_mask\"], dim=-1).tolist() with marked_timer(\"reward\", timing_raw, color=\"yellow\"): # compute reward model score if self.use_rm: reward_tensor = self.rm_wg.compute_rm_score(batch) batch = batch.union(reward_tensor) if self.config.reward_model.launch_reward_fn_async: future_reward = compute_reward_async.remote(batch, self.config, self.tokenizer) else: reward_tensor, reward_extra_infos_dict = compute_reward(batch, self.reward_fn) # recompute old_log_probs with marked_timer(\"old_log_prob\", timing_raw, color=\"blue\"): old_log_prob = self.actor_rollout_wg.compute_log_prob(batch) entropys = old_log_prob.batch[\"entropys\"] response_masks = batch.batch[\"response_mask\"] loss_agg_mode = self.config.actor_rollout_ref.actor.loss_agg_mode entropy_agg = agg_loss(loss_mat=entropys, loss_mask=response_masks, loss_agg_mode=loss_agg_mode) old_log_prob_metrics = {\"actor/entropy\": entropy_agg.detach().item()} metrics.update(old_log_prob_metrics) old_log_prob.batch.pop(\"entropys\") batch = batch.union(old_log_prob) if \"rollout_log_probs\" in batch.batch.keys(): # TODO: we may want to add diff of probs too. rollout_old_log_probs = batch.batch[\"rollout_log_probs\"] actor_old_log_probs = batch.batch[\"old_log_probs\"] attention_mask = batch.batch[\"attention_mask\"] responses = batch.batch[\"responses\"] response_length = responses.size(1) response_mask = attention_mask[:, -response_length:] rollout_probs = torch.exp(rollout_old_log_probs) actor_probs = torch.exp(actor_old_log_probs) rollout_probs_diff = torch.abs(rollout_probs - actor_probs) rollout_probs_diff = torch.masked_select(rollout_probs_diff, response_mask.bool()) rollout_probs_diff_max = torch.max(rollout_probs_diff) rollout_probs_diff_mean = torch.mean(rollout_probs_diff) rollout_probs_diff_std = torch.std(rollout_probs_diff) metrics.update( { \"training/rollout_probs_diff_max\": rollout_probs_diff_max.detach().item(), \"training/rollout_probs_diff_mean\": rollout_probs_diff_mean.detach().item(), \"training/rollout_probs_diff_std\": rollout_probs_diff_std.detach().item(), } ) if self.use_reference_policy: # compute reference log_prob with marked_timer(\"ref\", timing_raw, color=\"olive\"): if not self.ref_in_actor: ref_log_prob = self.ref_policy_wg.compute_ref_log_prob(batch) else: ref_log_prob = self.actor_rollout_wg.compute_ref_log_prob(batch) batch = batch.union(ref_log_prob) # compute values if self.use_critic: with marked_timer(\"values\", timing_raw, color=\"cyan\"): values = self.critic_wg.compute_values(batch) batch = batch.union(values) with marked_timer(\"adv\", timing_raw, color=\"brown\"): # we combine with rule-based rm reward_extra_infos_dict: dict[str, list] if self.config.reward_model.launch_reward_fn_async: reward_tensor, reward_extra_infos_dict = ray.get(future_reward) batch.batch[\"token_level_scores\"] = reward_tensor if reward_extra_infos_dict: batch.non_tensor_batch.update({k: np.array(v) for k, v in reward_extra_infos_dict.items()}) # compute rewards. apply_kl_penalty if available if self.config.algorithm.use_kl_in_reward: batch, kl_metrics = apply_kl_penalty(batch, kl_ctrl=self.kl_ctrl_in_reward, kl_penalty=self.config.algorithm.kl_penalty) metrics.update(kl_metrics) else: batch.batch[\"token_level_rewards\"] = batch.batch[\"token_level_scores\"] # compute advantages, executed on the driver process norm_adv_by_std_in_grpo = self.config.algorithm.get(\"norm_adv_by_std_in_grpo\", True) # GRPO adv normalization factor batch = compute_advantage( batch, adv_estimator=self.config.algorithm.adv_estimator, gamma=self.config.algorithm.gamma, lam=self.config.algorithm.lam, num_repeat=self.config.actor_rollout_ref.rollout.n, norm_adv_by_std_in_grpo=norm_adv_by_std_in_grpo, multi_turn=self.config.actor_rollout_ref.rollout.multi_turn.enable, config=self.config.algorithm, ) # update critic if self.use_critic: with marked_timer(\"update_critic\", timing_raw, color=\"pink\"): critic_output = self.critic_wg.update_critic(batch) critic_output_metrics = reduce_metrics(critic_output.meta_info[\"metrics\"]) metrics.update(critic_output_metrics) # implement critic warmup if self.config.trainer.critic_warmup \u003c= self.global_steps: # update actor with marked_timer(\"update_actor\", timing_raw, color=\"red\"): batch.meta_info[\"multi_turn\"] = self.config.actor_rollout_ref.rollout.multi_turn.enable actor_output = self.actor_rollout_wg.update_actor(batch) actor_output_metrics = reduce_metrics(actor_output.meta_info[\"metrics\"]) metrics.update(actor_output_metrics) # Log rollout generations if enabled rollout_data_dir = self.config.trainer.get(\"rollout_data_dir\", None) if rollout_data_dir: with marked_timer(\"dump_rollout_generations\", timing_raw, color=\"green\"): print(batch.batch.keys()) inputs = self.tokenizer.batch_decode(batch.batch[\"prompts\"], skip_special_tokens=True) outputs = self.tokenizer.batch_decode(batch.batch[\"responses\"], skip_special_tokens=True) scores = batch.batch[\"token_level_scores\"].sum(-1).cpu().tolist() self._dump_generations( inputs=inputs, outputs=outputs, scores=scores, reward_extra_infos_dict=reward_extra_infos_dict, dump_path=rollout_data_dir, ) # validate if self.val_reward_fn is not None and self.config.trainer.test_freq \u003e 0 and (is_last_step or self.global_steps % self.config.trainer.test_freq == 0): with marked_timer(\"testing\", timing_raw, color=\"green\"): val_metrics: dict = self._validate() if is_last_step: last_val_metrics = val_metrics metrics.update(val_metrics) if self.config.trainer.save_freq \u003e 0 and (is_last_step or self.global_steps % self.config.trainer.save_freq == 0): with marked_timer(\"save_checkpoint\", timing_raw, color=\"green\"): self._save_checkpoint() # training metrics metrics.update( { \"training/global_step\": self.global_steps, \"training/epoch\": epoch, } ) # collect metrics metrics.update(compute_data_metrics(batch=batch, use_critic=self.use_critic)) metrics.update(compute_timing_metrics(batch=batch, timing_raw=timing_raw)) # TODO: implement actual tflpo and theoretical tflpo n_gpus = self.resource_pool_manager.get_n_gpus() metrics.update(compute_throughout_metrics(batch=batch, timing_raw=timing_raw, n_gpus=n_gpus)) # TODO: make a canonical logger that supports various backend logger.log(data=metrics, step=self.global_steps) progress_bar.update(1) self.global_steps += 1 if do_profile: self.actor_rollout_wg.stop_profile() if self.use_reference_policy: self.ref_policy_wg.stop_profile() if self.use_critic: self.critic_wg.stop_profile() if self.use_rm: self.rm_wg.stop_profile() if is_last_step: pprint(f\"Final validation metrics: {last_val_metrics}\") progress_bar.close() return 我们究竟在异步什么？ 这里很值得分享一个核心问题，对 SGLang 而言，或者对现在的 RL 而言，我们每天说来说去的 async 究竟是什么意思？和 PD 分离一样，async 也有非常多的层面：\nAsync RL 代表的是在 training rollout 分离的系统上，rollout 只在 update weights 的时候被打断，其余时刻永远 rollout，哪怕 target policy 正在被 training engine 更新。这方面是 AreaL 和 SLIME。\nAsync Rollout 这个词是特指在 rollout 的时候，把一个 batch requests 拆为单个 request，然后逐个调用 SGLangEngine.generate()。\n乍一听，这没有什么特别的，似乎还会更慢些。但是考虑到 tool call 的问题，这就非常严肃了。假设我们把一整个 batch 的 requests 作为一个 batch 塞给 sglang 似乎还要快些，毕竟对 SGLang 的 scheduler 而言，更好组 batch。但是，一整个 batch 进去，得一整个 batch 出来。这些 batch 里面的 requests 同时返回，同时被 paser 解析查看是否有 tool call 的 parameter，然后发送请求给 tool。如此以来，整个 tool 的调用大概率会拥堵，甚至在我们考虑到如果要加入多个 tool（虽然目前没有）的话，用一个状态机去管理每个 request 的 tool call 状态会成一场噩梦，何况有的 requests 会在多轮里面多次调用 tool。因此，为了方便管理每个 request tool call 的状态机和让 tool 被调度的更加均匀。SGLang 采取了 Async Rollout 策略，也即把一个 batch 的 requests 拆为单个 request，然后逐个异步调用 SGLangEngine.generate()。这样每个 reqeuest 自己管理自己的状态机，方便维护并且 tool call 效率更高。\n理解了这一层，我们可以来看看代码实现：\ngenerate_sequences 源码 1 2 3 4 5 6 7 @GPUMemoryLogger(role=\"sglang rollout\", logger=logger) @torch.no_grad() def generate_sequences(self, prompts: DataProto, **kwargs) -\u003e DataProto: if self.config.multi_turn.enable: return self._req_level_generate_sequences(prompts, **kwargs) return self._batch_level_generate_sequences(prompts, **kwargs) 这里明确指出，如果是用了 mutli-turn 训练，则将 batch 的 requests 拆为单个 request，调用 _req_level_generate_sequences；而不调用 tool 的单轮 RL，仍旧组 batch 直接发送。\n我们只观察 _req_level_generate_sequences 的部分源码：\n_req_level_generate_sequences 部分源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 @GPUMemoryLogger(role=\"sglang rollout\", logger=logger) @torch.no_grad() def _req_level_generate_sequences(self, prompts: DataProto, **kwargs) -\u003e DataProto: # Async rollout with tools support do_sample = prompts.meta_info.get(\"do_sample\", True) is_validate = prompts.meta_info.get(\"validate\", False) tgt_device = prompts.batch[\"input_ids\"].device if self._tp_rank == 0: req_list = self._preprocess_prompt_to_async_rollout_requests( prompts, n=1 if is_validate else self.config.n, ) loop = asyncio.get_event_loop() output_req_list = loop.run_until_complete( asyncio.gather( *[self._async_rollout_a_request(req, do_sample, is_validate, **kwargs) for req in req_list], ) ) sorted_output_req_list = sorted(output_req_list, key=lambda x: (x.batch_data_id, x.rollout_offset)) else: sorted_output_req_list = None 现在来看，asyncio.gather(*[self._async_rollout_a_request(req, do_sample, is_validate, **kwargs) for req in req_list],) 就显得无比清晰了。\n数据流管理 我们继续去理解 RayPPOTrainer.fit() 函数，从数据流管理开始。这里我认为最重要的两个类是 DataProto 和 RLHFDataset。\nDataProto DataProto 是 verl 的数据交换协议，定义在 protocol.py：\n1 2 3 4 5 6 7 8 9 10 11 12 @dataclass class DataProto: \"\"\" A DataProto is a data structure that aims to provide a standard protocol for data exchange between functions. It contains a batch (TensorDict) and a meta_info (Dict). The batch is a TensorDict https://pytorch.org/tensordict/. TensorDict allows you to manipulate a dictionary of Tensors like a single Tensor. Ideally, the tensors with the same batch size should be put inside batch. \"\"\" batch: TensorDict = None non_tensor_batch: Dict = field(default_factory=dict) meta_info: Dict = field(default_factory=dict) DataProto 提供标准化的数据交换协议，基于 PyTorch 的 TensorDict，支持张量的批量操作，同时通过 non_tensor_batch 字典来处理 NumPy 数组等非张量数据。meta_info 存储额外的元信息。本身支持的操作挺基础的，典型的比如数据创建、切片、选择、合并、重命名、重复、填充、分块、以及分布式环境下的数据集合与分发。除此之外，DataProto 还通过数据验证 check_consistency() 确保在数据分离和合并过程的一致性。\nRLHFDataset RLHFDataset 是 verl 中用于 RLHF 数据加载的数据集类，继承自 datasets.Dataset，主要用于处理 Parquet 文件中的数据，包括数据下载、tokenize、过滤、预处理等。\nRLHFDataset 源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 class RLHFDataset(Dataset): \"\"\" Load and preprocess RLHF data from Parquet files. - Caches files locally. - Reads into a HuggingFace Dataset and tokenizes prompts. - Optionally handles images/videos via a ProcessorMixin. - Filters prompts over a max length. - Supports resuming from checkpoints. Args: data_files (str or list): Path(s) to Parquet file(s). tokenizer (PreTrainedTokenizer): For the tokenization of text to token IDs. config (DictConfig): Options like cache_dir, prompt_key, max_prompt_length, truncation, etc. processor (ProcessorMixin, optional): Multimodal preprocessor for images/videos. \"\"\" def __init__( self, data_files: Union[str, List[str]], tokenizer: PreTrainedTokenizer, config: DictConfig, processor: Optional[ProcessorMixin] = None, ): if not isinstance(data_files, (List, ListConfig)): data_files = [data_files] self.data_files = copy.deepcopy(data_files) self.original_data_files = copy.deepcopy(data_files) # use for resume self.tokenizer = tokenizer self.processor = processor self.config = config self.cache_dir = os.path.expanduser(config.get(\"cache_dir\", \"~/.cache/verl/rlhf\")) self.prompt_key = config.get(\"prompt_key\", \"prompt\") self.image_key = config.get(\"image_key\", \"images\") self.video_key = config.get(\"video_key\", \"videos\") self.max_prompt_length = config.get(\"max_prompt_length\", 1024) self.return_raw_chat = config.get(\"return_raw_chat\", False) self.return_full_prompt = config.get(\"return_full_prompt\", False) self.truncation = config.get(\"truncation\", \"error\") self.filter_overlong_prompts = config.get(\"filter_overlong_prompts\", True) self.num_workers = config.get(\"filter_overlong_prompts_workers\", max(1, os.cpu_count() // 4)) self.num_workers = min(self.num_workers, os.cpu_count()) self.use_shm = config.get(\"use_shm\", False) self.chat_template_func = config.get(\"chat_template_func\", None) self.need_tools_kwargs = config.get(\"need_tools_kwargs\", False) self.filter_prompts = config.get(\"filter_prompts\", True) self.serialize_dataset = False self._download() self._read_files_and_tokenize() 有了 DataProto 和 RLHFDataset 后，我们来观察数据流：\n1 A：Parquet 文件 --\u003e B：RLHFDataset --\u003e C：DataLoader + collate_fn --\u003e D：DataProto 原始数据 --\u003e E：pop 提取生成数据 --\u003e F：Rollout 生成 --\u003e G：union 合并数据 --\u003e H：奖励计算 --\u003e I：优势计算 --\u003e J：重新计算 log_probs --\u003e K：计算参考 log_probs --\u003e L：计算价值函数 --\u003e M1：更新 critic --\u003e M2：更新 actor --\u003e N：返回训练指标 事实上，只有最初的三步不是 DataProto，其他都是通过 DataProto 进行数据交换的。具体每步的数据流向如下：\n数据流详细分析 A：Parquet 文件\n1 data_files = \"~/data/rlhf/gsm8k/train.parquet\" B：RLHFDataset\n1 2 3 4 5 6 dataset = RLHFDataset( data_files=data_files, tokenizer=tokenizer, config=config, processor=processor ) C：DataLoader + collate_fn\n1 2 3 4 5 6 7 dataloader = DataLoader( dataset=dataset, batch_size=16, shuffle=True, drop_last=True, collate_fn=collate_fn ) D：DataProto 原始数据\n1 2 batch_dict = next(iter(dataloader)) # 返回 dict batch: DataProto = DataProto.from_single_dict(batch_dict) E：pop 提取生成数据\n1 gen_batch = batch.pop(batch_keys=[\"input_ids\", \"attention_mask\", \"position_ids\"]) F：Rollout 生成\n1 gen_batch_output = self.actor_rollout_wg.generate_sequences(gen_batch) G：union 合并数据\n1 batch = batch.union(gen_batch_output) H：奖励计算\n1 2 rewards = self.reward_fn(batch) batch.batch[\"token_level_rewards\"] = rewards I：优势计算\n1 batch = compute_advantage(batch, adv_estimator=self.config.algorithm.adv_estimator) J：重新计算 log_probs\n1 2 old_log_prob = self.actor_rollout_wg.compute_log_prob(batch) batch = batch.union(old_log_prob) K：计算 reference model 的 log_probs\n1 2 3 if self.use_reference_policy: ref_log_prob = self.ref_policy_wg.compute_ref_log_prob(batch) batch = batch.union(ref_log_prob) L：计算 value function\n1 2 3 if self.use_critic: values = self.critic_wg.compute_values(batch) batch = batch.union(values) M1：更新 critic\n1 2 3 4 if self.use_critic: critic_output = self.critic_wg.update_critic(batch) critic_output_metrics = reduce_metrics(critic_output.meta_info[\"metrics\"]) metrics.update(critic_output_metrics) M2：更新 actor\n1 actor_output = self.actor_rollout_wg.update_actor(batch) N：返回训练指标\n1 2 3 actor_output_metrics = reduce_metrics(actor_output.meta_info[\"metrics\"]) metrics.update(actor_output_metrics) logger.log(data=metrics, step=self.global_steps) Rollout 在 part 1 已经讲过了 SGLang 的几个关键函数：\nActorRolloutRefWorker._build_rollout() SGLangRollout.__init__() SGLangRollout.AsyncEngine SGLangRollout._init_inference_engine() 此外，我们还介绍了在“我们究竟在异步什么？“里面介绍了 SGLang 对 multi-turn 场景下的 _req_level_generate_sequences 的特殊实现。我们接着继续分析 SGLang rollout 对 multi-turn 的处理，包括状态机和 tool 调用。\n_req_level_generate_sequences 接着上文的讨论，我们继续来看看源代码。\n如果当前是 tp rank 0，则将一整个 batch 的 prompts 预处理成单个异步请求，并并发执行这些请求以生成序列。rollout 的返回顺序是乱序的，因此需要按照 batch ID 和在 batch 内的 offset 来对返回值重新排序。 如果不是 tp rank 0，则将输出请求列表设置为 None。这里其实也是之前提到过的 mock SPMD 的体现。 使用分布式通信，将 tp rank 0 生成的排序后的请求列表广播给所有其他 rank。 提取 prompt IDs、response IDs、attention masks、position IDs、loss masks、原始消息和 reward scores。 使用 padding token 对 prompt IDs 和 response IDs 进行填充，使其长度一致。 将填充后的 prompt 和 response 的 IDs、attention masks 等在最后一个维度上进行拼接，形成完整的序列数据。 将处理后的 prompts 和 responses 存储到 TensorDict 对象中，并设置批次大小。 将包含批次化张量数据的 TensorDict 和包含原始消息及奖励分数的字典封装到 DataProto 对象中并返回。 这里有个比较有趣的地方，注意到 2 中我们强调了，SGLang 并不是严格的 SPMD，但是 3 中，我们仍旧将 tp 0 得到的 response broadcast 给了所有 rank。但是，为了保持 SGLang 外部的训练循环仍旧得到的是一个 SPMD 的返回结果，我们需要让每个 tp randk 都构造并返回相同的 batch，这就需要通过 broadcast 让其他 tp rank 获得 tp 0 的计算结果。这导致了一定的计算冗余，但是相比推理本身的开销，仍旧是可以负担的。\n_req_level_generate_sequences 源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 @GPUMemoryLogger(role=\"sglang rollout\", logger=logger) @torch.no_grad() def _req_level_generate_sequences(self, prompts: DataProto, **kwargs) -\u003e DataProto: do_sample = prompts.meta_info.get(\"do_sample\", True) is_validate = prompts.meta_info.get(\"validate\", False) tgt_device = prompts.batch[\"input_ids\"].device if self._tp_rank == 0: req_list = self._preprocess_prompt_to_async_rollout_requests( prompts, n=1 if is_validate else self.config.n, ) loop = asyncio.get_event_loop() output_req_list = loop.run_until_complete( asyncio.gather( *[self._async_rollout_a_request(req, do_sample, is_validate, **kwargs) for req in req_list], ) ) sorted_output_req_list = sorted(output_req_list, key=lambda x: (x.batch_data_id, x.rollout_offset)) else: sorted_output_req_list = None dist.barrier() [sorted_output_req_list] = broadcast_pyobj( data=[sorted_output_req_list], rank=self._rank, dist_group=self._device_mesh_cpu[\"tp\"].get_group(), src=self._device_mesh_cpu[\"tp\"].mesh[0].item(), force_cpu_device=False, ) prompt_ids, response_ids = [], [] prompt_attention_mask, response_attention_mask = [], [] prompt_position_ids, response_position_ids = [], [] prompt_loss_mask, response_loss_mask = [], [] messages = [] reward_scores = [] for req in sorted_output_req_list: assert req.state == AsyncRolloutRequestStateEnum.COMPLETED, f\"Request {req.request_id} is not completed\" assert len(req.input_ids) == len(req.attention_mask) == len(req.position_ids) == len(req.loss_mask), f\"\"\"Request {req.request_id} has different length of {len(req.input_ids)=}, {len(req.attention_mask)=}, {len(req.position_ids)=}, {len(req.loss_mask)=}\"\"\" error_message_lines = [ f\"\"\"Request {req.request_id} has input_ids length {len(req.input_ids)} greater than max_model_len {self.config.max_model_len}\"\"\", f\"Decoded input_ids: {self.tokenizer.decode(req.input_ids)}\", f\"Decoded prompt_ids: {self.tokenizer.decode(req.prompt_ids)}\", f\"Decoded response_ids: {self.tokenizer.decode(req.response_ids)}\", f\"Messages: {req.messages}\", f\"Max model length: {req.max_model_len}\", ] error_message = \"\\n\".join(error_message_lines) assert len(req.input_ids) \u003c= self.config.max_model_len, error_message prompt_ids.append(torch.tensor(req.prompt_ids, dtype=torch.int, device=tgt_device)) response_ids.append(torch.tensor(req.response_ids, dtype=torch.int, device=tgt_device)) if len(req.response_ids) \u003e self.config.response_length: logger.warning( f\"\"\"{req.request_id=} has response_ids length {len(req.response_ids)} greater than max_response_len {self.config.response_length},\\n{req=}\"\"\" ) prompt_attention_mask.append(torch.tensor(req.prompt_attention_mask, dtype=torch.int, device=tgt_device)) response_attention_mask.append(torch.tensor(req.response_attention_mask, dtype=torch.int, device=tgt_device)) prompt_position_ids.append(torch.tensor(req.prompt_position_ids, dtype=torch.int, device=tgt_device)) response_position_ids.append(torch.tensor(req.response_position_ids, dtype=torch.int, device=tgt_device)) prompt_loss_mask.append(torch.tensor(req.prompt_loss_mask, dtype=torch.int, device=tgt_device)) response_loss_mask.append(torch.tensor(req.response_loss_mask, dtype=torch.int, device=tgt_device)) messages.append({\"messages\": req.messages}) reward_scores.append(req.reward_scores) prompt_ids = pad_sequence( prompt_ids, batch_first=True, padding_value=self.pad_token_id, padding_side=\"left\", ) if prompt_ids.shape[1] \u003c self.config.prompt_length: prompt_ids = pad_sequence_to_length(prompt_ids, self.config.prompt_length, self.pad_token_id, left_pad=True) response_ids = pad_sequence(response_ids, batch_first=True, padding_value=self.pad_token_id) if response_ids.shape[1] \u003c self.config.response_length: response_ids = pad_sequence_to_length(response_ids, self.config.response_length, self.pad_token_id) prompt_attention_mask = pad_sequence( prompt_attention_mask, batch_first=True, padding_value=0, padding_side=\"left\", ) if prompt_attention_mask.shape[1] \u003c self.config.prompt_length: prompt_attention_mask = pad_sequence_to_length(prompt_attention_mask, self.config.prompt_length, 0, left_pad=True) response_attention_mask = pad_sequence(response_attention_mask, batch_first=True, padding_value=0) if response_attention_mask.shape[1] \u003c self.config.response_length: response_attention_mask = pad_sequence_to_length(response_attention_mask, self.config.response_length, 0) prompt_position_ids = pad_sequence(prompt_position_ids, batch_first=True, padding_value=0, padding_side=\"left\") if prompt_position_ids.shape[1] \u003c self.config.prompt_length: prompt_position_ids = pad_sequence_to_length(prompt_position_ids, self.config.prompt_length, 0, left_pad=True) response_length = response_ids.size(1) delta_position_id = torch.arange(1, response_length + 1, device=response_ids.device) delta_position_id = delta_position_id.unsqueeze(0).repeat(len(sorted_output_req_list), 1) response_position_ids = prompt_position_ids[:, -1:] + delta_position_id prompt_loss_mask = pad_sequence(prompt_loss_mask, batch_first=True, padding_value=0, padding_side=\"left\") if prompt_loss_mask.shape[1] \u003c self.config.prompt_length: prompt_loss_mask = pad_sequence_to_length(prompt_loss_mask, self.config.prompt_length, 0, left_pad=True) response_loss_mask = pad_sequence(response_loss_mask, batch_first=True, padding_value=0) if response_loss_mask.shape[1] \u003c self.config.response_length: response_loss_mask = pad_sequence_to_length(response_loss_mask, self.config.response_length, 0) input_ids = torch.cat((prompt_ids, response_ids), dim=-1) attention_mask = torch.cat((prompt_attention_mask, response_attention_mask), dim=-1) position_ids = torch.cat((prompt_position_ids, response_position_ids), dim=-1) loss_mask = torch.cat((prompt_loss_mask, response_loss_mask), dim=-1) batch = TensorDict( { \"prompts\": prompt_ids, \"responses\": response_ids, \"input_ids\": input_ids, \"attention_mask\": attention_mask, \"position_ids\": position_ids, \"loss_mask\": loss_mask, }, batch_size=len(sorted_output_req_list), ) if self.config.free_cache_engine and self._engine is not None and self._tp_rank == 0: loop = asyncio.get_event_loop() loop.run_until_complete(self._engine.flush_cache()) return DataProto( batch=batch, non_tensor_batch={ \"messages\": np.array(messages), \"reward_scores\": np.array(reward_scores), }, ) 显然，_req_level_generate_sequences 的核心在于这两个函数：\n_preprocess_prompt_to_async_rollout_requests _async_rollout_a_request 我们分别展开。\n_preprocess_prompt_to_async_rollout_requests 将 prompts 展开，首先拆开 batch 中的每个 prompt，内层循环为每个 prompt 生成 n 个不同的序列。每个生成的请求都有唯一的 batch_data_id 和 rollout_offset 标识。 当配置了工具时，_input_ids 和 _attention_mask 被设为 None，因为工具调用需要动态构建输入。而没有配置工具的话，使用 _pre_process_inputs 函数处理预处理的 token IDs，去除左填充。 每个请求对象包含状态管理、工具配置、序列长度限制、tokenizer 配置等元数据，为后续的异步处理提供完整信息。 _preprocess_prompt_to_async_rollout_requests 源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 def _preprocess_prompt_to_async_rollout_requests(self, prompts: DataProto, n: int) -\u003e list[AsyncRolloutRequest]: assert \"raw_prompt\" in prompts.non_tensor_batch, \"need data.return_raw_chat=True, due to no official way do parse_messages\" req_list = [] for data_idx, raw_prompt in enumerate(prompts.non_tensor_batch[\"raw_prompt\"]): for rollout_offset in range(n): if self._tool_schemas: _tools_kwargs = prompts.non_tensor_batch[\"tools_kwargs\"][data_idx] _tool_schemas = [self._tool_map[k].get_openai_tool_schema() for k in _tools_kwargs.keys()] _input_ids = None _attention_mask = None else: _input_ids = _pre_process_inputs(self.pad_token_id, prompts.batch[\"input_ids\"][data_idx]) _attention_mask = _pre_process_inputs(0, prompts.batch[\"attention_mask\"][data_idx]) _tools_kwargs = {} _tool_schemas = None req = AsyncRolloutRequest( batch_data_id=data_idx, rollout_offset=rollout_offset, request_id=str(uuid4()), state=AsyncRolloutRequestStateEnum.PENDING, messages=raw_prompt.tolist(), tool_schemas=_tool_schemas, tools_kwargs=_tools_kwargs, input_ids=_input_ids, response_ids=[], attention_mask=_attention_mask, response_attention_mask=[], response_position_ids=[], response_loss_mask=[], reward_scores={}, max_prompt_len=self.config.prompt_length, max_response_len=self.config.response_length, max_model_len=min(self.config.max_model_len, self.config.prompt_length + self.config.response_length), use_inference_chat_template=self.config.multi_turn.use_inference_chat_template, enable_tokenization_sanity_check=self.config.multi_turn.enable_tokenization_sanity_check, tokenizer=self.tokenizer, ) error_message = f\"Request {req.request_id} has mismatched lengths: input_ids={len(req.input_ids)}, attention_mask={len(req.attention_mask)}, position_ids={len(req.position_ids)}, loss_mask={len(req.loss_mask)}\" assert len(req.input_ids) == len(req.attention_mask) == len(req.position_ids) == len(req.loss_mask), error_message req_list.append(req) return req_list 这里其实重要的在于整个 AsyncRolloutRequest，或者说我们用于管理 tool calling 的整个状态机 schema。\nschema 状态机 stateDiagram-v2 [*] --\u003e PENDING PENDING --\u003e RUNNING : _handle_pending_state() RUNNING --\u003e TOOL_CALLING : detect_tool_call TOOL_CALLING --\u003e RUNNING : tool_call_executed TOOL_CALLING --\u003e COMPLETED : tool_call_decode_failed RUNNING --\u003e COMPLETED : stop_reason == STOP RUNNING --\u003e [Exit] : finish_reason == LENGTH COMPLETED --\u003e [Exit] note right of TOOL_CALLING if tool_calls == None: raise ValueError end note note right of RUNNING if exceeds max length: finish_reason = LENGTH end note 这些状态机挺抽象的，需要到了和 SGLang rollout 的交互部分才能真的理解到用法，不过我们还是先列举出来。\nFinishReasonTypeEnum LENGTH：达到最大长度限制 STOP：正常停止（如生成 EOS token） TOOL_CALL：检测到工具调用 Message role：消息角色（user/assistant/tool） content：消息内容 tool_calls：可选的工具调用列表，每个工具调用包含 name 和 args 字段 目前的实现只支持单个工具的调用，但是魔改玩家太多了，甚至可以做一个 tool manager。\nAsyncRolloutRequestStateEnum PENDING：等待处理 RUNNING：正在运行 TOOL_CALLING：正在调用工具 COMPLETED：已完成 FAILED：失败 AsyncRolloutRequest initialize_request：验证必需字段（messages、max_prompt_len、tokenizer），使用 tokenizer 的 chat_template 处理消息，初始化所有序列相关字段（input_ids、attention_mask、position_ids、loss_mask），计算生成提示的位置信息 _update_input_ids：以增量方式更新序列信息，自动计算新的 position_ids，维护数据一致性验证 get_generation_prompt_ids：根据配置决定是否使用推理时的 chat_template，动态添加生成提示到输入序列 add_assistant_message：添加助手回复到消息历史，更新输入序列以包含新的回复内容，支持工具调用信息 add_tool_response_messages：添加工具响应到消息历史，更新输入序列但不标记为损失计算部分 finalize：完成请求处理，执行 tokenization 一致性检查，清理生成提示，截断输出序列到合理长度 truncate_output_ids：确保所有序列长度不超过限制，分别处理 input_ids、attention_mask、position_ids、loss_mask _async_rollout_a_request 文档写的很详尽了，容易 lost in the middle。不过，我们回到主线，先前通过 _preprocess_prompt_to_async_rollout_requests 构造了 AsyncRolloutRequest 后，返回给 _req_level_generate_sequences，接着进一步通过 _async_rollout_a_request 根据 AsyncRolloutRequest 的状态来 rollout 到底。\n通过一个 while 循环来处理多轮对话，循环次数上限由 self.config.multi_turn.max_turns 控制，或者 requests 返回 FinishReasonTypeEnum.STOP。 在循环内部，函数根据 _req 的当前状态 (AsyncRolloutRequestStateEnum) 执行不同的操作（这块儿逻辑确实很复杂）： PENDING 状态：如果请求处于 PENDING 状态，则调用 self._handle_pending_state(_req) 初始化，然后将状态更新为 RUNNING。 TOOL_CALLING 状态：检查最后一条消息的工具调用信息 (_req.messages[-1].tool_calls)。解析工具调用信息，并通过 asyncio.gather 并发地执行每个工具调用。工具的执行逻辑封装在 self._tool_map 中，通过工具的名称进行调用。在 tool call 返回后，通过 _req.add_tool_response_messages 将工具的响应添加到消息历史中。遍历每个工具调用及其结果，通过 _req.update_metrics 更新请求的指标信息。检查当前输入序列长度是否超过模型最大长度限制，如果超过，则设置 finish_reason_type 为 STOP 并跳出循环。最后，将请求状态更新回 RUNNING，以便进行下一轮的生成。 RUNNING 状态：SGLang engine 需要进行 rollout。检查当前 prompt 的长度加上生成一个 token 的长度是否会超过 model context length。调用 self._handle_engine_call 来实际调用 SGLang engine；得到输出后，将 finish reason 从字符串转换为 FinishReasonTypeEnum，并递增当前对话轮数 current_turns。如果完成原因是达到最大长度限制 (LENGTH)，则将生成的内容添加到消息历史中，并结束循环。如果没有到达最大长度，则判断 SGLang engine 生成的内容是否包含工具调用，通过 self._function_call_parser 来解析生成的内容。如果检测到工具调用，则将 finish_reason_type 设置为 TOOL_CALL，并将请求状态更新为 TOOL_CALLING。然后，使用 self._function_call_parser.parse_non_stream 解析出工具调用，转换为 OpenAIFunctionToolCall。如果存在有效的工具调用，则通过 _req.add_assistant_message 将工具调用信息添加到消息历史中。否则，只添加生成的内容，并将 finish_reason_type 设置为 STOP，请求状态设置为 COMPLETED，并结束循环。如果生成的内容不包含工具调用，则直接通过 _req.add_assistant_message 将生成的内容添加到消息历史中，并结束循环。 如果循环达到 self.config.multi_turn.max_turns 上限，则将 finish_reason_type 设置为 STOP。 在对话循环结束后，为每个调用的工具计算奖励。遍历 _req.tools_kwargs 中的每个工具，调用工具的 calc_reward 方法来计算奖励，以及 release 方法来释放工具占用的·资源。计算结果以字典形式存储在 tool_reward_scores 中。 调用 _req.finalize 方法，完成请求的最终处理，包括执行 tokenization 一致性检查、清理生成提示、截断输出序列到合理长度等。tool_reward_scores 和最终的 finish_reason_type 会传递给 finalize 方法。最后，函数最终返回处理完成的 AsyncRolloutRequest 对象 _req。 _async_rollout_a_request 源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 async def _async_rollout_a_request( self, req: AsyncRolloutRequest, do_sample: bool = True, is_validate: bool = False, **kwargs, ) -\u003e AsyncRolloutRequest: assert self._tp_rank == 0, \"only the master process can call this function\" _req = deepcopy(req) finish_reason_type = None output = None current_turns = 0 while current_turns \u003c self.config.multi_turn.max_turns: if _req.state == AsyncRolloutRequestStateEnum.PENDING: await self._handle_pending_state(_req) _req.state = AsyncRolloutRequestStateEnum.RUNNING elif _req.state == AsyncRolloutRequestStateEnum.TOOL_CALLING: if _req.messages[-1].tool_calls is not None: parsed_tool_calls = _req.messages[-1].tool_calls tool_call_results = await asyncio.gather( *[ self._tool_map[tool_call.function.name].execute( _req.request_id, tool_call.function.arguments, **_req.tools_kwargs[tool_call.function.name].get(\"execute_kwargs\", {}), ) for tool_call in parsed_tool_calls ] ) _req.add_tool_response_messages(self.tokenizer, [resp for resp, _, _ in tool_call_results]) for tool_call, (resp, reward, metrics) in zip(parsed_tool_calls, tool_call_results): _req.update_metrics(metrics, tool_call.function.name) if len(_req.input_ids) \u003e= self.config.max_model_len: finish_reason_type = FinishReasonTypeEnum.STOP break _req.state = AsyncRolloutRequestStateEnum.RUNNING else: raise ValueError(f\"Unexpected tool calling last message state: {_req.messages[-1]}\") elif _req.state == AsyncRolloutRequestStateEnum.RUNNING: # Only continue the conversation if the prompt length is not greater than max_model_len - 1, # since SGLang raises an error when max_new_tokens + 1 is greater to max_model_len (the extra token accounts for the EOS token). if len(_req.get_generation_prompt_ids(self.tokenizer)) + 1 \u003e= self.config.max_model_len: finish_reason_type = FinishReasonTypeEnum.LENGTH break output = await self._handle_engine_call(_req, do_sample, is_validate, **kwargs) content = output[\"text\"] finish_reason_type = FinishReasonTypeEnum.from_str(output[\"meta_info\"][\"finish_reason\"][\"type\"]) current_turns += 1 if finish_reason_type == FinishReasonTypeEnum.LENGTH: _req.add_assistant_message(self.tokenizer, content) break else: if self._function_call_parser and self._function_call_parser.has_tool_call(content): finish_reason_type = FinishReasonTypeEnum.TOOL_CALL _req.state = AsyncRolloutRequestStateEnum.TOOL_CALLING try: normed_content, tool_calls = self._function_call_parser.parse_non_stream(content) except JSONDecodeError: normed_content = content tool_calls = [] except AttributeError: normed_content = content tool_calls = [] parsed_tool_calls = [] for tool_call in tool_calls: function, has_decode_error = OpenAIFunctionCallSchema.from_openai_function_parsed_schema( OpenAIFunctionParsedSchema( name=tool_call.name, arguments=tool_call.parameters, ) ) # Drop the tool call if its arguments has decode error if has_decode_error: continue parsed_tool_calls.append( OpenAIFunctionToolCall( id=str(tool_call.tool_index), function=function, ) ) if len(parsed_tool_calls) \u003e 0: _req.add_assistant_message(self.tokenizer, normed_content, tool_calls=parsed_tool_calls) else: _req.add_assistant_message(self.tokenizer, content) finish_reason_type = FinishReasonTypeEnum.STOP _req.state = AsyncRolloutRequestStateEnum.COMPLETED break else: _req.add_assistant_message(self.tokenizer, content) break if current_turns \u003e= self.config.multi_turn.max_turns: finish_reason_type = FinishReasonTypeEnum.STOP # Calculate the reward for each tool async def calc_reward_and_release_fn(name: str, tool: BaseTool): reward = await tool.calc_reward(_req.request_id, **_req.tools_kwargs[name].get(\"calc_reward_kwargs\", {})) await tool.release(_req.request_id, **_req.tools_kwargs[name].get(\"release_kwargs\", {})) return name, reward tool_reward_tasks = [] for name in _req.tools_kwargs.keys(): tool = self._tool_map[name] tool_reward_tasks.append(calc_reward_and_release_fn(name, tool)) tool_reward_scores = await asyncio.gather(*tool_reward_tasks) tool_reward_scores = dict(tool_reward_scores) _req.finalize(self.tokenizer, tool_reward_scores, finish_reason_type) return _req pop and union 经过艰难深挖，我们终于完成了 Rollout 的理解，现在回到 RayPPOTrainer.fit() 上。我们来看看 rollout 部分的实现逻辑：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 with marked_timer(\"step\", timing_raw): # generate a batch with marked_timer(\"gen\", timing_raw, color=\"red\"): if not self.async_rollout_mode: gen_batch_output = self.actor_rollout_wg.generate_sequences(gen_batch) else: self.async_rollout_manager.wake_up() gen_batch_output = self.async_rollout_manager.generate_sequences(gen_batch) self.async_rollout_manager.sleep() timing_raw.update(gen_batch_output.meta_info[\"timing\"]) gen_batch_output.meta_info.pop(\"timing\", None) if self.config.algorithm.adv_estimator == AdvantageEstimator.REMAX: with marked_timer(\"gen_max\", timing_raw, color=\"purple\"): gen_baseline_batch = deepcopy(gen_batch) gen_baseline_batch.meta_info[\"do_sample\"] = False gen_baseline_output = self.actor_rollout_wg.generate_sequences(gen_baseline_batch) batch = batch.union(gen_baseline_output) reward_baseline_tensor = self.reward_fn(batch) reward_baseline_tensor = reward_baseline_tensor.sum(dim=-1) batch.pop(batch_keys=list(gen_baseline_output.batch.keys())) batch.batch[\"reward_baselines\"] = reward_baseline_tensor del gen_baseline_batch, gen_baseline_output batch.non_tensor_batch[\"uid\"] = np.array([str(uuid.uuid4()) for _ in range(len(batch.batch))], dtype=object) # repeat to align with repeated responses in rollout batch = batch.repeat(repeat_times=self.config.actor_rollout_ref.rollout.n, interleave=True) batch = batch.union(gen_batch_output) 值得一提的是，我自己写了代码才理解到在 verl 当中，发给 rollout engine 的并不是整个完整的从 dataset 读取的 batch，而是通过 pop 构造的 gen_batch。pop 是一个就地操作，完成后 batch 里面的 key 当然就没了。为此，如果想让 pop 前后都有一些需要的 key，得留一手考虑。比如说，我希望通过 uid 来把 gen_batch 和 batch 重新 union 起来，得反复添加 uid。\nMake Experience 经过了漫长的战线，我们终于分析完了 rollout 部分的逻辑。我们接着分析 make experience 部分的逻辑。\nMake Experience 源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 with marked_timer(\"reward\", timing_raw, color=\"yellow\"): # compute reward model score if self.use_rm: reward_tensor = self.rm_wg.compute_rm_score(batch) batch = batch.union(reward_tensor) if self.config.reward_model.launch_reward_fn_async: future_reward = compute_reward_async.remote(batch, self.config, self.tokenizer) else: reward_tensor, reward_extra_infos_dict = compute_reward(batch, self.reward_fn) # recompute old_log_probs with marked_timer(\"old_log_prob\", timing_raw, color=\"blue\"): old_log_prob = self.actor_rollout_wg.compute_log_prob(batch) entropys = old_log_prob.batch[\"entropys\"] response_masks = batch.batch[\"response_mask\"] loss_agg_mode = self.config.actor_rollout_ref.actor.loss_agg_mode entropy_agg = agg_loss(loss_mat=entropys, loss_mask=response_masks, loss_agg_mode=loss_agg_mode) old_log_prob_metrics = {\"actor/entropy\": entropy_agg.detach().item()} metrics.update(old_log_prob_metrics) old_log_prob.batch.pop(\"entropys\") batch = batch.union(old_log_prob) if \"rollout_log_probs\" in batch.batch.keys(): # TODO: we may want to add diff of probs too. rollout_old_log_probs = batch.batch[\"rollout_log_probs\"] actor_old_log_probs = batch.batch[\"old_log_probs\"] attention_mask = batch.batch[\"attention_mask\"] responses = batch.batch[\"responses\"] response_length = responses.size(1) response_mask = attention_mask[:, -response_length:] rollout_probs = torch.exp(rollout_old_log_probs) actor_probs = torch.exp(actor_old_log_probs) rollout_probs_diff = torch.abs(rollout_probs - actor_probs) rollout_probs_diff = torch.masked_select(rollout_probs_diff, response_mask.bool()) rollout_probs_diff_max = torch.max(rollout_probs_diff) rollout_probs_diff_mean = torch.mean(rollout_probs_diff) rollout_probs_diff_std = torch.std(rollout_probs_diff) metrics.update( { \"training/rollout_probs_diff_max\": rollout_probs_diff_max.detach().item(), \"training/rollout_probs_diff_mean\": rollout_probs_diff_mean.detach().item(), \"training/rollout_probs_diff_std\": rollout_probs_diff_std.detach().item(), } ) if self.use_reference_policy: # compute reference log_prob with marked_timer(\"ref\", timing_raw, color=\"olive\"): if not self.ref_in_actor: ref_log_prob = self.ref_policy_wg.compute_ref_log_prob(batch) else: ref_log_prob = self.actor_rollout_wg.compute_ref_log_prob(batch) batch = batch.union(ref_log_prob) # compute values if self.use_critic: with marked_timer(\"values\", timing_raw, color=\"cyan\"): values = self.critic_wg.compute_values(batch) batch = batch.union(values) with marked_timer(\"adv\", timing_raw, color=\"brown\"): # we combine with rule-based rm reward_extra_infos_dict: dict[str, list] if self.config.reward_model.launch_reward_fn_async: reward_tensor, reward_extra_infos_dict = ray.get(future_reward) batch.batch[\"token_level_scores\"] = reward_tensor if reward_extra_infos_dict: batch.non_tensor_batch.update({k: np.array(v) for k, v in reward_extra_infos_dict.items()}) # compute rewards. apply_kl_penalty if available if self.config.algorithm.use_kl_in_reward: batch, kl_metrics = apply_kl_penalty(batch, kl_ctrl=self.kl_ctrl_in_reward, kl_penalty=self.config.algorithm.kl_penalty) metrics.update(kl_metrics) else: batch.batch[\"token_level_rewards\"] = batch.batch[\"token_level_scores\"] # compute advantages, executed on the driver process norm_adv_by_std_in_grpo = self.config.algorithm.get(\"norm_adv_by_std_in_grpo\", True) # GRPO adv normalization factor batch = compute_advantage( batch, adv_estimator=self.config.algorithm.adv_estimator, gamma=self.config.algorithm.gamma, lam=self.config.algorithm.lam, num_repeat=self.config.actor_rollout_ref.rollout.n, norm_adv_by_std_in_grpo=norm_adv_by_std_in_grpo, multi_turn=self.config.actor_rollout_ref.rollout.multi_turn.enable, config=self.config.algorithm, ) 这一部分的操作还是很好读懂了，非常 standard：\n通过 self.reward_fn 或 self.rm_wg.compute_rm_score 计算 trajectory 的 reward。verl 支持各式各样的 reward，不单单是 reward model。 重算 behaviour policy 的 log probabilities: 使用 self.actor_rollout_wg.compute_log_prob(batch) 来重算 log probs。这里原因在 part 1 讲述 importance sampling 的部分也阐述过了。这里非常让我想吐槽的是，verl 里面 old_log_prob 就是用 training engine 重算的 behaviour policy 的 log probs，用 old 来描述让我比较费解。 计算 reference policy 的 log probabilities: 如果使用了 reference policy，则计算 reference policy 的 log probs，用于 KL divergence 约束。 计算 Critic 的 value: 如果使用了 Critic model，则通过 self.critic_wg.compute_values(batch) 预测当前 state 的 value。 估算 Advantage: 调用 compute_advantage 函数，根据配置的advantage estimator、折扣因子 (gamma)、GALA 因子 (lam) 等参数，利用 reward 和 value 估计计算优势函数。 Training 非常标准：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # update critic if self.use_critic: with marked_timer(\"update_critic\", timing_raw, color=\"pink\"): critic_output = self.critic_wg.update_critic(batch) critic_output_metrics = reduce_metrics(critic_output.meta_info[\"metrics\"]) metrics.update(critic_output_metrics) # implement critic warmup if self.config.trainer.critic_warmup \u003c= self.global_steps: # update actor with marked_timer(\"update_actor\", timing_raw, color=\"red\"): batch.meta_info[\"multi_turn\"] = self.config.actor_rollout_ref.rollout.multi_turn.enable actor_output = self.actor_rollout_wg.update_actor(batch) actor_output_metrics = reduce_metrics(actor_output.meta_info[\"metrics\"]) metrics.update(actor_output_metrics) ","wordCount":"5743","inLanguage":"en","image":"https://pillumina.github.io/imgs/icon_head.png","datePublished":"2025-08-03T17:30:12+08:00","dateModified":"2025-08-03T17:30:12+08:00","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://pillumina.github.io/posts/aiinfra/08-verl-multiturn-2/"},"publisher":{"@type":"Organization","name":"CctoctoFX","logo":{"@type":"ImageObject","url":"https://pillumina.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://pillumina.github.io/ accesskey=h title="CctoctoFX (Alt + H)"><img src=https://pillumina.github.io/apple-touch-icon.png alt aria-label=logo height=30>CctoctoFX</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://pillumina.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://pillumina.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://pillumina.github.io/posts/aiinfra/ title="AI Infra"><span>AI Infra</span></a></li><li><a href=https://pillumina.github.io/posts/llmtheory/ title=Thoery><span>Thoery</span></a></li><li><a href=https://pillumina.github.io/posts/programming/ title=Programming><span>Programming</span></a></li><li><a href=https://pillumina.github.io/social/ title=Social><span>Social</span></a></li><li><a href=https://pillumina.github.io/open_courses/ title=Study><span>Study</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://pillumina.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://pillumina.github.io/posts/>Posts</a>&nbsp;»&nbsp;<a href=https://pillumina.github.io/posts/aiinfra/>AI Infra</a></div><h1 class="post-title entry-hint-parent">[VeRL] Multi-Turn RL训练源码走读（2）</h1><div class=post-meta><span title='2025-08-03 17:30:12 +0800 CST'>August 3, 2025</span>&nbsp;·&nbsp;27 min&nbsp;·&nbsp;5743 words&nbsp;·&nbsp;Me</div></header><div class="toc side left"><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#数据加载与预处理>数据加载与预处理</a></li><li><a href=#训练入口-rayppotrainerfit>训练入口 <a href=https://github.com/volcengine/verl/blob/76f63cffa5081564d8fea93a1cb3ce8bd5bdcc39/verl/trainer/ppo/ray_trainer.py#L903><code>RayPPOTrainer.fit()</code></a></a></li><li><a href=#我们究竟在异步什么>我们究竟在异步什么？</a></li><li><a href=#数据流管理>数据流管理</a><ul><li><a href=#dataproto><code>DataProto</code></a></li><li><a href=#rlhfdataset><code>RLHFDataset</code></a></li></ul></li><li><a href=#rollout>Rollout</a><ul><li><a href=#_req_level_generate_sequences><a href=https://github.com/volcengine/verl/blob/76f63cffa5081564d8fea93a1cb3ce8bd5bdcc39/verl/workers/rollout/sglang_rollout/sglang_rollout.py#L853><code>_req_level_generate_sequences</code></a></a></li><li><a href=#_preprocess_prompt_to_async_rollout_requests><a href=https://github.com/volcengine/verl/blob/76f63cffa5081564d8fea93a1cb3ce8bd5bdcc39/verl/workers/rollout/sglang_rollout/sglang_rollout.py#L987><code>_preprocess_prompt_to_async_rollout_requests</code></a></a></li><li><a href=#schema-状态机>schema 状态机</a></li><li><a href=#_async_rollout_a_request><a href=https://github.com/volcengine/verl/blob/76f63cffa5081564d8fea93a1cb3ce8bd5bdcc39/verl/workers/rollout/sglang_rollout/sglang_rollout.py#L681><code>_async_rollout_a_request</code></a></a></li><li><a href=#pop-and-union>pop and union</a></li></ul></li><li><a href=#make-experience>Make Experience</a></li><li><a href=#training>Training</a></li></ul></nav></div></details></div><div class=post-content><blockquote><p>在 Part 1 中，我们介绍了 verl 的初始化过程，我们进一步介绍 verl 的训练过程，包括rollout部分、make experience部分以及training部分。</p></blockquote><p>在 GRPO 中，单个 step 包含四个阶段：load data -> rollout -> make experience -> update model。区别于前一节的详述，本节会使用伪代码结合源码的方式进行阐述。</p><pre class=mermaid>
  flowchart LR
subgraph W2[&#34;Initialize&#34;]
WP[Process Data] --&gt; A
direction TB D1[Data Prepare] --&gt; A
A[TaskRunner] --&gt; B1[RayPPOTrainer]
B1 --&gt; Workers

    subgraph Workers[&#34;Workers&#34;]
        direction TB
                WA[ActorRolloutWorker] --&gt; WD[FSDP Engine]
        WB[CriticWorker] --&gt; WD
        WC[RewardModelWorker] --&gt; WD
        WD --&gt; WE[SGLang Engine]
    end
    
    Workers --&gt; C1[Hybrid Engine]
end 

subgraph W3[&#34;Train Loop&#34;]
    direction TB
    E[DataLoader] --&gt; RolloutBox
    
    subgraph RolloutBox[&#34;Rollout&#34;]
        F1[Prepare Data] --&gt; F2[SGLang Async Rollout]
        F2 --&gt; F3[Multi-turn Chat Process]
    end
    
    RolloutBox --&gt; ExpBox
    
    subgraph ExpBox[&#34;Make Experience&#34;]
        G1[Recompute Log Probs] --&gt; G2[Compute Reward]
        G2 --&gt; G3[Compute Advantage]
    end
    
    ExpBox --&gt; UpdateBox
    
    subgraph UpdateBox[&#34;Train The Model&#34;]
        H1[Load FSDP Model Weight] --&gt; H2[Compute Gradient]
        H2 --&gt; H3[Weights Update]
        H3 --&gt; H4[Sync Weights]
    end
    
    UpdateBox --&gt; E
end

W2 --&gt; W3
</pre><h2 id=数据加载与预处理>数据加载与预处理<a hidden class=anchor aria-hidden=true href=#数据加载与预处理>#</a></h2><p>verl 通过 <code>DataProto</code> 和 <code>RLHFDataset</code> 来实现数据处理。具体来说，在 <a href=https://github.com/volcengine/verl/blob/76f63cffa5081564d8fea93a1cb3ce8bd5bdcc39/verl/trainer/main_ppo.py#L193><code>main_ppo.py</code></a> 中，我们观察这个函数：</p><details><summary>create_rl_dataset 源码</summary><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>create_rl_dataset</span><span class=p>(</span><span class=n>data_paths</span><span class=p>,</span> <span class=n>data_config</span><span class=p>,</span> <span class=n>tokenizer</span><span class=p>,</span> <span class=n>processor</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Create a dataset.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Arguments:
</span></span></span><span class=line><span class=cl><span class=s2>        data_paths: List of paths to data files.
</span></span></span><span class=line><span class=cl><span class=s2>        data_config: The data config.
</span></span></span><span class=line><span class=cl><span class=s2>        tokenizer (Tokenizer): The tokenizer.
</span></span></span><span class=line><span class=cl><span class=s2>        processor (Processor): The processor.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        dataset (Dataset): The dataset.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=kn>from</span> <span class=nn>torch.utils.data</span> <span class=kn>import</span> <span class=n>Dataset</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=kn>from</span> <span class=nn>verl.utils.dataset.rl_dataset</span> <span class=kn>import</span> <span class=n>RLHFDataset</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Check if a custom dataset class is specified in the data configuration</span>
</span></span><span class=line><span class=cl>    <span class=c1># and if the path to the custom class is provided</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=s2>&#34;custom_cls&#34;</span> <span class=ow>in</span> <span class=n>data_config</span> <span class=ow>and</span> <span class=n>data_config</span><span class=o>.</span><span class=n>custom_cls</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;path&#34;</span><span class=p>,</span> <span class=kc>None</span><span class=p>)</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=kn>from</span> <span class=nn>verl.utils.import_utils</span> <span class=kn>import</span> <span class=n>load_extern_type</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Dynamically load the custom dataset class</span>
</span></span><span class=line><span class=cl>        <span class=n>dataset_cls</span> <span class=o>=</span> <span class=n>load_extern_type</span><span class=p>(</span><span class=n>data_config</span><span class=o>.</span><span class=n>custom_cls</span><span class=o>.</span><span class=n>path</span><span class=p>,</span> <span class=n>data_config</span><span class=o>.</span><span class=n>custom_cls</span><span class=o>.</span><span class=n>name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># Verify that the custom dataset class inherits from torch.utils.data.Dataset</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=ow>not</span> <span class=nb>issubclass</span><span class=p>(</span><span class=n>dataset_cls</span><span class=p>,</span> <span class=n>Dataset</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=k>raise</span> <span class=ne>TypeError</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;The custom dataset class &#39;</span><span class=si>{</span><span class=n>data_config</span><span class=o>.</span><span class=n>custom_cls</span><span class=o>.</span><span class=n>name</span><span class=si>}</span><span class=s2>&#39; from &#39;</span><span class=si>{</span><span class=n>data_config</span><span class=o>.</span><span class=n>custom_cls</span><span class=o>.</span><span class=n>path</span><span class=si>}</span><span class=s2>&#39; must inherit from torch.utils.data.Dataset&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># Use the default RLHFDataset class if no custom class is specified</span>
</span></span><span class=line><span class=cl>        <span class=n>dataset_cls</span> <span class=o>=</span> <span class=n>RLHFDataset</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Using dataset class: </span><span class=si>{</span><span class=n>dataset_cls</span><span class=o>.</span><span class=vm>__name__</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Instantiate the dataset using the determined dataset class</span>
</span></span><span class=line><span class=cl>    <span class=n>dataset</span> <span class=o>=</span> <span class=n>dataset_cls</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>data_files</span><span class=o>=</span><span class=n>data_paths</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>tokenizer</span><span class=o>=</span><span class=n>tokenizer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>processor</span><span class=o>=</span><span class=n>processor</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>config</span><span class=o>=</span><span class=n>data_config</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>dataset</span>
</span></span></code></pre></td></tr></table></div></div></details><p>非常典型，创造一个了 <code>RLHFDataset</code> 实例，并返回。而具体的 <a href=https://github.com/volcengine/verl/blob/76f63cffa5081564d8fea93a1cb3ce8bd5bdcc39/verl/utils/dataset/rl_dataset.py#L68><code>RLHFDataset</code></a> 实现如下：</p><details><summary>RLHFDataset 实现</summary><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span><span class=lnt>108
</span><span class=lnt>109
</span><span class=lnt>110
</span><span class=lnt>111
</span><span class=lnt>112
</span><span class=lnt>113
</span><span class=lnt>114
</span><span class=lnt>115
</span><span class=lnt>116
</span><span class=lnt>117
</span><span class=lnt>118
</span><span class=lnt>119
</span><span class=lnt>120
</span><span class=lnt>121
</span><span class=lnt>122
</span><span class=lnt>123
</span><span class=lnt>124
</span><span class=lnt>125
</span><span class=lnt>126
</span><span class=lnt>127
</span><span class=lnt>128
</span><span class=lnt>129
</span><span class=lnt>130
</span><span class=lnt>131
</span><span class=lnt>132
</span><span class=lnt>133
</span><span class=lnt>134
</span><span class=lnt>135
</span><span class=lnt>136
</span><span class=lnt>137
</span><span class=lnt>138
</span><span class=lnt>139
</span><span class=lnt>140
</span><span class=lnt>141
</span><span class=lnt>142
</span><span class=lnt>143
</span><span class=lnt>144
</span><span class=lnt>145
</span><span class=lnt>146
</span><span class=lnt>147
</span><span class=lnt>148
</span><span class=lnt>149
</span><span class=lnt>150
</span><span class=lnt>151
</span><span class=lnt>152
</span><span class=lnt>153
</span><span class=lnt>154
</span><span class=lnt>155
</span><span class=lnt>156
</span><span class=lnt>157
</span><span class=lnt>158
</span><span class=lnt>159
</span><span class=lnt>160
</span><span class=lnt>161
</span><span class=lnt>162
</span><span class=lnt>163
</span><span class=lnt>164
</span><span class=lnt>165
</span><span class=lnt>166
</span><span class=lnt>167
</span><span class=lnt>168
</span><span class=lnt>169
</span><span class=lnt>170
</span><span class=lnt>171
</span><span class=lnt>172
</span><span class=lnt>173
</span><span class=lnt>174
</span><span class=lnt>175
</span><span class=lnt>176
</span><span class=lnt>177
</span><span class=lnt>178
</span><span class=lnt>179
</span><span class=lnt>180
</span><span class=lnt>181
</span><span class=lnt>182
</span><span class=lnt>183
</span><span class=lnt>184
</span><span class=lnt>185
</span><span class=lnt>186
</span><span class=lnt>187
</span><span class=lnt>188
</span><span class=lnt>189
</span><span class=lnt>190
</span><span class=lnt>191
</span><span class=lnt>192
</span><span class=lnt>193
</span><span class=lnt>194
</span><span class=lnt>195
</span><span class=lnt>196
</span><span class=lnt>197
</span><span class=lnt>198
</span><span class=lnt>199
</span><span class=lnt>200
</span><span class=lnt>201
</span><span class=lnt>202
</span><span class=lnt>203
</span><span class=lnt>204
</span><span class=lnt>205
</span><span class=lnt>206
</span><span class=lnt>207
</span><span class=lnt>208
</span><span class=lnt>209
</span><span class=lnt>210
</span><span class=lnt>211
</span><span class=lnt>212
</span><span class=lnt>213
</span><span class=lnt>214
</span><span class=lnt>215
</span><span class=lnt>216
</span><span class=lnt>217
</span><span class=lnt>218
</span><span class=lnt>219
</span><span class=lnt>220
</span><span class=lnt>221
</span><span class=lnt>222
</span><span class=lnt>223
</span><span class=lnt>224
</span><span class=lnt>225
</span><span class=lnt>226
</span><span class=lnt>227
</span><span class=lnt>228
</span><span class=lnt>229
</span><span class=lnt>230
</span><span class=lnt>231
</span><span class=lnt>232
</span><span class=lnt>233
</span><span class=lnt>234
</span><span class=lnt>235
</span><span class=lnt>236
</span><span class=lnt>237
</span><span class=lnt>238
</span><span class=lnt>239
</span><span class=lnt>240
</span><span class=lnt>241
</span><span class=lnt>242
</span><span class=lnt>243
</span><span class=lnt>244
</span><span class=lnt>245
</span><span class=lnt>246
</span><span class=lnt>247
</span><span class=lnt>248
</span><span class=lnt>249
</span><span class=lnt>250
</span><span class=lnt>251
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>RLHFDataset</span><span class=p>(</span><span class=n>Dataset</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Load and preprocess RLHF data from Parquet files.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    - Caches files locally.
</span></span></span><span class=line><span class=cl><span class=s2>    - Reads into a HuggingFace Dataset and tokenizes prompts.
</span></span></span><span class=line><span class=cl><span class=s2>    - Optionally handles images/videos via a ProcessorMixin.
</span></span></span><span class=line><span class=cl><span class=s2>    - Filters prompts over a max length.
</span></span></span><span class=line><span class=cl><span class=s2>    - Supports resuming from checkpoints.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        data_files (str or list): Path(s) to Parquet file(s).
</span></span></span><span class=line><span class=cl><span class=s2>        tokenizer (PreTrainedTokenizer): For the tokenization of text to token IDs.
</span></span></span><span class=line><span class=cl><span class=s2>        config (DictConfig): Options like cache_dir, prompt_key, max_prompt_length, truncation, etc.
</span></span></span><span class=line><span class=cl><span class=s2>        processor (ProcessorMixin, optional): Multimodal preprocessor for images/videos.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>data_files</span><span class=p>:</span> <span class=n>Union</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>]],</span>
</span></span><span class=line><span class=cl>        <span class=n>tokenizer</span><span class=p>:</span> <span class=n>PreTrainedTokenizer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>config</span><span class=p>:</span> <span class=n>DictConfig</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>processor</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>ProcessorMixin</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=ow>not</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>data_files</span><span class=p>,</span> <span class=p>(</span><span class=n>List</span><span class=p>,</span> <span class=n>ListConfig</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>            <span class=n>data_files</span> <span class=o>=</span> <span class=p>[</span><span class=n>data_files</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>data_files</span> <span class=o>=</span> <span class=n>copy</span><span class=o>.</span><span class=n>deepcopy</span><span class=p>(</span><span class=n>data_files</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>original_data_files</span> <span class=o>=</span> <span class=n>copy</span><span class=o>.</span><span class=n>deepcopy</span><span class=p>(</span><span class=n>data_files</span><span class=p>)</span>  <span class=c1># use for resume</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span> <span class=o>=</span> <span class=n>tokenizer</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>processor</span> <span class=o>=</span> <span class=n>processor</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>config</span> <span class=o>=</span> <span class=n>config</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>cache_dir</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>expanduser</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;cache_dir&#34;</span><span class=p>,</span> <span class=s2>&#34;~/.cache/verl/rlhf&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>prompt_key</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;prompt_key&#34;</span><span class=p>,</span> <span class=s2>&#34;prompt&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>image_key</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;image_key&#34;</span><span class=p>,</span> <span class=s2>&#34;images&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>video_key</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;video_key&#34;</span><span class=p>,</span> <span class=s2>&#34;videos&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>max_prompt_length</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;max_prompt_length&#34;</span><span class=p>,</span> <span class=mi>1024</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>return_raw_chat</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;return_raw_chat&#34;</span><span class=p>,</span> <span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>return_full_prompt</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;return_full_prompt&#34;</span><span class=p>,</span> <span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>truncation</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;truncation&#34;</span><span class=p>,</span> <span class=s2>&#34;error&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>filter_overlong_prompts</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;filter_overlong_prompts&#34;</span><span class=p>,</span> <span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>num_workers</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;filter_overlong_prompts_workers&#34;</span><span class=p>,</span> <span class=nb>max</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>os</span><span class=o>.</span><span class=n>cpu_count</span><span class=p>()</span> <span class=o>//</span> <span class=mi>4</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>num_workers</span> <span class=o>=</span> <span class=nb>min</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>num_workers</span><span class=p>,</span> <span class=n>os</span><span class=o>.</span><span class=n>cpu_count</span><span class=p>())</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>use_shm</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;use_shm&#34;</span><span class=p>,</span> <span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>chat_template_func</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;chat_template_func&#34;</span><span class=p>,</span> <span class=kc>None</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>need_tools_kwargs</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;need_tools_kwargs&#34;</span><span class=p>,</span> <span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>filter_prompts</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;filter_prompts&#34;</span><span class=p>,</span> <span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>serialize_dataset</span> <span class=o>=</span> <span class=kc>False</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>_download</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>_read_files_and_tokenize</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_download</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>use_origin_parquet</span><span class=o>=</span><span class=kc>False</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=kn>from</span> <span class=nn>verl.utils.fs</span> <span class=kn>import</span> <span class=n>copy_to_local</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>data_files</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>data_files</span> <span class=k>if</span> <span class=ow>not</span> <span class=n>use_origin_parquet</span> <span class=k>else</span> <span class=bp>self</span><span class=o>.</span><span class=n>original_data_files</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>parquet_file</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>data_files</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>data_files</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>copy_to_local</span><span class=p>(</span><span class=n>src</span><span class=o>=</span><span class=n>parquet_file</span><span class=p>,</span> <span class=n>cache_dir</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>cache_dir</span><span class=p>,</span> <span class=n>use_shm</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>use_shm</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_read_files_and_tokenize</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>dataframes</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>parquet_file</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>data_files</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># read parquet files and cache</span>
</span></span><span class=line><span class=cl>            <span class=n>dataframe</span> <span class=o>=</span> <span class=n>datasets</span><span class=o>.</span><span class=n>load_dataset</span><span class=p>(</span><span class=s2>&#34;parquet&#34;</span><span class=p>,</span> <span class=n>data_files</span><span class=o>=</span><span class=n>parquet_file</span><span class=p>)[</span><span class=s2>&#34;train&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=n>dataframes</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>dataframe</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>dataframe</span><span class=p>:</span> <span class=n>datasets</span><span class=o>.</span><span class=n>Dataset</span> <span class=o>=</span> <span class=n>datasets</span><span class=o>.</span><span class=n>concatenate_datasets</span><span class=p>(</span><span class=n>dataframes</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;dataset len: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>dataframe</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># filter out too long prompts</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>filter_overlong_prompts</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>tokenizer</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span>
</span></span><span class=line><span class=cl>            <span class=n>processor</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>processor</span>
</span></span><span class=line><span class=cl>            <span class=n>prompt_key</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>prompt_key</span>
</span></span><span class=line><span class=cl>            <span class=n>image_key</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>image_key</span>
</span></span><span class=line><span class=cl>            <span class=n>video_key</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>video_key</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>processor</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=kn>from</span> <span class=nn>verl.utils.dataset.vision_utils</span> <span class=kn>import</span> <span class=n>process_image</span><span class=p>,</span> <span class=n>process_video</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=k>def</span> <span class=nf>doc2len</span><span class=p>(</span><span class=n>doc</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>int</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=n>messages</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_build_messages</span><span class=p>(</span><span class=n>doc</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>raw_prompt</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>processor</span><span class=o>.</span><span class=n>apply_chat_template</span><span class=p>(</span><span class=n>messages</span><span class=p>,</span> <span class=n>add_generation_prompt</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>tokenize</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>images</span> <span class=o>=</span> <span class=p>[</span><span class=n>process_image</span><span class=p>(</span><span class=n>image</span><span class=p>)</span> <span class=k>for</span> <span class=n>image</span> <span class=ow>in</span> <span class=n>messages</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=n>image_key</span><span class=p>)]</span> <span class=k>if</span> <span class=n>image_key</span> <span class=ow>in</span> <span class=n>messages</span> <span class=k>else</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>                    <span class=n>videos</span> <span class=o>=</span> <span class=p>[</span><span class=n>process_video</span><span class=p>(</span><span class=n>video</span><span class=p>)</span> <span class=k>for</span> <span class=n>video</span> <span class=ow>in</span> <span class=n>messages</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=n>video_key</span><span class=p>)]</span> <span class=k>if</span> <span class=n>video_key</span> <span class=ow>in</span> <span class=n>messages</span> <span class=k>else</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                    <span class=k>return</span> <span class=nb>len</span><span class=p>(</span><span class=n>processor</span><span class=p>(</span><span class=n>text</span><span class=o>=</span><span class=p>[</span><span class=n>raw_prompt</span><span class=p>],</span> <span class=n>images</span><span class=o>=</span><span class=n>images</span><span class=p>,</span> <span class=n>videos</span><span class=o>=</span><span class=n>videos</span><span class=p>)[</span><span class=s2>&#34;input_ids&#34;</span><span class=p>][</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=k>def</span> <span class=nf>doc2len</span><span class=p>(</span><span class=n>doc</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>int</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=k>return</span> <span class=nb>len</span><span class=p>(</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>apply_chat_template</span><span class=p>(</span><span class=n>doc</span><span class=p>[</span><span class=n>prompt_key</span><span class=p>],</span> <span class=n>add_generation_prompt</span><span class=o>=</span><span class=kc>True</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>dataframe</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>dataframe</span><span class=o>.</span><span class=n>filter</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=k>lambda</span> <span class=n>doc</span><span class=p>:</span> <span class=n>doc2len</span><span class=p>(</span><span class=n>doc</span><span class=p>)</span> <span class=o>&lt;=</span> <span class=bp>self</span><span class=o>.</span><span class=n>max_prompt_length</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>num_proc</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>num_workers</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>desc</span><span class=o>=</span><span class=sa>f</span><span class=s2>&#34;Filtering prompts longer than </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>max_prompt_length</span><span class=si>}</span><span class=s2> tokens&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;filter dataset len: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>dataframe</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>resume_dataset_state</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>serialize_dataset</span> <span class=o>=</span> <span class=ow>not</span> <span class=nb>hasattr</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=s2>&#34;original_data_files&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># resume dataframe if not it&#39;s serialized in data.pt</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=ow>not</span> <span class=bp>self</span><span class=o>.</span><span class=n>serialize_dataset</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>_download</span><span class=p>(</span><span class=n>use_origin_parquet</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>  <span class=c1># download and resume from original parquet files</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>_read_files_and_tokenize</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>r</span><span class=s2>&#34;old dataloader ckpt file is used, please train from scratch for better ckpt performance&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__len__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>dataframe</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_build_messages</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>example</span><span class=p>:</span> <span class=nb>dict</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>messages</span><span class=p>:</span> <span class=nb>list</span> <span class=o>=</span> <span class=n>example</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>prompt_key</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>image_key</span> <span class=ow>in</span> <span class=n>example</span> <span class=ow>or</span> <span class=bp>self</span><span class=o>.</span><span class=n>video_key</span> <span class=ow>in</span> <span class=n>example</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>message</span> <span class=ow>in</span> <span class=n>messages</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>content</span> <span class=o>=</span> <span class=n>message</span><span class=p>[</span><span class=s2>&#34;content&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                <span class=n>content_list</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>                <span class=n>segments</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s2>&#34;(&lt;image&gt;|&lt;video&gt;)&#34;</span><span class=p>,</span> <span class=n>content</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>segments</span> <span class=o>=</span> <span class=p>[</span><span class=n>item</span> <span class=k>for</span> <span class=n>item</span> <span class=ow>in</span> <span class=n>segments</span> <span class=k>if</span> <span class=n>item</span> <span class=o>!=</span> <span class=s2>&#34;&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                <span class=k>for</span> <span class=n>segment</span> <span class=ow>in</span> <span class=n>segments</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=k>if</span> <span class=n>segment</span> <span class=o>==</span> <span class=s2>&#34;&lt;image&gt;&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                        <span class=n>content_list</span><span class=o>.</span><span class=n>append</span><span class=p>({</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;image&#34;</span><span class=p>})</span>
</span></span><span class=line><span class=cl>                    <span class=k>elif</span> <span class=n>segment</span> <span class=o>==</span> <span class=s2>&#34;&lt;video&gt;&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                        <span class=n>content_list</span><span class=o>.</span><span class=n>append</span><span class=p>({</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;video&#34;</span><span class=p>})</span>
</span></span><span class=line><span class=cl>                    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                        <span class=n>content_list</span><span class=o>.</span><span class=n>append</span><span class=p>({</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;text&#34;</span><span class=p>,</span> <span class=s2>&#34;text&#34;</span><span class=p>:</span> <span class=n>segment</span><span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=n>message</span><span class=p>[</span><span class=s2>&#34;content&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>content_list</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>messages</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__getitem__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>item</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        Note that we also return the raw_input_ids so that it can be combined with other chat template
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>row_dict</span><span class=p>:</span> <span class=nb>dict</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>dataframe</span><span class=p>[</span><span class=n>item</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>messages</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_build_messages</span><span class=p>(</span><span class=n>row_dict</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>model_inputs</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>processor</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=kn>from</span> <span class=nn>verl.utils.dataset.vision_utils</span> <span class=kn>import</span> <span class=n>process_image</span><span class=p>,</span> <span class=n>process_video</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>raw_prompt</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>processor</span><span class=o>.</span><span class=n>apply_chat_template</span><span class=p>(</span><span class=n>messages</span><span class=p>,</span> <span class=n>add_generation_prompt</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>tokenize</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>multi_modal_data</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>images</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>image_key</span> <span class=ow>in</span> <span class=n>row_dict</span> <span class=ow>and</span> <span class=n>row_dict</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>image_key</span><span class=p>,</span> <span class=kc>None</span><span class=p>)</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>images</span> <span class=o>=</span> <span class=p>[</span><span class=n>process_image</span><span class=p>(</span><span class=n>image</span><span class=p>)</span> <span class=k>for</span> <span class=n>image</span> <span class=ow>in</span> <span class=n>row_dict</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>image_key</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>                <span class=n>multi_modal_data</span><span class=p>[</span><span class=s2>&#34;image&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>images</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>videos</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>video_key</span> <span class=ow>in</span> <span class=n>row_dict</span> <span class=ow>and</span> <span class=n>row_dict</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>video_key</span><span class=p>,</span> <span class=kc>None</span><span class=p>)</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>videos</span> <span class=o>=</span> <span class=p>[</span><span class=n>process_video</span><span class=p>(</span><span class=n>video</span><span class=p>)</span> <span class=k>for</span> <span class=n>video</span> <span class=ow>in</span> <span class=n>row_dict</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>video_key</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>                <span class=n>multi_modal_data</span><span class=p>[</span><span class=s2>&#34;video&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=p>[</span><span class=n>video</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span> <span class=k>for</span> <span class=n>video</span> <span class=ow>in</span> <span class=n>videos</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>model_inputs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>processor</span><span class=p>(</span><span class=n>text</span><span class=o>=</span><span class=p>[</span><span class=n>raw_prompt</span><span class=p>],</span> <span class=n>images</span><span class=o>=</span><span class=n>images</span><span class=p>,</span> <span class=n>videos</span><span class=o>=</span><span class=n>videos</span><span class=p>,</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>input_ids</span> <span class=o>=</span> <span class=n>model_inputs</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=s2>&#34;input_ids&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>attention_mask</span> <span class=o>=</span> <span class=n>model_inputs</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=s2>&#34;attention_mask&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=s2>&#34;second_per_grid_ts&#34;</span> <span class=ow>in</span> <span class=n>model_inputs</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>model_inputs</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=s2>&#34;second_per_grid_ts&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># There&#39;s a trap here, multi_modal_inputs has to be a dict, not BatchFeature</span>
</span></span><span class=line><span class=cl>            <span class=n>row_dict</span><span class=p>[</span><span class=s2>&#34;multi_modal_data&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>multi_modal_data</span>
</span></span><span class=line><span class=cl>            <span class=n>row_dict</span><span class=p>[</span><span class=s2>&#34;multi_modal_inputs&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=nb>dict</span><span class=p>(</span><span class=n>model_inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># second_per_grid_ts isn&#39;t used for training, just for mrope</span>
</span></span><span class=line><span class=cl>            <span class=n>row_dict</span><span class=p>[</span><span class=s2>&#34;multi_modal_inputs&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=s2>&#34;second_per_grid_ts&#34;</span><span class=p>,</span> <span class=kc>None</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>raw_prompt</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>apply_chat_template</span><span class=p>(</span><span class=n>messages</span><span class=p>,</span> <span class=n>add_generation_prompt</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>tokenize</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>model_inputs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=p>(</span><span class=n>raw_prompt</span><span class=p>,</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>,</span> <span class=n>add_special_tokens</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>input_ids</span> <span class=o>=</span> <span class=n>model_inputs</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=s2>&#34;input_ids&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>attention_mask</span> <span class=o>=</span> <span class=n>model_inputs</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=s2>&#34;attention_mask&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>input_ids</span><span class=p>,</span> <span class=n>attention_mask</span> <span class=o>=</span> <span class=n>verl_F</span><span class=o>.</span><span class=n>postprocess_data</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>input_ids</span><span class=o>=</span><span class=n>input_ids</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>attention_mask</span><span class=o>=</span><span class=n>attention_mask</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>max_length</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>max_prompt_length</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>pad_token_id</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>pad_token_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>left_pad</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>truncation</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>truncation</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>processor</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span> <span class=ow>and</span> <span class=s2>&#34;Qwen2VLImageProcessor&#34;</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>processor</span><span class=o>.</span><span class=n>image_processor</span><span class=o>.</span><span class=vm>__class__</span><span class=o>.</span><span class=vm>__name__</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=kn>from</span> <span class=nn>verl.models.transformers.qwen2_vl</span> <span class=kn>import</span> <span class=n>get_rope_index</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>position_ids</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>                <span class=n>get_rope_index</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                    <span class=bp>self</span><span class=o>.</span><span class=n>processor</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>input_ids</span><span class=o>=</span><span class=n>input_ids</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                    <span class=n>image_grid_thw</span><span class=o>=</span><span class=n>model_inputs</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;image_grid_thw&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                    <span class=n>video_grid_thw</span><span class=o>=</span><span class=n>model_inputs</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;video_grid_thw&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                    <span class=n>second_per_grid_ts</span><span class=o>=</span><span class=n>model_inputs</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;second_per_grid_ts&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                    <span class=n>attention_mask</span><span class=o>=</span><span class=n>attention_mask</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                <span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=p>]</span>  <span class=c1># (1, 3, seq_len)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>position_ids</span> <span class=o>=</span> <span class=n>compute_position_id_with_mask</span><span class=p>(</span><span class=n>attention_mask</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>row_dict</span><span class=p>[</span><span class=s2>&#34;input_ids&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>input_ids</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>row_dict</span><span class=p>[</span><span class=s2>&#34;attention_mask&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>attention_mask</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>row_dict</span><span class=p>[</span><span class=s2>&#34;position_ids&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>position_ids</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>raw_prompt_ids</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=n>raw_prompt</span><span class=p>,</span> <span class=n>add_special_tokens</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>raw_prompt_ids</span><span class=p>)</span> <span class=o>&gt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>max_prompt_length</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>truncation</span> <span class=o>==</span> <span class=s2>&#34;left&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>raw_prompt_ids</span> <span class=o>=</span> <span class=n>raw_prompt_ids</span><span class=p>[</span><span class=o>-</span><span class=bp>self</span><span class=o>.</span><span class=n>max_prompt_length</span> <span class=p>:]</span>
</span></span><span class=line><span class=cl>            <span class=k>elif</span> <span class=bp>self</span><span class=o>.</span><span class=n>truncation</span> <span class=o>==</span> <span class=s2>&#34;right&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>raw_prompt_ids</span> <span class=o>=</span> <span class=n>raw_prompt_ids</span><span class=p>[:</span> <span class=bp>self</span><span class=o>.</span><span class=n>max_prompt_length</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=k>elif</span> <span class=bp>self</span><span class=o>.</span><span class=n>truncation</span> <span class=o>==</span> <span class=s2>&#34;middle&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>left_half</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>max_prompt_length</span> <span class=o>//</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl>                <span class=n>right_half</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>max_prompt_length</span> <span class=o>-</span> <span class=n>left_half</span>
</span></span><span class=line><span class=cl>                <span class=n>raw_prompt_ids</span> <span class=o>=</span> <span class=n>raw_prompt_ids</span><span class=p>[:</span><span class=n>left_half</span><span class=p>]</span> <span class=o>+</span> <span class=n>raw_prompt_ids</span><span class=p>[</span><span class=o>-</span><span class=n>right_half</span><span class=p>:]</span>
</span></span><span class=line><span class=cl>            <span class=k>elif</span> <span class=bp>self</span><span class=o>.</span><span class=n>truncation</span> <span class=o>==</span> <span class=s2>&#34;error&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Prompt length </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>raw_prompt_ids</span><span class=p>)</span><span class=si>}</span><span class=s2> is longer than </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>max_prompt_length</span><span class=si>}</span><span class=s2>.&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>row_dict</span><span class=p>[</span><span class=s2>&#34;raw_prompt_ids&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>raw_prompt_ids</span>
</span></span><span class=line><span class=cl>        <span class=c1># encode prompts without chat template</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>return_raw_chat</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>row_dict</span><span class=p>[</span><span class=s2>&#34;raw_prompt&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>messages</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># get prompts with chat template</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>return_full_prompt</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>row_dict</span><span class=p>[</span><span class=s2>&#34;full_prompts&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>raw_prompt</span>  <span class=c1># array of strings</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># add index for each prompt</span>
</span></span><span class=line><span class=cl>        <span class=n>index</span> <span class=o>=</span> <span class=n>row_dict</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;extra_info&#34;</span><span class=p>,</span> <span class=p>{})</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;index&#34;</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>tools_kwargs</span> <span class=o>=</span> <span class=n>row_dict</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;extra_info&#34;</span><span class=p>,</span> <span class=p>{})</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;tools_kwargs&#34;</span><span class=p>,</span> <span class=p>{})</span>
</span></span><span class=line><span class=cl>        <span class=n>need_tools_kwargs</span> <span class=o>=</span> <span class=n>row_dict</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;extra_info&#34;</span><span class=p>,</span> <span class=p>{})</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;need_tools_kwargs&#34;</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>need_tools_kwargs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>need_tools_kwargs</span> <span class=ow>and</span> <span class=ow>not</span> <span class=n>tools_kwargs</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>logger</span><span class=o>.</span><span class=n>warning</span><span class=p>(</span><span class=s2>&#34;tools_kwargs is empty for index </span><span class=si>{}</span><span class=s2>, data source: </span><span class=si>{}</span><span class=s2>&#34;</span><span class=p>,</span> <span class=n>index</span><span class=p>,</span> <span class=n>row_dict</span><span class=p>[</span><span class=s2>&#34;data_source&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=n>row_dict</span><span class=p>[</span><span class=s2>&#34;index&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>index</span>
</span></span><span class=line><span class=cl>        <span class=n>row_dict</span><span class=p>[</span><span class=s2>&#34;tools_kwargs&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>tools_kwargs</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>row_dict</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>__getstate__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=ow>not</span> <span class=bp>self</span><span class=o>.</span><span class=n>serialize_dataset</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>state</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=vm>__dict__</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=s2>&#34;dataframe&#34;</span> <span class=ow>in</span> <span class=n>state</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>del</span> <span class=n>state</span><span class=p>[</span><span class=s2>&#34;dataframe&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=n>state</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=vm>__dict__</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div></details><ol><li>支持从远程存储下载 Parquet 文件到本地缓存，支持共享内存加速文件访问，自动管理文件路径，支持检查点恢复。</li><li>使用 HuggingFace <code>datasets</code> 库读取 Parquet 文件，支持多个数据文件的合并，自动处理数据格式转换。</li><li>根据最大长度过滤过长的 prompts，支持多进程并行处理，可配置的过滤策略。</li><li>支持图像和视频的多模态输入，解析 <code>&lt;image></code> 和 <code>&lt;video></code> 标签，将多模态内容转换为结构化格式。</li><li>添加 chat template 来格式化对话，将文本转换为 token IDs，生成 attn mask 和 position ids。</li><li>padding 到指定长度，支持多种截断策略（left, right, middle, error），生成位置编码。</li><li>支持训练中断后的恢复，可以从原始文件重新构建数据集，兼容序列化/反序列化。</li><li>返回包含以下关键字段的字典：<code>input_ids</code>, <code>attention_mask</code>, <code>position_ids</code>, <code>raw_prompt_ids</code>, <code>multi_modal_data</code>, <code>multi_modal_inputs</code>, <code>index</code>, <code>tools_kwargs</code>。</li></ol><p>这里最重要的一个参数是 <code>tools_kwargs</code>，用于为不同的 tools 提供配置参数。它的结构如下：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>tools_kwargs</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;tool_name&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;create_kwargs&#34;</span><span class=p>:</span> <span class=p>{</span><span class=o>...</span><span class=p>},</span>      <span class=c1># 工具创建时的参数</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;execute_kwargs&#34;</span><span class=p>:</span> <span class=p>{</span><span class=o>...</span><span class=p>},</span>     <span class=c1># 工具执行时的参数（可选）</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;calc_reward_kwargs&#34;</span><span class=p>:</span> <span class=p>{</span><span class=o>...</span><span class=p>},</span> <span class=c1># 计算奖励时的参数（可选）</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;release_kwargs&#34;</span><span class=p>:</span> <span class=p>{</span><span class=o>...</span><span class=p>},</span>     <span class=c1># 释放资源时的参数（可选）</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><p>比如 Search-R1 的 <code>tools_kwargs</code> 如下：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>tools_kwargs</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;search-r1&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;create_kwargs&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;ground_truth&#34;</span><span class=p>:</span> <span class=n>ground_truth</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;question&#34;</span><span class=p>:</span> <span class=n>question</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>            <span class=s2>&#34;data_source&#34;</span><span class=p>:</span> <span class=n>data_source_tagged</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><p>具体这些参数是如何调用了一个 tool，我们会留在后续部分继续介绍。</p><h2 id=训练入口-rayppotrainerfit>训练入口 <a href=https://github.com/volcengine/verl/blob/76f63cffa5081564d8fea93a1cb3ce8bd5bdcc39/verl/trainer/ppo/ray_trainer.py#L903><code>RayPPOTrainer.fit()</code></a><a hidden class=anchor aria-hidden=true href=#训练入口-rayppotrainerfit>#</a></h2><ol><li>创建 Tracking 日志记录器，设置全局步数，加载检查点，并在训练前进行验证。</li><li>使用 tqdm 创建进度条，显示训练进度，并设置初始步数。</li><li>遍历配置的总 epoch 数和数据加载器，每个 train batch 更新多步。</li><li>从 batch 中分离出用于 rollout 的数据（<code>input_ids</code>, <code>attention_mask</code>, <code>position_ids</code> 等），保留其他数据用于后续处理。</li><li>调用 <code>ActorRolloutWorker</code> 生成序列，并记录生成时间。</li><li>处理 REMAX 基线（如果使用）：生成确定性基线序列，计算基线奖励，用于 REMAX 优势估计器。</li><li>为每个样本分配唯一 ID，重复数据以对齐多次采样，计算响应掩码，并可选地进行批次平衡。</li><li>根据配置使用奖励模型或自定义奖励函数计算 token 级别的奖励分数，支持同步和异步计算。</li><li>使用 megatron 基于训练开始前的 policy 重新计算 behaviour policy 的 log probabilities，用于重要性采样，同时计算熵值。（原因在 part 1讲过）</li><li>使用 reference policy 计算 log probs，用于 KL 散度计算。</li><li>使用 Critic 网络计算状态价值，用于优势函数估计。</li><li>根据配置的优势估计器（GAE、GRPO、REMAX 等）计算优势函数，支持 KL 惩罚。</li><li>使用计算出的优势函数更新 Critic 网络参数。</li><li>在 Critic 预热完成后，使用 PPO 损失函数更新 Actor 网络参数。</li><li>将生成的序列、输入、输出和分数保存到指定目录。</li><li>根据配置的频率执行验证，计算验证指标并记录。</li><li>根据配置的频率保存模型检查点。</li><li>收集训练指标、时序指标和吞吐量指标，并记录到日志系统。</li><li>更新进度条，递增全局步数，并在达到总训练步数时结束训练。</li><li>根据配置在特定步数启用/禁用性能分析，用于调试和优化。</li></ol><details><summary>RayPPOTrainer.fit() 源码</summary><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span><span class=lnt>108
</span><span class=lnt>109
</span><span class=lnt>110
</span><span class=lnt>111
</span><span class=lnt>112
</span><span class=lnt>113
</span><span class=lnt>114
</span><span class=lnt>115
</span><span class=lnt>116
</span><span class=lnt>117
</span><span class=lnt>118
</span><span class=lnt>119
</span><span class=lnt>120
</span><span class=lnt>121
</span><span class=lnt>122
</span><span class=lnt>123
</span><span class=lnt>124
</span><span class=lnt>125
</span><span class=lnt>126
</span><span class=lnt>127
</span><span class=lnt>128
</span><span class=lnt>129
</span><span class=lnt>130
</span><span class=lnt>131
</span><span class=lnt>132
</span><span class=lnt>133
</span><span class=lnt>134
</span><span class=lnt>135
</span><span class=lnt>136
</span><span class=lnt>137
</span><span class=lnt>138
</span><span class=lnt>139
</span><span class=lnt>140
</span><span class=lnt>141
</span><span class=lnt>142
</span><span class=lnt>143
</span><span class=lnt>144
</span><span class=lnt>145
</span><span class=lnt>146
</span><span class=lnt>147
</span><span class=lnt>148
</span><span class=lnt>149
</span><span class=lnt>150
</span><span class=lnt>151
</span><span class=lnt>152
</span><span class=lnt>153
</span><span class=lnt>154
</span><span class=lnt>155
</span><span class=lnt>156
</span><span class=lnt>157
</span><span class=lnt>158
</span><span class=lnt>159
</span><span class=lnt>160
</span><span class=lnt>161
</span><span class=lnt>162
</span><span class=lnt>163
</span><span class=lnt>164
</span><span class=lnt>165
</span><span class=lnt>166
</span><span class=lnt>167
</span><span class=lnt>168
</span><span class=lnt>169
</span><span class=lnt>170
</span><span class=lnt>171
</span><span class=lnt>172
</span><span class=lnt>173
</span><span class=lnt>174
</span><span class=lnt>175
</span><span class=lnt>176
</span><span class=lnt>177
</span><span class=lnt>178
</span><span class=lnt>179
</span><span class=lnt>180
</span><span class=lnt>181
</span><span class=lnt>182
</span><span class=lnt>183
</span><span class=lnt>184
</span><span class=lnt>185
</span><span class=lnt>186
</span><span class=lnt>187
</span><span class=lnt>188
</span><span class=lnt>189
</span><span class=lnt>190
</span><span class=lnt>191
</span><span class=lnt>192
</span><span class=lnt>193
</span><span class=lnt>194
</span><span class=lnt>195
</span><span class=lnt>196
</span><span class=lnt>197
</span><span class=lnt>198
</span><span class=lnt>199
</span><span class=lnt>200
</span><span class=lnt>201
</span><span class=lnt>202
</span><span class=lnt>203
</span><span class=lnt>204
</span><span class=lnt>205
</span><span class=lnt>206
</span><span class=lnt>207
</span><span class=lnt>208
</span><span class=lnt>209
</span><span class=lnt>210
</span><span class=lnt>211
</span><span class=lnt>212
</span><span class=lnt>213
</span><span class=lnt>214
</span><span class=lnt>215
</span><span class=lnt>216
</span><span class=lnt>217
</span><span class=lnt>218
</span><span class=lnt>219
</span><span class=lnt>220
</span><span class=lnt>221
</span><span class=lnt>222
</span><span class=lnt>223
</span><span class=lnt>224
</span><span class=lnt>225
</span><span class=lnt>226
</span><span class=lnt>227
</span><span class=lnt>228
</span><span class=lnt>229
</span><span class=lnt>230
</span><span class=lnt>231
</span><span class=lnt>232
</span><span class=lnt>233
</span><span class=lnt>234
</span><span class=lnt>235
</span><span class=lnt>236
</span><span class=lnt>237
</span><span class=lnt>238
</span><span class=lnt>239
</span><span class=lnt>240
</span><span class=lnt>241
</span><span class=lnt>242
</span><span class=lnt>243
</span><span class=lnt>244
</span><span class=lnt>245
</span><span class=lnt>246
</span><span class=lnt>247
</span><span class=lnt>248
</span><span class=lnt>249
</span><span class=lnt>250
</span><span class=lnt>251
</span><span class=lnt>252
</span><span class=lnt>253
</span><span class=lnt>254
</span><span class=lnt>255
</span><span class=lnt>256
</span><span class=lnt>257
</span><span class=lnt>258
</span><span class=lnt>259
</span><span class=lnt>260
</span><span class=lnt>261
</span><span class=lnt>262
</span><span class=lnt>263
</span><span class=lnt>264
</span><span class=lnt>265
</span><span class=lnt>266
</span><span class=lnt>267
</span><span class=lnt>268
</span><span class=lnt>269
</span><span class=lnt>270
</span><span class=lnt>271
</span><span class=lnt>272
</span><span class=lnt>273
</span><span class=lnt>274
</span><span class=lnt>275
</span><span class=lnt>276
</span><span class=lnt>277
</span><span class=lnt>278
</span><span class=lnt>279
</span><span class=lnt>280
</span><span class=lnt>281
</span><span class=lnt>282
</span><span class=lnt>283
</span><span class=lnt>284
</span><span class=lnt>285
</span><span class=lnt>286
</span><span class=lnt>287
</span><span class=lnt>288
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>fit</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    The training loop of PPO.
</span></span></span><span class=line><span class=cl><span class=s2>    The driver process only need to call the compute functions of the worker group through RPC
</span></span></span><span class=line><span class=cl><span class=s2>    to construct the PPO dataflow.
</span></span></span><span class=line><span class=cl><span class=s2>    The light-weight advantage computation is done on the driver process.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=kn>from</span> <span class=nn>omegaconf</span> <span class=kn>import</span> <span class=n>OmegaConf</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=kn>from</span> <span class=nn>verl.utils.tracking</span> <span class=kn>import</span> <span class=n>Tracking</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>logger</span> <span class=o>=</span> <span class=n>Tracking</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>project_name</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>project_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>experiment_name</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>experiment_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>default_backend</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>logger</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>config</span><span class=o>=</span><span class=n>OmegaConf</span><span class=o>.</span><span class=n>to_container</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=p>,</span> <span class=n>resolve</span><span class=o>=</span><span class=kc>True</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>global_steps</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># load checkpoint before doing anything</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>_load_checkpoint</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># perform validation before training</span>
</span></span><span class=line><span class=cl>    <span class=c1># currently, we only support validation using the reward_function.</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>val_reward_fn</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span> <span class=ow>and</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;val_before_train&#34;</span><span class=p>,</span> <span class=kc>True</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>val_metrics</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_validate</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>assert</span> <span class=n>val_metrics</span><span class=p>,</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>val_metrics</span><span class=si>=}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>pprint</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Initial validation metrics: </span><span class=si>{</span><span class=n>val_metrics</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>logger</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>data</span><span class=o>=</span><span class=n>val_metrics</span><span class=p>,</span> <span class=n>step</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>global_steps</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;val_only&#34;</span><span class=p>,</span> <span class=kc>False</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># add tqdm</span>
</span></span><span class=line><span class=cl>    <span class=n>progress_bar</span> <span class=o>=</span> <span class=n>tqdm</span><span class=p>(</span><span class=n>total</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>total_training_steps</span><span class=p>,</span> <span class=n>initial</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>global_steps</span><span class=p>,</span> <span class=n>desc</span><span class=o>=</span><span class=s2>&#34;Training Progress&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># we start from step 1</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>global_steps</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>    <span class=n>last_val_metrics</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>total_epochs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>batch_dict</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>train_dataloader</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>do_profile</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>global_steps</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>profile_steps</span> <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>profile_steps</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span> <span class=k>else</span> <span class=kc>False</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>do_profile</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>actor_rollout_wg</span><span class=o>.</span><span class=n>start_profile</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>use_reference_policy</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=bp>self</span><span class=o>.</span><span class=n>ref_policy_wg</span><span class=o>.</span><span class=n>start_profile</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>use_critic</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=bp>self</span><span class=o>.</span><span class=n>critic_wg</span><span class=o>.</span><span class=n>start_profile</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>use_rm</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=bp>self</span><span class=o>.</span><span class=n>rm_wg</span><span class=o>.</span><span class=n>start_profile</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>metrics</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>            <span class=n>timing_raw</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>            <span class=n>batch</span><span class=p>:</span> <span class=n>DataProto</span> <span class=o>=</span> <span class=n>DataProto</span><span class=o>.</span><span class=n>from_single_dict</span><span class=p>(</span><span class=n>batch_dict</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># pop those keys for generation</span>
</span></span><span class=line><span class=cl>            <span class=n>batch_keys_to_pop</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&#34;input_ids&#34;</span><span class=p>,</span> <span class=s2>&#34;attention_mask&#34;</span><span class=p>,</span> <span class=s2>&#34;position_ids&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=n>non_tensor_batch_keys_to_pop</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&#34;raw_prompt_ids&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=s2>&#34;multi_modal_data&#34;</span> <span class=ow>in</span> <span class=n>batch</span><span class=o>.</span><span class=n>non_tensor_batch</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>non_tensor_batch_keys_to_pop</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=s2>&#34;multi_modal_data&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=s2>&#34;raw_prompt&#34;</span> <span class=ow>in</span> <span class=n>batch</span><span class=o>.</span><span class=n>non_tensor_batch</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>non_tensor_batch_keys_to_pop</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=s2>&#34;raw_prompt&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=s2>&#34;tools_kwargs&#34;</span> <span class=ow>in</span> <span class=n>batch</span><span class=o>.</span><span class=n>non_tensor_batch</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>non_tensor_batch_keys_to_pop</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=s2>&#34;tools_kwargs&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>gen_batch</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>batch_keys</span><span class=o>=</span><span class=n>batch_keys_to_pop</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>non_tensor_batch_keys</span><span class=o>=</span><span class=n>non_tensor_batch_keys_to_pop</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>is_last_step</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>global_steps</span> <span class=o>&gt;=</span> <span class=bp>self</span><span class=o>.</span><span class=n>total_training_steps</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=k>with</span> <span class=n>marked_timer</span><span class=p>(</span><span class=s2>&#34;step&#34;</span><span class=p>,</span> <span class=n>timing_raw</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=c1># generate a batch</span>
</span></span><span class=line><span class=cl>                <span class=k>with</span> <span class=n>marked_timer</span><span class=p>(</span><span class=s2>&#34;gen&#34;</span><span class=p>,</span> <span class=n>timing_raw</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&#34;red&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                    <span class=k>if</span> <span class=ow>not</span> <span class=bp>self</span><span class=o>.</span><span class=n>async_rollout_mode</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                        <span class=n>gen_batch_output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>actor_rollout_wg</span><span class=o>.</span><span class=n>generate_sequences</span><span class=p>(</span><span class=n>gen_batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                        <span class=bp>self</span><span class=o>.</span><span class=n>async_rollout_manager</span><span class=o>.</span><span class=n>wake_up</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                        <span class=n>gen_batch_output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>async_rollout_manager</span><span class=o>.</span><span class=n>generate_sequences</span><span class=p>(</span><span class=n>gen_batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=bp>self</span><span class=o>.</span><span class=n>async_rollout_manager</span><span class=o>.</span><span class=n>sleep</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                    <span class=n>timing_raw</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=n>gen_batch_output</span><span class=o>.</span><span class=n>meta_info</span><span class=p>[</span><span class=s2>&#34;timing&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>                    <span class=n>gen_batch_output</span><span class=o>.</span><span class=n>meta_info</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=s2>&#34;timing&#34;</span><span class=p>,</span> <span class=kc>None</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>algorithm</span><span class=o>.</span><span class=n>adv_estimator</span> <span class=o>==</span> <span class=n>AdvantageEstimator</span><span class=o>.</span><span class=n>REMAX</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=k>with</span> <span class=n>marked_timer</span><span class=p>(</span><span class=s2>&#34;gen_max&#34;</span><span class=p>,</span> <span class=n>timing_raw</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&#34;purple&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                        <span class=n>gen_baseline_batch</span> <span class=o>=</span> <span class=n>deepcopy</span><span class=p>(</span><span class=n>gen_batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=n>gen_baseline_batch</span><span class=o>.</span><span class=n>meta_info</span><span class=p>[</span><span class=s2>&#34;do_sample&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=kc>False</span>
</span></span><span class=line><span class=cl>                        <span class=n>gen_baseline_output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>actor_rollout_wg</span><span class=o>.</span><span class=n>generate_sequences</span><span class=p>(</span><span class=n>gen_baseline_batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                        <span class=n>batch</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>union</span><span class=p>(</span><span class=n>gen_baseline_output</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=n>reward_baseline_tensor</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>reward_fn</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=n>reward_baseline_tensor</span> <span class=o>=</span> <span class=n>reward_baseline_tensor</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                        <span class=n>batch</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=n>batch_keys</span><span class=o>=</span><span class=nb>list</span><span class=p>(</span><span class=n>gen_baseline_output</span><span class=o>.</span><span class=n>batch</span><span class=o>.</span><span class=n>keys</span><span class=p>()))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                        <span class=n>batch</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;reward_baselines&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>reward_baseline_tensor</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                        <span class=k>del</span> <span class=n>gen_baseline_batch</span><span class=p>,</span> <span class=n>gen_baseline_output</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=n>batch</span><span class=o>.</span><span class=n>non_tensor_batch</span><span class=p>[</span><span class=s2>&#34;uid&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=nb>str</span><span class=p>(</span><span class=n>uuid</span><span class=o>.</span><span class=n>uuid4</span><span class=p>())</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>batch</span><span class=o>.</span><span class=n>batch</span><span class=p>))],</span> <span class=n>dtype</span><span class=o>=</span><span class=nb>object</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=c1># repeat to align with repeated responses in rollout</span>
</span></span><span class=line><span class=cl>                <span class=n>batch</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>repeat</span><span class=p>(</span><span class=n>repeat_times</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>n</span><span class=p>,</span> <span class=n>interleave</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>batch</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>union</span><span class=p>(</span><span class=n>gen_batch_output</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=n>batch</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;response_mask&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>compute_response_mask</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=c1># Balance the number of valid tokens across DP ranks.</span>
</span></span><span class=line><span class=cl>                <span class=c1># NOTE: This usually changes the order of data in the `batch`,</span>
</span></span><span class=line><span class=cl>                <span class=c1># which won&#39;t affect the advantage calculation (since it&#39;s based on uid),</span>
</span></span><span class=line><span class=cl>                <span class=c1># but might affect the loss calculation (due to the change of mini-batching).</span>
</span></span><span class=line><span class=cl>                <span class=c1># TODO: Decouple the DP balancing and mini-batching.</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>balance_batch</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=bp>self</span><span class=o>.</span><span class=n>_balance_batch</span><span class=p>(</span><span class=n>batch</span><span class=p>,</span> <span class=n>metrics</span><span class=o>=</span><span class=n>metrics</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=c1># compute global_valid tokens</span>
</span></span><span class=line><span class=cl>                <span class=n>batch</span><span class=o>.</span><span class=n>meta_info</span><span class=p>[</span><span class=s2>&#34;global_token_num&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>batch</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;attention_mask&#34;</span><span class=p>],</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>tolist</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=k>with</span> <span class=n>marked_timer</span><span class=p>(</span><span class=s2>&#34;reward&#34;</span><span class=p>,</span> <span class=n>timing_raw</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&#34;yellow&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                    <span class=c1># compute reward model score</span>
</span></span><span class=line><span class=cl>                    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>use_rm</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                        <span class=n>reward_tensor</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>rm_wg</span><span class=o>.</span><span class=n>compute_rm_score</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=n>batch</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>union</span><span class=p>(</span><span class=n>reward_tensor</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>reward_model</span><span class=o>.</span><span class=n>launch_reward_fn_async</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                        <span class=n>future_reward</span> <span class=o>=</span> <span class=n>compute_reward_async</span><span class=o>.</span><span class=n>remote</span><span class=p>(</span><span class=n>batch</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                        <span class=n>reward_tensor</span><span class=p>,</span> <span class=n>reward_extra_infos_dict</span> <span class=o>=</span> <span class=n>compute_reward</span><span class=p>(</span><span class=n>batch</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>reward_fn</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=c1># recompute old_log_probs</span>
</span></span><span class=line><span class=cl>                <span class=k>with</span> <span class=n>marked_timer</span><span class=p>(</span><span class=s2>&#34;old_log_prob&#34;</span><span class=p>,</span> <span class=n>timing_raw</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&#34;blue&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                    <span class=n>old_log_prob</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>actor_rollout_wg</span><span class=o>.</span><span class=n>compute_log_prob</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>entropys</span> <span class=o>=</span> <span class=n>old_log_prob</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;entropys&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                    <span class=n>response_masks</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;response_mask&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                    <span class=n>loss_agg_mode</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>actor</span><span class=o>.</span><span class=n>loss_agg_mode</span>
</span></span><span class=line><span class=cl>                    <span class=n>entropy_agg</span> <span class=o>=</span> <span class=n>agg_loss</span><span class=p>(</span><span class=n>loss_mat</span><span class=o>=</span><span class=n>entropys</span><span class=p>,</span> <span class=n>loss_mask</span><span class=o>=</span><span class=n>response_masks</span><span class=p>,</span> <span class=n>loss_agg_mode</span><span class=o>=</span><span class=n>loss_agg_mode</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>old_log_prob_metrics</span> <span class=o>=</span> <span class=p>{</span><span class=s2>&#34;actor/entropy&#34;</span><span class=p>:</span> <span class=n>entropy_agg</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span><span class=o>.</span><span class=n>item</span><span class=p>()}</span>
</span></span><span class=line><span class=cl>                    <span class=n>metrics</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=n>old_log_prob_metrics</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>old_log_prob</span><span class=o>.</span><span class=n>batch</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=s2>&#34;entropys&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>batch</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>union</span><span class=p>(</span><span class=n>old_log_prob</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                    <span class=k>if</span> <span class=s2>&#34;rollout_log_probs&#34;</span> <span class=ow>in</span> <span class=n>batch</span><span class=o>.</span><span class=n>batch</span><span class=o>.</span><span class=n>keys</span><span class=p>():</span>
</span></span><span class=line><span class=cl>                        <span class=c1># TODO: we may want to add diff of probs too.</span>
</span></span><span class=line><span class=cl>                        <span class=n>rollout_old_log_probs</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;rollout_log_probs&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                        <span class=n>actor_old_log_probs</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;old_log_probs&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                        <span class=n>attention_mask</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;attention_mask&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                        <span class=n>responses</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;responses&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                        <span class=n>response_length</span> <span class=o>=</span> <span class=n>responses</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=n>response_mask</span> <span class=o>=</span> <span class=n>attention_mask</span><span class=p>[:,</span> <span class=o>-</span><span class=n>response_length</span><span class=p>:]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                        <span class=n>rollout_probs</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=n>rollout_old_log_probs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=n>actor_probs</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=n>actor_old_log_probs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=n>rollout_probs_diff</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>rollout_probs</span> <span class=o>-</span> <span class=n>actor_probs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=n>rollout_probs_diff</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>masked_select</span><span class=p>(</span><span class=n>rollout_probs_diff</span><span class=p>,</span> <span class=n>response_mask</span><span class=o>.</span><span class=n>bool</span><span class=p>())</span>
</span></span><span class=line><span class=cl>                        <span class=n>rollout_probs_diff_max</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>rollout_probs_diff</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=n>rollout_probs_diff_mean</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>rollout_probs_diff</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=n>rollout_probs_diff_std</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>std</span><span class=p>(</span><span class=n>rollout_probs_diff</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=n>metrics</span><span class=o>.</span><span class=n>update</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                            <span class=p>{</span>
</span></span><span class=line><span class=cl>                                <span class=s2>&#34;training/rollout_probs_diff_max&#34;</span><span class=p>:</span> <span class=n>rollout_probs_diff_max</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span><span class=o>.</span><span class=n>item</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>                                <span class=s2>&#34;training/rollout_probs_diff_mean&#34;</span><span class=p>:</span> <span class=n>rollout_probs_diff_mean</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span><span class=o>.</span><span class=n>item</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>                                <span class=s2>&#34;training/rollout_probs_diff_std&#34;</span><span class=p>:</span> <span class=n>rollout_probs_diff_std</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span><span class=o>.</span><span class=n>item</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>                            <span class=p>}</span>
</span></span><span class=line><span class=cl>                        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>use_reference_policy</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=c1># compute reference log_prob</span>
</span></span><span class=line><span class=cl>                    <span class=k>with</span> <span class=n>marked_timer</span><span class=p>(</span><span class=s2>&#34;ref&#34;</span><span class=p>,</span> <span class=n>timing_raw</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&#34;olive&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                        <span class=k>if</span> <span class=ow>not</span> <span class=bp>self</span><span class=o>.</span><span class=n>ref_in_actor</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                            <span class=n>ref_log_prob</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>ref_policy_wg</span><span class=o>.</span><span class=n>compute_ref_log_prob</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                            <span class=n>ref_log_prob</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>actor_rollout_wg</span><span class=o>.</span><span class=n>compute_ref_log_prob</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=n>batch</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>union</span><span class=p>(</span><span class=n>ref_log_prob</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=c1># compute values</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>use_critic</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=k>with</span> <span class=n>marked_timer</span><span class=p>(</span><span class=s2>&#34;values&#34;</span><span class=p>,</span> <span class=n>timing_raw</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&#34;cyan&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                        <span class=n>values</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>critic_wg</span><span class=o>.</span><span class=n>compute_values</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=n>batch</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>union</span><span class=p>(</span><span class=n>values</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=k>with</span> <span class=n>marked_timer</span><span class=p>(</span><span class=s2>&#34;adv&#34;</span><span class=p>,</span> <span class=n>timing_raw</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&#34;brown&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                    <span class=c1># we combine with rule-based rm</span>
</span></span><span class=line><span class=cl>                    <span class=n>reward_extra_infos_dict</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=nb>list</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>reward_model</span><span class=o>.</span><span class=n>launch_reward_fn_async</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                        <span class=n>reward_tensor</span><span class=p>,</span> <span class=n>reward_extra_infos_dict</span> <span class=o>=</span> <span class=n>ray</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>future_reward</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>batch</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;token_level_scores&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>reward_tensor</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                    <span class=k>if</span> <span class=n>reward_extra_infos_dict</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                        <span class=n>batch</span><span class=o>.</span><span class=n>non_tensor_batch</span><span class=o>.</span><span class=n>update</span><span class=p>({</span><span class=n>k</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>v</span><span class=p>)</span> <span class=k>for</span> <span class=n>k</span><span class=p>,</span> <span class=n>v</span> <span class=ow>in</span> <span class=n>reward_extra_infos_dict</span><span class=o>.</span><span class=n>items</span><span class=p>()})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                    <span class=c1># compute rewards. apply_kl_penalty if available</span>
</span></span><span class=line><span class=cl>                    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>algorithm</span><span class=o>.</span><span class=n>use_kl_in_reward</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                        <span class=n>batch</span><span class=p>,</span> <span class=n>kl_metrics</span> <span class=o>=</span> <span class=n>apply_kl_penalty</span><span class=p>(</span><span class=n>batch</span><span class=p>,</span> <span class=n>kl_ctrl</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>kl_ctrl_in_reward</span><span class=p>,</span> <span class=n>kl_penalty</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>algorithm</span><span class=o>.</span><span class=n>kl_penalty</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=n>metrics</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=n>kl_metrics</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                        <span class=n>batch</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;token_level_rewards&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;token_level_scores&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                    <span class=c1># compute advantages, executed on the driver process</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                    <span class=n>norm_adv_by_std_in_grpo</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>algorithm</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;norm_adv_by_std_in_grpo&#34;</span><span class=p>,</span> <span class=kc>True</span><span class=p>)</span>  <span class=c1># GRPO adv normalization factor</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                    <span class=n>batch</span> <span class=o>=</span> <span class=n>compute_advantage</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                        <span class=n>batch</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>adv_estimator</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>algorithm</span><span class=o>.</span><span class=n>adv_estimator</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>gamma</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>algorithm</span><span class=o>.</span><span class=n>gamma</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>lam</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>algorithm</span><span class=o>.</span><span class=n>lam</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>num_repeat</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>n</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>norm_adv_by_std_in_grpo</span><span class=o>=</span><span class=n>norm_adv_by_std_in_grpo</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>multi_turn</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>multi_turn</span><span class=o>.</span><span class=n>enable</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>config</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>algorithm</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=c1># update critic</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>use_critic</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=k>with</span> <span class=n>marked_timer</span><span class=p>(</span><span class=s2>&#34;update_critic&#34;</span><span class=p>,</span> <span class=n>timing_raw</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&#34;pink&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                        <span class=n>critic_output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>critic_wg</span><span class=o>.</span><span class=n>update_critic</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>critic_output_metrics</span> <span class=o>=</span> <span class=n>reduce_metrics</span><span class=p>(</span><span class=n>critic_output</span><span class=o>.</span><span class=n>meta_info</span><span class=p>[</span><span class=s2>&#34;metrics&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>                    <span class=n>metrics</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=n>critic_output_metrics</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=c1># implement critic warmup</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>critic_warmup</span> <span class=o>&lt;=</span> <span class=bp>self</span><span class=o>.</span><span class=n>global_steps</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=c1># update actor</span>
</span></span><span class=line><span class=cl>                    <span class=k>with</span> <span class=n>marked_timer</span><span class=p>(</span><span class=s2>&#34;update_actor&#34;</span><span class=p>,</span> <span class=n>timing_raw</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&#34;red&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                        <span class=n>batch</span><span class=o>.</span><span class=n>meta_info</span><span class=p>[</span><span class=s2>&#34;multi_turn&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>multi_turn</span><span class=o>.</span><span class=n>enable</span>
</span></span><span class=line><span class=cl>                        <span class=n>actor_output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>actor_rollout_wg</span><span class=o>.</span><span class=n>update_actor</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>actor_output_metrics</span> <span class=o>=</span> <span class=n>reduce_metrics</span><span class=p>(</span><span class=n>actor_output</span><span class=o>.</span><span class=n>meta_info</span><span class=p>[</span><span class=s2>&#34;metrics&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>                    <span class=n>metrics</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=n>actor_output_metrics</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=c1># Log rollout generations if enabled</span>
</span></span><span class=line><span class=cl>                <span class=n>rollout_data_dir</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;rollout_data_dir&#34;</span><span class=p>,</span> <span class=kc>None</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=n>rollout_data_dir</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=k>with</span> <span class=n>marked_timer</span><span class=p>(</span><span class=s2>&#34;dump_rollout_generations&#34;</span><span class=p>,</span> <span class=n>timing_raw</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&#34;green&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                        <span class=nb>print</span><span class=p>(</span><span class=n>batch</span><span class=o>.</span><span class=n>batch</span><span class=o>.</span><span class=n>keys</span><span class=p>())</span>
</span></span><span class=line><span class=cl>                        <span class=n>inputs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>batch_decode</span><span class=p>(</span><span class=n>batch</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;prompts&#34;</span><span class=p>],</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=n>outputs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>batch_decode</span><span class=p>(</span><span class=n>batch</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;responses&#34;</span><span class=p>],</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=n>scores</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;token_level_scores&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>tolist</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                        <span class=bp>self</span><span class=o>.</span><span class=n>_dump_generations</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                            <span class=n>inputs</span><span class=o>=</span><span class=n>inputs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                            <span class=n>outputs</span><span class=o>=</span><span class=n>outputs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                            <span class=n>scores</span><span class=o>=</span><span class=n>scores</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                            <span class=n>reward_extra_infos_dict</span><span class=o>=</span><span class=n>reward_extra_infos_dict</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                            <span class=n>dump_path</span><span class=o>=</span><span class=n>rollout_data_dir</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=c1># validate</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>val_reward_fn</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span> <span class=ow>and</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>test_freq</span> <span class=o>&gt;</span> <span class=mi>0</span> <span class=ow>and</span> <span class=p>(</span><span class=n>is_last_step</span> <span class=ow>or</span> <span class=bp>self</span><span class=o>.</span><span class=n>global_steps</span> <span class=o>%</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>test_freq</span> <span class=o>==</span> <span class=mi>0</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                    <span class=k>with</span> <span class=n>marked_timer</span><span class=p>(</span><span class=s2>&#34;testing&#34;</span><span class=p>,</span> <span class=n>timing_raw</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&#34;green&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                        <span class=n>val_metrics</span><span class=p>:</span> <span class=nb>dict</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_validate</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                        <span class=k>if</span> <span class=n>is_last_step</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                            <span class=n>last_val_metrics</span> <span class=o>=</span> <span class=n>val_metrics</span>
</span></span><span class=line><span class=cl>                    <span class=n>metrics</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=n>val_metrics</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>save_freq</span> <span class=o>&gt;</span> <span class=mi>0</span> <span class=ow>and</span> <span class=p>(</span><span class=n>is_last_step</span> <span class=ow>or</span> <span class=bp>self</span><span class=o>.</span><span class=n>global_steps</span> <span class=o>%</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>save_freq</span> <span class=o>==</span> <span class=mi>0</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                    <span class=k>with</span> <span class=n>marked_timer</span><span class=p>(</span><span class=s2>&#34;save_checkpoint&#34;</span><span class=p>,</span> <span class=n>timing_raw</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&#34;green&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                        <span class=bp>self</span><span class=o>.</span><span class=n>_save_checkpoint</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># training metrics</span>
</span></span><span class=line><span class=cl>            <span class=n>metrics</span><span class=o>.</span><span class=n>update</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=p>{</span>
</span></span><span class=line><span class=cl>                    <span class=s2>&#34;training/global_step&#34;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>global_steps</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=s2>&#34;training/epoch&#34;</span><span class=p>:</span> <span class=n>epoch</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=p>}</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=c1># collect metrics</span>
</span></span><span class=line><span class=cl>            <span class=n>metrics</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=n>compute_data_metrics</span><span class=p>(</span><span class=n>batch</span><span class=o>=</span><span class=n>batch</span><span class=p>,</span> <span class=n>use_critic</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>use_critic</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=n>metrics</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=n>compute_timing_metrics</span><span class=p>(</span><span class=n>batch</span><span class=o>=</span><span class=n>batch</span><span class=p>,</span> <span class=n>timing_raw</span><span class=o>=</span><span class=n>timing_raw</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=c1># TODO: implement actual tflpo and theoretical tflpo</span>
</span></span><span class=line><span class=cl>            <span class=n>n_gpus</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>resource_pool_manager</span><span class=o>.</span><span class=n>get_n_gpus</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>metrics</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=n>compute_throughout_metrics</span><span class=p>(</span><span class=n>batch</span><span class=o>=</span><span class=n>batch</span><span class=p>,</span> <span class=n>timing_raw</span><span class=o>=</span><span class=n>timing_raw</span><span class=p>,</span> <span class=n>n_gpus</span><span class=o>=</span><span class=n>n_gpus</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># TODO: make a canonical logger that supports various backend</span>
</span></span><span class=line><span class=cl>            <span class=n>logger</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>data</span><span class=o>=</span><span class=n>metrics</span><span class=p>,</span> <span class=n>step</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>global_steps</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>progress_bar</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>global_steps</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>do_profile</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>actor_rollout_wg</span><span class=o>.</span><span class=n>stop_profile</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>use_reference_policy</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=bp>self</span><span class=o>.</span><span class=n>ref_policy_wg</span><span class=o>.</span><span class=n>stop_profile</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>use_critic</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=bp>self</span><span class=o>.</span><span class=n>critic_wg</span><span class=o>.</span><span class=n>stop_profile</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>use_rm</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=bp>self</span><span class=o>.</span><span class=n>rm_wg</span><span class=o>.</span><span class=n>stop_profile</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>is_last_step</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>pprint</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Final validation metrics: </span><span class=si>{</span><span class=n>last_val_metrics</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>progress_bar</span><span class=o>.</span><span class=n>close</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                <span class=k>return</span>
</span></span></code></pre></td></tr></table></div></div></details><h2 id=我们究竟在异步什么>我们究竟在异步什么？<a hidden class=anchor aria-hidden=true href=#我们究竟在异步什么>#</a></h2><p>这里很值得分享一个核心问题，对 SGLang 而言，或者对现在的 RL 而言，我们每天说来说去的 async 究竟是什么意思？和 PD 分离一样，async 也有非常多的层面：</p><ol><li><p>Async RL 代表的是在 training rollout 分离的系统上，rollout 只在 update weights 的时候被打断，其余时刻永远 rollout，哪怕 target policy 正在被 training engine 更新。这方面是 <a href=https://github.com/inclusionAI/AReaL>AreaL</a> 和 <a href=https://github.com/THUDM/slime>SLIME</a>。</p></li><li><p>Async Rollout 这个词是特指在 rollout 的时候，把一个 batch requests 拆为单个 request，然后逐个调用 <code>SGLangEngine.generate()</code>。</p></li></ol><p>乍一听，这没有什么特别的，似乎还会更慢些。但是考虑到 tool call 的问题，这就非常严肃了。假设我们把一整个 batch 的 requests 作为一个 batch 塞给 sglang 似乎还要快些，毕竟对 SGLang 的 scheduler 而言，更好组 batch。但是，一整个 batch 进去，得一整个 batch 出来。这些 batch 里面的 requests 同时返回，同时被 paser 解析查看是否有 tool call 的 parameter，然后发送请求给 tool。如此以来，整个 tool 的调用大概率会拥堵，甚至在我们考虑到如果要加入多个 tool（虽然目前没有）的话，用一个状态机去管理每个 request 的 tool call 状态会成一场噩梦，何况有的 requests 会在多轮里面多次调用 tool。因此，为了方便管理每个 request tool call 的状态机和让 tool 被调度的更加均匀。SGLang 采取了 Async Rollout 策略，也即把一个 batch 的 requests 拆为单个 request，然后逐个异步调用 <code>SGLangEngine.generate()</code>。这样每个 reqeuest 自己管理自己的状态机，方便维护并且 tool call 效率更高。</p><p>理解了这一层，我们可以来看看代码实现：</p><details><summary>generate_sequences 源码</summary><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@GPUMemoryLogger</span><span class=p>(</span><span class=n>role</span><span class=o>=</span><span class=s2>&#34;sglang rollout&#34;</span><span class=p>,</span> <span class=n>logger</span><span class=o>=</span><span class=n>logger</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nd>@torch.no_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>generate_sequences</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>prompts</span><span class=p>:</span> <span class=n>DataProto</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>DataProto</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>multi_turn</span><span class=o>.</span><span class=n>enable</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_req_level_generate_sequences</span><span class=p>(</span><span class=n>prompts</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>_batch_level_generate_sequences</span><span class=p>(</span><span class=n>prompts</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></details><p>这里明确指出，如果是用了 mutli-turn 训练，则将 batch 的 requests 拆为单个 request，调用 <code>_req_level_generate_sequences</code>；而不调用 tool 的单轮 RL，仍旧组 batch 直接发送。</p><p>我们只观察 <code>_req_level_generate_sequences</code> 的部分源码：</p><details><summary>_req_level_generate_sequences 部分源码</summary><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@GPUMemoryLogger</span><span class=p>(</span><span class=n>role</span><span class=o>=</span><span class=s2>&#34;sglang rollout&#34;</span><span class=p>,</span> <span class=n>logger</span><span class=o>=</span><span class=n>logger</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nd>@torch.no_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>_req_level_generate_sequences</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>prompts</span><span class=p>:</span> <span class=n>DataProto</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>DataProto</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># Async rollout with tools support</span>
</span></span><span class=line><span class=cl>    <span class=n>do_sample</span> <span class=o>=</span> <span class=n>prompts</span><span class=o>.</span><span class=n>meta_info</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;do_sample&#34;</span><span class=p>,</span> <span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>is_validate</span> <span class=o>=</span> <span class=n>prompts</span><span class=o>.</span><span class=n>meta_info</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;validate&#34;</span><span class=p>,</span> <span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>tgt_device</span> <span class=o>=</span> <span class=n>prompts</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;input_ids&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>device</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>_tp_rank</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>req_list</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_preprocess_prompt_to_async_rollout_requests</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>prompts</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>n</span><span class=o>=</span><span class=mi>1</span> <span class=k>if</span> <span class=n>is_validate</span> <span class=k>else</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>n</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>loop</span> <span class=o>=</span> <span class=n>asyncio</span><span class=o>.</span><span class=n>get_event_loop</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>output_req_list</span> <span class=o>=</span> <span class=n>loop</span><span class=o>.</span><span class=n>run_until_complete</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>asyncio</span><span class=o>.</span><span class=n>gather</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=o>*</span><span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>_async_rollout_a_request</span><span class=p>(</span><span class=n>req</span><span class=p>,</span> <span class=n>do_sample</span><span class=p>,</span> <span class=n>is_validate</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>)</span> <span class=k>for</span> <span class=n>req</span> <span class=ow>in</span> <span class=n>req_list</span><span class=p>],</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>sorted_output_req_list</span> <span class=o>=</span> <span class=nb>sorted</span><span class=p>(</span><span class=n>output_req_list</span><span class=p>,</span> <span class=n>key</span><span class=o>=</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>batch_data_id</span><span class=p>,</span> <span class=n>x</span><span class=o>.</span><span class=n>rollout_offset</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>sorted_output_req_list</span> <span class=o>=</span> <span class=kc>None</span>
</span></span></code></pre></td></tr></table></div></div></details><p>现在来看，<code>asyncio.gather(*[self._async_rollout_a_request(req, do_sample, is_validate, **kwargs) for req in req_list],)</code> 就显得无比清晰了。</p><h2 id=数据流管理>数据流管理<a hidden class=anchor aria-hidden=true href=#数据流管理>#</a></h2><p>我们继续去理解 <code>RayPPOTrainer.fit()</code> 函数，从数据流管理开始。这里我认为最重要的两个类是 <code>DataProto</code> 和 <code>RLHFDataset</code>。</p><h3 id=dataproto><code>DataProto</code><a hidden class=anchor aria-hidden=true href=#dataproto>#</a></h3><p><code>DataProto</code> 是 verl 的数据交换协议，定义在 <a href=https://github.com/volcengine/verl/blob/76f63cffa5081564d8fea93a1cb3ce8bd5bdcc39/verl/protocol.py#L202><code>protocol.py</code></a>：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@dataclass</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>DataProto</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    A DataProto is a data structure that aims to provide a standard protocol for data exchange between functions.
</span></span></span><span class=line><span class=cl><span class=s2>    It contains a batch (TensorDict) and a meta_info (Dict). The batch is a TensorDict https://pytorch.org/tensordict/.
</span></span></span><span class=line><span class=cl><span class=s2>    TensorDict allows you to manipulate a dictionary of Tensors like a single Tensor. Ideally, the tensors with the
</span></span></span><span class=line><span class=cl><span class=s2>    same batch size should be put inside batch.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>batch</span><span class=p>:</span> <span class=n>TensorDict</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>    <span class=n>non_tensor_batch</span><span class=p>:</span> <span class=n>Dict</span> <span class=o>=</span> <span class=n>field</span><span class=p>(</span><span class=n>default_factory</span><span class=o>=</span><span class=nb>dict</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>meta_info</span><span class=p>:</span> <span class=n>Dict</span> <span class=o>=</span> <span class=n>field</span><span class=p>(</span><span class=n>default_factory</span><span class=o>=</span><span class=nb>dict</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p><code>DataProto</code> 提供标准化的数据交换协议，基于 PyTorch 的 TensorDict，支持张量的批量操作，同时通过 <code>non_tensor_batch</code> 字典来处理 NumPy 数组等非张量数据。<code>meta_info</code> 存储额外的元信息。本身支持的操作挺基础的，典型的比如数据创建、切片、选择、合并、重命名、重复、填充、分块、以及分布式环境下的数据集合与分发。除此之外，<code>DataProto</code> 还通过数据验证 <code>check_consistency()</code> 确保在数据分离和合并过程的一致性。</p><h3 id=rlhfdataset><code>RLHFDataset</code><a hidden class=anchor aria-hidden=true href=#rlhfdataset>#</a></h3><p><a href=https://github.com/volcengine/verl/blob/76f63cffa5081564d8fea93a1cb3ce8bd5bdcc39/verl/utils/dataset/rl_dataset.py#L68><code>RLHFDataset</code></a> 是 verl 中用于 RLHF 数据加载的数据集类，继承自 <code>datasets.Dataset</code>，主要用于处理 Parquet 文件中的数据，包括数据下载、tokenize、过滤、预处理等。</p><details><summary>RLHFDataset 源码</summary><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>RLHFDataset</span><span class=p>(</span><span class=n>Dataset</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Load and preprocess RLHF data from Parquet files.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    - Caches files locally.
</span></span></span><span class=line><span class=cl><span class=s2>    - Reads into a HuggingFace Dataset and tokenizes prompts.
</span></span></span><span class=line><span class=cl><span class=s2>    - Optionally handles images/videos via a ProcessorMixin.
</span></span></span><span class=line><span class=cl><span class=s2>    - Filters prompts over a max length.
</span></span></span><span class=line><span class=cl><span class=s2>    - Supports resuming from checkpoints.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        data_files (str or list): Path(s) to Parquet file(s).
</span></span></span><span class=line><span class=cl><span class=s2>        tokenizer (PreTrainedTokenizer): For the tokenization of text to token IDs.
</span></span></span><span class=line><span class=cl><span class=s2>        config (DictConfig): Options like cache_dir, prompt_key, max_prompt_length, truncation, etc.
</span></span></span><span class=line><span class=cl><span class=s2>        processor (ProcessorMixin, optional): Multimodal preprocessor for images/videos.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>data_files</span><span class=p>:</span> <span class=n>Union</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>]],</span>
</span></span><span class=line><span class=cl>        <span class=n>tokenizer</span><span class=p>:</span> <span class=n>PreTrainedTokenizer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>config</span><span class=p>:</span> <span class=n>DictConfig</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>processor</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>ProcessorMixin</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=ow>not</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>data_files</span><span class=p>,</span> <span class=p>(</span><span class=n>List</span><span class=p>,</span> <span class=n>ListConfig</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>            <span class=n>data_files</span> <span class=o>=</span> <span class=p>[</span><span class=n>data_files</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>data_files</span> <span class=o>=</span> <span class=n>copy</span><span class=o>.</span><span class=n>deepcopy</span><span class=p>(</span><span class=n>data_files</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>original_data_files</span> <span class=o>=</span> <span class=n>copy</span><span class=o>.</span><span class=n>deepcopy</span><span class=p>(</span><span class=n>data_files</span><span class=p>)</span>  <span class=c1># use for resume</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span> <span class=o>=</span> <span class=n>tokenizer</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>processor</span> <span class=o>=</span> <span class=n>processor</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>config</span> <span class=o>=</span> <span class=n>config</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>cache_dir</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>expanduser</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;cache_dir&#34;</span><span class=p>,</span> <span class=s2>&#34;~/.cache/verl/rlhf&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>prompt_key</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;prompt_key&#34;</span><span class=p>,</span> <span class=s2>&#34;prompt&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>image_key</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;image_key&#34;</span><span class=p>,</span> <span class=s2>&#34;images&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>video_key</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;video_key&#34;</span><span class=p>,</span> <span class=s2>&#34;videos&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>max_prompt_length</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;max_prompt_length&#34;</span><span class=p>,</span> <span class=mi>1024</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>return_raw_chat</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;return_raw_chat&#34;</span><span class=p>,</span> <span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>return_full_prompt</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;return_full_prompt&#34;</span><span class=p>,</span> <span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>truncation</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;truncation&#34;</span><span class=p>,</span> <span class=s2>&#34;error&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>filter_overlong_prompts</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;filter_overlong_prompts&#34;</span><span class=p>,</span> <span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>num_workers</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;filter_overlong_prompts_workers&#34;</span><span class=p>,</span> <span class=nb>max</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>os</span><span class=o>.</span><span class=n>cpu_count</span><span class=p>()</span> <span class=o>//</span> <span class=mi>4</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>num_workers</span> <span class=o>=</span> <span class=nb>min</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>num_workers</span><span class=p>,</span> <span class=n>os</span><span class=o>.</span><span class=n>cpu_count</span><span class=p>())</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>use_shm</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;use_shm&#34;</span><span class=p>,</span> <span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>chat_template_func</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;chat_template_func&#34;</span><span class=p>,</span> <span class=kc>None</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>need_tools_kwargs</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;need_tools_kwargs&#34;</span><span class=p>,</span> <span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>filter_prompts</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;filter_prompts&#34;</span><span class=p>,</span> <span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>serialize_dataset</span> <span class=o>=</span> <span class=kc>False</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>_download</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>_read_files_and_tokenize</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div></details><p>有了 <code>DataProto</code> 和 <code>RLHFDataset</code> 后，我们来观察数据流：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>A：Parquet 文件 --&gt; B：RLHFDataset --&gt; C：DataLoader + collate_fn --&gt; D：DataProto 原始数据 --&gt; E：pop 提取生成数据 --&gt; F：Rollout 生成 --&gt; G：union 合并数据 --&gt; H：奖励计算 --&gt; I：优势计算 --&gt; J：重新计算 log_probs --&gt; K：计算参考 log_probs --&gt; L：计算价值函数 --&gt; M1：更新 critic --&gt; M2：更新 actor --&gt; N：返回训练指标
</span></span></code></pre></td></tr></table></div></div><p>事实上，只有最初的三步不是 <code>DataProto</code>，其他都是通过 <code>DataProto</code> 进行数据交换的。具体每步的数据流向如下：</p><details><summary>数据流详细分析</summary><p>A：<code>Parquet</code> 文件</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>data_files</span> <span class=o>=</span> <span class=s2>&#34;~/data/rlhf/gsm8k/train.parquet&#34;</span>
</span></span></code></pre></td></tr></table></div></div><p>B：RLHFDataset</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>dataset</span> <span class=o>=</span> <span class=n>RLHFDataset</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>data_files</span><span class=o>=</span><span class=n>data_files</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>tokenizer</span><span class=o>=</span><span class=n>tokenizer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>config</span><span class=o>=</span><span class=n>config</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>processor</span><span class=o>=</span><span class=n>processor</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>C：DataLoader + collate_fn</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>dataloader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>dataset</span><span class=o>=</span><span class=n>dataset</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>batch_size</span><span class=o>=</span><span class=mi>16</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>drop_last</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>collate_fn</span><span class=o>=</span><span class=n>collate_fn</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>D：<code>DataProto</code> 原始数据</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>batch_dict</span> <span class=o>=</span> <span class=nb>next</span><span class=p>(</span><span class=nb>iter</span><span class=p>(</span><span class=n>dataloader</span><span class=p>))</span>  <span class=c1># 返回 dict</span>
</span></span><span class=line><span class=cl><span class=n>batch</span><span class=p>:</span> <span class=n>DataProto</span> <span class=o>=</span> <span class=n>DataProto</span><span class=o>.</span><span class=n>from_single_dict</span><span class=p>(</span><span class=n>batch_dict</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>E：<code>pop</code> 提取生成数据</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>gen_batch</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=n>batch_keys</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;input_ids&#34;</span><span class=p>,</span> <span class=s2>&#34;attention_mask&#34;</span><span class=p>,</span> <span class=s2>&#34;position_ids&#34;</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><p>F：<code>Rollout</code> 生成</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>gen_batch_output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>actor_rollout_wg</span><span class=o>.</span><span class=n>generate_sequences</span><span class=p>(</span><span class=n>gen_batch</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>G：<code>union</code> 合并数据</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>batch</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>union</span><span class=p>(</span><span class=n>gen_batch_output</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>H：奖励计算</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>rewards</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>reward_fn</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>batch</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;token_level_rewards&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>rewards</span>
</span></span></code></pre></td></tr></table></div></div><p>I：优势计算</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>batch</span> <span class=o>=</span> <span class=n>compute_advantage</span><span class=p>(</span><span class=n>batch</span><span class=p>,</span> <span class=n>adv_estimator</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>algorithm</span><span class=o>.</span><span class=n>adv_estimator</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>J：重新计算 <code>log_probs</code></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>old_log_prob</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>actor_rollout_wg</span><span class=o>.</span><span class=n>compute_log_prob</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>batch</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>union</span><span class=p>(</span><span class=n>old_log_prob</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>K：计算 reference model 的 <code>log_probs</code></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>use_reference_policy</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>ref_log_prob</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>ref_policy_wg</span><span class=o>.</span><span class=n>compute_ref_log_prob</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>batch</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>union</span><span class=p>(</span><span class=n>ref_log_prob</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>L：计算 value function</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>use_critic</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>values</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>critic_wg</span><span class=o>.</span><span class=n>compute_values</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>batch</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>union</span><span class=p>(</span><span class=n>values</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>M1：更新 critic</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>use_critic</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>critic_output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>critic_wg</span><span class=o>.</span><span class=n>update_critic</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>critic_output_metrics</span> <span class=o>=</span> <span class=n>reduce_metrics</span><span class=p>(</span><span class=n>critic_output</span><span class=o>.</span><span class=n>meta_info</span><span class=p>[</span><span class=s2>&#34;metrics&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>metrics</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=n>critic_output_metrics</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>M2：更新 actor</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>actor_output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>actor_rollout_wg</span><span class=o>.</span><span class=n>update_actor</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>N：返回训练指标</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>actor_output_metrics</span> <span class=o>=</span> <span class=n>reduce_metrics</span><span class=p>(</span><span class=n>actor_output</span><span class=o>.</span><span class=n>meta_info</span><span class=p>[</span><span class=s2>&#34;metrics&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>metrics</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=n>actor_output_metrics</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logger</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>data</span><span class=o>=</span><span class=n>metrics</span><span class=p>,</span> <span class=n>step</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>global_steps</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></details><h2 id=rollout>Rollout<a hidden class=anchor aria-hidden=true href=#rollout>#</a></h2><p>在 part 1 已经讲过了 SGLang 的几个关键函数：</p><ol><li><code>ActorRolloutRefWorker._build_rollout()</code></li><li><code>SGLangRollout.__init__()</code></li><li><code>SGLangRollout.AsyncEngine</code></li><li><code>SGLangRollout._init_inference_engine()</code></li></ol><p>此外，我们还介绍了在<a href=/posts/aiinfra/08-verl-multiturn-2/#%e6%88%91%e4%bb%ac%e7%a9%b6%e7%ab%9f%e5%9c%a8%e5%bc%82%e6%ad%a5%e4%bb%80%e4%b9%88>“我们究竟在异步什么？“</a>里面介绍了 SGLang 对 multi-turn 场景下的 <code>_req_level_generate_sequences</code> 的特殊实现。我们接着继续分析 SGLang rollout 对 multi-turn 的处理，包括状态机和 tool 调用。</p><h3 id=_req_level_generate_sequences><a href=https://github.com/volcengine/verl/blob/76f63cffa5081564d8fea93a1cb3ce8bd5bdcc39/verl/workers/rollout/sglang_rollout/sglang_rollout.py#L853><code>_req_level_generate_sequences</code></a><a hidden class=anchor aria-hidden=true href=#_req_level_generate_sequences>#</a></h3><p>接着上文的讨论，我们继续来看看源代码。</p><ol><li>如果当前是 tp rank 0，则将一整个 batch 的 prompts 预处理成单个异步请求，并并发执行这些请求以生成序列。rollout 的返回顺序是乱序的，因此需要按照 batch ID 和在 batch 内的 offset 来对返回值重新排序。</li><li>如果不是 tp rank 0，则将输出请求列表设置为 <code>None</code>。这里其实也是之前提到过的 <a href>mock SPMD 的体现</a>。</li><li>使用分布式通信，将 tp rank 0 生成的排序后的请求列表广播给所有其他 rank。</li><li>提取 prompt IDs、response IDs、attention masks、position IDs、loss masks、原始消息和 reward scores。</li><li>使用 padding token 对 prompt IDs 和 response IDs 进行填充，使其长度一致。</li><li>将填充后的 prompt 和 response 的 IDs、attention masks 等在最后一个维度上进行拼接，形成完整的序列数据。</li><li>将处理后的 prompts 和 responses 存储到 <code>TensorDict</code> 对象中，并设置批次大小。</li><li>将包含批次化张量数据的 <code>TensorDict</code> 和包含原始消息及奖励分数的字典封装到 <code>DataProto</code> 对象中并返回。</li></ol><p>这里有个比较有趣的地方，注意到 2 中我们强调了，SGLang 并不是严格的 SPMD，但是 3 中，我们仍旧将 tp 0 得到的 response broadcast 给了所有 rank。但是，为了保持 SGLang 外部的训练循环仍旧得到的是一个 SPMD 的返回结果，我们需要让每个 tp randk 都构造并返回相同的 batch，这就需要通过 broadcast 让其他 tp rank 获得 tp 0 的计算结果。这导致了一定的计算冗余，但是相比推理本身的开销，仍旧是可以负担的。</p><details><summary>_req_level_generate_sequences 源码</summary><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span><span class=lnt>108
</span><span class=lnt>109
</span><span class=lnt>110
</span><span class=lnt>111
</span><span class=lnt>112
</span><span class=lnt>113
</span><span class=lnt>114
</span><span class=lnt>115
</span><span class=lnt>116
</span><span class=lnt>117
</span><span class=lnt>118
</span><span class=lnt>119
</span><span class=lnt>120
</span><span class=lnt>121
</span><span class=lnt>122
</span><span class=lnt>123
</span><span class=lnt>124
</span><span class=lnt>125
</span><span class=lnt>126
</span><span class=lnt>127
</span><span class=lnt>128
</span><span class=lnt>129
</span><span class=lnt>130
</span><span class=lnt>131
</span><span class=lnt>132
</span><span class=lnt>133
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@GPUMemoryLogger</span><span class=p>(</span><span class=n>role</span><span class=o>=</span><span class=s2>&#34;sglang rollout&#34;</span><span class=p>,</span> <span class=n>logger</span><span class=o>=</span><span class=n>logger</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nd>@torch.no_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_req_level_generate_sequences</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>prompts</span><span class=p>:</span> <span class=n>DataProto</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>DataProto</span><span class=p>:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>do_sample</span> <span class=o>=</span> <span class=n>prompts</span><span class=o>.</span><span class=n>meta_info</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;do_sample&#34;</span><span class=p>,</span> <span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>is_validate</span> <span class=o>=</span> <span class=n>prompts</span><span class=o>.</span><span class=n>meta_info</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;validate&#34;</span><span class=p>,</span> <span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>tgt_device</span> <span class=o>=</span> <span class=n>prompts</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;input_ids&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>device</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>_tp_rank</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>req_list</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_preprocess_prompt_to_async_rollout_requests</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>prompts</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>n</span><span class=o>=</span><span class=mi>1</span> <span class=k>if</span> <span class=n>is_validate</span> <span class=k>else</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>n</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>loop</span> <span class=o>=</span> <span class=n>asyncio</span><span class=o>.</span><span class=n>get_event_loop</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>output_req_list</span> <span class=o>=</span> <span class=n>loop</span><span class=o>.</span><span class=n>run_until_complete</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>asyncio</span><span class=o>.</span><span class=n>gather</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                    <span class=o>*</span><span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>_async_rollout_a_request</span><span class=p>(</span><span class=n>req</span><span class=p>,</span> <span class=n>do_sample</span><span class=p>,</span> <span class=n>is_validate</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>)</span> <span class=k>for</span> <span class=n>req</span> <span class=ow>in</span> <span class=n>req_list</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                <span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>sorted_output_req_list</span> <span class=o>=</span> <span class=nb>sorted</span><span class=p>(</span><span class=n>output_req_list</span><span class=p>,</span> <span class=n>key</span><span class=o>=</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>batch_data_id</span><span class=p>,</span> <span class=n>x</span><span class=o>.</span><span class=n>rollout_offset</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>sorted_output_req_list</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>dist</span><span class=o>.</span><span class=n>barrier</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=n>sorted_output_req_list</span><span class=p>]</span> <span class=o>=</span> <span class=n>broadcast_pyobj</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>data</span><span class=o>=</span><span class=p>[</span><span class=n>sorted_output_req_list</span><span class=p>],</span>
</span></span><span class=line><span class=cl>            <span class=n>rank</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>_rank</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>dist_group</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>_device_mesh_cpu</span><span class=p>[</span><span class=s2>&#34;tp&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>get_group</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>src</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>_device_mesh_cpu</span><span class=p>[</span><span class=s2>&#34;tp&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>mesh</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>item</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>force_cpu_device</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>prompt_ids</span><span class=p>,</span> <span class=n>response_ids</span> <span class=o>=</span> <span class=p>[],</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=n>prompt_attention_mask</span><span class=p>,</span> <span class=n>response_attention_mask</span> <span class=o>=</span> <span class=p>[],</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=n>prompt_position_ids</span><span class=p>,</span> <span class=n>response_position_ids</span> <span class=o>=</span> <span class=p>[],</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=n>prompt_loss_mask</span><span class=p>,</span> <span class=n>response_loss_mask</span> <span class=o>=</span> <span class=p>[],</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=n>messages</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=n>reward_scores</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>req</span> <span class=ow>in</span> <span class=n>sorted_output_req_list</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>assert</span> <span class=n>req</span><span class=o>.</span><span class=n>state</span> <span class=o>==</span> <span class=n>AsyncRolloutRequestStateEnum</span><span class=o>.</span><span class=n>COMPLETED</span><span class=p>,</span> <span class=sa>f</span><span class=s2>&#34;Request </span><span class=si>{</span><span class=n>req</span><span class=o>.</span><span class=n>request_id</span><span class=si>}</span><span class=s2> is not completed&#34;</span>
</span></span><span class=line><span class=cl>            <span class=k>assert</span> <span class=nb>len</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>input_ids</span><span class=p>)</span> <span class=o>==</span> <span class=nb>len</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>attention_mask</span><span class=p>)</span> <span class=o>==</span> <span class=nb>len</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>position_ids</span><span class=p>)</span> <span class=o>==</span> <span class=nb>len</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>loss_mask</span><span class=p>),</span> <span class=sa>f</span><span class=s2>&#34;&#34;&#34;Request </span><span class=si>{</span><span class=n>req</span><span class=o>.</span><span class=n>request_id</span><span class=si>}</span><span class=s2> has different length of
</span></span></span><span class=line><span class=cl><span class=s2>                </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>input_ids</span><span class=p>)</span><span class=si>=}</span><span class=s2>, </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>attention_mask</span><span class=p>)</span><span class=si>=}</span><span class=s2>, </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>position_ids</span><span class=p>)</span><span class=si>=}</span><span class=s2>, </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>loss_mask</span><span class=p>)</span><span class=si>=}</span><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>            <span class=n>error_message_lines</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>                <span class=sa>f</span><span class=s2>&#34;&#34;&#34;Request </span><span class=si>{</span><span class=n>req</span><span class=o>.</span><span class=n>request_id</span><span class=si>}</span><span class=s2> has input_ids length </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>input_ids</span><span class=p>)</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>                    greater than max_model_len </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>max_model_len</span><span class=si>}</span><span class=s2>&#34;&#34;&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=sa>f</span><span class=s2>&#34;Decoded input_ids: </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>input_ids</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=sa>f</span><span class=s2>&#34;Decoded prompt_ids: </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>prompt_ids</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=sa>f</span><span class=s2>&#34;Decoded response_ids: </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>response_ids</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=sa>f</span><span class=s2>&#34;Messages: </span><span class=si>{</span><span class=n>req</span><span class=o>.</span><span class=n>messages</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=sa>f</span><span class=s2>&#34;Max model length: </span><span class=si>{</span><span class=n>req</span><span class=o>.</span><span class=n>max_model_len</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=n>error_message</span> <span class=o>=</span> <span class=s2>&#34;</span><span class=se>\n</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>error_message_lines</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>assert</span> <span class=nb>len</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>input_ids</span><span class=p>)</span> <span class=o>&lt;=</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>max_model_len</span><span class=p>,</span> <span class=n>error_message</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>prompt_ids</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>prompt_ids</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>tgt_device</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=n>response_ids</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>response_ids</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>tgt_device</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>response_ids</span><span class=p>)</span> <span class=o>&gt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>response_length</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>logger</span><span class=o>.</span><span class=n>warning</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                    <span class=sa>f</span><span class=s2>&#34;&#34;&#34;</span><span class=si>{</span><span class=n>req</span><span class=o>.</span><span class=n>request_id</span><span class=si>=}</span><span class=s2> has response_ids length </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>response_ids</span><span class=p>)</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>                    greater than max_response_len </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>response_length</span><span class=si>}</span><span class=s2>,</span><span class=se>\n</span><span class=si>{</span><span class=n>req</span><span class=si>=}</span><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>                <span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>prompt_attention_mask</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>prompt_attention_mask</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>tgt_device</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=n>response_attention_mask</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>response_attention_mask</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>tgt_device</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=n>prompt_position_ids</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>prompt_position_ids</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>tgt_device</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=n>response_position_ids</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>response_position_ids</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>tgt_device</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=n>prompt_loss_mask</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>prompt_loss_mask</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>tgt_device</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=n>response_loss_mask</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>response_loss_mask</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>tgt_device</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=n>messages</span><span class=o>.</span><span class=n>append</span><span class=p>({</span><span class=s2>&#34;messages&#34;</span><span class=p>:</span> <span class=n>req</span><span class=o>.</span><span class=n>messages</span><span class=p>})</span>
</span></span><span class=line><span class=cl>            <span class=n>reward_scores</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>reward_scores</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>prompt_ids</span> <span class=o>=</span> <span class=n>pad_sequence</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>prompt_ids</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>batch_first</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>padding_value</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>pad_token_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>padding_side</span><span class=o>=</span><span class=s2>&#34;left&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>prompt_ids</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>&lt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>prompt_length</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>prompt_ids</span> <span class=o>=</span> <span class=n>pad_sequence_to_length</span><span class=p>(</span><span class=n>prompt_ids</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>prompt_length</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>pad_token_id</span><span class=p>,</span> <span class=n>left_pad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>response_ids</span> <span class=o>=</span> <span class=n>pad_sequence</span><span class=p>(</span><span class=n>response_ids</span><span class=p>,</span> <span class=n>batch_first</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>padding_value</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>pad_token_id</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>response_ids</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>&lt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>response_length</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>response_ids</span> <span class=o>=</span> <span class=n>pad_sequence_to_length</span><span class=p>(</span><span class=n>response_ids</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>response_length</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>pad_token_id</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>prompt_attention_mask</span> <span class=o>=</span> <span class=n>pad_sequence</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>prompt_attention_mask</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>batch_first</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>padding_value</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>padding_side</span><span class=o>=</span><span class=s2>&#34;left&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>prompt_attention_mask</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>&lt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>prompt_length</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>prompt_attention_mask</span> <span class=o>=</span> <span class=n>pad_sequence_to_length</span><span class=p>(</span><span class=n>prompt_attention_mask</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>prompt_length</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>left_pad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>response_attention_mask</span> <span class=o>=</span> <span class=n>pad_sequence</span><span class=p>(</span><span class=n>response_attention_mask</span><span class=p>,</span> <span class=n>batch_first</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>padding_value</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>response_attention_mask</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>&lt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>response_length</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>response_attention_mask</span> <span class=o>=</span> <span class=n>pad_sequence_to_length</span><span class=p>(</span><span class=n>response_attention_mask</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>response_length</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>prompt_position_ids</span> <span class=o>=</span> <span class=n>pad_sequence</span><span class=p>(</span><span class=n>prompt_position_ids</span><span class=p>,</span> <span class=n>batch_first</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>padding_value</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>padding_side</span><span class=o>=</span><span class=s2>&#34;left&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>prompt_position_ids</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>&lt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>prompt_length</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>prompt_position_ids</span> <span class=o>=</span> <span class=n>pad_sequence_to_length</span><span class=p>(</span><span class=n>prompt_position_ids</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>prompt_length</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>left_pad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>response_length</span> <span class=o>=</span> <span class=n>response_ids</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>delta_position_id</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>response_length</span> <span class=o>+</span> <span class=mi>1</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>response_ids</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>delta_position_id</span> <span class=o>=</span> <span class=n>delta_position_id</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span><span class=o>.</span><span class=n>repeat</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>sorted_output_req_list</span><span class=p>),</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>response_position_ids</span> <span class=o>=</span> <span class=n>prompt_position_ids</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>:]</span> <span class=o>+</span> <span class=n>delta_position_id</span>
</span></span><span class=line><span class=cl>        <span class=n>prompt_loss_mask</span> <span class=o>=</span> <span class=n>pad_sequence</span><span class=p>(</span><span class=n>prompt_loss_mask</span><span class=p>,</span> <span class=n>batch_first</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>padding_value</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>padding_side</span><span class=o>=</span><span class=s2>&#34;left&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>prompt_loss_mask</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>&lt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>prompt_length</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>prompt_loss_mask</span> <span class=o>=</span> <span class=n>pad_sequence_to_length</span><span class=p>(</span><span class=n>prompt_loss_mask</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>prompt_length</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>left_pad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>response_loss_mask</span> <span class=o>=</span> <span class=n>pad_sequence</span><span class=p>(</span><span class=n>response_loss_mask</span><span class=p>,</span> <span class=n>batch_first</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>padding_value</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>response_loss_mask</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>&lt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>response_length</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>response_loss_mask</span> <span class=o>=</span> <span class=n>pad_sequence_to_length</span><span class=p>(</span><span class=n>response_loss_mask</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>response_length</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>input_ids</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>((</span><span class=n>prompt_ids</span><span class=p>,</span> <span class=n>response_ids</span><span class=p>),</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>attention_mask</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>((</span><span class=n>prompt_attention_mask</span><span class=p>,</span> <span class=n>response_attention_mask</span><span class=p>),</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>position_ids</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>((</span><span class=n>prompt_position_ids</span><span class=p>,</span> <span class=n>response_position_ids</span><span class=p>),</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>loss_mask</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>((</span><span class=n>prompt_loss_mask</span><span class=p>,</span> <span class=n>response_loss_mask</span><span class=p>),</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>batch</span> <span class=o>=</span> <span class=n>TensorDict</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;prompts&#34;</span><span class=p>:</span> <span class=n>prompt_ids</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;responses&#34;</span><span class=p>:</span> <span class=n>response_ids</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;input_ids&#34;</span><span class=p>:</span> <span class=n>input_ids</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;attention_mask&#34;</span><span class=p>:</span> <span class=n>attention_mask</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;position_ids&#34;</span><span class=p>:</span> <span class=n>position_ids</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;loss_mask&#34;</span><span class=p>:</span> <span class=n>loss_mask</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=p>},</span>
</span></span><span class=line><span class=cl>            <span class=n>batch_size</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>sorted_output_req_list</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>free_cache_engine</span> <span class=ow>and</span> <span class=bp>self</span><span class=o>.</span><span class=n>_engine</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span> <span class=ow>and</span> <span class=bp>self</span><span class=o>.</span><span class=n>_tp_rank</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>loop</span> <span class=o>=</span> <span class=n>asyncio</span><span class=o>.</span><span class=n>get_event_loop</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>loop</span><span class=o>.</span><span class=n>run_until_complete</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_engine</span><span class=o>.</span><span class=n>flush_cache</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>DataProto</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>batch</span><span class=o>=</span><span class=n>batch</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>non_tensor_batch</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;messages&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>messages</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;reward_scores&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>reward_scores</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></details><p>显然，<code>_req_level_generate_sequences</code> 的核心在于这两个函数：</p><ol><li><code>_preprocess_prompt_to_async_rollout_requests</code></li><li><code>_async_rollout_a_request</code></li></ol><p>我们分别展开。</p><h3 id=_preprocess_prompt_to_async_rollout_requests><a href=https://github.com/volcengine/verl/blob/76f63cffa5081564d8fea93a1cb3ce8bd5bdcc39/verl/workers/rollout/sglang_rollout/sglang_rollout.py#L987><code>_preprocess_prompt_to_async_rollout_requests</code></a><a hidden class=anchor aria-hidden=true href=#_preprocess_prompt_to_async_rollout_requests>#</a></h3><ol><li>将 prompts 展开，首先拆开 batch 中的每个 prompt，内层循环为每个 prompt 生成 <code>n</code> 个不同的序列。每个生成的请求都有唯一的 <code>batch_data_id</code> 和 <code>rollout_offset</code> 标识。</li><li>当配置了工具时，<code>_input_ids</code> 和 <code>_attention_mask</code> 被设为 <code>None</code>，因为工具调用需要动态构建输入。而没有配置工具的话，使用 <code>_pre_process_inputs</code> 函数处理预处理的 token IDs，去除左填充。</li><li>每个请求对象包含状态管理、工具配置、序列长度限制、tokenizer 配置等元数据，为后续的异步处理提供完整信息。</li></ol><details><summary>_preprocess_prompt_to_async_rollout_requests 源码</summary><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>_preprocess_prompt_to_async_rollout_requests</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>prompts</span><span class=p>:</span> <span class=n>DataProto</span><span class=p>,</span> <span class=n>n</span><span class=p>:</span> <span class=nb>int</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>list</span><span class=p>[</span><span class=n>AsyncRolloutRequest</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=s2>&#34;raw_prompt&#34;</span> <span class=ow>in</span> <span class=n>prompts</span><span class=o>.</span><span class=n>non_tensor_batch</span><span class=p>,</span> <span class=s2>&#34;need data.return_raw_chat=True, due to no official way do parse_messages&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>req_list</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>data_idx</span><span class=p>,</span> <span class=n>raw_prompt</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>prompts</span><span class=o>.</span><span class=n>non_tensor_batch</span><span class=p>[</span><span class=s2>&#34;raw_prompt&#34;</span><span class=p>]):</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>rollout_offset</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>_tool_schemas</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>_tools_kwargs</span> <span class=o>=</span> <span class=n>prompts</span><span class=o>.</span><span class=n>non_tensor_batch</span><span class=p>[</span><span class=s2>&#34;tools_kwargs&#34;</span><span class=p>][</span><span class=n>data_idx</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                <span class=n>_tool_schemas</span> <span class=o>=</span> <span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>_tool_map</span><span class=p>[</span><span class=n>k</span><span class=p>]</span><span class=o>.</span><span class=n>get_openai_tool_schema</span><span class=p>()</span> <span class=k>for</span> <span class=n>k</span> <span class=ow>in</span> <span class=n>_tools_kwargs</span><span class=o>.</span><span class=n>keys</span><span class=p>()]</span>
</span></span><span class=line><span class=cl>                <span class=n>_input_ids</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>                <span class=n>_attention_mask</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>            <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>_input_ids</span> <span class=o>=</span> <span class=n>_pre_process_inputs</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>pad_token_id</span><span class=p>,</span> <span class=n>prompts</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;input_ids&#34;</span><span class=p>][</span><span class=n>data_idx</span><span class=p>])</span>
</span></span><span class=line><span class=cl>                <span class=n>_attention_mask</span> <span class=o>=</span> <span class=n>_pre_process_inputs</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>prompts</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;attention_mask&#34;</span><span class=p>][</span><span class=n>data_idx</span><span class=p>])</span>
</span></span><span class=line><span class=cl>                <span class=n>_tools_kwargs</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>                <span class=n>_tool_schemas</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>req</span> <span class=o>=</span> <span class=n>AsyncRolloutRequest</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>batch_data_id</span><span class=o>=</span><span class=n>data_idx</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>rollout_offset</span><span class=o>=</span><span class=n>rollout_offset</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>request_id</span><span class=o>=</span><span class=nb>str</span><span class=p>(</span><span class=n>uuid4</span><span class=p>()),</span>
</span></span><span class=line><span class=cl>                <span class=n>state</span><span class=o>=</span><span class=n>AsyncRolloutRequestStateEnum</span><span class=o>.</span><span class=n>PENDING</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>messages</span><span class=o>=</span><span class=n>raw_prompt</span><span class=o>.</span><span class=n>tolist</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>                <span class=n>tool_schemas</span><span class=o>=</span><span class=n>_tool_schemas</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>tools_kwargs</span><span class=o>=</span><span class=n>_tools_kwargs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>input_ids</span><span class=o>=</span><span class=n>_input_ids</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>response_ids</span><span class=o>=</span><span class=p>[],</span>
</span></span><span class=line><span class=cl>                <span class=n>attention_mask</span><span class=o>=</span><span class=n>_attention_mask</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>response_attention_mask</span><span class=o>=</span><span class=p>[],</span>
</span></span><span class=line><span class=cl>                <span class=n>response_position_ids</span><span class=o>=</span><span class=p>[],</span>
</span></span><span class=line><span class=cl>                <span class=n>response_loss_mask</span><span class=o>=</span><span class=p>[],</span>
</span></span><span class=line><span class=cl>                <span class=n>reward_scores</span><span class=o>=</span><span class=p>{},</span>
</span></span><span class=line><span class=cl>                <span class=n>max_prompt_len</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>prompt_length</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>max_response_len</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>response_length</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>max_model_len</span><span class=o>=</span><span class=nb>min</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>max_model_len</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>prompt_length</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>response_length</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=n>use_inference_chat_template</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>multi_turn</span><span class=o>.</span><span class=n>use_inference_chat_template</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>enable_tokenization_sanity_check</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>multi_turn</span><span class=o>.</span><span class=n>enable_tokenization_sanity_check</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>tokenizer</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>error_message</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;Request </span><span class=si>{</span><span class=n>req</span><span class=o>.</span><span class=n>request_id</span><span class=si>}</span><span class=s2> has mismatched lengths: input_ids=</span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>input_ids</span><span class=p>)</span><span class=si>}</span><span class=s2>, attention_mask=</span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>attention_mask</span><span class=p>)</span><span class=si>}</span><span class=s2>, position_ids=</span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>position_ids</span><span class=p>)</span><span class=si>}</span><span class=s2>, loss_mask=</span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>loss_mask</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>            <span class=k>assert</span> <span class=nb>len</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>input_ids</span><span class=p>)</span> <span class=o>==</span> <span class=nb>len</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>attention_mask</span><span class=p>)</span> <span class=o>==</span> <span class=nb>len</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>position_ids</span><span class=p>)</span> <span class=o>==</span> <span class=nb>len</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>loss_mask</span><span class=p>),</span> <span class=n>error_message</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>req_list</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>req</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>req_list</span>
</span></span></code></pre></td></tr></table></div></div></details><p>这里其实重要的在于整个 <code>AsyncRolloutRequest</code>，或者说我们用于管理 tool calling 的整个状态机 <a href=https://github.com/volcengine/verl/blob/76f63cffa5081564d8fea93a1cb3ce8bd5bdcc39/verl/workers/rollout/schemas.py>schema</a>。</p><h3 id=schema-状态机>schema 状态机<a hidden class=anchor aria-hidden=true href=#schema-状态机>#</a></h3><pre class=mermaid>
  stateDiagram-v2
    [*] --&gt; PENDING
    PENDING --&gt; RUNNING : _handle_pending_state()

    RUNNING --&gt; TOOL_CALLING : detect_tool_call
    TOOL_CALLING --&gt; RUNNING : tool_call_executed
    TOOL_CALLING --&gt; COMPLETED : tool_call_decode_failed

    RUNNING --&gt; COMPLETED : stop_reason == STOP
    RUNNING --&gt; [Exit] : finish_reason == LENGTH

    COMPLETED --&gt; [Exit]

    note right of TOOL_CALLING
        if tool_calls == None:
        raise ValueError
    end note

    note right of RUNNING
        if exceeds max length:
        finish_reason = LENGTH
    end note
</pre><p>这些状态机挺抽象的，需要到了和 SGLang rollout 的交互部分才能真的理解到用法，不过我们还是先列举出来。</p><ol><li><a href=https://github.com/volcengine/verl/blob/76f63cffa5081564d8fea93a1cb3ce8bd5bdcc39/verl/workers/rollout/schemas.py#L33><code>FinishReasonTypeEnum</code></a></li></ol><ul><li><code>LENGTH</code>：达到最大长度限制</li><li><code>STOP</code>：正常停止（如生成 EOS token）</li><li><code>TOOL_CALL</code>：检测到工具调用</li></ul><ol start=2><li><a href=https://github.com/volcengine/verl/blob/76f63cffa5081564d8fea93a1cb3ce8bd5bdcc39/verl/workers/rollout/schemas.py#L52><code>Message</code></a></li></ol><ul><li><code>role</code>：消息角色（user/assistant/tool）</li><li><code>content</code>：消息内容</li><li><code>tool_calls</code>：可选的工具调用列表，每个工具调用包含 <code>name</code> 和 <code>args</code> 字段</li></ul><p>目前的实现只支持单个工具的调用，但是魔改玩家太多了，甚至可以做一个 tool manager。</p><ol start=3><li><a href=https://github.com/volcengine/verl/blob/76f63cffa5081564d8fea93a1cb3ce8bd5bdcc39/verl/workers/rollout/schemas.py#L58><code>AsyncRolloutRequestStateEnum</code></a></li></ol><ul><li><code>PENDING</code>：等待处理</li><li><code>RUNNING</code>：正在运行</li><li><code>TOOL_CALLING</code>：正在调用工具</li><li><code>COMPLETED</code>：已完成</li><li><code>FAILED</code>：失败</li></ul><ol start=4><li><a href=https://github.com/volcengine/verl/blob/76f63cffa5081564d8fea93a1cb3ce8bd5bdcc39/verl/workers/rollout/schemas.py#L68><code>AsyncRolloutRequest</code></a></li></ol><ul><li><code>initialize_request</code>：验证必需字段（messages、max_prompt_len、tokenizer），使用 tokenizer 的 chat_template 处理消息，初始化所有序列相关字段（input_ids、attention_mask、position_ids、loss_mask），计算生成提示的位置信息</li><li><code>_update_input_ids</code>：以增量方式更新序列信息，自动计算新的 position_ids，维护数据一致性验证</li><li><code>get_generation_prompt_ids</code>：根据配置决定是否使用推理时的 chat_template，动态添加生成提示到输入序列</li><li><code>add_assistant_message</code>：添加助手回复到消息历史，更新输入序列以包含新的回复内容，支持工具调用信息</li><li><code>add_tool_response_messages</code>：添加工具响应到消息历史，更新输入序列但不标记为损失计算部分</li><li><code>finalize</code>：完成请求处理，执行 tokenization 一致性检查，清理生成提示，截断输出序列到合理长度</li><li><code>truncate_output_ids</code>：确保所有序列长度不超过限制，分别处理 input_ids、attention_mask、position_ids、loss_mask</li></ul><h3 id=_async_rollout_a_request><a href=https://github.com/volcengine/verl/blob/76f63cffa5081564d8fea93a1cb3ce8bd5bdcc39/verl/workers/rollout/sglang_rollout/sglang_rollout.py#L681><code>_async_rollout_a_request</code></a><a hidden class=anchor aria-hidden=true href=#_async_rollout_a_request>#</a></h3><p>文档写的很详尽了，容易 lost in the middle。不过，我们回到主线，先前通过 <code>_preprocess_prompt_to_async_rollout_requests</code> 构造了 <code>AsyncRolloutRequest</code> 后，返回给 <code>_req_level_generate_sequences</code>，接着进一步通过 <code>_async_rollout_a_request</code> 根据 <code>AsyncRolloutRequest</code> 的状态来 rollout 到底。</p><ol><li>通过一个 <code>while</code> 循环来处理多轮对话，循环次数上限由 <code>self.config.multi_turn.max_turns</code> 控制，或者 requests 返回 <code>FinishReasonTypeEnum.STOP</code>。</li><li>在循环内部，函数根据 <code>_req</code> 的当前状态 (<code>AsyncRolloutRequestStateEnum</code>) 执行不同的操作（这块儿逻辑确实很复杂）：<ul><li><code>PENDING</code> 状态：如果请求处于 <code>PENDING</code> 状态，则调用 <code>self._handle_pending_state(_req)</code> 初始化，然后将状态更新为 <code>RUNNING</code>。</li><li><code>TOOL_CALLING</code> 状态：检查最后一条消息的工具调用信息 (<code>_req.messages[-1].tool_calls</code>)。解析工具调用信息，并通过 <code>asyncio.gather</code> 并发地执行每个工具调用。工具的执行逻辑封装在 <code>self._tool_map</code> 中，通过工具的名称进行调用。在 tool call 返回后，通过 <code>_req.add_tool_response_messages</code> 将工具的响应添加到消息历史中。遍历每个工具调用及其结果，通过 <code>_req.update_metrics</code> 更新请求的指标信息。检查当前输入序列长度是否超过模型最大长度限制，如果超过，则设置 <code>finish_reason_type</code> 为 <code>STOP</code> 并跳出循环。最后，将请求状态更新回 <code>RUNNING</code>，以便进行下一轮的生成。</li><li><code>RUNNING</code> 状态：SGLang engine 需要进行 rollout。检查当前 prompt 的长度加上生成一个 token 的长度是否会超过 model context length。调用 <code>self._handle_engine_call</code> 来实际调用 SGLang engine；得到输出后，将 finish reason 从字符串转换为 <code>FinishReasonTypeEnum</code>，并递增当前对话轮数 <code>current_turns</code>。如果完成原因是达到最大长度限制 (<code>LENGTH</code>)，则将生成的内容添加到消息历史中，并结束循环。如果没有到达最大长度，则判断 SGLang engine 生成的内容是否包含工具调用，通过 <code>self._function_call_parser</code> 来解析生成的内容。如果检测到工具调用，则将 <code>finish_reason_type</code> 设置为 <code>TOOL_CALL</code>，并将请求状态更新为 <code>TOOL_CALLING</code>。然后，使用 <code>self._function_call_parser.parse_non_stream</code> 解析出工具调用，转换为 <code>OpenAIFunctionToolCall</code>。如果存在有效的工具调用，则通过 <code>_req.add_assistant_message</code> 将工具调用信息添加到消息历史中。否则，只添加生成的内容，并将 <code>finish_reason_type</code> 设置为 <code>STOP</code>，请求状态设置为 <code>COMPLETED</code>，并结束循环。如果生成的内容不包含工具调用，则直接通过 <code>_req.add_assistant_message</code> 将生成的内容添加到消息历史中，并结束循环。</li></ul></li><li>如果循环达到 <code>self.config.multi_turn.max_turns</code> 上限，则将 <code>finish_reason_type</code> 设置为 <code>STOP</code>。</li><li>在对话循环结束后，为每个调用的工具计算奖励。遍历 <code>_req.tools_kwargs</code> 中的每个工具，调用工具的 <code>calc_reward</code> 方法来计算奖励，以及 <code>release</code> 方法来释放工具占用的·资源。计算结果以字典形式存储在 <code>tool_reward_scores</code> 中。</li><li>调用 <code>_req.finalize</code> 方法，完成请求的最终处理，包括执行 tokenization 一致性检查、清理生成提示、截断输出序列到合理长度等。<code>tool_reward_scores</code> 和最终的 <code>finish_reason_type</code> 会传递给 <code>finalize</code> 方法。最后，函数最终返回处理完成的 <code>AsyncRolloutRequest</code> 对象 <code>_req</code>。</li></ol><details><summary>_async_rollout_a_request 源码</summary><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span><span class=lnt>108
</span><span class=lnt>109
</span><span class=lnt>110
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>async</span> <span class=k>def</span> <span class=nf>_async_rollout_a_request</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>req</span><span class=p>:</span> <span class=n>AsyncRolloutRequest</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>do_sample</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>is_validate</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=o>**</span><span class=n>kwargs</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>AsyncRolloutRequest</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=bp>self</span><span class=o>.</span><span class=n>_tp_rank</span> <span class=o>==</span> <span class=mi>0</span><span class=p>,</span> <span class=s2>&#34;only the master process can call this function&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>_req</span> <span class=o>=</span> <span class=n>deepcopy</span><span class=p>(</span><span class=n>req</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>finish_reason_type</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>    <span class=n>output</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>current_turns</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=k>while</span> <span class=n>current_turns</span> <span class=o>&lt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>multi_turn</span><span class=o>.</span><span class=n>max_turns</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>_req</span><span class=o>.</span><span class=n>state</span> <span class=o>==</span> <span class=n>AsyncRolloutRequestStateEnum</span><span class=o>.</span><span class=n>PENDING</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>await</span> <span class=bp>self</span><span class=o>.</span><span class=n>_handle_pending_state</span><span class=p>(</span><span class=n>_req</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>_req</span><span class=o>.</span><span class=n>state</span> <span class=o>=</span> <span class=n>AsyncRolloutRequestStateEnum</span><span class=o>.</span><span class=n>RUNNING</span>
</span></span><span class=line><span class=cl>        <span class=k>elif</span> <span class=n>_req</span><span class=o>.</span><span class=n>state</span> <span class=o>==</span> <span class=n>AsyncRolloutRequestStateEnum</span><span class=o>.</span><span class=n>TOOL_CALLING</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>_req</span><span class=o>.</span><span class=n>messages</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>tool_calls</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>parsed_tool_calls</span> <span class=o>=</span> <span class=n>_req</span><span class=o>.</span><span class=n>messages</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>tool_calls</span>
</span></span><span class=line><span class=cl>                <span class=n>tool_call_results</span> <span class=o>=</span> <span class=k>await</span> <span class=n>asyncio</span><span class=o>.</span><span class=n>gather</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                    <span class=o>*</span><span class=p>[</span>
</span></span><span class=line><span class=cl>                        <span class=bp>self</span><span class=o>.</span><span class=n>_tool_map</span><span class=p>[</span><span class=n>tool_call</span><span class=o>.</span><span class=n>function</span><span class=o>.</span><span class=n>name</span><span class=p>]</span><span class=o>.</span><span class=n>execute</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                            <span class=n>_req</span><span class=o>.</span><span class=n>request_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                            <span class=n>tool_call</span><span class=o>.</span><span class=n>function</span><span class=o>.</span><span class=n>arguments</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                            <span class=o>**</span><span class=n>_req</span><span class=o>.</span><span class=n>tools_kwargs</span><span class=p>[</span><span class=n>tool_call</span><span class=o>.</span><span class=n>function</span><span class=o>.</span><span class=n>name</span><span class=p>]</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;execute_kwargs&#34;</span><span class=p>,</span> <span class=p>{}),</span>
</span></span><span class=line><span class=cl>                        <span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=k>for</span> <span class=n>tool_call</span> <span class=ow>in</span> <span class=n>parsed_tool_calls</span>
</span></span><span class=line><span class=cl>                    <span class=p>]</span>
</span></span><span class=line><span class=cl>                <span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>_req</span><span class=o>.</span><span class=n>add_tool_response_messages</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=p>,</span> <span class=p>[</span><span class=n>resp</span> <span class=k>for</span> <span class=n>resp</span><span class=p>,</span> <span class=n>_</span><span class=p>,</span> <span class=n>_</span> <span class=ow>in</span> <span class=n>tool_call_results</span><span class=p>])</span>
</span></span><span class=line><span class=cl>                <span class=k>for</span> <span class=n>tool_call</span><span class=p>,</span> <span class=p>(</span><span class=n>resp</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>metrics</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>parsed_tool_calls</span><span class=p>,</span> <span class=n>tool_call_results</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                    <span class=n>_req</span><span class=o>.</span><span class=n>update_metrics</span><span class=p>(</span><span class=n>metrics</span><span class=p>,</span> <span class=n>tool_call</span><span class=o>.</span><span class=n>function</span><span class=o>.</span><span class=n>name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>_req</span><span class=o>.</span><span class=n>input_ids</span><span class=p>)</span> <span class=o>&gt;=</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>max_model_len</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=n>finish_reason_type</span> <span class=o>=</span> <span class=n>FinishReasonTypeEnum</span><span class=o>.</span><span class=n>STOP</span>
</span></span><span class=line><span class=cl>                    <span class=k>break</span>
</span></span><span class=line><span class=cl>                <span class=n>_req</span><span class=o>.</span><span class=n>state</span> <span class=o>=</span> <span class=n>AsyncRolloutRequestStateEnum</span><span class=o>.</span><span class=n>RUNNING</span>
</span></span><span class=line><span class=cl>            <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Unexpected tool calling last message state: </span><span class=si>{</span><span class=n>_req</span><span class=o>.</span><span class=n>messages</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>elif</span> <span class=n>_req</span><span class=o>.</span><span class=n>state</span> <span class=o>==</span> <span class=n>AsyncRolloutRequestStateEnum</span><span class=o>.</span><span class=n>RUNNING</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># Only continue the conversation if the prompt length is not greater than max_model_len - 1,</span>
</span></span><span class=line><span class=cl>            <span class=c1># since SGLang raises an error when max_new_tokens + 1 is greater to max_model_len (the extra token accounts for the EOS token).</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>_req</span><span class=o>.</span><span class=n>get_generation_prompt_ids</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=p>))</span> <span class=o>+</span> <span class=mi>1</span> <span class=o>&gt;=</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>max_model_len</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>finish_reason_type</span> <span class=o>=</span> <span class=n>FinishReasonTypeEnum</span><span class=o>.</span><span class=n>LENGTH</span>
</span></span><span class=line><span class=cl>                <span class=k>break</span>
</span></span><span class=line><span class=cl>            <span class=n>output</span> <span class=o>=</span> <span class=k>await</span> <span class=bp>self</span><span class=o>.</span><span class=n>_handle_engine_call</span><span class=p>(</span><span class=n>_req</span><span class=p>,</span> <span class=n>do_sample</span><span class=p>,</span> <span class=n>is_validate</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>content</span> <span class=o>=</span> <span class=n>output</span><span class=p>[</span><span class=s2>&#34;text&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=n>finish_reason_type</span> <span class=o>=</span> <span class=n>FinishReasonTypeEnum</span><span class=o>.</span><span class=n>from_str</span><span class=p>(</span><span class=n>output</span><span class=p>[</span><span class=s2>&#34;meta_info&#34;</span><span class=p>][</span><span class=s2>&#34;finish_reason&#34;</span><span class=p>][</span><span class=s2>&#34;type&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>            <span class=n>current_turns</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>finish_reason_type</span> <span class=o>==</span> <span class=n>FinishReasonTypeEnum</span><span class=o>.</span><span class=n>LENGTH</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>_req</span><span class=o>.</span><span class=n>add_assistant_message</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=p>,</span> <span class=n>content</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=k>break</span>
</span></span><span class=line><span class=cl>            <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>_function_call_parser</span> <span class=ow>and</span> <span class=bp>self</span><span class=o>.</span><span class=n>_function_call_parser</span><span class=o>.</span><span class=n>has_tool_call</span><span class=p>(</span><span class=n>content</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                    <span class=n>finish_reason_type</span> <span class=o>=</span> <span class=n>FinishReasonTypeEnum</span><span class=o>.</span><span class=n>TOOL_CALL</span>
</span></span><span class=line><span class=cl>                    <span class=n>_req</span><span class=o>.</span><span class=n>state</span> <span class=o>=</span> <span class=n>AsyncRolloutRequestStateEnum</span><span class=o>.</span><span class=n>TOOL_CALLING</span>
</span></span><span class=line><span class=cl>                    <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                        <span class=n>normed_content</span><span class=p>,</span> <span class=n>tool_calls</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_function_call_parser</span><span class=o>.</span><span class=n>parse_non_stream</span><span class=p>(</span><span class=n>content</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=k>except</span> <span class=n>JSONDecodeError</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                        <span class=n>normed_content</span> <span class=o>=</span> <span class=n>content</span>
</span></span><span class=line><span class=cl>                        <span class=n>tool_calls</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>                    <span class=k>except</span> <span class=ne>AttributeError</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                        <span class=n>normed_content</span> <span class=o>=</span> <span class=n>content</span>
</span></span><span class=line><span class=cl>                        <span class=n>tool_calls</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>                    <span class=n>parsed_tool_calls</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>                    <span class=k>for</span> <span class=n>tool_call</span> <span class=ow>in</span> <span class=n>tool_calls</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                        <span class=n>function</span><span class=p>,</span> <span class=n>has_decode_error</span> <span class=o>=</span> <span class=n>OpenAIFunctionCallSchema</span><span class=o>.</span><span class=n>from_openai_function_parsed_schema</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                            <span class=n>OpenAIFunctionParsedSchema</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                                <span class=n>name</span><span class=o>=</span><span class=n>tool_call</span><span class=o>.</span><span class=n>name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                <span class=n>arguments</span><span class=o>=</span><span class=n>tool_call</span><span class=o>.</span><span class=n>parameters</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                            <span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=c1># Drop the tool call if its arguments has decode error</span>
</span></span><span class=line><span class=cl>                        <span class=k>if</span> <span class=n>has_decode_error</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                            <span class=k>continue</span>
</span></span><span class=line><span class=cl>                        <span class=n>parsed_tool_calls</span><span class=o>.</span><span class=n>append</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                            <span class=n>OpenAIFunctionToolCall</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                                <span class=nb>id</span><span class=o>=</span><span class=nb>str</span><span class=p>(</span><span class=n>tool_call</span><span class=o>.</span><span class=n>tool_index</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                                <span class=n>function</span><span class=o>=</span><span class=n>function</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                            <span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>parsed_tool_calls</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                        <span class=n>_req</span><span class=o>.</span><span class=n>add_assistant_message</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=p>,</span> <span class=n>normed_content</span><span class=p>,</span> <span class=n>tool_calls</span><span class=o>=</span><span class=n>parsed_tool_calls</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                        <span class=n>_req</span><span class=o>.</span><span class=n>add_assistant_message</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=p>,</span> <span class=n>content</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=n>finish_reason_type</span> <span class=o>=</span> <span class=n>FinishReasonTypeEnum</span><span class=o>.</span><span class=n>STOP</span>
</span></span><span class=line><span class=cl>                        <span class=n>_req</span><span class=o>.</span><span class=n>state</span> <span class=o>=</span> <span class=n>AsyncRolloutRequestStateEnum</span><span class=o>.</span><span class=n>COMPLETED</span>
</span></span><span class=line><span class=cl>                        <span class=k>break</span>
</span></span><span class=line><span class=cl>                <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=n>_req</span><span class=o>.</span><span class=n>add_assistant_message</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=p>,</span> <span class=n>content</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=k>break</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>current_turns</span> <span class=o>&gt;=</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>multi_turn</span><span class=o>.</span><span class=n>max_turns</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>finish_reason_type</span> <span class=o>=</span> <span class=n>FinishReasonTypeEnum</span><span class=o>.</span><span class=n>STOP</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Calculate the reward for each tool</span>
</span></span><span class=line><span class=cl>    <span class=k>async</span> <span class=k>def</span> <span class=nf>calc_reward_and_release_fn</span><span class=p>(</span><span class=n>name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>tool</span><span class=p>:</span> <span class=n>BaseTool</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>reward</span> <span class=o>=</span> <span class=k>await</span> <span class=n>tool</span><span class=o>.</span><span class=n>calc_reward</span><span class=p>(</span><span class=n>_req</span><span class=o>.</span><span class=n>request_id</span><span class=p>,</span> <span class=o>**</span><span class=n>_req</span><span class=o>.</span><span class=n>tools_kwargs</span><span class=p>[</span><span class=n>name</span><span class=p>]</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;calc_reward_kwargs&#34;</span><span class=p>,</span> <span class=p>{}))</span>
</span></span><span class=line><span class=cl>        <span class=k>await</span> <span class=n>tool</span><span class=o>.</span><span class=n>release</span><span class=p>(</span><span class=n>_req</span><span class=o>.</span><span class=n>request_id</span><span class=p>,</span> <span class=o>**</span><span class=n>_req</span><span class=o>.</span><span class=n>tools_kwargs</span><span class=p>[</span><span class=n>name</span><span class=p>]</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;release_kwargs&#34;</span><span class=p>,</span> <span class=p>{}))</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>name</span><span class=p>,</span> <span class=n>reward</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>tool_reward_tasks</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>name</span> <span class=ow>in</span> <span class=n>_req</span><span class=o>.</span><span class=n>tools_kwargs</span><span class=o>.</span><span class=n>keys</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>tool</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_tool_map</span><span class=p>[</span><span class=n>name</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>tool_reward_tasks</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>calc_reward_and_release_fn</span><span class=p>(</span><span class=n>name</span><span class=p>,</span> <span class=n>tool</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>tool_reward_scores</span> <span class=o>=</span> <span class=k>await</span> <span class=n>asyncio</span><span class=o>.</span><span class=n>gather</span><span class=p>(</span><span class=o>*</span><span class=n>tool_reward_tasks</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>tool_reward_scores</span> <span class=o>=</span> <span class=nb>dict</span><span class=p>(</span><span class=n>tool_reward_scores</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>_req</span><span class=o>.</span><span class=n>finalize</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=p>,</span> <span class=n>tool_reward_scores</span><span class=p>,</span> <span class=n>finish_reason_type</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>_req</span>
</span></span></code></pre></td></tr></table></div></div></details><h3 id=pop-and-union>pop and union<a hidden class=anchor aria-hidden=true href=#pop-and-union>#</a></h3><p>经过艰难深挖，我们终于完成了 Rollout 的理解，现在回到 <code>RayPPOTrainer.fit()</code> 上。我们来看看 rollout 部分的实现逻辑：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>with</span> <span class=n>marked_timer</span><span class=p>(</span><span class=s2>&#34;step&#34;</span><span class=p>,</span> <span class=n>timing_raw</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># generate a batch</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>marked_timer</span><span class=p>(</span><span class=s2>&#34;gen&#34;</span><span class=p>,</span> <span class=n>timing_raw</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&#34;red&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=ow>not</span> <span class=bp>self</span><span class=o>.</span><span class=n>async_rollout_mode</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>gen_batch_output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>actor_rollout_wg</span><span class=o>.</span><span class=n>generate_sequences</span><span class=p>(</span><span class=n>gen_batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>async_rollout_manager</span><span class=o>.</span><span class=n>wake_up</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>gen_batch_output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>async_rollout_manager</span><span class=o>.</span><span class=n>generate_sequences</span><span class=p>(</span><span class=n>gen_batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>async_rollout_manager</span><span class=o>.</span><span class=n>sleep</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>timing_raw</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=n>gen_batch_output</span><span class=o>.</span><span class=n>meta_info</span><span class=p>[</span><span class=s2>&#34;timing&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=n>gen_batch_output</span><span class=o>.</span><span class=n>meta_info</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=s2>&#34;timing&#34;</span><span class=p>,</span> <span class=kc>None</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>algorithm</span><span class=o>.</span><span class=n>adv_estimator</span> <span class=o>==</span> <span class=n>AdvantageEstimator</span><span class=o>.</span><span class=n>REMAX</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>marked_timer</span><span class=p>(</span><span class=s2>&#34;gen_max&#34;</span><span class=p>,</span> <span class=n>timing_raw</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&#34;purple&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>gen_baseline_batch</span> <span class=o>=</span> <span class=n>deepcopy</span><span class=p>(</span><span class=n>gen_batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>gen_baseline_batch</span><span class=o>.</span><span class=n>meta_info</span><span class=p>[</span><span class=s2>&#34;do_sample&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=kc>False</span>
</span></span><span class=line><span class=cl>            <span class=n>gen_baseline_output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>actor_rollout_wg</span><span class=o>.</span><span class=n>generate_sequences</span><span class=p>(</span><span class=n>gen_baseline_batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>batch</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>union</span><span class=p>(</span><span class=n>gen_baseline_output</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>reward_baseline_tensor</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>reward_fn</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>reward_baseline_tensor</span> <span class=o>=</span> <span class=n>reward_baseline_tensor</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>batch</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=n>batch_keys</span><span class=o>=</span><span class=nb>list</span><span class=p>(</span><span class=n>gen_baseline_output</span><span class=o>.</span><span class=n>batch</span><span class=o>.</span><span class=n>keys</span><span class=p>()))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>batch</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;reward_baselines&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>reward_baseline_tensor</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=k>del</span> <span class=n>gen_baseline_batch</span><span class=p>,</span> <span class=n>gen_baseline_output</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>batch</span><span class=o>.</span><span class=n>non_tensor_batch</span><span class=p>[</span><span class=s2>&#34;uid&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=nb>str</span><span class=p>(</span><span class=n>uuid</span><span class=o>.</span><span class=n>uuid4</span><span class=p>())</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>batch</span><span class=o>.</span><span class=n>batch</span><span class=p>))],</span> <span class=n>dtype</span><span class=o>=</span><span class=nb>object</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># repeat to align with repeated responses in rollout</span>
</span></span><span class=line><span class=cl>    <span class=n>batch</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>repeat</span><span class=p>(</span><span class=n>repeat_times</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>n</span><span class=p>,</span> <span class=n>interleave</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>batch</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>union</span><span class=p>(</span><span class=n>gen_batch_output</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>值得一提的是，我自己写了代码才理解到在 verl 当中，发给 rollout engine 的并不是整个完整的从 dataset 读取的 batch，而是通过 pop 构造的 <code>gen_batch</code>。pop 是一个就地操作，完成后 batch 里面的 key 当然就没了。为此，如果想让 pop 前后都有一些需要的 key，得留一手考虑。比如说，我希望通过 uid 来把 <code>gen_batch</code> 和 <code>batch</code> 重新 union 起来，得<a href=https://github.com/volcengine/verl/pull/2258>反复添加 uid</a>。</p><h2 id=make-experience>Make Experience<a hidden class=anchor aria-hidden=true href=#make-experience>#</a></h2><p>经过了漫长的战线，我们终于分析完了 rollout 部分的逻辑。我们接着分析 make experience 部分的逻辑。</p><details><summary>Make Experience 源码</summary><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span><span class=lnt>72
</span><span class=lnt>73
</span><span class=lnt>74
</span><span class=lnt>75
</span><span class=lnt>76
</span><span class=lnt>77
</span><span class=lnt>78
</span><span class=lnt>79
</span><span class=lnt>80
</span><span class=lnt>81
</span><span class=lnt>82
</span><span class=lnt>83
</span><span class=lnt>84
</span><span class=lnt>85
</span><span class=lnt>86
</span><span class=lnt>87
</span><span class=lnt>88
</span><span class=lnt>89
</span><span class=lnt>90
</span><span class=lnt>91
</span><span class=lnt>92
</span><span class=lnt>93
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>with</span> <span class=n>marked_timer</span><span class=p>(</span><span class=s2>&#34;reward&#34;</span><span class=p>,</span> <span class=n>timing_raw</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&#34;yellow&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># compute reward model score</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>use_rm</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>reward_tensor</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>rm_wg</span><span class=o>.</span><span class=n>compute_rm_score</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>batch</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>union</span><span class=p>(</span><span class=n>reward_tensor</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>reward_model</span><span class=o>.</span><span class=n>launch_reward_fn_async</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>future_reward</span> <span class=o>=</span> <span class=n>compute_reward_async</span><span class=o>.</span><span class=n>remote</span><span class=p>(</span><span class=n>batch</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>reward_tensor</span><span class=p>,</span> <span class=n>reward_extra_infos_dict</span> <span class=o>=</span> <span class=n>compute_reward</span><span class=p>(</span><span class=n>batch</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>reward_fn</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># recompute old_log_probs</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>marked_timer</span><span class=p>(</span><span class=s2>&#34;old_log_prob&#34;</span><span class=p>,</span> <span class=n>timing_raw</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&#34;blue&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>old_log_prob</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>actor_rollout_wg</span><span class=o>.</span><span class=n>compute_log_prob</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>entropys</span> <span class=o>=</span> <span class=n>old_log_prob</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;entropys&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>response_masks</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;response_mask&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>loss_agg_mode</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>actor</span><span class=o>.</span><span class=n>loss_agg_mode</span>
</span></span><span class=line><span class=cl>    <span class=n>entropy_agg</span> <span class=o>=</span> <span class=n>agg_loss</span><span class=p>(</span><span class=n>loss_mat</span><span class=o>=</span><span class=n>entropys</span><span class=p>,</span> <span class=n>loss_mask</span><span class=o>=</span><span class=n>response_masks</span><span class=p>,</span> <span class=n>loss_agg_mode</span><span class=o>=</span><span class=n>loss_agg_mode</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>old_log_prob_metrics</span> <span class=o>=</span> <span class=p>{</span><span class=s2>&#34;actor/entropy&#34;</span><span class=p>:</span> <span class=n>entropy_agg</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span><span class=o>.</span><span class=n>item</span><span class=p>()}</span>
</span></span><span class=line><span class=cl>    <span class=n>metrics</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=n>old_log_prob_metrics</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>old_log_prob</span><span class=o>.</span><span class=n>batch</span><span class=o>.</span><span class=n>pop</span><span class=p>(</span><span class=s2>&#34;entropys&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>batch</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>union</span><span class=p>(</span><span class=n>old_log_prob</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=s2>&#34;rollout_log_probs&#34;</span> <span class=ow>in</span> <span class=n>batch</span><span class=o>.</span><span class=n>batch</span><span class=o>.</span><span class=n>keys</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=c1># TODO: we may want to add diff of probs too.</span>
</span></span><span class=line><span class=cl>        <span class=n>rollout_old_log_probs</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;rollout_log_probs&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>actor_old_log_probs</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;old_log_probs&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>attention_mask</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;attention_mask&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>responses</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;responses&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>response_length</span> <span class=o>=</span> <span class=n>responses</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>response_mask</span> <span class=o>=</span> <span class=n>attention_mask</span><span class=p>[:,</span> <span class=o>-</span><span class=n>response_length</span><span class=p>:]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>rollout_probs</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=n>rollout_old_log_probs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>actor_probs</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=n>actor_old_log_probs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>rollout_probs_diff</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>rollout_probs</span> <span class=o>-</span> <span class=n>actor_probs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>rollout_probs_diff</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>masked_select</span><span class=p>(</span><span class=n>rollout_probs_diff</span><span class=p>,</span> <span class=n>response_mask</span><span class=o>.</span><span class=n>bool</span><span class=p>())</span>
</span></span><span class=line><span class=cl>        <span class=n>rollout_probs_diff_max</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>rollout_probs_diff</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>rollout_probs_diff_mean</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>rollout_probs_diff</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>rollout_probs_diff_std</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>std</span><span class=p>(</span><span class=n>rollout_probs_diff</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>metrics</span><span class=o>.</span><span class=n>update</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;training/rollout_probs_diff_max&#34;</span><span class=p>:</span> <span class=n>rollout_probs_diff_max</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span><span class=o>.</span><span class=n>item</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;training/rollout_probs_diff_mean&#34;</span><span class=p>:</span> <span class=n>rollout_probs_diff_mean</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span><span class=o>.</span><span class=n>item</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;training/rollout_probs_diff_std&#34;</span><span class=p>:</span> <span class=n>rollout_probs_diff_std</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span><span class=o>.</span><span class=n>item</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>use_reference_policy</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># compute reference log_prob</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>marked_timer</span><span class=p>(</span><span class=s2>&#34;ref&#34;</span><span class=p>,</span> <span class=n>timing_raw</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&#34;olive&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=ow>not</span> <span class=bp>self</span><span class=o>.</span><span class=n>ref_in_actor</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>ref_log_prob</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>ref_policy_wg</span><span class=o>.</span><span class=n>compute_ref_log_prob</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>ref_log_prob</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>actor_rollout_wg</span><span class=o>.</span><span class=n>compute_ref_log_prob</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>batch</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>union</span><span class=p>(</span><span class=n>ref_log_prob</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># compute values</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>use_critic</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>marked_timer</span><span class=p>(</span><span class=s2>&#34;values&#34;</span><span class=p>,</span> <span class=n>timing_raw</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&#34;cyan&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>values</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>critic_wg</span><span class=o>.</span><span class=n>compute_values</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>batch</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>union</span><span class=p>(</span><span class=n>values</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>marked_timer</span><span class=p>(</span><span class=s2>&#34;adv&#34;</span><span class=p>,</span> <span class=n>timing_raw</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&#34;brown&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># we combine with rule-based rm</span>
</span></span><span class=line><span class=cl>    <span class=n>reward_extra_infos_dict</span><span class=p>:</span> <span class=nb>dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=nb>list</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>reward_model</span><span class=o>.</span><span class=n>launch_reward_fn_async</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>reward_tensor</span><span class=p>,</span> <span class=n>reward_extra_infos_dict</span> <span class=o>=</span> <span class=n>ray</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>future_reward</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>batch</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;token_level_scores&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>reward_tensor</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>reward_extra_infos_dict</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>batch</span><span class=o>.</span><span class=n>non_tensor_batch</span><span class=o>.</span><span class=n>update</span><span class=p>({</span><span class=n>k</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>v</span><span class=p>)</span> <span class=k>for</span> <span class=n>k</span><span class=p>,</span> <span class=n>v</span> <span class=ow>in</span> <span class=n>reward_extra_infos_dict</span><span class=o>.</span><span class=n>items</span><span class=p>()})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># compute rewards. apply_kl_penalty if available</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>algorithm</span><span class=o>.</span><span class=n>use_kl_in_reward</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>batch</span><span class=p>,</span> <span class=n>kl_metrics</span> <span class=o>=</span> <span class=n>apply_kl_penalty</span><span class=p>(</span><span class=n>batch</span><span class=p>,</span> <span class=n>kl_ctrl</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>kl_ctrl_in_reward</span><span class=p>,</span> <span class=n>kl_penalty</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>algorithm</span><span class=o>.</span><span class=n>kl_penalty</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>metrics</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=n>kl_metrics</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>batch</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;token_level_rewards&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;token_level_scores&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># compute advantages, executed on the driver process</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>norm_adv_by_std_in_grpo</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>algorithm</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;norm_adv_by_std_in_grpo&#34;</span><span class=p>,</span> <span class=kc>True</span><span class=p>)</span>  <span class=c1># GRPO adv normalization factor</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>batch</span> <span class=o>=</span> <span class=n>compute_advantage</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>batch</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>adv_estimator</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>algorithm</span><span class=o>.</span><span class=n>adv_estimator</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>gamma</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>algorithm</span><span class=o>.</span><span class=n>gamma</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>lam</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>algorithm</span><span class=o>.</span><span class=n>lam</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>num_repeat</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>n</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>norm_adv_by_std_in_grpo</span><span class=o>=</span><span class=n>norm_adv_by_std_in_grpo</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>multi_turn</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>multi_turn</span><span class=o>.</span><span class=n>enable</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>config</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>algorithm</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></details><p>这一部分的操作还是很好读懂了，非常 standard：</p><ol><li>通过 <code>self.reward_fn</code> 或 <code>self.rm_wg.compute_rm_score</code> 计算 trajectory 的 reward。verl 支持各式各样的 reward，不单单是 reward model。</li><li>重算 behaviour policy 的 log probabilities: 使用 <code>self.actor_rollout_wg.compute_log_prob(batch)</code> 来重算 log probs。这里原因在 part 1 讲述 <a href>importance sampling</a> 的部分也阐述过了。这里非常让我想吐槽的是，verl 里面 <code>old_log_prob</code> 就是用 training engine 重算的 behaviour policy 的 log probs，用 old 来描述让我比较费解。</li><li>计算 reference policy 的 log probabilities: 如果使用了 reference policy，则计算 reference policy 的 log probs，用于 KL divergence 约束。</li><li>计算 Critic 的 value: 如果使用了 Critic model，则通过 <code>self.critic_wg.compute_values(batch)</code> 预测当前 state 的 value。</li><li>估算 Advantage: 调用 <code>compute_advantage</code> 函数，根据配置的advantage estimator、折扣因子 (gamma)、GALA 因子 (lam) 等参数，利用 reward 和 value 估计计算优势函数。</li></ol><h2 id=training>Training<a hidden class=anchor aria-hidden=true href=#training>#</a></h2><p>非常标准：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># update critic</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>use_critic</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>marked_timer</span><span class=p>(</span><span class=s2>&#34;update_critic&#34;</span><span class=p>,</span> <span class=n>timing_raw</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&#34;pink&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>critic_output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>critic_wg</span><span class=o>.</span><span class=n>update_critic</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>critic_output_metrics</span> <span class=o>=</span> <span class=n>reduce_metrics</span><span class=p>(</span><span class=n>critic_output</span><span class=o>.</span><span class=n>meta_info</span><span class=p>[</span><span class=s2>&#34;metrics&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>metrics</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=n>critic_output_metrics</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># implement critic warmup</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>critic_warmup</span> <span class=o>&lt;=</span> <span class=bp>self</span><span class=o>.</span><span class=n>global_steps</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># update actor</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>marked_timer</span><span class=p>(</span><span class=s2>&#34;update_actor&#34;</span><span class=p>,</span> <span class=n>timing_raw</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s2>&#34;red&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>batch</span><span class=o>.</span><span class=n>meta_info</span><span class=p>[</span><span class=s2>&#34;multi_turn&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>actor_rollout_ref</span><span class=o>.</span><span class=n>rollout</span><span class=o>.</span><span class=n>multi_turn</span><span class=o>.</span><span class=n>enable</span>
</span></span><span class=line><span class=cl>        <span class=n>actor_output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>actor_rollout_wg</span><span class=o>.</span><span class=n>update_actor</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>actor_output_metrics</span> <span class=o>=</span> <span class=n>reduce_metrics</span><span class=p>(</span><span class=n>actor_output</span><span class=o>.</span><span class=n>meta_info</span><span class=p>[</span><span class=s2>&#34;metrics&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>metrics</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=n>actor_output_metrics</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://pillumina.github.io/tags/framework/>Framework</a></li><li><a href=https://pillumina.github.io/tags/verl/>Verl</a></li><li><a href=https://pillumina.github.io/tags/sglang/>Sglang</a></li></ul><nav class=paginav><a class=prev href=https://pillumina.github.io/posts/aiinfra/01-ascend-cloudmatrix/><span class=title>« Prev</span><br><span>昇腾超节点CloudMatrix384论文拆解</span>
</a><a class=next href=https://pillumina.github.io/posts/aiinfra/07-verl-multiturn-1/><span class=title>Next »</span><br><span>[VeRL] Multi-Turn RL训练源码走读（1）</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share [VeRL] Multi-Turn RL训练源码走读（2） on x" href="https://x.com/intent/tweet/?text=%5bVeRL%5d%20Multi-Turn%20RL%e8%ae%ad%e7%bb%83%e6%ba%90%e7%a0%81%e8%b5%b0%e8%af%bb%ef%bc%882%ef%bc%89&amp;url=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f08-verl-multiturn-2%2f&amp;hashtags=framework%2cverl%2csglang"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [VeRL] Multi-Turn RL训练源码走读（2） on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f08-verl-multiturn-2%2f&amp;title=%5bVeRL%5d%20Multi-Turn%20RL%e8%ae%ad%e7%bb%83%e6%ba%90%e7%a0%81%e8%b5%b0%e8%af%bb%ef%bc%882%ef%bc%89&amp;summary=%5bVeRL%5d%20Multi-Turn%20RL%e8%ae%ad%e7%bb%83%e6%ba%90%e7%a0%81%e8%b5%b0%e8%af%bb%ef%bc%882%ef%bc%89&amp;source=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f08-verl-multiturn-2%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [VeRL] Multi-Turn RL训练源码走读（2） on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f08-verl-multiturn-2%2f&title=%5bVeRL%5d%20Multi-Turn%20RL%e8%ae%ad%e7%bb%83%e6%ba%90%e7%a0%81%e8%b5%b0%e8%af%bb%ef%bc%882%ef%bc%89"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [VeRL] Multi-Turn RL训练源码走读（2） on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f08-verl-multiturn-2%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [VeRL] Multi-Turn RL训练源码走读（2） on whatsapp" href="https://api.whatsapp.com/send?text=%5bVeRL%5d%20Multi-Turn%20RL%e8%ae%ad%e7%bb%83%e6%ba%90%e7%a0%81%e8%b5%b0%e8%af%bb%ef%bc%882%ef%bc%89%20-%20https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f08-verl-multiturn-2%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [VeRL] Multi-Turn RL训练源码走读（2） on telegram" href="https://telegram.me/share/url?text=%5bVeRL%5d%20Multi-Turn%20RL%e8%ae%ad%e7%bb%83%e6%ba%90%e7%a0%81%e8%b5%b0%e8%af%bb%ef%bc%882%ef%bc%89&amp;url=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f08-verl-multiturn-2%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [VeRL] Multi-Turn RL训练源码走读（2） on ycombinator" href="https://news.ycombinator.com/submitlink?t=%5bVeRL%5d%20Multi-Turn%20RL%e8%ae%ad%e7%bb%83%e6%ba%90%e7%a0%81%e8%b5%b0%e8%af%bb%ef%bc%882%ef%bc%89&u=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f08-verl-multiturn-2%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul><div class=related-posts><div class=related-series><h3>同系列文章</h3><ul><li><a href=/posts/aiinfra/10-verl-dataproto/>[VeRL] DataProto介绍</a>
<span class=meta>2025-08-25
· 17 min read</span></li><li><a href=/posts/aiinfra/09-verl-agentloop/>[VeRL] AgentLoop源码走读</a>
<span class=meta>2025-08-14
· 15 min read</span></li><li><a href=/posts/aiinfra/05-verl-params/>[VeRL] 参数速览</a>
<span class=meta>2025-08-14
· 6 min read</span></li><li><a href=/posts/aiinfra/07-verl-multiturn-1/>[VeRL] Multi-Turn RL训练源码走读（1）</a>
<span class=meta>2025-08-03
· 27 min read</span></li></ul></div><div class=related-tags><h3>相关文章</h3><ul><li><a href=/posts/aiinfra/10-verl-dataproto/>[VeRL] DataProto介绍</a>
<span class=meta>2025-08-25
· 17 min read
· Tags: framework, verl</span></li><li><a href=/posts/aiinfra/09-verl-agentloop/>[VeRL] AgentLoop源码走读</a>
<span class=meta>2025-08-14
· 15 min read
· Tags: framework, verl, sglang</span></li><li><a href=/posts/aiinfra/05-verl-params/>[VeRL] 参数速览</a>
<span class=meta>2025-08-14
· 6 min read
· Tags: framework, verl</span></li><li><a href=/posts/aiinfra/06-sglang-backend/>[SGLang] 后端代码速览</a>
<span class=meta>2025-08-13
· 5 min read
· Tags: inference, sglang</span></li><li><a href=/posts/aiinfra/02-slime/>[RL4LLM] 异步RL框架: Slime</a>
<span class=meta>2025-08-07
· 15 min read
· Tags: framework, LLM, RL</span></li></ul></div></div></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://pillumina.github.io/>CctoctoFX</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg></a><div class=reading-progress-bar></div><script src=https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js></script><script>document.addEventListener("DOMContentLoaded",function(){const t=document.querySelector(".reading-progress-bar");if(!t)return;const n=document.querySelector(".post-single");if(!n)return;function s(){const e=n.getBoundingClientRect(),s=e.height,o=window.innerHeight,i=window.scrollY||window.pageYOffset,a=i/(s-o)*100;t.style.width=`${Math.min(100,Math.max(0,a))}%`}let e=!1;window.addEventListener("scroll",function(){e||(window.requestAnimationFrame(function(){s(),e=!1}),e=!0)}),s()}),document.addEventListener("DOMContentLoaded",function(){mediumZoom("article img:not(.nozoom)",{margin:24,background:"var(--theme)",scrollOffset:0})})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>