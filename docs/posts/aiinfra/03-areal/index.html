<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[RL4LLM] 异步RL框架: Areal | CctoctoFX</title><meta name=keywords content="framework,LLM,RL"><meta name=description content="
https://github.com/inclusionAI/AReaL
纯异步RL方案
异步PPO训练调用流程

  graph TD
    A[用户执行: examples/run_async_ppo.sh] --> B[training/main_async_ppo.py]
    B --> C[AsyncPPOMATHConfig配置解析]
    C --> D[training/utils.py: run_experiment]
    
    D --> E[Ray初始化]
    E --> F[exp_cfg.initial_setup]
    F --> G[AsyncRLExperimentConfig.initial_setup]
    G --> H[创建ExperimentConfig]
    
    H --> I[启动Workers]
    I --> J[MasterWorker]
    I --> K[ModelWorker]
    I --> L[GenerationServer]
    I --> M[GserverManager]
    I --> N[RolloutWorker]
    
    %% MasterWorker训练流程
    J --> J1[MasterWorker._poll_async]
    J1 --> J2[FunctionExecutor.execute_step]
    J2 --> J3[执行数据流图遍历]
    J3 --> J4[发送训练请求到ModelWorker]
    
    %% ModelWorker处理流程
    K --> K1[ModelWorker._poll]
    K1 --> K2[接收MasterWorker请求]
    K2 --> K3[处理训练/推理请求]
    K3 --> K4[执行模型前向/反向传播]
    
    %% Rollout流程
    N --> N1[RolloutWorker._poll_async]
    N1 --> N2[load_next_data]
    N2 --> N3[allocate_new_rollout]
    N3 --> N4[agent.collect_trajectory]
    N4 --> N5[env.step计算奖励]
    N5 --> N6[推送数据到训练端]
    
    %% 生成服务器流程
    L --> L1[GenerationServer._poll]
    L1 --> L2[启动SGLang子进程]
    L2 --> L3[处理生成请求]
    
    %% 生成服务器管理器
    M --> M1[GserverManager._poll]
    M1 --> M2[HTTP服务线程]
    M2 --> M3[请求调度和权重更新]
    
    %% 数据流
    N6 --> O[stream_dataset.py]
    O --> J4
    
    %% 异步通信
    J4 -.->|异步请求| K2
    N3 -.->|HTTP请求| M2
    M2 -.->|调度请求| L3
    
    %% 权重更新
    K4 --> P[参数更新]
    P --> Q[权重同步]
    Q --> M3
    M3 --> R[更新生成服务器权重]
    
    style A fill:#e1f5fe
    style J fill:#f3e5f5
    style K fill:#e8f5e8
    style L fill:#fff3e0
    style M fill:#fce4ec
    style N fill:#f1f8e9


用户入口到配置解析


examples/run_async_ppo.sh → training/main_async_ppo.py"><meta name=author content="Me"><link rel=canonical href=https://pillumina.github.io/posts/aiinfra/03-areal/><link crossorigin=anonymous href=/assets/css/stylesheet.9d388901283682bb45dd422fcaa0d0a2054a3c8ff47c9cc6b2baab15508b1b90.css integrity="sha256-nTiJASg2grtF3UIvyqDQogVKPI/0fJzGsrqrFVCLG5A=" rel="preload stylesheet" as=style><link rel=icon href=https://pillumina.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://pillumina.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://pillumina.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://pillumina.github.io/apple-touch-icon.png><link rel=mask-icon href=https://pillumina.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://pillumina.github.io/posts/aiinfra/03-areal/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js crossorigin=anonymous></script><script>(function(){function t(){return document.querySelector(".post-content")||document.querySelector(".post-single")||document.body}function n(e){return/\$\$[\s\S]+?\$\$|\\\(|\\\)|\\\[|\\\]/.test(e)}function s(e){if(window.__mathjaxLoaded)return;window.__mathjaxLoaded=!0,window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code","tt"],ignoreHtmlClass:"no-math"}};var t=document.createElement("script");t.src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js",t.defer=!0,t.onload=function(){window.MathJax&&window.MathJax.typesetPromise&&window.MathJax.typesetPromise([e]).catch(function(e){console.warn("MathJax typeset error",e)})},document.head.appendChild(t)}function e(){try{if(typeof renderMathInElement=="function"){const e=t();renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\[",right:"\\]",display:!0},{left:"\\(",right:"\\)",display:!1}],throwOnError:!1,strict:!1,trust:!0,ignoredTags:["script","noscript","style","textarea","pre","code","tt"],ignoredClasses:["no-math"],macros:{"\\boldsymbol":"\\mathbf{#1}","\\bm":"\\mathbf{#1}"}}),setTimeout(function(){n(e.innerHTML)&&s(e)},200)}}catch(e){console.warn("KaTeX render error:",e)}}document.addEventListener("DOMContentLoaded",function(){e(),setTimeout(e,200)}),window.addEventListener("load",function(){setTimeout(e,0)})})()</script><script src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script><script>const config={startOnLoad:!0,theme:"neutral",themeVariables:{lineColor:"#0f0f0f"},flowchart:{useMaxWidth:!1,htmlLabels:!0}};mermaid.initialize(config),window.onload=()=>{window.mermaid.init(0[0],document.querySelectorAll(".language-mermaid"))}</script><link rel=stylesheet href=/css/custom.min.bda7229c4269a242639e058fb11a4782f02f8d77071ba16609befee67cc41c49.css integrity="sha256-vacinEJpokJjngWPsRpHgvAvjXcHG6FmCb7+5nzEHEk="><script>document.addEventListener("DOMContentLoaded",function(){const t=document.querySelectorAll("h1[id], h2[id], h3[id], h4[id], h5[id], h6[id]"),n=document.querySelectorAll(".toc a");if(t.length===0||n.length===0)return;const s={};t.forEach(e=>{s[e.id]=e.offsetTop});function i(){const t=window.scrollY+100;let e="";for(const[n,o]of Object.entries(s))if(t>=o)e=n;else break;return e}function o(){const e=i();if(n.forEach(e=>{e.classList.remove("active")}),e){const t=document.querySelector(`.toc a[href="#${e}"]`);t&&t.classList.add("active")}}let e=!1;window.addEventListener("scroll",function(){e||(window.requestAnimationFrame(function(){o(),e=!1}),e=!0)}),o()})</script><meta property="og:url" content="https://pillumina.github.io/posts/aiinfra/03-areal/"><meta property="og:site_name" content="CctoctoFX"><meta property="og:title" content="[RL4LLM] 异步RL框架: Areal"><meta property="og:description" content=" https://github.com/inclusionAI/AReaL
纯异步RL方案
异步PPO训练调用流程 graph TD A[用户执行: examples/run_async_ppo.sh] --> B[training/main_async_ppo.py] B --> C[AsyncPPOMATHConfig配置解析] C --> D[training/utils.py: run_experiment] D --> E[Ray初始化] E --> F[exp_cfg.initial_setup] F --> G[AsyncRLExperimentConfig.initial_setup] G --> H[创建ExperimentConfig] H --> I[启动Workers] I --> J[MasterWorker] I --> K[ModelWorker] I --> L[GenerationServer] I --> M[GserverManager] I --> N[RolloutWorker] %% MasterWorker训练流程 J --> J1[MasterWorker._poll_async] J1 --> J2[FunctionExecutor.execute_step] J2 --> J3[执行数据流图遍历] J3 --> J4[发送训练请求到ModelWorker] %% ModelWorker处理流程 K --> K1[ModelWorker._poll] K1 --> K2[接收MasterWorker请求] K2 --> K3[处理训练/推理请求] K3 --> K4[执行模型前向/反向传播] %% Rollout流程 N --> N1[RolloutWorker._poll_async] N1 --> N2[load_next_data] N2 --> N3[allocate_new_rollout] N3 --> N4[agent.collect_trajectory] N4 --> N5[env.step计算奖励] N5 --> N6[推送数据到训练端] %% 生成服务器流程 L --> L1[GenerationServer._poll] L1 --> L2[启动SGLang子进程] L2 --> L3[处理生成请求] %% 生成服务器管理器 M --> M1[GserverManager._poll] M1 --> M2[HTTP服务线程] M2 --> M3[请求调度和权重更新] %% 数据流 N6 --> O[stream_dataset.py] O --> J4 %% 异步通信 J4 -.->|异步请求| K2 N3 -.->|HTTP请求| M2 M2 -.->|调度请求| L3 %% 权重更新 K4 --> P[参数更新] P --> Q[权重同步] Q --> M3 M3 --> R[更新生成服务器权重] style A fill:#e1f5fe style J fill:#f3e5f5 style K fill:#e8f5e8 style L fill:#fff3e0 style M fill:#fce4ec style N fill:#f1f8e9 用户入口到配置解析 examples/run_async_ppo.sh → training/main_async_ppo.py"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-08-07T14:40:12+08:00"><meta property="article:modified_time" content="2025-08-07T14:40:12+08:00"><meta property="article:tag" content="Framework"><meta property="article:tag" content="LLM"><meta property="article:tag" content="RL"><meta property="og:image" content="https://pillumina.github.io/imgs/icon_head.png"><meta property="og:see_also" content="https://pillumina.github.io/posts/aiinfra/05-verl-params/"><meta property="og:see_also" content="https://pillumina.github.io/posts/aiinfra/02-slime/"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://pillumina.github.io/imgs/icon_head.png"><meta name=twitter:title content="[RL4LLM] 异步RL框架: Areal"><meta name=twitter:description content="
https://github.com/inclusionAI/AReaL
纯异步RL方案
异步PPO训练调用流程

  graph TD
    A[用户执行: examples/run_async_ppo.sh] --> B[training/main_async_ppo.py]
    B --> C[AsyncPPOMATHConfig配置解析]
    C --> D[training/utils.py: run_experiment]
    
    D --> E[Ray初始化]
    E --> F[exp_cfg.initial_setup]
    F --> G[AsyncRLExperimentConfig.initial_setup]
    G --> H[创建ExperimentConfig]
    
    H --> I[启动Workers]
    I --> J[MasterWorker]
    I --> K[ModelWorker]
    I --> L[GenerationServer]
    I --> M[GserverManager]
    I --> N[RolloutWorker]
    
    %% MasterWorker训练流程
    J --> J1[MasterWorker._poll_async]
    J1 --> J2[FunctionExecutor.execute_step]
    J2 --> J3[执行数据流图遍历]
    J3 --> J4[发送训练请求到ModelWorker]
    
    %% ModelWorker处理流程
    K --> K1[ModelWorker._poll]
    K1 --> K2[接收MasterWorker请求]
    K2 --> K3[处理训练/推理请求]
    K3 --> K4[执行模型前向/反向传播]
    
    %% Rollout流程
    N --> N1[RolloutWorker._poll_async]
    N1 --> N2[load_next_data]
    N2 --> N3[allocate_new_rollout]
    N3 --> N4[agent.collect_trajectory]
    N4 --> N5[env.step计算奖励]
    N5 --> N6[推送数据到训练端]
    
    %% 生成服务器流程
    L --> L1[GenerationServer._poll]
    L1 --> L2[启动SGLang子进程]
    L2 --> L3[处理生成请求]
    
    %% 生成服务器管理器
    M --> M1[GserverManager._poll]
    M1 --> M2[HTTP服务线程]
    M2 --> M3[请求调度和权重更新]
    
    %% 数据流
    N6 --> O[stream_dataset.py]
    O --> J4
    
    %% 异步通信
    J4 -.->|异步请求| K2
    N3 -.->|HTTP请求| M2
    M2 -.->|调度请求| L3
    
    %% 权重更新
    K4 --> P[参数更新]
    P --> Q[权重同步]
    Q --> M3
    M3 --> R[更新生成服务器权重]
    
    style A fill:#e1f5fe
    style J fill:#f3e5f5
    style K fill:#e8f5e8
    style L fill:#fff3e0
    style M fill:#fce4ec
    style N fill:#f1f8e9


用户入口到配置解析


examples/run_async_ppo.sh → training/main_async_ppo.py"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://pillumina.github.io/posts/"},{"@type":"ListItem","position":2,"name":"AI Infra","item":"https://pillumina.github.io/posts/aiinfra/"},{"@type":"ListItem","position":3,"name":"[RL4LLM] 异步RL框架: Areal","item":"https://pillumina.github.io/posts/aiinfra/03-areal/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[RL4LLM] 异步RL框架: Areal","name":"[RL4LLM] 异步RL框架: Areal","description":" https://github.com/inclusionAI/AReaL\n纯异步RL方案\n异步PPO训练调用流程 graph TD A[用户执行: examples/run_async_ppo.sh] --\u0026gt; B[training/main_async_ppo.py] B --\u0026gt; C[AsyncPPOMATHConfig配置解析] C --\u0026gt; D[training/utils.py: run_experiment] D --\u0026gt; E[Ray初始化] E --\u0026gt; F[exp_cfg.initial_setup] F --\u0026gt; G[AsyncRLExperimentConfig.initial_setup] G --\u0026gt; H[创建ExperimentConfig] H --\u0026gt; I[启动Workers] I --\u0026gt; J[MasterWorker] I --\u0026gt; K[ModelWorker] I --\u0026gt; L[GenerationServer] I --\u0026gt; M[GserverManager] I --\u0026gt; N[RolloutWorker] %% MasterWorker训练流程 J --\u0026gt; J1[MasterWorker._poll_async] J1 --\u0026gt; J2[FunctionExecutor.execute_step] J2 --\u0026gt; J3[执行数据流图遍历] J3 --\u0026gt; J4[发送训练请求到ModelWorker] %% ModelWorker处理流程 K --\u0026gt; K1[ModelWorker._poll] K1 --\u0026gt; K2[接收MasterWorker请求] K2 --\u0026gt; K3[处理训练/推理请求] K3 --\u0026gt; K4[执行模型前向/反向传播] %% Rollout流程 N --\u0026gt; N1[RolloutWorker._poll_async] N1 --\u0026gt; N2[load_next_data] N2 --\u0026gt; N3[allocate_new_rollout] N3 --\u0026gt; N4[agent.collect_trajectory] N4 --\u0026gt; N5[env.step计算奖励] N5 --\u0026gt; N6[推送数据到训练端] %% 生成服务器流程 L --\u0026gt; L1[GenerationServer._poll] L1 --\u0026gt; L2[启动SGLang子进程] L2 --\u0026gt; L3[处理生成请求] %% 生成服务器管理器 M --\u0026gt; M1[GserverManager._poll] M1 --\u0026gt; M2[HTTP服务线程] M2 --\u0026gt; M3[请求调度和权重更新] %% 数据流 N6 --\u0026gt; O[stream_dataset.py] O --\u0026gt; J4 %% 异步通信 J4 -.-\u0026gt;|异步请求| K2 N3 -.-\u0026gt;|HTTP请求| M2 M2 -.-\u0026gt;|调度请求| L3 %% 权重更新 K4 --\u0026gt; P[参数更新] P --\u0026gt; Q[权重同步] Q --\u0026gt; M3 M3 --\u0026gt; R[更新生成服务器权重] style A fill:#e1f5fe style J fill:#f3e5f5 style K fill:#e8f5e8 style L fill:#fff3e0 style M fill:#fce4ec style N fill:#f1f8e9 用户入口到配置解析 examples/run_async_ppo.sh → training/main_async_ppo.py\n","keywords":["framework","LLM","RL"],"articleBody":" https://github.com/inclusionAI/AReaL\n纯异步RL方案\n异步PPO训练调用流程 graph TD A[用户执行: examples/run_async_ppo.sh] --\u003e B[training/main_async_ppo.py] B --\u003e C[AsyncPPOMATHConfig配置解析] C --\u003e D[training/utils.py: run_experiment] D --\u003e E[Ray初始化] E --\u003e F[exp_cfg.initial_setup] F --\u003e G[AsyncRLExperimentConfig.initial_setup] G --\u003e H[创建ExperimentConfig] H --\u003e I[启动Workers] I --\u003e J[MasterWorker] I --\u003e K[ModelWorker] I --\u003e L[GenerationServer] I --\u003e M[GserverManager] I --\u003e N[RolloutWorker] %% MasterWorker训练流程 J --\u003e J1[MasterWorker._poll_async] J1 --\u003e J2[FunctionExecutor.execute_step] J2 --\u003e J3[执行数据流图遍历] J3 --\u003e J4[发送训练请求到ModelWorker] %% ModelWorker处理流程 K --\u003e K1[ModelWorker._poll] K1 --\u003e K2[接收MasterWorker请求] K2 --\u003e K3[处理训练/推理请求] K3 --\u003e K4[执行模型前向/反向传播] %% Rollout流程 N --\u003e N1[RolloutWorker._poll_async] N1 --\u003e N2[load_next_data] N2 --\u003e N3[allocate_new_rollout] N3 --\u003e N4[agent.collect_trajectory] N4 --\u003e N5[env.step计算奖励] N5 --\u003e N6[推送数据到训练端] %% 生成服务器流程 L --\u003e L1[GenerationServer._poll] L1 --\u003e L2[启动SGLang子进程] L2 --\u003e L3[处理生成请求] %% 生成服务器管理器 M --\u003e M1[GserverManager._poll] M1 --\u003e M2[HTTP服务线程] M2 --\u003e M3[请求调度和权重更新] %% 数据流 N6 --\u003e O[stream_dataset.py] O --\u003e J4 %% 异步通信 J4 -.-\u003e|异步请求| K2 N3 -.-\u003e|HTTP请求| M2 M2 -.-\u003e|调度请求| L3 %% 权重更新 K4 --\u003e P[参数更新] P --\u003e Q[权重同步] Q --\u003e M3 M3 --\u003e R[更新生成服务器权重] style A fill:#e1f5fe style J fill:#f3e5f5 style K fill:#e8f5e8 style L fill:#fff3e0 style M fill:#fce4ec style N fill:#f1f8e9 用户入口到配置解析 examples/run_async_ppo.sh → training/main_async_ppo.py\n通过Hydra解析CLI参数为AsyncPPOMATHConfig\n调用initial_setup()生成ExperimentConfig\nWorker启动和初始化 training/utils.py:run_experiment()启动Ray集群\n根据scheduling_setup()创建各类Worker\n每个Worker执行_configure()和_poll()/_poll_async()\n训练端数据流 MasterWorker._poll_async() → FunctionExecutor.execute_step()\n通过request_reply_stream发送请求到ModelWorker\nModelWorker处理训练/推理请求，执行模型计算\nRollout端数据流 RolloutWorker._poll_async() → agent.collect_trajectory()\n通过GserverManager调度生成请求到GenerationServer\n通过stream_dataset.py推送轨迹数据到训练端\n异步通信机制 训练端和Rollout端通过TCP Socket通信\nGserverManager提供HTTP API进行请求调度\n权重更新通过文件系统同步\n全局架构 部署形态 进程部署架构 以单机8卡为例\nMasterWorker：1个CPU进程，协调训练流程\nModelWorker：6个GPU进程（GPU0-5），执行模型训练\nGenerationServer：2个GPU进程（GPU6-7），运行SGLang推理服务\nGserverManager：1个CPU进程，管理生成服务器\nRolloutWorker：多个CPU进程，执行智能体逻辑\n训推资源分配 框架支持分离部署和共享部署两种模式\n分离部署 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 ┌─────────────────────────────────────────────────────────────┐ │ Ray Cluster (1 Node, 8 GPUs) │ ├─────────────────────────────────────────────────────────────┤ │ ┌─────────────┐ ┌─────────────┐ ┌─────────────┐ │ │ │MasterWorker │ │ModelWorker │ │ModelWorker │ │ │ │ (CPU) │ │ (GPU0) │ │ (GPU1) │ │ │ └─────────────┘ └─────────────┘ └─────────────┘ │ │ │ │ ┌─────────────┐ ┌─────────────┐ ┌─────────────┐ │ │ │ModelWorker │ │ModelWorker │ │ModelWorker │ │ │ │ (GPU2) │ │ (GPU3) │ │ (GPU4) │ │ │ └─────────────┘ └─────────────┘ └─────────────┘ │ │ │ │ ┌─────────────┐ ┌─────────────┐ ┌─────────────┐ │ │ │ModelWorker │ │GServerMgr │ │RolloutWorker│ │ │ │ (GPU5) │ │ (CPU) │ │ (CPU) │ │ │ └─────────────┘ └─────────────┘ └─────────────┘ │ │ │ │ ┌─────────────┐ ┌─────────────┐ ┌─────────────┐ │ │ │GenServer │ │GenServer │ │RolloutWorker│ │ │ │ (SGLang) │ │ (SGLang) │ │ (CPU) │ │ │ │ (GPU6) │ │ (GPU7) │ └─────────────┘ │ │ └─────────────┘ └─────────────┘ │ └─────────────────────────────────────────────────────────────┘ 训练端：使用4个GPU（d2p2m1 = 2×2×1）\n推理端：使用4个GPU（d4p1m1 = 4×1×1）\n优势：完全解耦，互不干扰，性能最优\n分层关系 graph TB subgraph \"用户层\" A[examples/run_async_ppo.sh] B[training/main_async_ppo.py] end subgraph \"配置层\" C[AsyncPPOMATHConfig] D[ExperimentConfig] E[WorkerConfigs] end subgraph \"系统层\" F[Ray集群管理] G[Name Resolution] H[日志系统] end subgraph \"训练端 Workers\" I[MasterWorker] J[ModelWorker] K[FunctionExecutor] end subgraph \"Rollout端 Workers\" L[RolloutWorker] M[GenerationServer] N[GserverManager] O[PartialRolloutManager] end subgraph \"核心组件\" P[Agent接口] Q[Environment接口] R[Model接口] S[Dataset接口] end subgraph \"通信层\" T[Request-Reply Stream] U[Push-Pull Stream] V[HTTP API] W[TCP Socket] end subgraph \"模型层\" X[SGLang Backend] Y[PyTorch Backend] Z[模型并行] end %% 连接关系 A --\u003e B B --\u003e C C --\u003e D D --\u003e E E --\u003e F F --\u003e G F --\u003e H E --\u003e I E --\u003e J E --\u003e L E --\u003e M E --\u003e N I --\u003e K K --\u003e T J --\u003e T L --\u003e O O --\u003e V M --\u003e V N --\u003e V L --\u003e P L --\u003e Q J --\u003e R I --\u003e S T --\u003e W U --\u003e W V --\u003e W J --\u003e Y M --\u003e X Y --\u003e Z X --\u003e Z style A fill:#e3f2fd style I fill:#f3e5f5 style L fill:#e8f5e8 style T fill:#fff3e0 style X fill:#fce4ec 全局类图 classDiagram %% 基类层 class AsyncWorker { \u003c\u003e +_configure(config) +_poll_async() PollResult +run_async() } class Worker { \u003c\u003e +_configure(config) +_poll() PollResult +run() } %% Worker实现层 - 训练端 class MasterWorker { -config: MasterWorkerConfig -func_executor: FunctionExecutor -__poll_async() -__lazy_init() } class ModelWorker { -config: ModelWorkerConfig -__request_queue: Queue -_poll() -handle_request() } %% Worker实现层 - Rollout端 class RolloutWorker { -config: RolloutWorkerConfig -agent: Agent -env: Environment -_poll_async() -rollout_task() } class GenerationServer { -config: GenerationServerConfig -server_process: Process -_poll() -launch_server_subprocess() } class GserverManager { -config: GserverManagerConfig -server_urls: List[str] -_poll() -_schedule_request() } %% 接口层 class Agent { \u003c\u003e +collect_trajectory(prompt, env, obs_queue, act_queue) } class Environment { \u003c\u003e +reset() +step(action) } class ModelInterface { \u003c\u003e +inference(model, data, mb_spec) +generate(model, data, mb_spec) +train_step(model, data, mb_spec) } %% 配置层 class AsyncPPOMATHConfig { +agent: AgentAbstraction +env: EnvServiceAbstraction +initial_setup() ExperimentConfig +scheduling_setup() ExperimentScheduling } class ExperimentConfig { +model_rpcs: List[ModelRPC] +model_worker: ModelWorkerConfig +generation_server: GenerationServerConfig +rollout_worker: RolloutWorkerConfig } %% 继承关系 - 垂直排列减少交叉 AsyncWorker \u003c|-- MasterWorker AsyncWorker \u003c|-- RolloutWorker Worker \u003c|-- ModelWorker Worker \u003c|-- GenerationServer Worker \u003c|-- GserverManager %% 组合关系 - 水平连接 MasterWorker --\u003e ModelInterface : uses RolloutWorker --\u003e Agent : uses RolloutWorker --\u003e Environment : uses ModelWorker --\u003e ModelInterface : implements %% 配置关系 - 底部连接 AsyncPPOMATHConfig --\u003e ExperimentConfig : creates ExperimentConfig --\u003e MasterWorker : configures ExperimentConfig --\u003e ModelWorker : configures ExperimentConfig --\u003e RolloutWorker : configures ExperimentConfig --\u003e GenerationServer : configures ExperimentConfig --\u003e GserverManager : configures 核心模块类图 classDiagram %% 基类 class AsyncWorker { \u003c\u003e +_poll_async() PollResult } class Worker { \u003c\u003e +_poll() PollResult } %% 训练端Workers class MasterWorker { -func_executor: FunctionExecutor -__poll_async() } class ModelWorker { -__request_queue: Queue -_poll() } %% Rollout端Workers class RolloutWorker { -agent: Agent -env: Environment -_poll_async() } class GenerationServer { -server_process: Process -_poll() } class GserverManager { -server_urls: List[str] -_poll() } %% 核心接口 class Agent { \u003c\u003e +collect_trajectory() } class Environment { \u003c\u003e +step(action) } class ModelInterface { \u003c\u003e +train_step() +generate() } %% 配置 class AsyncPPOMATHConfig { +initial_setup() +scheduling_setup() } %% 继承关系 AsyncWorker \u003c|-- MasterWorker AsyncWorker \u003c|-- RolloutWorker Worker \u003c|-- ModelWorker Worker \u003c|-- GenerationServer Worker \u003c|-- GserverManager %% 关键关系 MasterWorker --\u003e ModelInterface RolloutWorker --\u003e Agent RolloutWorker --\u003e Environment ModelWorker --\u003e ModelInterface AsyncPPOMATHConfig --\u003e MasterWorker AsyncPPOMATHConfig --\u003e ModelWorker AsyncPPOMATHConfig --\u003e RolloutWorker 异步流程机制细节 异步完整流程图 sequenceDiagram participant User as 用户 participant MW as MasterWorker participant RW as RolloutWorker participant GS as GenerationServer participant GSM as GserverManager participant ZMQ as ZMQ Stream participant SD as StreamDataset participant MW2 as ModelWorker participant NR as NameResolving participant FS as 文件系统 Note over User: 启动异步PPO训练 User-\u003e\u003eUser: examples/run_async_ppo.sh输入：GPU数量、并行策略、模型路径 User-\u003e\u003eMW: training/main_async_ppo.py输入：AsyncPPOMATHConfig Note over MW: 初始化阶段 MW-\u003e\u003eMW: run_experiment(config)输入：实验配置 MW-\u003e\u003eMW: initial_setup()输入：worker配置 MW-\u003e\u003eNR: 注册各Worker地址变量：worker_info, msid2mwid Note over MW: 设置版本差异控制参数变量：max_head_offpolicyness Note over RW,GS: Rollout端启动 RW-\u003e\u003eRW: _configure(config)输入：RolloutWorkerConfig RW-\u003e\u003eZMQ: 初始化NameResolvingZmqPusher变量：experiment_name, trial_name, worker_index GS-\u003e\u003eGS: _configure(config)输入：GenerationServerConfig GS-\u003e\u003eGS: 初始化SGLang后端变量：model_path, tokenizer_path GSM-\u003e\u003eGSM: _configure(config)输入：GserverManagerConfig GSM-\u003e\u003eGSM: 初始化权重版本跟踪变量：_last_param_realloc_step Note over MW2: 训练端启动 MW2-\u003e\u003eMW2: _configure(config)输入：ModelWorkerConfig MW2-\u003e\u003eSD: 初始化PullerStreamDataset变量：dataset_size, pull_timeout_ms MW2-\u003e\u003eMW2: 初始化模型和优化器变量：model_config, optimizer_config Note over MW: 训练循环开始 MW-\u003e\u003eMW: __poll_async()输入：训练控制参数 MW-\u003e\u003eMW: func_executor.execute_step()输入：数据流图 Note over RW,GS: 并行生成轨迹 loop 持续生成轨迹 RW-\u003e\u003eGS: 发送生成请求输入：prompt, max_tokens Note over GS: 使用当前加载的权重版本变量：current_model_version GS-\u003e\u003eGS: SGLang生成输入：模型权重、生成参数 GS--\u003e\u003eRW: 返回生成结果输出：generated_text RW-\u003e\u003eRW: agent.collect_trajectory()输入：生成结果 RW-\u003e\u003eRW: 计算奖励、构建轨迹变量：trajectory, reward Note over RW: 为轨迹添加版本信息变量：trajectory.model_version = current_model_version RW-\u003e\u003eZMQ: push_stream.push(traj)输入：轨迹数据(JSON格式) end Note over ZMQ,SD: 数据传递 ZMQ-\u003e\u003eSD: 接收轨迹数据输入：JSON序列化数据 SD-\u003e\u003eSD: _pull_data_worker()后台线程持续拉取 SD-\u003e\u003eSD: 转换为SequenceSample变量：data_queue, processed_data Note over MW2: 训练执行 - 版本差异控制 MW2-\u003e\u003eSD: 获取训练数据输入：batch_size SD--\u003e\u003eMW2: 返回SequenceSample输出：训练样本 Note over MW2: 检查数据版本差异变量：data_version, current_version, max_head_offpolicyness MW2-\u003e\u003eMW2: validate_data_version(data_version, current_version)输入：数据版本、当前版本、最大允许差异 alt 版本差异在允许范围内 Note over MW2: 接受数据，继续训练变量：version_diff \u003c= max_head_offpolicyness MW2-\u003e\u003eMW2: train_step(data)输入：训练数据、优化器状态 MW2-\u003e\u003eMW2: 计算PPO损失变量：policy_loss, value_loss, entropy_loss MW2-\u003e\u003eMW2: 更新模型参数变量：optimizer.step(), global_step else 版本差异过大 Note over MW2: 丢弃过期数据变量：version_diff \u003e max_head_offpolicyness MW2-\u003e\u003eMW2: discard_stale_data(data)输入：过期数据 Note over MW2: 记录数据丢弃统计变量：stale_data_count++ MW2-\u003e\u003eSD: 请求新的训练数据输入：batch_size end Note over MW2,FS: 权重同步 - 版本控制 MW2-\u003e\u003eFS: __save_model(save_meta)输入：model, save_dir, global_step Note over FS: 保存权重分片到磁盘变量：param_realloc_path/model_name/step/ MW2-\u003e\u003eNR: name_resolve.add(model_version, global_step)输入：experiment, trial, model_name, step Note over NR: 原子性更新版本号变量：model_version = global_step Note over GSM,GS: 推理端权重更新 - 数据陈旧性控制 loop 定期检查新权重 GSM-\u003e\u003eNR: check_new_params()输入：experiment, trial, model_name NR--\u003e\u003eGSM: 返回最新global_step alt 有新权重版本 GSM-\u003e\u003eGSM: 发现版本更新变量：realloc_version \u003e _last_param_realloc_step GSM-\u003e\u003eGS: flush_requests_and_update_weights(load_dir)输入：新权重路径 Note over GS: 中断当前所有推理请求变量：_interrupt_requests() GS-\u003e\u003eFS: 读取新权重文件输入：load_dir GS-\u003e\u003eGS: update_weights_from_disk(load_dir)变量：分片rank, 权重文件 Note over GS: 按TP/PP分片加载权重变量：新model_version生效 GS--\u003e\u003eGSM: 权重更新完成 GSM-\u003e\u003eGSM: 更新版本跟踪变量：_last_param_realloc_step = realloc_version Note over GS: 恢复推理服务变量：使用新权重版本 else 无新权重 GSM-\u003e\u003eGSM: 继续使用当前权重变量：_last_param_realloc_step end end Note over MW: 训练控制 - 版本差异监控 MW-\u003e\u003eMW: 检查训练终止条件输入：epoch, global_step, loss MW-\u003e\u003eMW: 监控版本差异统计变量：stale_data_count, version_diff_stats Note over MW: 记录版本差异对训练的影响变量：training_efficiency, data_freshness alt 继续训练 MW-\u003e\u003eMW: 更新训练状态变量：step_info, epoch_step Note over MW: 返回训练循环开始 else 训练完成 MW-\u003e\u003eUser: 训练结束输出：最终模型、训练日志、版本差异统计 end 异步带来的算法修正 同步PPO完整流程 先回顾一下ppo的计算流程：\n我们有一个策略π(a|s)，它决定在状态s下选择动作a的概率。PPO的目标是优化这个策略，使其能够获得更高的累积奖励。\n数据收集（rollout） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 使用当前策略π_θ生成轨迹 for episode in range(num_episodes): state = env.reset() trajectory = [] while not done: # 使用当前策略选择动作 action_probs = π_θ(state) # 当前策略的概率分布 action = sample(action_probs) # 采样动作 # 记录动作概率（用于后续计算重要性比率） old_logp = log(action_probs[action]) # 这就是old_logp # 执行动作 next_state, reward, done = env.step(action) trajectory.append((state, action, reward, old_logp)) state = next_state 计算优势函数 1 2 3 # 使用GAE计算优势函数 advantages = compute_gae(trajectory, γ=0.99, λ=0.95) returns = compute_returns(trajectory, γ=0.99) 策略更新 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 对收集的数据进行多次更新 for epoch in range(num_epochs): for batch in data_loader: # 重新计算当前策略的概率 current_action_probs = π_θ(batch.states) # 当前策略 cur_logp = log(current_action_probs[batch.actions]) # 这就是cur_logp # 计算重要性比率 ratio = exp(cur_logp - old_logp) # PPO损失函数 surr1 = ratio * advantages surr2 = clip(ratio, 1-ε, 1+ε) * advantages loss = -min(surr1, surr2) # 更新策略参数 optimizer.zero_grad() loss.backward() optimizer.step() 为什么需要重要性采样 ratio = π_θ(a|s) / π_θ_old(a|s) = exp(cur_logp - old_logp)\n我们想用当前策略π_θ来评估旧策略π_θ_old生成的数据 重要性采样修正了这种分布偏移 框架的异步PPO修正机制 异步带来的问题，数据生成和训练并行 1 2 3 4 5 # 时间线 t=0: 策略π_θ_0生成数据 t=1: 策略π_θ_1生成数据，同时训练π_θ_0的数据 t=2: 策略π_θ_2生成数据，同时训练π_θ_1的数据 ... 这导致：\n训练数据来自较旧的策略版本\n重要性比率可能变得很大或很小\n策略更新可能不稳定\n框架引入的修正机制如下：\n机制1： 版本控制\n1 2 3 4 5 6 7 8 # 记录数据生成时的策略版本 data = { \"version_start\": model_version_when_generation_started, \"version_end\": model_version_when_generation_ended, \"old_logp\": logprobs_from_generation, \"actions\": actions, \"rewards\": rewards } 机制2：数据过滤\n1 2 3 4 5 # 检查版本差异 version_diff = current_version - data.version_start if version_diff \u003e max_head_offpolicyness: # 数据太旧，丢弃 continue 机制3：解耦损失（Decoupled Loss）\n1 2 3 4 5 6 7 8 9 10 11 # 标准PPO损失 def standard_ppo_loss(cur_logp, old_logp, advantages): ratio = exp(cur_logp - old_logp) return -min(ratio * advantages, clip(ratio, 1-ε, 1+ε) * advantages) # AReaL解耦损失 def decoupled_loss(cur_logp, old_logp, prox_logp, advantages): # 使用prox_logp作为中间策略 ratio = exp(cur_logp - prox_logp) behav_weight = exp(prox_logp - old_logp) return -min(ratio * advantages, clip(ratio, 1-ε, 1+ε) * advantages) * behav_weight 修正的合理性分析 数学基础\n解耦损失可以分解为:\n1 2 3 4 5 6 7 8 9 # 标准PPO ratio = π_θ(a|s) / π_θ_old(a|s) # AReaL解耦 ratio = π_θ(a|s) / π_prox(a|s) behav_weight = π_prox(a|s) / π_θ_old(a|s) # 等价性 ratio * behav_weight = π_θ(a|s) / π_θ_old(a|s) # 与标准PPO相同 稳定性提升\n1 2 3 4 5 6 7 8 9 # 异步场景下的问题 # 如果π_θ与π_θ_old差异很大 ratio = π_θ(a|s) / π_θ_old(a|s) # 可能很大或很小 # AReaL的解决方案 # 引入中间策略π_prox，使得： # π_θ ≈ π_prox ≈ π_θ_old ratio = π_θ(a|s) / π_prox(a|s) # 更稳定 behav_weight = π_prox(a|s) / π_θ_old(a|s) # 更稳定 渐进式更新\n1 2 # 标准异步PPO：直接从π_θ_old跳到π_θ # AReaL：π_θ_old → π_prox → π_θ，分两步更新 具体实现 核心修正机制实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # AReaL的解耦损失实现 if proximal_logprobs is not None: # 计算行为策略权重 behav_kl = proximal_logprobs - old_logprobs behav_imp_weight = behav_kl.exp() # 应用权重上限 if behav_imp_weight_cap is not None: behav_mask = (behav_imp_weight \u003c= behav_imp_weight_cap).logical_and(loss_mask) else: behav_mask = loss_mask # 应用行为策略权重 pg_loss = pg_loss * behav_imp_weight 数学等价性证明\n1 2 3 4 5 6 7 8 9 10 11 12 13 # 标准PPO损失 L_standard = -min(ratio * A, clip(ratio, 1-ε, 1+ε) * A) 其中 ratio = π_θ(a|s) / π_θ_old(a|s) # AReaL解耦损失 L_decoupled = -min(ratio * A, clip(ratio, 1-ε, 1+ε) * A) * behav_weight 其中 ratio = π_θ(a|s) / π_prox(a|s) behav_weight = π_prox(a|s) / π_θ_old(a|s) # 等价性证明 L_decoupled = -min(ratio * A, clip(ratio, 1-ε, 1+ε) * A) * behav_weight = -min((π_θ/π_prox) * A, clip(π_θ/π_prox, 1-ε, 1+ε) * A) * (π_prox/π_θ_old) = -min((π_θ/π_θ_old) * A, clip(π_θ/π_prox, 1-ε, 1+ε) * A * (π_prox/π_θ_old)) 流程图视角 graph TD %% 生成阶段 - SGLang推理服务 A[用户Promptpacked_prompts] --\u003e B[SGLang推理服务actor_gen] B --\u003e B1[PPOActorInterface.generate使用策略π_θ_old] B1 --\u003e B2[模型前向传播genstep函数] B2 --\u003e B3[采样token计算logprob] B3 --\u003e B4[concat_prompt_to_generation_output拼接prompt和生成结果] B4 --\u003e B5[输出: packed_input_idspacked_logprobsprompt_maskseq_no_eos_mask] %% 推理阶段 - 四个组件并行执行 B5 --\u003e C[推理阶段开始] %% Actor推理 - 计算proximal_logp C --\u003e D[actor_infPPOActorInterface.inference使用策略π_θ_prox] D --\u003e D1[输入: packed_input_ids] D1 --\u003e D2[calc_logprobs post_hookgather_packed_shifted_log_probs] D2 --\u003e D3[输出: proximal_logprobsπ_θ_prox] %% Reference推理 - 计算ref_logp C --\u003e E[ref_infPPOActorInterface.inference使用策略π_ref] E --\u003e E1[输入: packed_input_ids] E1 --\u003e E2[calc_logprobs post_hookgather_packed_shifted_log_probs] E2 --\u003e E3[输出: packed_ref_logprobsπ_ref] %% Critic推理 - 计算values C --\u003e F[critic_infPPOCriticInterface.inference使用价值网络V_θ] F --\u003e F1[输入: packed_input_idsseq_no_eos_mask] F1 --\u003e F2[module.forward直接输出value] F2 --\u003e F3[输出: valuesV_θ] %% Reward推理 - 计算rewards C --\u003e G[rew_infMultiTaskRewardInterface.inference使用奖励函数R] G --\u003e G1[输入: packed_input_idspacked_promptstask_ids] G1 --\u003e G2[calculate_task_reward异步任务处理] G2 --\u003e G3[输出: rewardsR] %% 数据汇聚 D3 --\u003e H[推理结果汇聚] E3 --\u003e H F3 --\u003e H G3 --\u003e H %% 训练阶段准备 H --\u003e I[训练数据准备packed_input_idspacked_logprobspacked_ref_logprobsproximal_logprobsrewardsvaluesprompt_maskseq_no_eos_mask] %% 训练阶段 - 计算current_logp和loss I --\u003e J[actor_trainPPOActorInterface.train_step使用策略π_θ] J --\u003e J1[模型前向传播module.forward] J1 --\u003e J2[gather_packed_shifted_log_probs计算current_logpπ_θ] J2 --\u003e J3[计算advantagesGAE算法] J3 --\u003e J4[计算rewardsKL正则化] J4 --\u003e J5[PPO Loss计算_ppo_actor_loss_from_model_outputs] %% PPO Loss详细计算 J5 --\u003e K[PPO Loss计算详情] K --\u003e K1[输入: current_logp, old_logp, proximal_logpadvantages, rewards] K1 --\u003e K2{use_decoupled_loss?} K2 --\u003e|是| K3[解耦损失计算ratio = expbehav_weight = exp] K2 --\u003e|否| K4[标准损失计算ratio = exp] K3 --\u003e K5[最终损失loss = -min ratio * advantages, clip ratio * advantages * behav_weight] K4 --\u003e K6[最终损失loss = -min ratio * advantages, clip ratio * advantages] K5 --\u003e L[输出: Actor Loss] K6 --\u003e L %% Critic训练 J3 --\u003e M[critic_trainPPOCriticInterface.train_step使用价值网络V_θ] M --\u003e M1[模型前向传播计算new_values] M1 --\u003e M2[Critic Loss计算_ppo_critic_loss_from_model_outputs] M2 --\u003e M3[输出: Critic Loss] %% 样式定义 classDef generateStyle fill:#e3f2fd,stroke:#1565c0,stroke-width:2px classDef inferenceStyle fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px classDef trainStyle fill:#e8f5e8,stroke:#2e7d32,stroke-width:2px classDef lossStyle fill:#fff3e0,stroke:#ef6c00,stroke-width:2px class B,B1,B2,B3,B4,B5 generateStyle class D,D1,D2,D3,E,E1,E2,E3,F,F1,F2,F3,G,G1,G2,G3 inferenceStyle class J,J1,J2,J3,J4,J5,M,M1,M2,M3 trainStyle class K,K1,K2,K3,K4,K5,K6,L lossStyle old_logp (π_θ_old)\n1 2 3 4 5 # 生成阶段 - SGLang推理服务 # 模型：Actor模型 (策略π_θ_old) # 时机：生成token时实时计算 # 函数：genstep() -\u003e distrb.log_prob(next_tokens) # 保存：concat_prompt_to_generation_output() -\u003e packed_logprobs proximal_logp (π_θ_prox)\n1 2 3 4 5 # 推理阶段 - actor_inf组件 # 模型：Actor模型 (策略π_θ_prox，比π_θ_old新，比π_θ旧) # 时机：生成完成后，训练前 # 函数：PPOActorInterface.inference() -\u003e calc_logprobs() # 条件：仅当use_decoupled_loss=True时计算 current_logp (π_θ)\n1 2 3 4 5 # 训练阶段 - actor_train组件 # 模型：Actor模型 (当前策略π_θ，最新) # 时机：训练时重新计算 # 函数：PPOActorInterface.train_step() -\u003e gather_packed_shifted_log_probs() # 作用：用于计算重要性采样比率 权重同步机制 sequenceDiagram participant MW as ModelWorker participant FS as 文件系统 participant NR as NameResolving participant GSM as GserverManager participant GS as GenerationServer Note over MW: 训练完成一次step后 MW-\u003e\u003eMW: __save_model(save_meta)输入：model, save_dir, global_step MW-\u003e\u003eFS: 保存权重文件路径: param_realloc_path/model_name/step/ Note over MW,FS: 权重以分片形式落盘（TP/PP分片） MW-\u003e\u003eNR: name_resolve.add(model_version, global_step)输入：experiment, trial, model_name, step NR--\u003e\u003eGSM: model_version更新 loop 推理端定期检查 GSM-\u003e\u003eNR: check_new_params()输入：experiment, trial, model_name NR--\u003e\u003eGSM: 返回最新global_step alt 有新权重 GSM-\u003e\u003eFS: 获取新权重路径 GSM-\u003e\u003eGS: flush_requests_and_update_weights(load_dir) GS-\u003e\u003eFS: 读取权重分片文件 GS-\u003e\u003eGS: update_weights_from_disk(load_dir)变量: load_dir, 分片rank Note over GS: 按TP/PP分片加载到各自分片 else 无新权重 GSM-\u003e\u003eGSM: 不做更新 end end Note over GS: 新权重生效，推理端继续服务 核心机制：\n训练端：ModelWorker在每次train_step后保存权重到param_realloc_path，并调用name_resolve.add(model_version, global_step)，在NameResolving服务中记录最新的权重版本号（global_step）。\n推理端：GserverManager定期检查model_version，发现新版本（model_version和已经加载的对比）时通过HTTP API更新所有GenerationServer的权重。\ns\n同步动作：权重更新时会中断正在进行的生成请求，确保推理使用最新权重。\n关键函数与变量说明：\n__save_model(save_meta)\n输入：model_name, save_dir, global_step\n输出：权重文件（分片）落盘\nname_resolve.add(model_version, global_step)\n输入：实验名、trial名、模型名、step\n输出：NameResolving服务中记录最新step\ncheck_new_params()\n输入：实验名、trial名、模型名\n输出：最新step（如果有更新）\nflush_requests_and_update_weights(load_dir)\n输入：权重目录\n输出：推理端各分片加载新权重\nupdate_weights_from_disk(load_dir)\n输入：分片rank、load_dir\n输出：各分片权重加载到内存\n变量传递链路：\nglobal_step/model_version：用于标识权重版本\nparam_realloc_path/load_dir：权重磁盘路径\n分片rank：决定每个worker加载哪一份权重\n数据陈旧性控制 异步训推协调的核心机制，需要限制陈旧性保证训练稳定性\n1 2 3 4 # GserverManager中的陈旧性检查 def is_staled(self): # 检查当前运行的rollout是否过时 return self.rollout_stat.running \u003e self.config.max_head_offpolicyness 协调机制：\n版本控制：每个生成请求都携带version_start和version_end，记录使用的权重版本\n陈旧性限制：通过max_head_offpolicyness参数控制允许的最大数据陈旧性\n请求调度：GserverManager在分配新rollout时检查容量和陈旧性，拒绝过时的请求\n确实存在使用老权重的情况：\n异步训练允许一定程度的权重陈旧性\n通过max_head_offpolicyness参数控制陈旧性上限\n这种设计在提高训练效率的同时，通过限制陈旧性保证训练稳定性\n数据传递机制 各个worker之间的通信核心是ZMQ：\n高性能：支持零拷贝和批量传输 多种模式：PUSH/PULL、PUB/SUB、REQ/REP等 异步通信：非阻塞I/O，适合高并发场景 跨语言：支持多种编程语言 网络透明：自动处理连接、重连、负载均衡 1 2 3 4 5 6 7 8 9 10 11 # zmq的配置举例 # 高性能配置 self.context = zmq.Context.instance(io_threads=8) self.context.set(zmq.MAX_SOCKETS, 65536) # 缓冲区优化 self.socket.setsockopt(zmq.SNDHWM, 1000) # 发送缓冲区 self.socket.setsockopt(zmq.RCVHWM, 1000) # 接收缓冲区 # 超时设置 self.socket.setsockopt(zmq.RCVTIMEO, timeout_ms) sequenceDiagram participant RW as RolloutWorker participant GS as GenerationServer participant GSM as GserverManager participant ZMQ as ZMQ Stream participant SD as StreamDataset participant MW as ModelWorker participant DM as DataManager Note over RW,DM: 1. 生成轨迹数据 RW-\u003e\u003eGS: 发送生成请求 GS-\u003e\u003eGS: SGLang生成结果 GS-\u003e\u003eRW: 返回生成结果 RW-\u003e\u003eRW: 计算奖励，构建轨迹 Note over RW,DM: 2. 推送数据到训练端 RW-\u003e\u003eZMQ: 推送轨迹数据(JSON格式) ZMQ-\u003e\u003eSD: 接收数据 SD-\u003e\u003eSD: 转换为SequenceSample Note over RW,DM: 3. 训练端处理数据 SD-\u003e\u003eMW: 提供数据给ModelWorker MW-\u003e\u003eDM: 存储到DataManager(内存) MW-\u003e\u003eMW: 执行训练步骤 数据传递层次 Rollout端到训练端： 使用ZMQ Push-Pull Stream传输轨迹数据\nRolloutWorker → NameResolvingZmqPusher → NameResolvingZmqPuller → StreamDataset\ngraph TB subgraph \"Rollout端\" RW[RolloutWorker] --\u003e NP[NameResolvingZmqPusher] NP --\u003e ZMQ1[ZMQ PUSH Socket] end subgraph \"训练端\" ZMQ2[ZMQ PULL Socket] --\u003e NP2[NameResolvingZmqPuller] NP2 --\u003e SD[StreamDataset] SD --\u003e MW[ModelWorker] end subgraph \"Name Resolution\" NR[name_resolve系统] end ZMQ1 -.-\u003e|TCP连接| ZMQ2 NP --\u003e NR NP2 --\u003e NR 训练端内部： 使用Request-Reply Stream传输训练请求\nMasterWorker → ModelWorker通过ZMQ通信\ngraph TB subgraph \"MasterWorker\" MW[MasterWorker] --\u003e NRC[NameResolvingRequestClient] NRC --\u003e ZMQ1[ZMQ PUSH Sockets] ZMQ2[ZMQ PULL Socket] --\u003e NRC end subgraph \"ModelWorker\" ZMQ3[ZMQ PULL Socket] --\u003e NRS[NameResolvingReplyServer] NRS --\u003e MW2[ModelWorker] MW2 --\u003e ZMQ4[ZMQ PUSH Socket] end subgraph \"通信协议\" REQ[Request] --\u003e ACK[ACK] ACK --\u003e SYN[SYN] SYN --\u003e RESP[Response] end ZMQ1 -.-\u003e|TCP| ZMQ3 ZMQ4 -.-\u003e|TCP| ZMQ2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 请求发送 def request(self, handlers, handle_type, datas, no_syn=True): requests = [ Payload( handler=handler, handle_name=handle_type, data=data, no_syn=no_syn, ) for handler, data in zip(handlers, datas) ] # 发送请求 for payload in requests: idx = self._handler_routing[payload.handler] self.send_sockets[idx].send(pickle.dumps(payload)) 存储分离： 训练数据：存储在DataManager中，支持分布式存储和重分布\nDataManager为内存存储： 1 2 3 4 5 6 7 8 9 10 11 12 class DataManager: def __init__(self, model_topos, msid2mwid, data_transfer_pairs): # 核心存储：内存字典 self.storage: Dict[Hashable, SequenceSample] = {} def store(self, x: SequenceSample): # 存储到内存字典 self.storage[x.ids[0]] = x def get(self, data_id: Hashable): # 从内存获取 return self.storage[data_id] 支持数据重分布：\n1 2 3 4 5 6 7 8 9 def redistribute(self, data_info: SequenceSample, plan: List[RedistribStep]): \"\"\"执行数据重分布\"\"\" for step in plan: if step.comm_type == \"bcast\": self._run_bcast(step, data_infos) elif step.comm_type == \"gather\": self._run_gather(step, data_infos) elif step.comm_type == \"scatter\": self._run_scatter(step, data_infos) 推理数据：存储在SGLang服务器的内存中\n元数据：通过name_resolve系统共享\n实现细节 RolloutWorker 数据发送 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # realhf/system/rollout_worker.py class RolloutWorker(AsyncWorker): def _configure(self, config): # 初始化ZMQ推送器 - 发送轨迹数据到训练端 self.push_stream = NameResolvingZmqPusher( self.experiment_name, self.trial_name, pusher_index=self.worker_index, pusher_cnt=self.worker_count, ) async def _poll_async(self): # 收集轨迹数据 traj = await self.agent.collect_trajectory() # 推送数据到训练端 self.push_stream.push([traj.as_json_serializable()]) GenerationServer 推理服务 1 2 3 4 5 6 7 8 9 10 # realhf/system/generation_server.py class GenerationServer(Worker): def launch_server_subprocess(self): # 启动SGLang推理服务器 self.server_process, self.server_port = launch_server_cmd(cmd, port=server_port) self.server_addr = f\"http://{host}:{self.server_port}\" # 注册服务地址到NameResolving name = names.gen_servers(self.experiment_name, self.trial_name) name_resolve.add_subentry(name, self.server_addr) GserverManager负载均衡 1 2 3 4 5 6 7 8 9 10 11 12 13 # realhf/system/gserver_manager.py class GserverManager(Worker): def _discover_servers(self, n_servers: int): # 通过NameResolving发现所有推理服务器 name = names.gen_servers(self.experiment_name, self.trial_name) urls = name_resolve.get_subtree(name) return urls def _run_routing_service(self): # HTTP服务，接收推理请求并路由到合适的服务器 async def schedule_request(req_meta): server_idx = self._least_requests_schedule(req_meta) return self.server_urls[server_idx] MasterWorker 训练协调 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # realhf/system/master_worker.py class MasterWorker(AsyncWorker): def _configure(self, config): # 初始化Request-Reply客户端 self.func_executor = FunctionExecutor( experiment_name=self.experiment_name, trial_name=self.trial_name, n_subscribers=self.config.n_model_workers, handler_routing=self.config.handler_routing, ) async def _poll_async(self): # 执行训练步骤，通过Request-Reply与ModelWorker通信 result = await self.func_executor.execute_step( step_name=\"train_step\", step_kwargs={\"batch\": batch} ) ModelWorker 模型训练 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # realhf/system/model_worker.py class ModelWorker(Worker): def _configure(self, config): # 初始化Request-Reply服务器 self.reply_server = NameResolvingReplyServer( experiment_name=self.experiment_name, trial_name=self.trial_name, idx=self.worker_index, ) # 注册训练处理函数 self.reply_server.register_handler(\"train_step\", self._train_step) def _train_step(self, batch): # 执行训练步骤 loss = self.model.train_step(batch) # 保存权重并更新版本号 self.model.save_weights(self.param_realloc_path) name = names.model_version(self.experiment_name, self.trial_name, self.model_name.role) name_resolve.add(name, self.global_step) return {\"loss\": loss, \"global_step\": self.global_step} StreamDataset 数据接收 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # realhf/system/stream_dataset.py class StreamDataset: def __init__(self, args, puller_index): # 初始化ZMQ拉取器 - 接收RolloutWorker推送的数据 self.puller = NameResolvingZmqPuller(args, puller_index) def __iter__(self): while True: # 从ZMQ接收数据 data = self.puller.pull() # 转换为训练格式 sample = SequenceSample.from_json_serializable(data) yield sample ZMQ通信层 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # realhf/system/push_pull_stream.py class NameResolvingZmqPusher(ZMQJsonPusher): def __init__(self, experiment_name, trial_name, pusher_index, pusher_cnt): # 通过NameResolving获取目标地址 pullers = name_resolve.get_subtree(names.stream_pullers(experiment_name, trial_name)) # 计算路由关系 groups = grouping(pusher_cnt, len(pullers)) puller_index = self._find_target_puller(groups, pusher_index) # 获取目标地址并连接 name = names.push_pull_stream(experiment_name, trial_name, f\"puller{puller_index}\") addr = name_resolve.wait(name) host, port = addr.split(\":\") super().__init__(host, int(port)) class NameResolvingZmqPuller(ZMQJsonPuller): def __init__(self, args, puller_index): # 绑定随机端口 host, port = network.gethostip(), network.find_free_port() addr = f\"{host}:{port}\" # 注册地址到NameResolving name = names.push_pull_stream(args.experiment_name, args.trial_name, f\"puller{puller_index}\") name_resolve.add(name, addr) super().__init__(host, port) Request-Reply 通信层 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # realhf/system/request_reply_stream.py class NameResolvingRequestClient: def __init__(self, experiment_name, trial_name, n_subscribers, handler_routing): # 创建多个发送socket for i in range(n_subscribers): s = self.context.socket(zmq.PUSH) send_port = s.bind_to_random_port(f\"tcp://{host_ip}\") # 注册发送地址 master_send_name = names.request_reply_stream(experiment_name, trial_name, f\"master_send_{i}\") name_resolve.add(name=master_send_name, value=f\"{host_ip}:{send_port}\") self.send_sockets.append(s) # 创建接收socket self.recv_socket = self.context.socket(zmq.PULL) recv_port = self.recv_socket.bind_to_random_port(f\"tcp://{host_ip}\") master_recv_name = names.request_reply_stream(experiment_name, trial_name, \"master_recv\") name_resolve.add(name=master_recv_name, value=f\"{host_ip}:{recv_port}\") class NameResolvingReplyServer: def __init__(self, experiment_name, trial_name, idx): # 等待MasterWorker注册地址 send_name = names.request_reply_stream(experiment_name, trial_name, \"master_recv\") master_recv_addr = name_resolve.wait(send_name, timeout=300) recv_name = names.request_reply_stream(experiment_name, trial_name, f\"master_send_{idx}\") master_send_addr = name_resolve.wait(recv_name, timeout=300) # 连接到MasterWorker self.accept(master_send_addr, master_recv_addr) 轨迹数据序列化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 轨迹数据序列化 class Trajectory: def as_json_serializable(self): return { \"observations\": self.observations, \"actions\": self.actions, \"rewards\": self.rewards, \"dones\": self.dones, \"values\": self.values, \"log_probs\": self.log_probs, } # ZMQ传输 self.push_stream.push([traj.as_json_serializable()]) # 接收端反序列化 data = self.puller.pull() sample = SequenceSample.from_json_serializable(data) QA 为什么数据流不通过MasterWorker而是直接到ModelWorker？ ModelWorker直接创建PullerStreamDataset，通过zmq接收RolloutWorker推送的数据。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # realhf/system/model_worker.py class ModelWorker(Worker): def _lazy_setup(self): # 在ModelWorker中创建数据集 datasets = [ data_api.make_dataset( d, self.config.base_seed, self.__dataset_dp_rank, self.__dataset_dp_size, self.config.tokenizer_name_or_path, ) for d in self.config.datasets ] # 特殊处理StreamDataset if not isinstance(self.__datasets[dataset_id], PullerStreamDataset): dataloader_kwargs[\"collate_fn\"] = data_api.SequenceSample.gather dataloader_kwargs[\"batch_size\"] = 10240 else: dataloader_kwargs[\"batch_size\"] = None # StreamDataset不需要batch_size 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class PullerStreamDataset(Dataset): def __init__(self, util, args, dataset_cfgs, pull_timeout_ms=100): # 创建后台线程来拉取数据 self.worker_thread = threading.Thread(target=self._pull_data_worker) self.worker_thread.start() def _pull_data_worker(self): # 在后台线程中创建ZMQ拉取器 stream = NameResolvingZmqPuller( self.args, puller_index=self.util.dp_rank, ) while not self._stop_event.is_set(): # 从ZMQ接收RolloutWorker推送的数据 data = stream.pull(timeout_ms=self.pull_timeout_ms) processed_data = [SequenceSample.from_json_compatible(x) for x in data] # 放入队列供训练使用 self.data_queue.put_nowait(processed_data) def __getitem__(self, idx): # 从队列中获取数据用于训练 samples = [] while True: try: samples += self.data_queue.get_nowait() except queue.Empty: break return samples 目的是为了控制流和数据流的分离，且减少数据中转 。MasterWorker只是做协调训练步骤，而ModelWorker直接接收数据:\n1 2 3 4 5 # MasterWorker: 控制流 await self.func_executor.execute_step() # 协调训练步骤 # ModelWorker: 数据流 stream = NameResolvingZmqPuller(args, puller_index) # 直接接收数据 这里需要理解一点：StreamDataset是持续接收RolloutWorker的数据的，不是按需获取的。stream过程会把数据缓存在内存的queue中，MasterWorker协调训练发生后，ModelWorker从内存队列里直接取数据训练。\n此外，RolloutWorker是按照DP rank分组的，每个ModelWorker负责特定分组的RolloutWorker,通过NameResolving动态发现和链接。\nModelWorker如何和RolloutWorker分组建链？ 问题的本质rollout worker是按照dp分组，那么rollout worker怎么找到对应的model worker的，这其中的服务发现是怎么实现的。\n首先理解如何分组的，比如发送者和接受者的个数不同:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 def grouping(num_senders, num_receivers): groups = {} assert num_senders \u003e= num_receivers # 每个接收者分配多个发送者 senders_per_receiver = num_senders // num_receivers for receiver_id in range(num_receivers): start = receiver_id * senders_per_receiver end = (receiver_id + 1) * senders_per_receiver groups[receiver_id] = list(range(start, end)) # 分配剩余的发送者 remaining = num_senders % num_receivers for i in range(remaining): groups[i].append(num_receivers * senders_per_receiver + i) return groups 1 2 3 4 5 6 7 8 # 假设有6个RolloutWorker，3个ModelWorker grouping(6, 3) # 6个发送者，3个接收者 # 结果： # { # 0: [0, 1], # ModelWorker 0 负责 RolloutWorker 0,1 # 1: [2, 3], # ModelWorker 1 负责 RolloutWorker 2,3 # 2: [4, 5] # ModelWorker 2 负责 RolloutWorker 4,5 # } 其次要理解ModelWorker如何确定自己的DP Rank:\n只有数据并行头节点（tp_rank == 0 and pp_rank == pp_size - 1）才负责接收数据。 每个DP rank对应一个ModelWorker。 DP rank通过拓扑结构确定。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # realhf/system/model_worker.py class ModelWorker(Worker): def _configure(self, cfg): # 遍历所有模型分片，找到数据并行头节点 for s in self.config.shards: _pp_size = s.id.topo.get_dim(\"pipe\") # 只有pipeline的最后一个stage且tensor rank为0的才是数据并行头 if not (s.id.tp_rank == 0 and s.id.pp_rank == _pp_size - 1): continue if src_rpc.model_name == s.id.model_name: self.__has_dataset = True self.__dataset_dp_size = s.id.topo.get_dim(\"data\") # 总DP数量 self.__dataset_dp_rank = s.id.dp_rank # 当前DP rank break # 注册到NameResolving系统 if self.__has_dataset: name = names.stream_pullers(self.__experiment_name, self.__trial_name) name_resolve.add_subentry(name, str(self.__dataset_dp_rank)) 还要理解RolloutWorker是如何找到对应的ModelWorker的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # realhf/system/push_pull_stream.py class NameResolvingZmqPusher(ZMQJsonPusher): def __init__(self, experiment_name, trial_name, pusher_index, pusher_cnt, **kwargs): # 1. 获取所有可用的puller（ModelWorker） pullers = name_resolve.get_subtree( names.stream_pullers(experiment_name, trial_name) ) pullers = list(map(int, pullers)) # 转换为整数列表 puller_cnt = len(pullers) # 2. 执行分组算法 groups = grouping(pusher_cnt, puller_cnt) # 3. 找到当前pusher属于哪个puller组 puller_index = None for puller_index, pusher_indices in groups.items(): if pusher_index in pusher_indices: # 这里有个bug，应该是pusher_index break # 4. 通过NameResolving获取目标地址 name = names.push_pull_stream( experiment_name, trial_name, stream_name=f\"puller{puller_index}\" ) addr = name_resolve.wait(name) host, port = addr.split(\":\") super().__init__(host, int(port), **kwargs) 最后理解完整的匹配流程：\nModelWorker注册 1 2 3 4 5 # ModelWorker启动时 if self.__has_dataset: name = names.stream_pullers(self.__experiment_name, self.__trial_name) name_resolve.add_subentry(name, str(self.__dataset_dp_rank)) # 例如：注册 \"puller0\", \"puller1\", \"puller2\" RolloutWorker发现分组 1 2 3 4 5 6 # RolloutWorker启动时 pullers = name_resolve.get_subtree(names.stream_pullers(exp_name, trial_name)) # 获取到 [\"0\", \"1\", \"2\"] 表示有3个ModelWorker groups = grouping(6, 3) # 6个RolloutWorker，3个ModelWorker # 结果：{0: [0,1], 1: [2,3], 2: [4,5]} 建立链接 1 2 3 4 5 6 # RolloutWorker 0,1 连接到 ModelWorker 0 # RolloutWorker 2,3 连接到 ModelWorker 1 # RolloutWorker 4,5 连接到 ModelWorker 2 name = names.push_pull_stream(exp_name, trial_name, f\"puller{puller_index}\") addr = name_resolve.wait(name) # 等待ModelWorker注册地址 MasterWorker如何和ModelWorker建链？ 与RolloutWorker-ModelWorker的Push-Pull模式（单向）不同，MasterWorker-ModelWorker使用Request-Reply模式（双向）。\nMasterWorker创建Request Client 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # realhf/system/master_worker.py def __lazy_init(self): # 构建handler路由表 handler_routing = copy.deepcopy(self.config.msid2mwid) # 为数据并行添加特殊路由 src_rpc = self.__rpc_srcs[0] src_rpc_topo = self.config.model_topos[src_rpc.model_name] src_rpc_dp_size = src_rpc_topo.get_dim(\"data\") src_rpc_pp_size = src_rpc_topo.get_dim(\"pipe\") for i in range(src_rpc_dp_size): # 找到每个DP rank对应的ModelWorker rank = src_rpc_topo.get_rank(data=i, pipe=src_rpc_pp_size - 1, tensor=0) handler_routing[f\"__data{i}__\"] = self.config.msid2mwid[ config_pkg.ModelShardID.from_parallelism_rank( model_name=src_rpc.model_name, topo=src_rpc_topo, parallelism_rank=rank, ) ] # 添加简单的worker_index映射 handler_routing.update({i: i for i in range(self.config.n_model_workers)}) # 创建Request-Reply Stream self.__stream = request_reply_stream.make_master_stream( self.config.worker_info, n_subscribers=self.config.n_model_workers, handler_routing=handler_routing, ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 # realhf/system/request_reply_stream.py class NameResolvingRequestClient: def __init__(self, experiment_name, trial_name, n_subscribers, handler_routing): self.context = zmq.Context.instance(io_threads=ZMQ_IO_THREADS) host_ip = socket.gethostbyname(socket.gethostname()) # 1. 为每个ModelWorker创建发送socket self.send_sockets: List[zmq.Socket] = [] for i in range(n_subscribers): s = self.context.socket(zmq.PUSH) send_port = s.bind_to_random_port(f\"tcp://{host_ip}\") s.setsockopt(zmq.LINGER, 0) # 注册发送地址到NameResolving master_send_name = names.request_reply_stream( experiment_name, trial_name, f\"master_send_{i}\" ) name_resolve.add(name=master_send_name, value=f\"{host_ip}:{send_port}\") self.send_sockets.append(s) # 2. 创建接收socket self.recv_socket = self.context.socket(zmq.PULL) recv_port = self.recv_socket.bind_to_random_port(f\"tcp://{host_ip}\") self.recv_socket.setsockopt(zmq.LINGER, 0) self.recv_address = f\"{host_ip}:{recv_port}\" # 注册接收地址 master_recv_name = names.request_reply_stream( experiment_name, trial_name, \"master_recv\" ) name_resolve.add(name=master_recv_name, value=self.recv_address) # 3. 等待所有ModelWorker连接 while ( len( name_resolve.get_subtree( names.request_reply_stream(experiment_name, trial_name, PUBSUB_BARRIER_NAME) ) ) \u003c n_subscribers ): time.sleep(0.1) ModelWorker创建Reply Server 1 2 3 4 5 6 7 # realhf/system/model_worker.py def __lazy_setup(self): # 创建与MasterWorker的连接 self.__stream = request_reply_stream.make_worker_stream( self.config.worker_info, idx=self.__worker_index, ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 # realhf/system/request_reply_stream.py class NameResolvingReplyServer: def __init__(self, experiment_name, trial_name, idx): self.context = zmq.Context.instance(io_threads=ZMQ_IO_THREADS) # 1. 等待MasterWorker注册接收地址 send_name = names.request_reply_stream( experiment_name, trial_name, \"master_recv\" ) try: master_recv_addr = name_resolve.wait(send_name, timeout=300) except TimeoutError as e: logger.error(f\"Worker timeout waiting for master receive stream.\") raise e # 2. 等待MasterWorker注册发送地址 recv_name = names.request_reply_stream( experiment_name, trial_name, f\"master_send_{idx}\" ) try: master_send_addr = name_resolve.wait(recv_name, timeout=300) except TimeoutError as e: logger.error(f\"Worker timeout waiting for master send stream\") raise e # 3. 建立连接 self.accept(master_send_addr, master_recv_addr) # 4. 注册到barrier，通知MasterWorker已连接 name_resolve.add_subentry( name=names.request_reply_stream( experiment_name, trial_name, PUBSUB_BARRIER_NAME ), value=socket.gethostbyname(socket.gethostname()), keepalive_ttl=1200, ) def accept(self, server_send_addr: str, server_recv_addr: str): # 连接到MasterWorker的发送socket recv_socket = self.context.socket(zmq.PULL) recv_socket.connect(f\"tcp://{server_send_addr}\") recv_socket.setsockopt(zmq.LINGER, 0) self.recv_socket = recv_socket # 连接到MasterWorker的接收socket send_socket = self.context.socket(zmq.PUSH) send_socket.connect(f\"tcp://{server_recv_addr}\") send_socket.setsockopt(zmq.LINGER, 0) self.send_socket = send_socket 为什么Request-Reply模式要设计路由表？ 问题本质是Push-Pull模式直接用DP rank分组策略。而MasterWorker和ModelWorker之间的路由策略要设计特定的路由表。\n因为RolloutWorker-ModelWorker的数据流场景有以下特点：\n持续推送：RolloutWorker持续生成数据 负载均衡：只需要确保数据均匀分布 简单映射：一个RolloutWorker组对应一个ModelWorker 无状态：不需要跟踪具体的任务状态 而控制流场景的特点是：\n精确控制：需要精确指定哪个ModelWorker执行哪个任务 复杂拓扑：模型可能有DP、TP、PP等多种并行维度 状态管理：需要跟踪请求-响应的状态 动态分配：任务可能需要根据负载动态分配 核心还是复杂模型的并行拓扑问题，比如还有细粒度的模型分片(tp, pp)等，不是push-pull场景的1：N映射，而是复杂的N:M映射，还需要考虑拓扑、负载、依赖关系等。所以路由表可以确保：\n每个ModelShardID精确映射到对应的ModelWorker 支持一个ModelWorker承载多个模型分片 支持复杂的跨模型通信（如Actor-Critic架构） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 路由表示例 handler_routing = { # 模型分片ID -\u003e ModelWorker索引 \"ModelShardID(model_name='actor', dp_rank=0, tp_rank=0, pp_rank=0)\": 0, \"ModelShardID(model_name='actor', dp_rank=1, tp_rank=0, pp_rank=0)\": 1, # 数据并行特殊路由 \"__data0__\": 0, # DP rank 0 -\u003e ModelWorker 0 \"__data1__\": 1, # DP rank 1 -\u003e ModelWorker 1 # 简单索引映射 0: 0, # ModelWorker 0 1: 1, # ModelWorker 1 } 不同并行场景下的路由表长什么样？ 场景1：纯DP（dp=2）\n配置：\n2个ModelWorker\n1种模型结构，DP=2\n每个ModelWorker承载1个DP rank\n1 2 3 4 5 6 7 8 9 10 11 12 13 handler_routing = { # 模型分片映射 ModelShardID(model=\"actor\", dp=0, tp=0, pp=0): 0, # DP rank 0 -\u003e MW 0 ModelShardID(model=\"actor\", dp=1, tp=0, pp=0): 1, # DP rank 1 -\u003e MW 1 # 数据路由映射 \"__data0__\": 0, # 数据0 -\u003e MW 0 \"__data1__\": 1, # 数据1 -\u003e MW 1 # 用于Worker间的直接通信 0: 0, # MW 0 -\u003e MW 0 1: 1, # MW 1 -\u003e MW 1 } 特点：\n简单的1:1映射\n每个ModelWorker独立处理一个DP rank\n数据路由与模型分片路由一致\n场景2: DP + TP （DP=2，TP=2）\n配置：\n4个ModelWorker\n1种模型结构，DP=2, TP=2\n每个ModelWorker承载1个模型分片\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 handler_routing = { # 模型分片映射 (DP=2, TP=2) ModelShardID(model=\"actor\", dp=0, tp=0, pp=0): 0, # (0,0) -\u003e MW 0 副本0的前半 ModelShardID(model=\"actor\", dp=0, tp=1, pp=0): 1, # (0,1) -\u003e MW 1 副本0的后半 ModelShardID(model=\"actor\", dp=1, tp=0, pp=0): 2, # (1,0) -\u003e MW 2 副本1的前半 ModelShardID(model=\"actor\", dp=1, tp=1, pp=0): 3, # (1,1) -\u003e MW 3 副本1的后半 # 数据路由映射 (每个DP rank对应多个TP rank) \"__data0__\": 0, # DP rank 0 的head -\u003e MW 0 (tp=0) \"__data1__\": 2, # DP rank 1 的head -\u003e MW 2 (tp=0) # 直接索引映射 0: 0, 1: 1, 2: 2, 3: 3, } 前向/反向时，MasterWorker会根据dp/tp/pp的rank，查找ModelShardID，路由到对应的worker（卡号）。\n数据分发时，比如dp=0的数据，直接通过\"data0“路由到卡0（tp=0的head）；dp=1的数据路由到卡2。\n特点：\n每个DP rank有多个TP分片\n数据路由指向每个DP rank的head (tp=0)\n需要TP内部的通信协调\n场景3：DP + TP + PP （DP=2, TP=2, PP=2）\n配置：\n8个ModelWorker\n1种模型结构，DP=2, TP=2, PP=2\n每个ModelWorker承载1个模型分片\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 handler_routing = { # 模型分片映射 (DP=2, TP=2, PP=2) # PP=0 ModelShardID(model=\"actor\", dp=0, tp=0, pp=0): 0, # (0,0,0) -\u003e MW 0 ModelShardID(model=\"actor\", dp=0, tp=1, pp=0): 1, # (0,1,0) -\u003e MW 1 ModelShardID(model=\"actor\", dp=1, tp=0, pp=0): 2, # (1,0,0) -\u003e MW 2 ModelShardID(model=\"actor\", dp=1, tp=1, pp=0): 3, # (1,1,0) -\u003e MW 3 # PP=1 (最后一层) ModelShardID(model=\"actor\", dp=0, tp=0, pp=1): 4, # (0,0,1) -\u003e MW 4 ModelShardID(model=\"actor\", dp=0, tp=1, pp=1): 5, # (0,1,1) -\u003e MW 5 ModelShardID(model=\"actor\", dp=1, tp=0, pp=1): 6, # (1,0,1) -\u003e MW 6 ModelShardID(model=\"actor\", dp=1, tp=1, pp=1): 7, # (1,1,1) -\u003e MW 7 # 数据路由映射 (每个dp组的head，通常pp=最后一层, tp=0) \"__data0__\": 4, # DP rank 0 的最后一层 -\u003e MW 4 (pp=1, tp=0) \"__data1__\": 6, # DP rank 1 的最后一层 -\u003e MW 6 (pp=1, tp=0) # 直接索引映射 0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, } 模型函数调用： MasterWorker根据dp/tp/pp的rank，构造ModelShardID，查找handler_routing，路由到对应worker（卡号）。\n例如：要调度dp=1, tp=0, pp=1的分片，查找ModelShardID(dp=1, tp=0, pp=1)，得到worker id=6（卡6）。\n数据分发：\n数据分发通常路由到每个dp组的“head”，即pp=最后一层、tp=0的分片。\n例如：dp=0的数据，查找”data0\"，得到worker id=4（卡4，dp=0, tp=0, pp=1）。\ndp=1的数据，查找\"data1\"，得到worker id=6（卡6，dp=1, tp=0, pp=1）。\n特点：\n最复杂的3D并行拓扑\n数据路由指向每个DP rank的最后一层 (pp=1)\n需要PP内部的流水线协调\n场景4：Actor-Critic架构 (DP=2)\n配置：\n2个ModelWorker\nActor和Critic两个模型结构，DP=2\n每个ModelWorker承载Actor和Critic的同一个DP rank\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 handler_routing = { # Actor模型分片 ModelShardID(model=\"actor\", dp=0, tp=0, pp=0): 0, # Actor DP=0 -\u003e MW 0 ModelShardID(model=\"actor\", dp=1, tp=0, pp=0): 1, # Actor DP=1 -\u003e MW 1 # Critic模型分片 ModelShardID(model=\"critic\", dp=0, tp=0, pp=0): 0, # Critic DP=0 -\u003e MW 0 ModelShardID(model=\"critic\", dp=1, tp=0, pp=0): 1, # Critic DP=1 -\u003e MW 1 # 数据路由映射 (Actor和Critic共享) \"__data0__\": 0, # 数据0 -\u003e MW 0 (Actor和Critic的DP=0) \"__data1__\": 1, # 数据1 -\u003e MW 1 (Actor和Critic的DP=1) # 直接索引映射 0: 0, 1: 1, } 特点：\n一个ModelWorker承载多个模型\nActor和Critic共享相同的DP rank\n支持模型间的参数同步\n框架针对不同的拓扑是按照什么顺序切分的？ 从路由表可以看到，3D并行下不同的切分顺序会影响卡和rank的映射，这个问题是一个分布式并行训练的基础问题，和框架的实现一起来理解。\n从代码中可以看到，AReaL框架使用固定的切分顺序：\n1 2 3 4 5 6 # realhf/base/topology.py class ProcessTopology: def __init__(self, axes, dims): # axes定义了切分顺序，dims定义了每个维度的切分大小 self.axes = axes # 切分顺序 self.dims = dims # 切分大小 1 2 3 4 5 # 训练时的拓扑 PipeDataTensorParallelTopology(axes=['pipe', 'data', 'tensor']) # 推理时的拓扑 DataPipeTensorParallelTopology(axes=['data', 'pipe', 'tensor']) 也就是训练和推理的切分拓扑不同。\n标准顺序：PP -\u003e DP -\u003e TP (训练时)：\n1 2 3 4 5 6 7 8 9 10 11 12 13 # 8张卡，DP=2, TP=2, PP=2 # 切分顺序：PP -\u003e DP -\u003e TP rank = pp_rank * (dp_size * tp_size) + dp_rank * tp_size + tp_rank # 映射结果： # 卡0: pp=0, dp=0, tp=0 (rank=0) # 卡1: pp=0, dp=0, tp=1 (rank=1) # 卡2: pp=0, dp=1, tp=0 (rank=2) # 卡3: pp=0, dp=1, tp=1 (rank=3) # 卡4: pp=1, dp=0, tp=0 (rank=4) # 卡5: pp=1, dp=0, tp=1 (rank=5) # 卡6: pp=1, dp=1, tp=0 (rank=6) # 卡7: pp=1, dp=1, tp=1 (rank=7) 原因：\n流水线友好：PP维度相邻的rank在物理上相邻，减少流水线通信开销\n数据并行效率：同一PP stage内的DP rank可以高效进行AllReduce\n内存局部性：同一PP stage的数据在内存上更接近\n推理时：DP -\u003e PP -\u003e TP:\n原因：\n数据分发友好：DP rank相邻，便于数据分发\n推理并行：同一DP组内的PP rank可以并行处理不同batch\n负载均衡：DP维度优先，便于负载均衡\n","wordCount":"4872","inLanguage":"en","image":"https://pillumina.github.io/imgs/icon_head.png","datePublished":"2025-08-07T14:40:12+08:00","dateModified":"2025-08-07T14:40:12+08:00","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://pillumina.github.io/posts/aiinfra/03-areal/"},"publisher":{"@type":"Organization","name":"CctoctoFX","logo":{"@type":"ImageObject","url":"https://pillumina.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://pillumina.github.io/ accesskey=h title="CctoctoFX (Alt + H)"><img src=https://pillumina.github.io/apple-touch-icon.png alt aria-label=logo height=30>CctoctoFX</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://pillumina.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://pillumina.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://pillumina.github.io/posts/aiinfra/ title="AI Infra"><span>AI Infra</span></a></li><li><a href=https://pillumina.github.io/posts/llmtheory/ title=Thoery><span>Thoery</span></a></li><li><a href=https://pillumina.github.io/posts/programming/ title=Programming><span>Programming</span></a></li><li><a href=https://pillumina.github.io/social/ title=Social><span>Social</span></a></li><li><a href=https://pillumina.github.io/open_courses/ title=Study><span>Study</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://pillumina.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://pillumina.github.io/posts/>Posts</a>&nbsp;»&nbsp;<a href=https://pillumina.github.io/posts/aiinfra/>AI Infra</a></div><h1 class="post-title entry-hint-parent">[RL4LLM] 异步RL框架: Areal</h1><div class=post-meta><span title='2025-08-07 14:40:12 +0800 CST'>August 7, 2025</span>&nbsp;·&nbsp;23 min&nbsp;·&nbsp;4872 words&nbsp;·&nbsp;Me</div></header><div class="toc side left"><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#异步ppo训练调用流程>异步PPO训练调用流程</a><ul><li><a href=#用户入口到配置解析>用户入口到配置解析</a></li><li><a href=#worker启动和初始化>Worker启动和初始化</a></li><li><a href=#训练端数据流>训练端数据流</a></li><li><a href=#rollout端数据流> Rollout端数据流</a></li><li><a href=#异步通信机制> 异步通信机制</a></li></ul></li><li><a href=#全局架构>全局架构</a><ul><li><a href=#部署形态>部署形态</a></li><li><a href=#训推资源分配>训推资源分配</a></li><li><a href=#分层关系>分层关系</a></li><li><a href=#全局类图>全局类图</a></li><li><a href=#核心模块类图>核心模块类图</a></li></ul></li><li><a href=#异步流程机制细节>异步流程机制细节</a><ul><li><a href=#异步完整流程图>异步完整流程图</a></li><li><a href=#异步带来的算法修正>异步带来的算法修正</a></li><li><a href=#权重同步机制>权重同步机制</a></li><li><a href=#数据陈旧性控制>数据陈旧性控制</a></li><li><a href=#数据传递机制>数据传递机制</a></li></ul></li></ul></nav></div></details></div><div class=post-content><blockquote><p><a href=https://github.com/inclusionAI/AReaL>https://github.com/inclusionAI/AReaL</a><br>纯异步RL方案</p></blockquote><h2 id=异步ppo训练调用流程>异步PPO训练调用流程<a hidden class=anchor aria-hidden=true href=#异步ppo训练调用流程>#</a></h2><pre class=mermaid>
  graph TD
    A[用户执行: examples/run_async_ppo.sh] --&gt; B[training/main_async_ppo.py]
    B --&gt; C[AsyncPPOMATHConfig配置解析]
    C --&gt; D[training/utils.py: run_experiment]
    
    D --&gt; E[Ray初始化]
    E --&gt; F[exp_cfg.initial_setup]
    F --&gt; G[AsyncRLExperimentConfig.initial_setup]
    G --&gt; H[创建ExperimentConfig]
    
    H --&gt; I[启动Workers]
    I --&gt; J[MasterWorker]
    I --&gt; K[ModelWorker]
    I --&gt; L[GenerationServer]
    I --&gt; M[GserverManager]
    I --&gt; N[RolloutWorker]
    
    %% MasterWorker训练流程
    J --&gt; J1[MasterWorker._poll_async]
    J1 --&gt; J2[FunctionExecutor.execute_step]
    J2 --&gt; J3[执行数据流图遍历]
    J3 --&gt; J4[发送训练请求到ModelWorker]
    
    %% ModelWorker处理流程
    K --&gt; K1[ModelWorker._poll]
    K1 --&gt; K2[接收MasterWorker请求]
    K2 --&gt; K3[处理训练/推理请求]
    K3 --&gt; K4[执行模型前向/反向传播]
    
    %% Rollout流程
    N --&gt; N1[RolloutWorker._poll_async]
    N1 --&gt; N2[load_next_data]
    N2 --&gt; N3[allocate_new_rollout]
    N3 --&gt; N4[agent.collect_trajectory]
    N4 --&gt; N5[env.step计算奖励]
    N5 --&gt; N6[推送数据到训练端]
    
    %% 生成服务器流程
    L --&gt; L1[GenerationServer._poll]
    L1 --&gt; L2[启动SGLang子进程]
    L2 --&gt; L3[处理生成请求]
    
    %% 生成服务器管理器
    M --&gt; M1[GserverManager._poll]
    M1 --&gt; M2[HTTP服务线程]
    M2 --&gt; M3[请求调度和权重更新]
    
    %% 数据流
    N6 --&gt; O[stream_dataset.py]
    O --&gt; J4
    
    %% 异步通信
    J4 -.-&gt;|异步请求| K2
    N3 -.-&gt;|HTTP请求| M2
    M2 -.-&gt;|调度请求| L3
    
    %% 权重更新
    K4 --&gt; P[参数更新]
    P --&gt; Q[权重同步]
    Q --&gt; M3
    M3 --&gt; R[更新生成服务器权重]
    
    style A fill:#e1f5fe
    style J fill:#f3e5f5
    style K fill:#e8f5e8
    style L fill:#fff3e0
    style M fill:#fce4ec
    style N fill:#f1f8e9
</pre><h3 id=用户入口到配置解析>用户入口到配置解析<a hidden class=anchor aria-hidden=true href=#用户入口到配置解析>#</a></h3><ul><li><p><code>examples/run_async_ppo.sh</code> → <code>training/main_async_ppo.py</code></p></li><li><p>通过Hydra解析CLI参数为<code>AsyncPPOMATHConfig</code></p></li><li><p>调用<code>initial_setup()</code>生成<code>ExperimentConfig</code></p></li></ul><h3 id=worker启动和初始化>Worker启动和初始化<a hidden class=anchor aria-hidden=true href=#worker启动和初始化>#</a></h3><ul><li><p><code>training/utils.py:run_experiment()</code>启动Ray集群</p></li><li><p>根据<code>scheduling_setup()</code>创建各类Worker</p></li><li><p>每个Worker执行<code>_configure()</code>和<code>_poll()/_poll_async()</code></p></li></ul><h3 id=训练端数据流>训练端数据流<a hidden class=anchor aria-hidden=true href=#训练端数据流>#</a></h3><ul><li><p><code>MasterWorker._poll_async()</code> → <code>FunctionExecutor.execute_step()</code></p></li><li><p>通过<code>request_reply_stream</code>发送请求到ModelWorker</p></li><li><p>ModelWorker处理训练/推理请求，执行模型计算</p></li></ul><h3 id=rollout端数据流> Rollout端数据流<a hidden class=anchor aria-hidden=true href=#rollout端数据流>#</a></h3><ul><li><p><code>RolloutWorker._poll_async()</code> → <code>agent.collect_trajectory()</code></p></li><li><p>通过<code>GserverManager</code>调度生成请求到<code>GenerationServer</code></p></li><li><p>通过<code>stream_dataset.py</code>推送轨迹数据到训练端</p></li></ul><h3 id=异步通信机制> 异步通信机制<a hidden class=anchor aria-hidden=true href=#异步通信机制>#</a></h3><ul><li><p>训练端和Rollout端通过TCP Socket通信</p></li><li><p><code>GserverManager</code>提供HTTP API进行请求调度</p></li><li><p>权重更新通过文件系统同步</p></li></ul><h2 id=全局架构>全局架构<a hidden class=anchor aria-hidden=true href=#全局架构>#</a></h2><h3 id=部署形态>部署形态<a hidden class=anchor aria-hidden=true href=#部署形态>#</a></h3><ul><li>进程部署架构</li></ul><blockquote><p>以单机8卡为例</p></blockquote><p><code>MasterWorker</code>：1个CPU进程，协调训练流程<br><code>ModelWorker</code>：6个GPU进程（GPU0-5），执行模型训练<br><code>GenerationServer</code>：2个GPU进程（GPU6-7），运行SGLang推理服务<br><code>GserverManager</code>：1个CPU进程，管理生成服务器<br><code>RolloutWorker</code>：多个CPU进程，执行智能体逻辑</p><h3 id=训推资源分配>训推资源分配<a hidden class=anchor aria-hidden=true href=#训推资源分配>#</a></h3><blockquote><p>框架支持<strong>分离部署</strong>和<strong>共享部署</strong>两种模式</p></blockquote><h4 id=分离部署>分离部署<a hidden class=anchor aria-hidden=true href=#分离部署>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>┌─────────────────────────────────────────────────────────────┐
</span></span><span class=line><span class=cl>│                    Ray Cluster <span class=o>(</span><span class=m>1</span> Node, <span class=m>8</span> GPUs<span class=o>)</span>             │
</span></span><span class=line><span class=cl>├─────────────────────────────────────────────────────────────┤
</span></span><span class=line><span class=cl>│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐         │
</span></span><span class=line><span class=cl>│  │MasterWorker │  │ModelWorker  │  │ModelWorker  │         │
</span></span><span class=line><span class=cl>│  │   <span class=o>(</span>CPU<span class=o>)</span>     │  │   <span class=o>(</span>GPU0<span class=o>)</span>    │  │   <span class=o>(</span>GPU1<span class=o>)</span>    │         │
</span></span><span class=line><span class=cl>│  └─────────────┘  └─────────────┘  └─────────────┘         │
</span></span><span class=line><span class=cl>│                                                             │
</span></span><span class=line><span class=cl>│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐         │
</span></span><span class=line><span class=cl>│  │ModelWorker  │  │ModelWorker  │  │ModelWorker  │         │
</span></span><span class=line><span class=cl>│  │   <span class=o>(</span>GPU2<span class=o>)</span>    │  │   <span class=o>(</span>GPU3<span class=o>)</span>    │  │   <span class=o>(</span>GPU4<span class=o>)</span>    │         │
</span></span><span class=line><span class=cl>│  └─────────────┘  └─────────────┘  └─────────────┘         │
</span></span><span class=line><span class=cl>│                                                             │
</span></span><span class=line><span class=cl>│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐         │
</span></span><span class=line><span class=cl>│  │ModelWorker  │  │GServerMgr   │  │RolloutWorker│         │
</span></span><span class=line><span class=cl>│  │   <span class=o>(</span>GPU5<span class=o>)</span>    │  │   <span class=o>(</span>CPU<span class=o>)</span>     │  │   <span class=o>(</span>CPU<span class=o>)</span>     │         │
</span></span><span class=line><span class=cl>│  └─────────────┘  └─────────────┘  └─────────────┘         │
</span></span><span class=line><span class=cl>│                                                             │
</span></span><span class=line><span class=cl>│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐         │
</span></span><span class=line><span class=cl>│  │GenServer    │  │GenServer    │  │RolloutWorker│         │
</span></span><span class=line><span class=cl>│  │ <span class=o>(</span>SGLang<span class=o>)</span>    │  │ <span class=o>(</span>SGLang<span class=o>)</span>    │  │   <span class=o>(</span>CPU<span class=o>)</span>     │         │
</span></span><span class=line><span class=cl>│  │   <span class=o>(</span>GPU6<span class=o>)</span>    │  │   <span class=o>(</span>GPU7<span class=o>)</span>    │  └─────────────┘         │
</span></span><span class=line><span class=cl>│  └─────────────┘  └─────────────┘                          │
</span></span><span class=line><span class=cl>└─────────────────────────────────────────────────────────────┘
</span></span></code></pre></td></tr></table></div></div><ul><li><p>训练端：使用4个GPU（d2p2m1 = 2×2×1）</p></li><li><p>推理端：使用4个GPU（d4p1m1 = 4×1×1）</p></li><li><p>优势：完全解耦，互不干扰，性能最优</p></li></ul><h3 id=分层关系>分层关系<a hidden class=anchor aria-hidden=true href=#分层关系>#</a></h3><pre class=mermaid>
  graph TB
    subgraph &#34;用户层&#34;
        A[examples/run_async_ppo.sh]
        B[training/main_async_ppo.py]
    end
    
    subgraph &#34;配置层&#34;
        C[AsyncPPOMATHConfig]
        D[ExperimentConfig]
        E[WorkerConfigs]
    end
    
    subgraph &#34;系统层&#34;
        F[Ray集群管理]
        G[Name Resolution]
        H[日志系统]
    end
    
    subgraph &#34;训练端 Workers&#34;
        I[MasterWorker]
        J[ModelWorker]
        K[FunctionExecutor]
    end
    
    subgraph &#34;Rollout端 Workers&#34;
        L[RolloutWorker]
        M[GenerationServer]
        N[GserverManager]
        O[PartialRolloutManager]
    end
    
    subgraph &#34;核心组件&#34;
        P[Agent接口]
        Q[Environment接口]
        R[Model接口]
        S[Dataset接口]
    end
    
    subgraph &#34;通信层&#34;
        T[Request-Reply Stream]
        U[Push-Pull Stream]
        V[HTTP API]
        W[TCP Socket]
    end
    
    subgraph &#34;模型层&#34;
        X[SGLang Backend]
        Y[PyTorch Backend]
        Z[模型并行]
    end
    
    %% 连接关系
    A --&gt; B
    B --&gt; C
    C --&gt; D
    D --&gt; E
    
    E --&gt; F
    F --&gt; G
    F --&gt; H
    
    E --&gt; I
    E --&gt; J
    E --&gt; L
    E --&gt; M
    E --&gt; N
    
    I --&gt; K
    K --&gt; T
    J --&gt; T
    
    L --&gt; O
    O --&gt; V
    M --&gt; V
    N --&gt; V
    
    L --&gt; P
    L --&gt; Q
    J --&gt; R
    I --&gt; S
    
    T --&gt; W
    U --&gt; W
    V --&gt; W
    
    J --&gt; Y
    M --&gt; X
    Y --&gt; Z
    X --&gt; Z
    
    style A fill:#e3f2fd
    style I fill:#f3e5f5
    style L fill:#e8f5e8
    style T fill:#fff3e0
    style X fill:#fce4ec
</pre><h3 id=全局类图>全局类图<a hidden class=anchor aria-hidden=true href=#全局类图>#</a></h3><pre class=mermaid>
  classDiagram
    %% 基类层
    class AsyncWorker {
        &lt;&lt;abstract&gt;&gt;
        +_configure(config)
        +_poll_async() PollResult
        +run_async()
    }
    
    class Worker {
        &lt;&lt;abstract&gt;&gt;
        +_configure(config)
        +_poll() PollResult
        +run()
    }
    
    %% Worker实现层 - 训练端
    class MasterWorker {
        -config: MasterWorkerConfig
        -func_executor: FunctionExecutor
        -__poll_async()
        -__lazy_init()
    }
    
    class ModelWorker {
        -config: ModelWorkerConfig
        -__request_queue: Queue
        -_poll()
        -handle_request()
    }
    
    %% Worker实现层 - Rollout端
    class RolloutWorker {
        -config: RolloutWorkerConfig
        -agent: Agent
        -env: Environment
        -_poll_async()
        -rollout_task()
    }
    
    class GenerationServer {
        -config: GenerationServerConfig
        -server_process: Process
        -_poll()
        -launch_server_subprocess()
    }
    
    class GserverManager {
        -config: GserverManagerConfig
        -server_urls: List[str]
        -_poll()
        -_schedule_request()
    }
    
    %% 接口层
    class Agent {
        &lt;&lt;interface&gt;&gt;
        +collect_trajectory(prompt, env, obs_queue, act_queue)
    }
    
    class Environment {
        &lt;&lt;interface&gt;&gt;
        +reset()
        +step(action)
    }
    
    class ModelInterface {
        &lt;&lt;interface&gt;&gt;
        +inference(model, data, mb_spec)
        +generate(model, data, mb_spec)
        +train_step(model, data, mb_spec)
    }
    
    %% 配置层
    class AsyncPPOMATHConfig {
        +agent: AgentAbstraction
        +env: EnvServiceAbstraction
        +initial_setup() ExperimentConfig
        +scheduling_setup() ExperimentScheduling
    }
    
    class ExperimentConfig {
        +model_rpcs: List[ModelRPC]
        +model_worker: ModelWorkerConfig
        +generation_server: GenerationServerConfig
        +rollout_worker: RolloutWorkerConfig
    }
    
    %% 继承关系 - 垂直排列减少交叉
    AsyncWorker &lt;|-- MasterWorker
    AsyncWorker &lt;|-- RolloutWorker
    Worker &lt;|-- ModelWorker
    Worker &lt;|-- GenerationServer
    Worker &lt;|-- GserverManager
    
    %% 组合关系 - 水平连接
    MasterWorker --&gt; ModelInterface : uses
    RolloutWorker --&gt; Agent : uses
    RolloutWorker --&gt; Environment : uses
    ModelWorker --&gt; ModelInterface : implements
    
    %% 配置关系 - 底部连接
    AsyncPPOMATHConfig --&gt; ExperimentConfig : creates
    ExperimentConfig --&gt; MasterWorker : configures
    ExperimentConfig --&gt; ModelWorker : configures
    ExperimentConfig --&gt; RolloutWorker : configures
    ExperimentConfig --&gt; GenerationServer : configures
    ExperimentConfig --&gt; GserverManager : configures
</pre><h3 id=核心模块类图>核心模块类图<a hidden class=anchor aria-hidden=true href=#核心模块类图>#</a></h3><pre class=mermaid>
  classDiagram
    %% 基类
    class AsyncWorker {
        &lt;&lt;abstract&gt;&gt;
        +_poll_async() PollResult
    }
    
    class Worker {
        &lt;&lt;abstract&gt;&gt;
        +_poll() PollResult
    }
    
    %% 训练端Workers
    class MasterWorker {
        -func_executor: FunctionExecutor
        -__poll_async()
    }
    
    class ModelWorker {
        -__request_queue: Queue
        -_poll()
    }
    
    %% Rollout端Workers
    class RolloutWorker {
        -agent: Agent
        -env: Environment
        -_poll_async()
    }
    
    class GenerationServer {
        -server_process: Process
        -_poll()
    }
    
    class GserverManager {
        -server_urls: List[str]
        -_poll()
    }
    
    %% 核心接口
    class Agent {
        &lt;&lt;interface&gt;&gt;
        +collect_trajectory()
    }
    
    class Environment {
        &lt;&lt;interface&gt;&gt;
        +step(action)
    }
    
    class ModelInterface {
        &lt;&lt;interface&gt;&gt;
        +train_step()
        +generate()
    }
    
    %% 配置
    class AsyncPPOMATHConfig {
        +initial_setup()
        +scheduling_setup()
    }
    
    %% 继承关系
    AsyncWorker &lt;|-- MasterWorker
    AsyncWorker &lt;|-- RolloutWorker
    Worker &lt;|-- ModelWorker
    Worker &lt;|-- GenerationServer
    Worker &lt;|-- GserverManager
    
    %% 关键关系
    MasterWorker --&gt; ModelInterface
    RolloutWorker --&gt; Agent
    RolloutWorker --&gt; Environment
    ModelWorker --&gt; ModelInterface
    AsyncPPOMATHConfig --&gt; MasterWorker
    AsyncPPOMATHConfig --&gt; ModelWorker
    AsyncPPOMATHConfig --&gt; RolloutWorker
</pre><h2 id=异步流程机制细节>异步流程机制细节<a hidden class=anchor aria-hidden=true href=#异步流程机制细节>#</a></h2><h3 id=异步完整流程图>异步完整流程图<a hidden class=anchor aria-hidden=true href=#异步完整流程图>#</a></h3><pre class=mermaid>
  sequenceDiagram
    participant User as 用户
    participant MW as MasterWorker
    participant RW as RolloutWorker
    participant GS as GenerationServer
    participant GSM as GserverManager
    participant ZMQ as ZMQ Stream
    participant SD as StreamDataset
    participant MW2 as ModelWorker
    participant NR as NameResolving
    participant FS as 文件系统

    Note over User: 启动异步PPO训练
    User-&gt;&gt;User: examples/run_async_ppo.sh&lt;br/&gt;输入：GPU数量、并行策略、模型路径
    User-&gt;&gt;MW: training/main_async_ppo.py&lt;br/&gt;输入：AsyncPPOMATHConfig

    Note over MW: 初始化阶段
    MW-&gt;&gt;MW: run_experiment(config)&lt;br/&gt;输入：实验配置
    MW-&gt;&gt;MW: initial_setup()&lt;br/&gt;输入：worker配置
    MW-&gt;&gt;NR: 注册各Worker地址&lt;br/&gt;变量：worker_info, msid2mwid
    Note over MW: 设置版本差异控制参数&lt;br/&gt;变量：max_head_offpolicyness

    Note over RW,GS: Rollout端启动
    RW-&gt;&gt;RW: _configure(config)&lt;br/&gt;输入：RolloutWorkerConfig
    RW-&gt;&gt;ZMQ: 初始化NameResolvingZmqPusher&lt;br/&gt;变量：experiment_name, trial_name, worker_index
    GS-&gt;&gt;GS: _configure(config)&lt;br/&gt;输入：GenerationServerConfig
    GS-&gt;&gt;GS: 初始化SGLang后端&lt;br/&gt;变量：model_path, tokenizer_path
    GSM-&gt;&gt;GSM: _configure(config)&lt;br/&gt;输入：GserverManagerConfig
    GSM-&gt;&gt;GSM: 初始化权重版本跟踪&lt;br/&gt;变量：_last_param_realloc_step

    Note over MW2: 训练端启动
    MW2-&gt;&gt;MW2: _configure(config)&lt;br/&gt;输入：ModelWorkerConfig
    MW2-&gt;&gt;SD: 初始化PullerStreamDataset&lt;br/&gt;变量：dataset_size, pull_timeout_ms
    MW2-&gt;&gt;MW2: 初始化模型和优化器&lt;br/&gt;变量：model_config, optimizer_config

    Note over MW: 训练循环开始
    MW-&gt;&gt;MW: __poll_async()&lt;br/&gt;输入：训练控制参数
    MW-&gt;&gt;MW: func_executor.execute_step()&lt;br/&gt;输入：数据流图

    Note over RW,GS: 并行生成轨迹
    loop 持续生成轨迹
        RW-&gt;&gt;GS: 发送生成请求&lt;br/&gt;输入：prompt, max_tokens
        Note over GS: 使用当前加载的权重版本&lt;br/&gt;变量：current_model_version
        GS-&gt;&gt;GS: SGLang生成&lt;br/&gt;输入：模型权重、生成参数
        GS--&gt;&gt;RW: 返回生成结果&lt;br/&gt;输出：generated_text
        RW-&gt;&gt;RW: agent.collect_trajectory()&lt;br/&gt;输入：生成结果
        RW-&gt;&gt;RW: 计算奖励、构建轨迹&lt;br/&gt;变量：trajectory, reward
        Note over RW: 为轨迹添加版本信息&lt;br/&gt;变量：trajectory.model_version = current_model_version
        RW-&gt;&gt;ZMQ: push_stream.push(traj)&lt;br/&gt;输入：轨迹数据(JSON格式)
    end

    Note over ZMQ,SD: 数据传递
    ZMQ-&gt;&gt;SD: 接收轨迹数据&lt;br/&gt;输入：JSON序列化数据
    SD-&gt;&gt;SD: _pull_data_worker()&lt;br/&gt;后台线程持续拉取
    SD-&gt;&gt;SD: 转换为SequenceSample&lt;br/&gt;变量：data_queue, processed_data

    Note over MW2: 训练执行 - 版本差异控制
    MW2-&gt;&gt;SD: 获取训练数据&lt;br/&gt;输入：batch_size
    SD--&gt;&gt;MW2: 返回SequenceSample&lt;br/&gt;输出：训练样本
    Note over MW2: 检查数据版本差异&lt;br/&gt;变量：data_version, current_version, max_head_offpolicyness
    MW2-&gt;&gt;MW2: validate_data_version(data_version, current_version)&lt;br/&gt;输入：数据版本、当前版本、最大允许差异
    alt 版本差异在允许范围内
        Note over MW2: 接受数据，继续训练&lt;br/&gt;变量：version_diff &lt;= max_head_offpolicyness
        MW2-&gt;&gt;MW2: train_step(data)&lt;br/&gt;输入：训练数据、优化器状态
        MW2-&gt;&gt;MW2: 计算PPO损失&lt;br/&gt;变量：policy_loss, value_loss, entropy_loss
        MW2-&gt;&gt;MW2: 更新模型参数&lt;br/&gt;变量：optimizer.step(), global_step
    else 版本差异过大
        Note over MW2: 丢弃过期数据&lt;br/&gt;变量：version_diff &gt; max_head_offpolicyness
        MW2-&gt;&gt;MW2: discard_stale_data(data)&lt;br/&gt;输入：过期数据
        Note over MW2: 记录数据丢弃统计&lt;br/&gt;变量：stale_data_count++
        MW2-&gt;&gt;SD: 请求新的训练数据&lt;br/&gt;输入：batch_size
    end

    Note over MW2,FS: 权重同步 - 版本控制
    MW2-&gt;&gt;FS: __save_model(save_meta)&lt;br/&gt;输入：model, save_dir, global_step
    Note over FS: 保存权重分片到磁盘&lt;br/&gt;变量：param_realloc_path/model_name/step/
    MW2-&gt;&gt;NR: name_resolve.add(model_version, global_step)&lt;br/&gt;输入：experiment, trial, model_name, step
    Note over NR: 原子性更新版本号&lt;br/&gt;变量：model_version = global_step

    Note over GSM,GS: 推理端权重更新 - 数据陈旧性控制
    loop 定期检查新权重
        GSM-&gt;&gt;NR: check_new_params()&lt;br/&gt;输入：experiment, trial, model_name
        NR--&gt;&gt;GSM: 返回最新global_step
        alt 有新权重版本
            GSM-&gt;&gt;GSM: 发现版本更新&lt;br/&gt;变量：realloc_version &gt; _last_param_realloc_step
            GSM-&gt;&gt;GS: flush_requests_and_update_weights(load_dir)&lt;br/&gt;输入：新权重路径
            Note over GS: 中断当前所有推理请求&lt;br/&gt;变量：_interrupt_requests()
            GS-&gt;&gt;FS: 读取新权重文件&lt;br/&gt;输入：load_dir
            GS-&gt;&gt;GS: update_weights_from_disk(load_dir)&lt;br/&gt;变量：分片rank, 权重文件
            Note over GS: 按TP/PP分片加载权重&lt;br/&gt;变量：新model_version生效
            GS--&gt;&gt;GSM: 权重更新完成
            GSM-&gt;&gt;GSM: 更新版本跟踪&lt;br/&gt;变量：_last_param_realloc_step = realloc_version
            Note over GS: 恢复推理服务&lt;br/&gt;变量：使用新权重版本
        else 无新权重
            GSM-&gt;&gt;GSM: 继续使用当前权重&lt;br/&gt;变量：_last_param_realloc_step
        end
    end

    Note over MW: 训练控制 - 版本差异监控
    MW-&gt;&gt;MW: 检查训练终止条件&lt;br/&gt;输入：epoch, global_step, loss
    MW-&gt;&gt;MW: 监控版本差异统计&lt;br/&gt;变量：stale_data_count, version_diff_stats
    Note over MW: 记录版本差异对训练的影响&lt;br/&gt;变量：training_efficiency, data_freshness
    alt 继续训练
        MW-&gt;&gt;MW: 更新训练状态&lt;br/&gt;变量：step_info, epoch_step
        Note over MW: 返回训练循环开始
    else 训练完成
        MW-&gt;&gt;User: 训练结束&lt;br/&gt;输出：最终模型、训练日志、版本差异统计
    end
</pre><h3 id=异步带来的算法修正>异步带来的算法修正<a hidden class=anchor aria-hidden=true href=#异步带来的算法修正>#</a></h3><h4 id=同步ppo完整流程>同步PPO完整流程<a hidden class=anchor aria-hidden=true href=#同步ppo完整流程>#</a></h4><p>先回顾一下ppo的计算流程：</p><blockquote><p>我们有一个策略π(a|s)，它决定在状态s下选择动作a的概率。PPO的目标是优化这个策略，使其能够获得更高的累积奖励。</p></blockquote><ul><li>数据收集（rollout）</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 使用当前策略π_θ生成轨迹</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>episode</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_episodes</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>state</span> <span class=o>=</span> <span class=n>env</span><span class=o>.</span><span class=n>reset</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>trajectory</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>while</span> <span class=ow>not</span> <span class=n>done</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># 使用当前策略选择动作</span>
</span></span><span class=line><span class=cl>        <span class=n>action_probs</span> <span class=o>=</span> <span class=n>π_θ</span><span class=p>(</span><span class=n>state</span><span class=p>)</span>  <span class=c1># 当前策略的概率分布</span>
</span></span><span class=line><span class=cl>        <span class=n>action</span> <span class=o>=</span> <span class=n>sample</span><span class=p>(</span><span class=n>action_probs</span><span class=p>)</span>  <span class=c1># 采样动作</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 记录动作概率（用于后续计算重要性比率）</span>
</span></span><span class=line><span class=cl>        <span class=n>old_logp</span> <span class=o>=</span> <span class=n>log</span><span class=p>(</span><span class=n>action_probs</span><span class=p>[</span><span class=n>action</span><span class=p>])</span>  <span class=c1># 这就是old_logp</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 执行动作</span>
</span></span><span class=line><span class=cl>        <span class=n>next_state</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>done</span> <span class=o>=</span> <span class=n>env</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>action</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>trajectory</span><span class=o>.</span><span class=n>append</span><span class=p>((</span><span class=n>state</span><span class=p>,</span> <span class=n>action</span><span class=p>,</span> <span class=n>reward</span><span class=p>,</span> <span class=n>old_logp</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>state</span> <span class=o>=</span> <span class=n>next_state</span>
</span></span></code></pre></td></tr></table></div></div><ul><li>计算优势函数</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 使用GAE计算优势函数</span>
</span></span><span class=line><span class=cl><span class=n>advantages</span> <span class=o>=</span> <span class=n>compute_gae</span><span class=p>(</span><span class=n>trajectory</span><span class=p>,</span> <span class=n>γ</span><span class=o>=</span><span class=mf>0.99</span><span class=p>,</span> <span class=n>λ</span><span class=o>=</span><span class=mf>0.95</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>returns</span> <span class=o>=</span> <span class=n>compute_returns</span><span class=p>(</span><span class=n>trajectory</span><span class=p>,</span> <span class=n>γ</span><span class=o>=</span><span class=mf>0.99</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><ul><li>策略更新</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 对收集的数据进行多次更新</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>batch</span> <span class=ow>in</span> <span class=n>data_loader</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># 重新计算当前策略的概率</span>
</span></span><span class=line><span class=cl>        <span class=n>current_action_probs</span> <span class=o>=</span> <span class=n>π_θ</span><span class=p>(</span><span class=n>batch</span><span class=o>.</span><span class=n>states</span><span class=p>)</span>  <span class=c1># 当前策略</span>
</span></span><span class=line><span class=cl>        <span class=n>cur_logp</span> <span class=o>=</span> <span class=n>log</span><span class=p>(</span><span class=n>current_action_probs</span><span class=p>[</span><span class=n>batch</span><span class=o>.</span><span class=n>actions</span><span class=p>])</span>  <span class=c1># 这就是cur_logp</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 计算重要性比率</span>
</span></span><span class=line><span class=cl>        <span class=n>ratio</span> <span class=o>=</span> <span class=n>exp</span><span class=p>(</span><span class=n>cur_logp</span> <span class=o>-</span> <span class=n>old_logp</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># PPO损失函数</span>
</span></span><span class=line><span class=cl>        <span class=n>surr1</span> <span class=o>=</span> <span class=n>ratio</span> <span class=o>*</span> <span class=n>advantages</span>
</span></span><span class=line><span class=cl>        <span class=n>surr2</span> <span class=o>=</span> <span class=n>clip</span><span class=p>(</span><span class=n>ratio</span><span class=p>,</span> <span class=mi>1</span><span class=o>-</span><span class=n>ε</span><span class=p>,</span> <span class=mi>1</span><span class=o>+</span><span class=n>ε</span><span class=p>)</span> <span class=o>*</span> <span class=n>advantages</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span> <span class=o>=</span> <span class=o>-</span><span class=nb>min</span><span class=p>(</span><span class=n>surr1</span><span class=p>,</span> <span class=n>surr2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 更新策略参数</span>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><blockquote><p>为什么需要重要性采样 ratio = π_θ(a|s) / π_θ_old(a|s) = exp(cur_logp - old_logp)</p><ol><li>我们想用当前策略π_θ来评估旧策略π_θ_old生成的数据</li><li>重要性采样修正了这种分布偏移</li></ol></blockquote><h4 id=框架的异步ppo修正机制>框架的异步PPO修正机制<a hidden class=anchor aria-hidden=true href=#框架的异步ppo修正机制>#</a></h4><ul><li>异步带来的问题，数据生成和训练并行</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 时间线</span>
</span></span><span class=line><span class=cl><span class=n>t</span><span class=o>=</span><span class=mi>0</span><span class=p>:</span> <span class=n>策略π_θ_0生成数据</span>
</span></span><span class=line><span class=cl><span class=n>t</span><span class=o>=</span><span class=mi>1</span><span class=p>:</span> <span class=n>策略π_θ_1生成数据</span><span class=err>，</span><span class=n>同时训练π_θ_0的数据</span>
</span></span><span class=line><span class=cl><span class=n>t</span><span class=o>=</span><span class=mi>2</span><span class=p>:</span> <span class=n>策略π_θ_2生成数据</span><span class=err>，</span><span class=n>同时训练π_θ_1的数据</span>
</span></span><span class=line><span class=cl><span class=o>...</span>
</span></span></code></pre></td></tr></table></div></div><p>这导致：</p><ul><li><p>训练数据来自较旧的策略版本</p></li><li><p>重要性比率可能变得很大或很小</p></li><li><p>策略更新可能不稳定</p></li></ul><blockquote><p>框架引入的修正机制如下：</p></blockquote><p><strong>机制1： 版本控制</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 记录数据生成时的策略版本</span>
</span></span><span class=line><span class=cl><span class=n>data</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;version_start&#34;</span><span class=p>:</span> <span class=n>model_version_when_generation_started</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;version_end&#34;</span><span class=p>:</span> <span class=n>model_version_when_generation_ended</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;old_logp&#34;</span><span class=p>:</span> <span class=n>logprobs_from_generation</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;actions&#34;</span><span class=p>:</span> <span class=n>actions</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;rewards&#34;</span><span class=p>:</span> <span class=n>rewards</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>机制2：数据过滤</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 检查版本差异</span>
</span></span><span class=line><span class=cl><span class=n>version_diff</span> <span class=o>=</span> <span class=n>current_version</span> <span class=o>-</span> <span class=n>data</span><span class=o>.</span><span class=n>version_start</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=n>version_diff</span> <span class=o>&gt;</span> <span class=n>max_head_offpolicyness</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># 数据太旧，丢弃</span>
</span></span><span class=line><span class=cl>    <span class=k>continue</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>机制3：解耦损失（Decoupled Loss）</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 标准PPO损失</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>standard_ppo_loss</span><span class=p>(</span><span class=n>cur_logp</span><span class=p>,</span> <span class=n>old_logp</span><span class=p>,</span> <span class=n>advantages</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>ratio</span> <span class=o>=</span> <span class=n>exp</span><span class=p>(</span><span class=n>cur_logp</span> <span class=o>-</span> <span class=n>old_logp</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=o>-</span><span class=nb>min</span><span class=p>(</span><span class=n>ratio</span> <span class=o>*</span> <span class=n>advantages</span><span class=p>,</span> <span class=n>clip</span><span class=p>(</span><span class=n>ratio</span><span class=p>,</span> <span class=mi>1</span><span class=o>-</span><span class=n>ε</span><span class=p>,</span> <span class=mi>1</span><span class=o>+</span><span class=n>ε</span><span class=p>)</span> <span class=o>*</span> <span class=n>advantages</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># AReaL解耦损失</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>decoupled_loss</span><span class=p>(</span><span class=n>cur_logp</span><span class=p>,</span> <span class=n>old_logp</span><span class=p>,</span> <span class=n>prox_logp</span><span class=p>,</span> <span class=n>advantages</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># 使用prox_logp作为中间策略</span>
</span></span><span class=line><span class=cl>    <span class=n>ratio</span> <span class=o>=</span> <span class=n>exp</span><span class=p>(</span><span class=n>cur_logp</span> <span class=o>-</span> <span class=n>prox_logp</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>behav_weight</span> <span class=o>=</span> <span class=n>exp</span><span class=p>(</span><span class=n>prox_logp</span> <span class=o>-</span> <span class=n>old_logp</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=o>-</span><span class=nb>min</span><span class=p>(</span><span class=n>ratio</span> <span class=o>*</span> <span class=n>advantages</span><span class=p>,</span> <span class=n>clip</span><span class=p>(</span><span class=n>ratio</span><span class=p>,</span> <span class=mi>1</span><span class=o>-</span><span class=n>ε</span><span class=p>,</span> <span class=mi>1</span><span class=o>+</span><span class=n>ε</span><span class=p>)</span> <span class=o>*</span> <span class=n>advantages</span><span class=p>)</span> <span class=o>*</span> <span class=n>behav_weight</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=修正的合理性分析>修正的合理性分析<a hidden class=anchor aria-hidden=true href=#修正的合理性分析>#</a></h4><p><strong>数学基础</strong><br>解耦损失可以分解为:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 标准PPO</span>
</span></span><span class=line><span class=cl><span class=n>ratio</span> <span class=o>=</span> <span class=n>π_θ</span><span class=p>(</span><span class=n>a</span><span class=o>|</span><span class=n>s</span><span class=p>)</span> <span class=o>/</span> <span class=n>π_θ_old</span><span class=p>(</span><span class=n>a</span><span class=o>|</span><span class=n>s</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># AReaL解耦</span>
</span></span><span class=line><span class=cl><span class=n>ratio</span> <span class=o>=</span> <span class=n>π_θ</span><span class=p>(</span><span class=n>a</span><span class=o>|</span><span class=n>s</span><span class=p>)</span> <span class=o>/</span> <span class=n>π_prox</span><span class=p>(</span><span class=n>a</span><span class=o>|</span><span class=n>s</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>behav_weight</span> <span class=o>=</span> <span class=n>π_prox</span><span class=p>(</span><span class=n>a</span><span class=o>|</span><span class=n>s</span><span class=p>)</span> <span class=o>/</span> <span class=n>π_θ_old</span><span class=p>(</span><span class=n>a</span><span class=o>|</span><span class=n>s</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 等价性</span>
</span></span><span class=line><span class=cl><span class=n>ratio</span> <span class=o>*</span> <span class=n>behav_weight</span> <span class=o>=</span> <span class=n>π_θ</span><span class=p>(</span><span class=n>a</span><span class=o>|</span><span class=n>s</span><span class=p>)</span> <span class=o>/</span> <span class=n>π_θ_old</span><span class=p>(</span><span class=n>a</span><span class=o>|</span><span class=n>s</span><span class=p>)</span>  <span class=c1># 与标准PPO相同</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>稳定性提升</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 异步场景下的问题</span>
</span></span><span class=line><span class=cl><span class=c1># 如果π_θ与π_θ_old差异很大</span>
</span></span><span class=line><span class=cl><span class=n>ratio</span> <span class=o>=</span> <span class=n>π_θ</span><span class=p>(</span><span class=n>a</span><span class=o>|</span><span class=n>s</span><span class=p>)</span> <span class=o>/</span> <span class=n>π_θ_old</span><span class=p>(</span><span class=n>a</span><span class=o>|</span><span class=n>s</span><span class=p>)</span>  <span class=c1># 可能很大或很小</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># AReaL的解决方案</span>
</span></span><span class=line><span class=cl><span class=c1># 引入中间策略π_prox，使得：</span>
</span></span><span class=line><span class=cl><span class=c1># π_θ ≈ π_prox ≈ π_θ_old</span>
</span></span><span class=line><span class=cl><span class=n>ratio</span> <span class=o>=</span> <span class=n>π_θ</span><span class=p>(</span><span class=n>a</span><span class=o>|</span><span class=n>s</span><span class=p>)</span> <span class=o>/</span> <span class=n>π_prox</span><span class=p>(</span><span class=n>a</span><span class=o>|</span><span class=n>s</span><span class=p>)</span>  <span class=c1># 更稳定</span>
</span></span><span class=line><span class=cl><span class=n>behav_weight</span> <span class=o>=</span> <span class=n>π_prox</span><span class=p>(</span><span class=n>a</span><span class=o>|</span><span class=n>s</span><span class=p>)</span> <span class=o>/</span> <span class=n>π_θ_old</span><span class=p>(</span><span class=n>a</span><span class=o>|</span><span class=n>s</span><span class=p>)</span>  <span class=c1># 更稳定</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>渐进式更新</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 标准异步PPO：直接从π_θ_old跳到π_θ</span>
</span></span><span class=line><span class=cl><span class=c1># AReaL：π_θ_old → π_prox → π_θ，分两步更新</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=具体实现>具体实现<a hidden class=anchor aria-hidden=true href=#具体实现>#</a></h4><p><strong>核心修正机制实现</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># AReaL的解耦损失实现</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=n>proximal_logprobs</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># 计算行为策略权重</span>
</span></span><span class=line><span class=cl>    <span class=n>behav_kl</span> <span class=o>=</span> <span class=n>proximal_logprobs</span> <span class=o>-</span> <span class=n>old_logprobs</span>
</span></span><span class=line><span class=cl>    <span class=n>behav_imp_weight</span> <span class=o>=</span> <span class=n>behav_kl</span><span class=o>.</span><span class=n>exp</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 应用权重上限</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>behav_imp_weight_cap</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>behav_mask</span> <span class=o>=</span> <span class=p>(</span><span class=n>behav_imp_weight</span> <span class=o>&lt;=</span> <span class=n>behav_imp_weight_cap</span><span class=p>)</span><span class=o>.</span><span class=n>logical_and</span><span class=p>(</span><span class=n>loss_mask</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>behav_mask</span> <span class=o>=</span> <span class=n>loss_mask</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 应用行为策略权重</span>
</span></span><span class=line><span class=cl>    <span class=n>pg_loss</span> <span class=o>=</span> <span class=n>pg_loss</span> <span class=o>*</span> <span class=n>behav_imp_weight</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>数学等价性证明</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 标准PPO损失</span>
</span></span><span class=line><span class=cl><span class=n>L_standard</span> <span class=o>=</span> <span class=o>-</span><span class=nb>min</span><span class=p>(</span><span class=n>ratio</span> <span class=o>*</span> <span class=n>A</span><span class=p>,</span> <span class=n>clip</span><span class=p>(</span><span class=n>ratio</span><span class=p>,</span> <span class=mi>1</span><span class=o>-</span><span class=n>ε</span><span class=p>,</span> <span class=mi>1</span><span class=o>+</span><span class=n>ε</span><span class=p>)</span> <span class=o>*</span> <span class=n>A</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>其中</span> <span class=n>ratio</span> <span class=o>=</span> <span class=n>π_θ</span><span class=p>(</span><span class=n>a</span><span class=o>|</span><span class=n>s</span><span class=p>)</span> <span class=o>/</span> <span class=n>π_θ_old</span><span class=p>(</span><span class=n>a</span><span class=o>|</span><span class=n>s</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># AReaL解耦损失</span>
</span></span><span class=line><span class=cl><span class=n>L_decoupled</span> <span class=o>=</span> <span class=o>-</span><span class=nb>min</span><span class=p>(</span><span class=n>ratio</span> <span class=o>*</span> <span class=n>A</span><span class=p>,</span> <span class=n>clip</span><span class=p>(</span><span class=n>ratio</span><span class=p>,</span> <span class=mi>1</span><span class=o>-</span><span class=n>ε</span><span class=p>,</span> <span class=mi>1</span><span class=o>+</span><span class=n>ε</span><span class=p>)</span> <span class=o>*</span> <span class=n>A</span><span class=p>)</span> <span class=o>*</span> <span class=n>behav_weight</span>
</span></span><span class=line><span class=cl><span class=n>其中</span> <span class=n>ratio</span> <span class=o>=</span> <span class=n>π_θ</span><span class=p>(</span><span class=n>a</span><span class=o>|</span><span class=n>s</span><span class=p>)</span> <span class=o>/</span> <span class=n>π_prox</span><span class=p>(</span><span class=n>a</span><span class=o>|</span><span class=n>s</span><span class=p>)</span>
</span></span><span class=line><span class=cl>     <span class=n>behav_weight</span> <span class=o>=</span> <span class=n>π_prox</span><span class=p>(</span><span class=n>a</span><span class=o>|</span><span class=n>s</span><span class=p>)</span> <span class=o>/</span> <span class=n>π_θ_old</span><span class=p>(</span><span class=n>a</span><span class=o>|</span><span class=n>s</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 等价性证明</span>
</span></span><span class=line><span class=cl><span class=n>L_decoupled</span> <span class=o>=</span> <span class=o>-</span><span class=nb>min</span><span class=p>(</span><span class=n>ratio</span> <span class=o>*</span> <span class=n>A</span><span class=p>,</span> <span class=n>clip</span><span class=p>(</span><span class=n>ratio</span><span class=p>,</span> <span class=mi>1</span><span class=o>-</span><span class=n>ε</span><span class=p>,</span> <span class=mi>1</span><span class=o>+</span><span class=n>ε</span><span class=p>)</span> <span class=o>*</span> <span class=n>A</span><span class=p>)</span> <span class=o>*</span> <span class=n>behav_weight</span>
</span></span><span class=line><span class=cl>           <span class=o>=</span> <span class=o>-</span><span class=nb>min</span><span class=p>((</span><span class=n>π_θ</span><span class=o>/</span><span class=n>π_prox</span><span class=p>)</span> <span class=o>*</span> <span class=n>A</span><span class=p>,</span> <span class=n>clip</span><span class=p>(</span><span class=n>π_θ</span><span class=o>/</span><span class=n>π_prox</span><span class=p>,</span> <span class=mi>1</span><span class=o>-</span><span class=n>ε</span><span class=p>,</span> <span class=mi>1</span><span class=o>+</span><span class=n>ε</span><span class=p>)</span> <span class=o>*</span> <span class=n>A</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=n>π_prox</span><span class=o>/</span><span class=n>π_θ_old</span><span class=p>)</span>
</span></span><span class=line><span class=cl>           <span class=o>=</span> <span class=o>-</span><span class=nb>min</span><span class=p>((</span><span class=n>π_θ</span><span class=o>/</span><span class=n>π_θ_old</span><span class=p>)</span> <span class=o>*</span> <span class=n>A</span><span class=p>,</span> <span class=n>clip</span><span class=p>(</span><span class=n>π_θ</span><span class=o>/</span><span class=n>π_prox</span><span class=p>,</span> <span class=mi>1</span><span class=o>-</span><span class=n>ε</span><span class=p>,</span> <span class=mi>1</span><span class=o>+</span><span class=n>ε</span><span class=p>)</span> <span class=o>*</span> <span class=n>A</span> <span class=o>*</span> <span class=p>(</span><span class=n>π_prox</span><span class=o>/</span><span class=n>π_θ_old</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=流程图视角>流程图视角<a hidden class=anchor aria-hidden=true href=#流程图视角>#</a></h4><pre class=mermaid>
  graph TD
    %% 生成阶段 - SGLang推理服务
    A[用户Prompt&lt;br/&gt;packed_prompts] --&gt; B[SGLang推理服务&lt;br/&gt;actor_gen]
    B --&gt; B1[PPOActorInterface.generate&lt;br/&gt;使用策略π_θ_old]
    B1 --&gt; B2[模型前向传播&lt;br/&gt;genstep函数]
    B2 --&gt; B3[采样token&lt;br/&gt;计算logprob]
    B3 --&gt; B4[concat_prompt_to_generation_output&lt;br/&gt;拼接prompt和生成结果]
    B4 --&gt; B5[输出: packed_input_ids&lt;br/&gt;packed_logprobs&lt;old_logp&gt;&lt;br/&gt;prompt_mask&lt;br/&gt;seq_no_eos_mask]
    
    %% 推理阶段 - 四个组件并行执行
    B5 --&gt; C[推理阶段开始]
    
    %% Actor推理 - 计算proximal_logp
    C --&gt; D[actor_inf&lt;br/&gt;PPOActorInterface.inference&lt;br/&gt;使用策略π_θ_prox]
    D --&gt; D1[输入: packed_input_ids]
    D1 --&gt; D2[calc_logprobs post_hook&lt;br/&gt;gather_packed_shifted_log_probs]
    D2 --&gt; D3[输出: proximal_logprobs&lt;br/&gt;π_θ_prox&lt;a,s&gt;]
    
    %% Reference推理 - 计算ref_logp
    C --&gt; E[ref_inf&lt;br/&gt;PPOActorInterface.inference&lt;br/&gt;使用策略π_ref]
    E --&gt; E1[输入: packed_input_ids]
    E1 --&gt; E2[calc_logprobs post_hook&lt;br/&gt;gather_packed_shifted_log_probs]
    E2 --&gt; E3[输出: packed_ref_logprobs&lt;br/&gt;π_ref&lt;a,s&gt;]
    
    %% Critic推理 - 计算values
    C --&gt; F[critic_inf&lt;br/&gt;PPOCriticInterface.inference&lt;br/&gt;使用价值网络V_θ]
    F --&gt; F1[输入: packed_input_ids&lt;br/&gt;seq_no_eos_mask]
    F1 --&gt; F2[module.forward&lt;br/&gt;直接输出value]
    F2 --&gt; F3[输出: values&lt;br/&gt;V_θ&lt;s&gt;]
    
    %% Reward推理 - 计算rewards
    C --&gt; G[rew_inf&lt;br/&gt;MultiTaskRewardInterface.inference&lt;br/&gt;使用奖励函数R]
    G --&gt; G1[输入: packed_input_ids&lt;br/&gt;packed_prompts&lt;br/&gt;task_ids]
    G1 --&gt; G2[calculate_task_reward&lt;br/&gt;异步任务处理]
    G2 --&gt; G3[输出: rewards&lt;br/&gt;R&lt;s,a&gt;]
    
    %% 数据汇聚
    D3 --&gt; H[推理结果汇聚]
    E3 --&gt; H
    F3 --&gt; H
    G3 --&gt; H
    
    %% 训练阶段准备
    H --&gt; I[训练数据准备&lt;br/&gt;packed_input_ids&lt;br/&gt;packed_logprobs&lt;old_logp&gt;&lt;br/&gt;packed_ref_logprobs&lt;br/&gt;proximal_logprobs&lt;br/&gt;rewards&lt;br/&gt;values&lt;br/&gt;prompt_mask&lt;br/&gt;seq_no_eos_mask]
    
    %% 训练阶段 - 计算current_logp和loss
    I --&gt; J[actor_train&lt;br/&gt;PPOActorInterface.train_step&lt;br/&gt;使用策略π_θ]
    J --&gt; J1[模型前向传播&lt;br/&gt;module.forward]
    J1 --&gt; J2[gather_packed_shifted_log_probs&lt;br/&gt;计算current_logp&lt;br/&gt;π_θ&lt;a,s&gt;]
    J2 --&gt; J3[计算advantages&lt;br/&gt;GAE算法]
    J3 --&gt; J4[计算rewards&lt;br/&gt;KL正则化]
    J4 --&gt; J5[PPO Loss计算&lt;br/&gt;_ppo_actor_loss_from_model_outputs]
    
    %% PPO Loss详细计算
    J5 --&gt; K[PPO Loss计算详情]
    K --&gt; K1[输入: current_logp, old_logp, proximal_logp&lt;br/&gt;advantages, rewards]
    K1 --&gt; K2{use_decoupled_loss?}
    K2 --&gt;|是| K3[解耦损失计算&lt;br/&gt;ratio = exp&lt;current_logp - proximal_logp&gt;&lt;br/&gt;behav_weight = exp&lt;proximal_logp - old_logp&gt;]
    K2 --&gt;|否| K4[标准损失计算&lt;br/&gt;ratio = exp&lt;current_logp - old_logp&gt;]
    K3 --&gt; K5[最终损失&lt;br/&gt;loss = -min ratio * advantages, clip ratio * advantages * behav_weight]
    K4 --&gt; K6[最终损失&lt;br/&gt;loss = -min ratio * advantages, clip ratio * advantages]
    K5 --&gt; L[输出: Actor Loss]
    K6 --&gt; L
    
    %% Critic训练
    J3 --&gt; M[critic_train&lt;br/&gt;PPOCriticInterface.train_step&lt;br/&gt;使用价值网络V_θ]
    M --&gt; M1[模型前向传播&lt;br/&gt;计算new_values]
    M1 --&gt; M2[Critic Loss计算&lt;br/&gt;_ppo_critic_loss_from_model_outputs]
    M2 --&gt; M3[输出: Critic Loss]
    
    %% 样式定义
    classDef generateStyle fill:#e3f2fd,stroke:#1565c0,stroke-width:2px
    classDef inferenceStyle fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef trainStyle fill:#e8f5e8,stroke:#2e7d32,stroke-width:2px
    classDef lossStyle fill:#fff3e0,stroke:#ef6c00,stroke-width:2px
    
    class B,B1,B2,B3,B4,B5 generateStyle
    class D,D1,D2,D3,E,E1,E2,E3,F,F1,F2,F3,G,G1,G2,G3 inferenceStyle
    class J,J1,J2,J3,J4,J5,M,M1,M2,M3 trainStyle
    class K,K1,K2,K3,K4,K5,K6,L lossStyle
</pre><p><strong>old_logp (π_θ_old)</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 生成阶段 - SGLang推理服务</span>
</span></span><span class=line><span class=cl><span class=c1># 模型：Actor模型 (策略π_θ_old)</span>
</span></span><span class=line><span class=cl><span class=c1># 时机：生成token时实时计算</span>
</span></span><span class=line><span class=cl><span class=c1># 函数：genstep() -&gt; distrb.log_prob(next_tokens)</span>
</span></span><span class=line><span class=cl><span class=c1># 保存：concat_prompt_to_generation_output() -&gt; packed_logprobs</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>proximal_logp (π_θ_prox)</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 推理阶段 - actor_inf组件</span>
</span></span><span class=line><span class=cl><span class=c1># 模型：Actor模型 (策略π_θ_prox，比π_θ_old新，比π_θ旧)</span>
</span></span><span class=line><span class=cl><span class=c1># 时机：生成完成后，训练前</span>
</span></span><span class=line><span class=cl><span class=c1># 函数：PPOActorInterface.inference() -&gt; calc_logprobs()</span>
</span></span><span class=line><span class=cl><span class=c1># 条件：仅当use_decoupled_loss=True时计算</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>current_logp (π_θ)</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 训练阶段 - actor_train组件</span>
</span></span><span class=line><span class=cl><span class=c1># 模型：Actor模型 (当前策略π_θ，最新)</span>
</span></span><span class=line><span class=cl><span class=c1># 时机：训练时重新计算</span>
</span></span><span class=line><span class=cl><span class=c1># 函数：PPOActorInterface.train_step() -&gt; gather_packed_shifted_log_probs()</span>
</span></span><span class=line><span class=cl><span class=c1># 作用：用于计算重要性采样比率</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=权重同步机制>权重同步机制<a hidden class=anchor aria-hidden=true href=#权重同步机制>#</a></h3><pre class=mermaid>
  sequenceDiagram
    participant MW as ModelWorker
    participant FS as 文件系统
    participant NR as NameResolving
    participant GSM as GserverManager
    participant GS as GenerationServer

    Note over MW: 训练完成一次step后
    MW-&gt;&gt;MW: __save_model(save_meta)&lt;br/&gt;输入：model, save_dir, global_step
    MW-&gt;&gt;FS: 保存权重文件&lt;br/&gt;路径: param_realloc_path/model_name/step/
    Note over MW,FS: 权重以分片形式落盘（TP/PP分片）

    MW-&gt;&gt;NR: name_resolve.add(model_version, global_step)&lt;br/&gt;输入：experiment, trial, model_name, step
    NR--&gt;&gt;GSM: model_version更新

    loop 推理端定期检查
        GSM-&gt;&gt;NR: check_new_params()&lt;br/&gt;输入：experiment, trial, model_name
        NR--&gt;&gt;GSM: 返回最新global_step
        alt 有新权重
            GSM-&gt;&gt;FS: 获取新权重路径
            GSM-&gt;&gt;GS: flush_requests_and_update_weights(load_dir)
            GS-&gt;&gt;FS: 读取权重分片文件
            GS-&gt;&gt;GS: update_weights_from_disk(load_dir)&lt;br/&gt;变量: load_dir, 分片rank
            Note over GS: 按TP/PP分片加载到各自分片
        else 无新权重
            GSM-&gt;&gt;GSM: 不做更新
        end
    end

    Note over GS: 新权重生效，推理端继续服务
</pre><p>核心机制：</p><ul><li><p>训练端：<code>ModelWorker</code>在每次<code>train_step</code>后保存权重到<code>param_realloc_path</code>，并调用<code>name_resolve.add(model_version, global_step)</code>，在<code>NameResolving</code>服务中记录最新的权重版本号（global_step）。</p></li><li><p>推理端：<code>GserverManager</code>定期检查<code>model_version</code>，发现新版本（<code>model_version</code>和已经加载的对比）时通过HTTP API更新所有<code>GenerationServer</code>的权重。<br>s</p></li><li><p>同步动作：权重更新时会中断正在进行的生成请求，确保推理使用最新权重。</p></li></ul><p>关键函数与变量说明：</p><ul><li><p><code>__save_model(save_meta)</code></p></li><li><p>输入：model_name, save_dir, global_step</p></li><li><p>输出：权重文件（分片）落盘</p></li><li><p><code>name_resolve.add(model_version, global_step)</code></p></li><li><p>输入：实验名、trial名、模型名、step</p></li><li><p>输出：NameResolving服务中记录最新step</p></li><li><p><code>check_new_params()</code></p></li><li><p>输入：实验名、trial名、模型名</p></li><li><p>输出：最新step（如果有更新）</p></li><li><p><code>flush_requests_and_update_weights(load_dir)</code></p></li><li><p>输入：权重目录</p></li><li><p>输出：推理端各分片加载新权重</p></li><li><p><code>update_weights_from_disk(load_dir)</code></p></li><li><p>输入：分片rank、load_dir</p></li><li><p>输出：各分片权重加载到内存</p></li></ul><p>变量传递链路：</p><ul><li><p><code>global_step/model_version</code>：用于标识权重版本</p></li><li><p><code>param_realloc_path/load_dir</code>：权重磁盘路径</p></li><li><p>分片rank：决定每个worker加载哪一份权重</p></li></ul><h3 id=数据陈旧性控制>数据陈旧性控制<a hidden class=anchor aria-hidden=true href=#数据陈旧性控制>#</a></h3><blockquote><p>异步训推协调的核心机制，需要限制陈旧性保证训练稳定性</p></blockquote><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># GserverManager中的陈旧性检查</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>is_staled</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># 检查当前运行的rollout是否过时</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>rollout_stat</span><span class=o>.</span><span class=n>running</span> <span class=o>&gt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>max_head_offpolicyness</span>
</span></span></code></pre></td></tr></table></div></div><p>协调机制：</p><ul><li><p>版本控制：每个生成请求都携带version_start和version_end，记录使用的权重版本</p></li><li><p>陈旧性限制：通过<code>max_head_offpolicyness</code>参数控制允许的最大数据陈旧性</p></li><li><p>请求调度：<code>GserverManager</code>在分配新rollout时检查容量和陈旧性，拒绝过时的请求</p></li></ul><p>确实存在使用老权重的情况：</p><ul><li><p>异步训练允许一定程度的权重陈旧性</p></li><li><p>通过<code>max_head_offpolicyness</code>参数控制陈旧性上限</p></li><li><p>这种设计在提高训练效率的同时，通过限制陈旧性保证训练稳定性</p></li></ul><h3 id=数据传递机制>数据传递机制<a hidden class=anchor aria-hidden=true href=#数据传递机制>#</a></h3><blockquote><p>各个worker之间的通信核心是ZMQ：</p><ul><li>高性能：支持零拷贝和批量传输</li><li>多种模式：PUSH/PULL、PUB/SUB、REQ/REP等</li><li>异步通信：非阻塞I/O，适合高并发场景</li><li>跨语言：支持多种编程语言</li><li>网络透明：自动处理连接、重连、负载均衡</li></ul></blockquote><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># zmq的配置举例</span>
</span></span><span class=line><span class=cl><span class=c1># 高性能配置</span>
</span></span><span class=line><span class=cl><span class=bp>self</span><span class=o>.</span><span class=n>context</span> <span class=o>=</span> <span class=n>zmq</span><span class=o>.</span><span class=n>Context</span><span class=o>.</span><span class=n>instance</span><span class=p>(</span><span class=n>io_threads</span><span class=o>=</span><span class=mi>8</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=bp>self</span><span class=o>.</span><span class=n>context</span><span class=o>.</span><span class=n>set</span><span class=p>(</span><span class=n>zmq</span><span class=o>.</span><span class=n>MAX_SOCKETS</span><span class=p>,</span> <span class=mi>65536</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 缓冲区优化</span>
</span></span><span class=line><span class=cl><span class=bp>self</span><span class=o>.</span><span class=n>socket</span><span class=o>.</span><span class=n>setsockopt</span><span class=p>(</span><span class=n>zmq</span><span class=o>.</span><span class=n>SNDHWM</span><span class=p>,</span> <span class=mi>1000</span><span class=p>)</span>  <span class=c1># 发送缓冲区</span>
</span></span><span class=line><span class=cl><span class=bp>self</span><span class=o>.</span><span class=n>socket</span><span class=o>.</span><span class=n>setsockopt</span><span class=p>(</span><span class=n>zmq</span><span class=o>.</span><span class=n>RCVHWM</span><span class=p>,</span> <span class=mi>1000</span><span class=p>)</span>  <span class=c1># 接收缓冲区</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 超时设置</span>
</span></span><span class=line><span class=cl><span class=bp>self</span><span class=o>.</span><span class=n>socket</span><span class=o>.</span><span class=n>setsockopt</span><span class=p>(</span><span class=n>zmq</span><span class=o>.</span><span class=n>RCVTIMEO</span><span class=p>,</span> <span class=n>timeout_ms</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><pre class=mermaid>
  sequenceDiagram
    participant RW as RolloutWorker
    participant GS as GenerationServer
    participant GSM as GserverManager
    participant ZMQ as ZMQ Stream
    participant SD as StreamDataset
    participant MW as ModelWorker
    participant DM as DataManager
    
    Note over RW,DM: 1. 生成轨迹数据
    RW-&gt;&gt;GS: 发送生成请求
    GS-&gt;&gt;GS: SGLang生成结果
    GS-&gt;&gt;RW: 返回生成结果
    RW-&gt;&gt;RW: 计算奖励，构建轨迹
    
    Note over RW,DM: 2. 推送数据到训练端
    RW-&gt;&gt;ZMQ: 推送轨迹数据(JSON格式)
    ZMQ-&gt;&gt;SD: 接收数据
    SD-&gt;&gt;SD: 转换为SequenceSample
    
    Note over RW,DM: 3. 训练端处理数据
    SD-&gt;&gt;MW: 提供数据给ModelWorker
    MW-&gt;&gt;DM: 存储到DataManager(内存)
    MW-&gt;&gt;MW: 执行训练步骤
</pre><h4 id=数据传递层次>数据传递层次<a hidden class=anchor aria-hidden=true href=#数据传递层次>#</a></h4><ol><li>Rollout端到训练端：</li></ol><ul><li><p>使用ZMQ Push-Pull Stream传输轨迹数据</p></li><li><p>RolloutWorker → NameResolvingZmqPusher → NameResolvingZmqPuller → StreamDataset</p></li></ul><pre class=mermaid>
  graph TB
    subgraph &#34;Rollout端&#34;
        RW[RolloutWorker] --&gt; NP[NameResolvingZmqPusher]
        NP --&gt; ZMQ1[ZMQ PUSH Socket]
    end
    
    subgraph &#34;训练端&#34;
        ZMQ2[ZMQ PULL Socket] --&gt; NP2[NameResolvingZmqPuller]
        NP2 --&gt; SD[StreamDataset]
        SD --&gt; MW[ModelWorker]
    end
    
    subgraph &#34;Name Resolution&#34;
        NR[name_resolve系统]
    end
    
    ZMQ1 -.-&gt;|TCP连接| ZMQ2
    NP --&gt; NR
    NP2 --&gt; NR
</pre><ol start=2><li>训练端内部：</li></ol><ul><li><p>使用Request-Reply Stream传输训练请求</p></li><li><p>MasterWorker → ModelWorker通过ZMQ通信</p></li></ul><pre class=mermaid>
  graph TB
    subgraph &#34;MasterWorker&#34;
        MW[MasterWorker] --&gt; NRC[NameResolvingRequestClient]
        NRC --&gt; ZMQ1[ZMQ PUSH Sockets]
        ZMQ2[ZMQ PULL Socket] --&gt; NRC
    end
    
    subgraph &#34;ModelWorker&#34;
        ZMQ3[ZMQ PULL Socket] --&gt; NRS[NameResolvingReplyServer]
        NRS --&gt; MW2[ModelWorker]
        MW2 --&gt; ZMQ4[ZMQ PUSH Socket]
    end
    
    subgraph &#34;通信协议&#34;
        REQ[Request] --&gt; ACK[ACK]
        ACK --&gt; SYN[SYN]
        SYN --&gt; RESP[Response]
    end
    
    ZMQ1 -.-&gt;|TCP| ZMQ3
    ZMQ4 -.-&gt;|TCP| ZMQ2
</pre><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 请求发送</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>request</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>handlers</span><span class=p>,</span> <span class=n>handle_type</span><span class=p>,</span> <span class=n>datas</span><span class=p>,</span> <span class=n>no_syn</span><span class=o>=</span><span class=kc>True</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>requests</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=n>Payload</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>handler</span><span class=o>=</span><span class=n>handler</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>handle_name</span><span class=o>=</span><span class=n>handle_type</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>data</span><span class=o>=</span><span class=n>data</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>no_syn</span><span class=o>=</span><span class=n>no_syn</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>handler</span><span class=p>,</span> <span class=n>data</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>handlers</span><span class=p>,</span> <span class=n>datas</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 发送请求</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>payload</span> <span class=ow>in</span> <span class=n>requests</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>idx</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_handler_routing</span><span class=p>[</span><span class=n>payload</span><span class=o>.</span><span class=n>handler</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>send_sockets</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span><span class=o>.</span><span class=n>send</span><span class=p>(</span><span class=n>pickle</span><span class=o>.</span><span class=n>dumps</span><span class=p>(</span><span class=n>payload</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><ol start=3><li>存储分离：</li></ol><ul><li>训练数据：存储在DataManager中，支持分布式存储和重分布<br><code>DataManager</code>为内存存储：</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>DataManager</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model_topos</span><span class=p>,</span> <span class=n>msid2mwid</span><span class=p>,</span> <span class=n>data_transfer_pairs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 核心存储：内存字典</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>storage</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=n>Hashable</span><span class=p>,</span> <span class=n>SequenceSample</span><span class=p>]</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>store</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>:</span> <span class=n>SequenceSample</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 存储到内存字典</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>storage</span><span class=p>[</span><span class=n>x</span><span class=o>.</span><span class=n>ids</span><span class=p>[</span><span class=mi>0</span><span class=p>]]</span> <span class=o>=</span> <span class=n>x</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>get</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>data_id</span><span class=p>:</span> <span class=n>Hashable</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 从内存获取</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>storage</span><span class=p>[</span><span class=n>data_id</span><span class=p>]</span>
</span></span></code></pre></td></tr></table></div></div><p>支持数据重分布：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>redistribute</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>data_info</span><span class=p>:</span> <span class=n>SequenceSample</span><span class=p>,</span> <span class=n>plan</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=n>RedistribStep</span><span class=p>]):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;执行数据重分布&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>step</span> <span class=ow>in</span> <span class=n>plan</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>step</span><span class=o>.</span><span class=n>comm_type</span> <span class=o>==</span> <span class=s2>&#34;bcast&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>_run_bcast</span><span class=p>(</span><span class=n>step</span><span class=p>,</span> <span class=n>data_infos</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>elif</span> <span class=n>step</span><span class=o>.</span><span class=n>comm_type</span> <span class=o>==</span> <span class=s2>&#34;gather&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>_run_gather</span><span class=p>(</span><span class=n>step</span><span class=p>,</span> <span class=n>data_infos</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>elif</span> <span class=n>step</span><span class=o>.</span><span class=n>comm_type</span> <span class=o>==</span> <span class=s2>&#34;scatter&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>_run_scatter</span><span class=p>(</span><span class=n>step</span><span class=p>,</span> <span class=n>data_infos</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><ul><li><p>推理数据：存储在SGLang服务器的内存中</p></li><li><p>元数据：通过name_resolve系统共享</p></li></ul><h4 id=实现细节>实现细节<a hidden class=anchor aria-hidden=true href=#实现细节>#</a></h4><h5 id=rolloutworker-数据发送><code>RolloutWorker</code> 数据发送<a hidden class=anchor aria-hidden=true href=#rolloutworker-数据发送>#</a></h5><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># realhf/system/rollout_worker.py</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>RolloutWorker</span><span class=p>(</span><span class=n>AsyncWorker</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_configure</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>config</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 初始化ZMQ推送器 - 发送轨迹数据到训练端</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>push_stream</span> <span class=o>=</span> <span class=n>NameResolvingZmqPusher</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>experiment_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>trial_name</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>            <span class=n>pusher_index</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>worker_index</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>pusher_cnt</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>worker_count</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>async</span> <span class=k>def</span> <span class=nf>_poll_async</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 收集轨迹数据</span>
</span></span><span class=line><span class=cl>        <span class=n>traj</span> <span class=o>=</span> <span class=k>await</span> <span class=bp>self</span><span class=o>.</span><span class=n>agent</span><span class=o>.</span><span class=n>collect_trajectory</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 推送数据到训练端</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>push_stream</span><span class=o>.</span><span class=n>push</span><span class=p>([</span><span class=n>traj</span><span class=o>.</span><span class=n>as_json_serializable</span><span class=p>()])</span>
</span></span></code></pre></td></tr></table></div></div><h5 id=generationserver-推理服务><code>GenerationServer</code> 推理服务<a hidden class=anchor aria-hidden=true href=#generationserver-推理服务>#</a></h5><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># realhf/system/generation_server.py  </span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>GenerationServer</span><span class=p>(</span><span class=n>Worker</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>launch_server_subprocess</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 启动SGLang推理服务器</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>server_process</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>server_port</span> <span class=o>=</span> <span class=n>launch_server_cmd</span><span class=p>(</span><span class=n>cmd</span><span class=p>,</span> <span class=n>port</span><span class=o>=</span><span class=n>server_port</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>server_addr</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;http://</span><span class=si>{</span><span class=n>host</span><span class=si>}</span><span class=s2>:</span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>server_port</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 注册服务地址到NameResolving</span>
</span></span><span class=line><span class=cl>        <span class=n>name</span> <span class=o>=</span> <span class=n>names</span><span class=o>.</span><span class=n>gen_servers</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>experiment_name</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>trial_name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>name_resolve</span><span class=o>.</span><span class=n>add_subentry</span><span class=p>(</span><span class=n>name</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>server_addr</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h5 id=gservermanager负载均衡><code>GserverManager</code>负载均衡<a hidden class=anchor aria-hidden=true href=#gservermanager负载均衡>#</a></h5><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># realhf/system/gserver_manager.py</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>GserverManager</span><span class=p>(</span><span class=n>Worker</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_discover_servers</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>n_servers</span><span class=p>:</span> <span class=nb>int</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 通过NameResolving发现所有推理服务器</span>
</span></span><span class=line><span class=cl>        <span class=n>name</span> <span class=o>=</span> <span class=n>names</span><span class=o>.</span><span class=n>gen_servers</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>experiment_name</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>trial_name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>urls</span> <span class=o>=</span> <span class=n>name_resolve</span><span class=o>.</span><span class=n>get_subtree</span><span class=p>(</span><span class=n>name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>urls</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_run_routing_service</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># HTTP服务，接收推理请求并路由到合适的服务器</span>
</span></span><span class=line><span class=cl>        <span class=k>async</span> <span class=k>def</span> <span class=nf>schedule_request</span><span class=p>(</span><span class=n>req_meta</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>server_idx</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_least_requests_schedule</span><span class=p>(</span><span class=n>req_meta</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>server_urls</span><span class=p>[</span><span class=n>server_idx</span><span class=p>]</span>
</span></span></code></pre></td></tr></table></div></div><h5 id=masterworker-训练协调><code>MasterWorker</code> 训练协调<a hidden class=anchor aria-hidden=true href=#masterworker-训练协调>#</a></h5><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># realhf/system/master_worker.py</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>MasterWorker</span><span class=p>(</span><span class=n>AsyncWorker</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_configure</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>config</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 初始化Request-Reply客户端</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>func_executor</span> <span class=o>=</span> <span class=n>FunctionExecutor</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>experiment_name</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>experiment_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>trial_name</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>trial_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>n_subscribers</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>n_model_workers</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>handler_routing</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>handler_routing</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>async</span> <span class=k>def</span> <span class=nf>_poll_async</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 执行训练步骤，通过Request-Reply与ModelWorker通信</span>
</span></span><span class=line><span class=cl>        <span class=n>result</span> <span class=o>=</span> <span class=k>await</span> <span class=bp>self</span><span class=o>.</span><span class=n>func_executor</span><span class=o>.</span><span class=n>execute_step</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>step_name</span><span class=o>=</span><span class=s2>&#34;train_step&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>step_kwargs</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;batch&#34;</span><span class=p>:</span> <span class=n>batch</span><span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h5 id=modelworker-模型训练><code>ModelWorker</code> 模型训练<a hidden class=anchor aria-hidden=true href=#modelworker-模型训练>#</a></h5><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># realhf/system/model_worker.py</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>ModelWorker</span><span class=p>(</span><span class=n>Worker</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_configure</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>config</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 初始化Request-Reply服务器</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>reply_server</span> <span class=o>=</span> <span class=n>NameResolvingReplyServer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>experiment_name</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>experiment_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>trial_name</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>trial_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>idx</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>worker_index</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 注册训练处理函数</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>reply_server</span><span class=o>.</span><span class=n>register_handler</span><span class=p>(</span><span class=s2>&#34;train_step&#34;</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>_train_step</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_train_step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 执行训练步骤</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>train_step</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 保存权重并更新版本号</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>save_weights</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>param_realloc_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>name</span> <span class=o>=</span> <span class=n>names</span><span class=o>.</span><span class=n>model_version</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>experiment_name</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>trial_name</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>model_name</span><span class=o>.</span><span class=n>role</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>name_resolve</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>name</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>global_step</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>{</span><span class=s2>&#34;loss&#34;</span><span class=p>:</span> <span class=n>loss</span><span class=p>,</span> <span class=s2>&#34;global_step&#34;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>global_step</span><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><h5 id=streamdataset-数据接收><code>StreamDataset</code> 数据接收<a hidden class=anchor aria-hidden=true href=#streamdataset-数据接收>#</a></h5><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># realhf/system/stream_dataset.py</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>StreamDataset</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>args</span><span class=p>,</span> <span class=n>puller_index</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 初始化ZMQ拉取器 - 接收RolloutWorker推送的数据</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>puller</span> <span class=o>=</span> <span class=n>NameResolvingZmqPuller</span><span class=p>(</span><span class=n>args</span><span class=p>,</span> <span class=n>puller_index</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__iter__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>while</span> <span class=kc>True</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># 从ZMQ接收数据</span>
</span></span><span class=line><span class=cl>            <span class=n>data</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>puller</span><span class=o>.</span><span class=n>pull</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 转换为训练格式</span>
</span></span><span class=line><span class=cl>            <span class=n>sample</span> <span class=o>=</span> <span class=n>SequenceSample</span><span class=o>.</span><span class=n>from_json_serializable</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>yield</span> <span class=n>sample</span>
</span></span></code></pre></td></tr></table></div></div><h5 id=zmq通信层><code>ZMQ</code>通信层<a hidden class=anchor aria-hidden=true href=#zmq通信层>#</a></h5><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># realhf/system/push_pull_stream.py</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>NameResolvingZmqPusher</span><span class=p>(</span><span class=n>ZMQJsonPusher</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>experiment_name</span><span class=p>,</span> <span class=n>trial_name</span><span class=p>,</span> <span class=n>pusher_index</span><span class=p>,</span> <span class=n>pusher_cnt</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 通过NameResolving获取目标地址</span>
</span></span><span class=line><span class=cl>        <span class=n>pullers</span> <span class=o>=</span> <span class=n>name_resolve</span><span class=o>.</span><span class=n>get_subtree</span><span class=p>(</span><span class=n>names</span><span class=o>.</span><span class=n>stream_pullers</span><span class=p>(</span><span class=n>experiment_name</span><span class=p>,</span> <span class=n>trial_name</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 计算路由关系</span>
</span></span><span class=line><span class=cl>        <span class=n>groups</span> <span class=o>=</span> <span class=n>grouping</span><span class=p>(</span><span class=n>pusher_cnt</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>pullers</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>puller_index</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_find_target_puller</span><span class=p>(</span><span class=n>groups</span><span class=p>,</span> <span class=n>pusher_index</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 获取目标地址并连接</span>
</span></span><span class=line><span class=cl>        <span class=n>name</span> <span class=o>=</span> <span class=n>names</span><span class=o>.</span><span class=n>push_pull_stream</span><span class=p>(</span><span class=n>experiment_name</span><span class=p>,</span> <span class=n>trial_name</span><span class=p>,</span> <span class=sa>f</span><span class=s2>&#34;puller</span><span class=si>{</span><span class=n>puller_index</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>addr</span> <span class=o>=</span> <span class=n>name_resolve</span><span class=o>.</span><span class=n>wait</span><span class=p>(</span><span class=n>name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>host</span><span class=p>,</span> <span class=n>port</span> <span class=o>=</span> <span class=n>addr</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s2>&#34;:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=n>host</span><span class=p>,</span> <span class=nb>int</span><span class=p>(</span><span class=n>port</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>NameResolvingZmqPuller</span><span class=p>(</span><span class=n>ZMQJsonPuller</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>args</span><span class=p>,</span> <span class=n>puller_index</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 绑定随机端口</span>
</span></span><span class=line><span class=cl>        <span class=n>host</span><span class=p>,</span> <span class=n>port</span> <span class=o>=</span> <span class=n>network</span><span class=o>.</span><span class=n>gethostip</span><span class=p>(),</span> <span class=n>network</span><span class=o>.</span><span class=n>find_free_port</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>addr</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>host</span><span class=si>}</span><span class=s2>:</span><span class=si>{</span><span class=n>port</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 注册地址到NameResolving</span>
</span></span><span class=line><span class=cl>        <span class=n>name</span> <span class=o>=</span> <span class=n>names</span><span class=o>.</span><span class=n>push_pull_stream</span><span class=p>(</span><span class=n>args</span><span class=o>.</span><span class=n>experiment_name</span><span class=p>,</span> <span class=n>args</span><span class=o>.</span><span class=n>trial_name</span><span class=p>,</span> <span class=sa>f</span><span class=s2>&#34;puller</span><span class=si>{</span><span class=n>puller_index</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>name_resolve</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>name</span><span class=p>,</span> <span class=n>addr</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=n>host</span><span class=p>,</span> <span class=n>port</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h5 id=request-reply-通信层><code>Request-Reply</code> 通信层<a hidden class=anchor aria-hidden=true href=#request-reply-通信层>#</a></h5><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># realhf/system/request_reply_stream.py</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>NameResolvingRequestClient</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>experiment_name</span><span class=p>,</span> <span class=n>trial_name</span><span class=p>,</span> <span class=n>n_subscribers</span><span class=p>,</span> <span class=n>handler_routing</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 创建多个发送socket</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_subscribers</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>s</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>context</span><span class=o>.</span><span class=n>socket</span><span class=p>(</span><span class=n>zmq</span><span class=o>.</span><span class=n>PUSH</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>send_port</span> <span class=o>=</span> <span class=n>s</span><span class=o>.</span><span class=n>bind_to_random_port</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;tcp://</span><span class=si>{</span><span class=n>host_ip</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 注册发送地址</span>
</span></span><span class=line><span class=cl>            <span class=n>master_send_name</span> <span class=o>=</span> <span class=n>names</span><span class=o>.</span><span class=n>request_reply_stream</span><span class=p>(</span><span class=n>experiment_name</span><span class=p>,</span> <span class=n>trial_name</span><span class=p>,</span> <span class=sa>f</span><span class=s2>&#34;master_send_</span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>name_resolve</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=n>master_send_name</span><span class=p>,</span> <span class=n>value</span><span class=o>=</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>host_ip</span><span class=si>}</span><span class=s2>:</span><span class=si>{</span><span class=n>send_port</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>send_sockets</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>s</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 创建接收socket</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>recv_socket</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>context</span><span class=o>.</span><span class=n>socket</span><span class=p>(</span><span class=n>zmq</span><span class=o>.</span><span class=n>PULL</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>recv_port</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>recv_socket</span><span class=o>.</span><span class=n>bind_to_random_port</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;tcp://</span><span class=si>{</span><span class=n>host_ip</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>master_recv_name</span> <span class=o>=</span> <span class=n>names</span><span class=o>.</span><span class=n>request_reply_stream</span><span class=p>(</span><span class=n>experiment_name</span><span class=p>,</span> <span class=n>trial_name</span><span class=p>,</span> <span class=s2>&#34;master_recv&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>name_resolve</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=n>master_recv_name</span><span class=p>,</span> <span class=n>value</span><span class=o>=</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>host_ip</span><span class=si>}</span><span class=s2>:</span><span class=si>{</span><span class=n>recv_port</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>NameResolvingReplyServer</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>experiment_name</span><span class=p>,</span> <span class=n>trial_name</span><span class=p>,</span> <span class=n>idx</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 等待MasterWorker注册地址</span>
</span></span><span class=line><span class=cl>        <span class=n>send_name</span> <span class=o>=</span> <span class=n>names</span><span class=o>.</span><span class=n>request_reply_stream</span><span class=p>(</span><span class=n>experiment_name</span><span class=p>,</span> <span class=n>trial_name</span><span class=p>,</span> <span class=s2>&#34;master_recv&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>master_recv_addr</span> <span class=o>=</span> <span class=n>name_resolve</span><span class=o>.</span><span class=n>wait</span><span class=p>(</span><span class=n>send_name</span><span class=p>,</span> <span class=n>timeout</span><span class=o>=</span><span class=mi>300</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=n>recv_name</span> <span class=o>=</span> <span class=n>names</span><span class=o>.</span><span class=n>request_reply_stream</span><span class=p>(</span><span class=n>experiment_name</span><span class=p>,</span> <span class=n>trial_name</span><span class=p>,</span> <span class=sa>f</span><span class=s2>&#34;master_send_</span><span class=si>{</span><span class=n>idx</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>master_send_addr</span> <span class=o>=</span> <span class=n>name_resolve</span><span class=o>.</span><span class=n>wait</span><span class=p>(</span><span class=n>recv_name</span><span class=p>,</span> <span class=n>timeout</span><span class=o>=</span><span class=mi>300</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 连接到MasterWorker</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>accept</span><span class=p>(</span><span class=n>master_send_addr</span><span class=p>,</span> <span class=n>master_recv_addr</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h5 id=轨迹数据序列化>轨迹数据序列化<a hidden class=anchor aria-hidden=true href=#轨迹数据序列化>#</a></h5><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 轨迹数据序列化</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>Trajectory</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>as_json_serializable</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;observations&#34;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>observations</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;actions&#34;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>actions</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>            <span class=s2>&#34;rewards&#34;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>rewards</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;dones&#34;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>dones</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;values&#34;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>values</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;log_probs&#34;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>log_probs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># ZMQ传输</span>
</span></span><span class=line><span class=cl><span class=bp>self</span><span class=o>.</span><span class=n>push_stream</span><span class=o>.</span><span class=n>push</span><span class=p>([</span><span class=n>traj</span><span class=o>.</span><span class=n>as_json_serializable</span><span class=p>()])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 接收端反序列化</span>
</span></span><span class=line><span class=cl><span class=n>data</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>puller</span><span class=o>.</span><span class=n>pull</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>sample</span> <span class=o>=</span> <span class=n>SequenceSample</span><span class=o>.</span><span class=n>from_json_serializable</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=qa>QA<a hidden class=anchor aria-hidden=true href=#qa>#</a></h4><h5 id=为什么数据流不通过masterworker而是直接到modelworker>为什么数据流不通过<code>MasterWorker</code>而是直接到<code>ModelWorker</code>？<a hidden class=anchor aria-hidden=true href=#为什么数据流不通过masterworker而是直接到modelworker>#</a></h5><blockquote><p><code>ModelWorker</code>直接创建<code>PullerStreamDataset</code>，通过<code>zmq</code>接收<code>RolloutWorker</code>推送的数据。</p></blockquote><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># realhf/system/model_worker.py</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>ModelWorker</span><span class=p>(</span><span class=n>Worker</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_lazy_setup</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 在ModelWorker中创建数据集</span>
</span></span><span class=line><span class=cl>        <span class=n>datasets</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=n>data_api</span><span class=o>.</span><span class=n>make_dataset</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>d</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>base_seed</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>__dataset_dp_rank</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>__dataset_dp_size</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>tokenizer_name_or_path</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>d</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>datasets</span>
</span></span><span class=line><span class=cl>        <span class=p>]</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 特殊处理StreamDataset</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=ow>not</span> <span class=nb>isinstance</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>__datasets</span><span class=p>[</span><span class=n>dataset_id</span><span class=p>],</span> <span class=n>PullerStreamDataset</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>dataloader_kwargs</span><span class=p>[</span><span class=s2>&#34;collate_fn&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>data_api</span><span class=o>.</span><span class=n>SequenceSample</span><span class=o>.</span><span class=n>gather</span>
</span></span><span class=line><span class=cl>            <span class=n>dataloader_kwargs</span><span class=p>[</span><span class=s2>&#34;batch_size&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=mi>10240</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>dataloader_kwargs</span><span class=p>[</span><span class=s2>&#34;batch_size&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>  <span class=c1># StreamDataset不需要batch_size</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>PullerStreamDataset</span><span class=p>(</span><span class=n>Dataset</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>util</span><span class=p>,</span> <span class=n>args</span><span class=p>,</span> <span class=n>dataset_cfgs</span><span class=p>,</span> <span class=n>pull_timeout_ms</span><span class=o>=</span><span class=mi>100</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 创建后台线程来拉取数据</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>worker_thread</span> <span class=o>=</span> <span class=n>threading</span><span class=o>.</span><span class=n>Thread</span><span class=p>(</span><span class=n>target</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>_pull_data_worker</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>worker_thread</span><span class=o>.</span><span class=n>start</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_pull_data_worker</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 在后台线程中创建ZMQ拉取器</span>
</span></span><span class=line><span class=cl>        <span class=n>stream</span> <span class=o>=</span> <span class=n>NameResolvingZmqPuller</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>args</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>puller_index</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>util</span><span class=o>.</span><span class=n>dp_rank</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=k>while</span> <span class=ow>not</span> <span class=bp>self</span><span class=o>.</span><span class=n>_stop_event</span><span class=o>.</span><span class=n>is_set</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=c1># 从ZMQ接收RolloutWorker推送的数据</span>
</span></span><span class=line><span class=cl>            <span class=n>data</span> <span class=o>=</span> <span class=n>stream</span><span class=o>.</span><span class=n>pull</span><span class=p>(</span><span class=n>timeout_ms</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>pull_timeout_ms</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>processed_data</span> <span class=o>=</span> <span class=p>[</span><span class=n>SequenceSample</span><span class=o>.</span><span class=n>from_json_compatible</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=n>data</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=c1># 放入队列供训练使用</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>data_queue</span><span class=o>.</span><span class=n>put_nowait</span><span class=p>(</span><span class=n>processed_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__getitem__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>idx</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 从队列中获取数据用于训练</span>
</span></span><span class=line><span class=cl>        <span class=n>samples</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=k>while</span> <span class=kc>True</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>samples</span> <span class=o>+=</span> <span class=bp>self</span><span class=o>.</span><span class=n>data_queue</span><span class=o>.</span><span class=n>get_nowait</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=k>except</span> <span class=n>queue</span><span class=o>.</span><span class=n>Empty</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>break</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>samples</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>目的是为了控制流和数据流的分离，且减少数据中转</strong> 。<code>MasterWorker</code>只是做协调训练步骤，而<code>ModelWorker</code>直接接收数据:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># MasterWorker: 控制流</span>
</span></span><span class=line><span class=cl><span class=k>await</span> <span class=bp>self</span><span class=o>.</span><span class=n>func_executor</span><span class=o>.</span><span class=n>execute_step</span><span class=p>()</span>  <span class=c1># 协调训练步骤</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># ModelWorker: 数据流  </span>
</span></span><span class=line><span class=cl><span class=n>stream</span> <span class=o>=</span> <span class=n>NameResolvingZmqPuller</span><span class=p>(</span><span class=n>args</span><span class=p>,</span> <span class=n>puller_index</span><span class=p>)</span>  <span class=c1># 直接接收数据</span>
</span></span></code></pre></td></tr></table></div></div><p>这里需要理解一点：<code>StreamDataset</code>是持续接收<code>RolloutWorker</code>的数据的，不是按需获取的。stream过程会把数据缓存在内存的queue中，<code>MasterWorker</code>协调训练发生后，<code>ModelWorker</code>从内存队列里直接取数据训练。</p><p>此外，<code>RolloutWorker</code>是按照DP rank分组的，每个<code>ModelWorker</code>负责特定分组的<code>RolloutWorker</code>,通过<code>NameResolving</code>动态发现和链接。</p><h5 id=modelworker如何和rolloutworker分组建链><code>ModelWorker</code>如何和<code>RolloutWorker</code>分组建链？<a hidden class=anchor aria-hidden=true href=#modelworker如何和rolloutworker分组建链>#</a></h5><blockquote><p>问题的本质rollout worker是按照<code>dp</code>分组，那么rollout worker怎么找到对应的model worker的，这其中的服务发现是怎么实现的。</p></blockquote><p>首先理解如何分组的，比如发送者和接受者的个数不同:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>grouping</span><span class=p>(</span><span class=n>num_senders</span><span class=p>,</span> <span class=n>num_receivers</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>groups</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=n>num_senders</span> <span class=o>&gt;=</span> <span class=n>num_receivers</span>
</span></span><span class=line><span class=cl>    <span class=c1># 每个接收者分配多个发送者</span>
</span></span><span class=line><span class=cl>    <span class=n>senders_per_receiver</span> <span class=o>=</span> <span class=n>num_senders</span> <span class=o>//</span> <span class=n>num_receivers</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>receiver_id</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_receivers</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>start</span> <span class=o>=</span> <span class=n>receiver_id</span> <span class=o>*</span> <span class=n>senders_per_receiver</span>
</span></span><span class=line><span class=cl>        <span class=n>end</span> <span class=o>=</span> <span class=p>(</span><span class=n>receiver_id</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>*</span> <span class=n>senders_per_receiver</span>
</span></span><span class=line><span class=cl>        <span class=n>groups</span><span class=p>[</span><span class=n>receiver_id</span><span class=p>]</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=n>start</span><span class=p>,</span> <span class=n>end</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=c1># 分配剩余的发送者</span>
</span></span><span class=line><span class=cl>    <span class=n>remaining</span> <span class=o>=</span> <span class=n>num_senders</span> <span class=o>%</span> <span class=n>num_receivers</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>remaining</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>groups</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>num_receivers</span> <span class=o>*</span> <span class=n>senders_per_receiver</span> <span class=o>+</span> <span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>groups</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 假设有6个RolloutWorker，3个ModelWorker</span>
</span></span><span class=line><span class=cl><span class=n>grouping</span><span class=p>(</span><span class=mi>6</span><span class=p>,</span> <span class=mi>3</span><span class=p>)</span>  <span class=c1># 6个发送者，3个接收者</span>
</span></span><span class=line><span class=cl><span class=c1># 结果：</span>
</span></span><span class=line><span class=cl><span class=c1># {</span>
</span></span><span class=line><span class=cl><span class=c1>#   0: [0, 1],  # ModelWorker 0 负责 RolloutWorker 0,1</span>
</span></span><span class=line><span class=cl><span class=c1>#   1: [2, 3],  # ModelWorker 1 负责 RolloutWorker 2,3  </span>
</span></span><span class=line><span class=cl><span class=c1>#   2: [4, 5]   # ModelWorker 2 负责 RolloutWorker 4,5</span>
</span></span><span class=line><span class=cl><span class=c1># }</span>
</span></span></code></pre></td></tr></table></div></div><p>其次要理解<code>ModelWorker</code>如何确定自己的DP Rank:</p><ul><li>只有数据并行头节点（<code>tp_rank == 0 and pp_rank == pp_size - 1</code>）才负责接收数据。</li><li>每个DP rank对应一个ModelWorker。</li><li><strong>DP rank通过拓扑结构确定</strong>。</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># realhf/system/model_worker.py</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>ModelWorker</span><span class=p>(</span><span class=n>Worker</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_configure</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>cfg</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 遍历所有模型分片，找到数据并行头节点</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>s</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>shards</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>_pp_size</span> <span class=o>=</span> <span class=n>s</span><span class=o>.</span><span class=n>id</span><span class=o>.</span><span class=n>topo</span><span class=o>.</span><span class=n>get_dim</span><span class=p>(</span><span class=s2>&#34;pipe&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=c1># 只有pipeline的最后一个stage且tensor rank为0的才是数据并行头</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=ow>not</span> <span class=p>(</span><span class=n>s</span><span class=o>.</span><span class=n>id</span><span class=o>.</span><span class=n>tp_rank</span> <span class=o>==</span> <span class=mi>0</span> <span class=ow>and</span> <span class=n>s</span><span class=o>.</span><span class=n>id</span><span class=o>.</span><span class=n>pp_rank</span> <span class=o>==</span> <span class=n>_pp_size</span> <span class=o>-</span> <span class=mi>1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=k>continue</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>src_rpc</span><span class=o>.</span><span class=n>model_name</span> <span class=o>==</span> <span class=n>s</span><span class=o>.</span><span class=n>id</span><span class=o>.</span><span class=n>model_name</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>__has_dataset</span> <span class=o>=</span> <span class=kc>True</span>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>__dataset_dp_size</span> <span class=o>=</span> <span class=n>s</span><span class=o>.</span><span class=n>id</span><span class=o>.</span><span class=n>topo</span><span class=o>.</span><span class=n>get_dim</span><span class=p>(</span><span class=s2>&#34;data&#34;</span><span class=p>)</span>  <span class=c1># 总DP数量</span>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>__dataset_dp_rank</span> <span class=o>=</span> <span class=n>s</span><span class=o>.</span><span class=n>id</span><span class=o>.</span><span class=n>dp_rank</span>               <span class=c1># 当前DP rank</span>
</span></span><span class=line><span class=cl>                <span class=k>break</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 注册到NameResolving系统</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>__has_dataset</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>name</span> <span class=o>=</span> <span class=n>names</span><span class=o>.</span><span class=n>stream_pullers</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>__experiment_name</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>__trial_name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>name_resolve</span><span class=o>.</span><span class=n>add_subentry</span><span class=p>(</span><span class=n>name</span><span class=p>,</span> <span class=nb>str</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>__dataset_dp_rank</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><p>还要理解<code>RolloutWorker</code>是如何找到对应的<code>ModelWorker</code>的：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># realhf/system/push_pull_stream.py</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>NameResolvingZmqPusher</span><span class=p>(</span><span class=n>ZMQJsonPusher</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>experiment_name</span><span class=p>,</span> <span class=n>trial_name</span><span class=p>,</span> <span class=n>pusher_index</span><span class=p>,</span> <span class=n>pusher_cnt</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 1. 获取所有可用的puller（ModelWorker）</span>
</span></span><span class=line><span class=cl>        <span class=n>pullers</span> <span class=o>=</span> <span class=n>name_resolve</span><span class=o>.</span><span class=n>get_subtree</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>names</span><span class=o>.</span><span class=n>stream_pullers</span><span class=p>(</span><span class=n>experiment_name</span><span class=p>,</span> <span class=n>trial_name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>pullers</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=nb>map</span><span class=p>(</span><span class=nb>int</span><span class=p>,</span> <span class=n>pullers</span><span class=p>))</span>  <span class=c1># 转换为整数列表</span>
</span></span><span class=line><span class=cl>        <span class=n>puller_cnt</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>pullers</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 2. 执行分组算法</span>
</span></span><span class=line><span class=cl>        <span class=n>groups</span> <span class=o>=</span> <span class=n>grouping</span><span class=p>(</span><span class=n>pusher_cnt</span><span class=p>,</span> <span class=n>puller_cnt</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 3. 找到当前pusher属于哪个puller组</span>
</span></span><span class=line><span class=cl>        <span class=n>puller_index</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>puller_index</span><span class=p>,</span> <span class=n>pusher_indices</span> <span class=ow>in</span> <span class=n>groups</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>pusher_index</span> <span class=ow>in</span> <span class=n>pusher_indices</span><span class=p>:</span>  <span class=c1># 这里有个bug，应该是pusher_index</span>
</span></span><span class=line><span class=cl>                <span class=k>break</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 4. 通过NameResolving获取目标地址</span>
</span></span><span class=line><span class=cl>        <span class=n>name</span> <span class=o>=</span> <span class=n>names</span><span class=o>.</span><span class=n>push_pull_stream</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>experiment_name</span><span class=p>,</span> <span class=n>trial_name</span><span class=p>,</span> <span class=n>stream_name</span><span class=o>=</span><span class=sa>f</span><span class=s2>&#34;puller</span><span class=si>{</span><span class=n>puller_index</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>addr</span> <span class=o>=</span> <span class=n>name_resolve</span><span class=o>.</span><span class=n>wait</span><span class=p>(</span><span class=n>name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>host</span><span class=p>,</span> <span class=n>port</span> <span class=o>=</span> <span class=n>addr</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s2>&#34;:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=n>host</span><span class=p>,</span> <span class=nb>int</span><span class=p>(</span><span class=n>port</span><span class=p>),</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>最后理解完整的匹配流程：</p><ol><li><code>ModelWorker</code>注册</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># ModelWorker启动时</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>__has_dataset</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>name</span> <span class=o>=</span> <span class=n>names</span><span class=o>.</span><span class=n>stream_pullers</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>__experiment_name</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>__trial_name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>name_resolve</span><span class=o>.</span><span class=n>add_subentry</span><span class=p>(</span><span class=n>name</span><span class=p>,</span> <span class=nb>str</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>__dataset_dp_rank</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=c1># 例如：注册 &#34;puller0&#34;, &#34;puller1&#34;, &#34;puller2&#34;</span>
</span></span></code></pre></td></tr></table></div></div><ol start=2><li><code>RolloutWorker</code>发现分组</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># RolloutWorker启动时</span>
</span></span><span class=line><span class=cl><span class=n>pullers</span> <span class=o>=</span> <span class=n>name_resolve</span><span class=o>.</span><span class=n>get_subtree</span><span class=p>(</span><span class=n>names</span><span class=o>.</span><span class=n>stream_pullers</span><span class=p>(</span><span class=n>exp_name</span><span class=p>,</span> <span class=n>trial_name</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=c1># 获取到 [&#34;0&#34;, &#34;1&#34;, &#34;2&#34;] 表示有3个ModelWorker</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>groups</span> <span class=o>=</span> <span class=n>grouping</span><span class=p>(</span><span class=mi>6</span><span class=p>,</span> <span class=mi>3</span><span class=p>)</span>  <span class=c1># 6个RolloutWorker，3个ModelWorker</span>
</span></span><span class=line><span class=cl><span class=c1># 结果：{0: [0,1], 1: [2,3], 2: [4,5]}</span>
</span></span></code></pre></td></tr></table></div></div><ol start=3><li>建立链接</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># RolloutWorker 0,1 连接到 ModelWorker 0</span>
</span></span><span class=line><span class=cl><span class=c1># RolloutWorker 2,3 连接到 ModelWorker 1  </span>
</span></span><span class=line><span class=cl><span class=c1># RolloutWorker 4,5 连接到 ModelWorker 2</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>name</span> <span class=o>=</span> <span class=n>names</span><span class=o>.</span><span class=n>push_pull_stream</span><span class=p>(</span><span class=n>exp_name</span><span class=p>,</span> <span class=n>trial_name</span><span class=p>,</span> <span class=sa>f</span><span class=s2>&#34;puller</span><span class=si>{</span><span class=n>puller_index</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>addr</span> <span class=o>=</span> <span class=n>name_resolve</span><span class=o>.</span><span class=n>wait</span><span class=p>(</span><span class=n>name</span><span class=p>)</span>  <span class=c1># 等待ModelWorker注册地址</span>
</span></span></code></pre></td></tr></table></div></div><h5 id=masterworker如何和modelworker建链><code>MasterWorker</code>如何和<code>ModelWorker</code>建链？<a hidden class=anchor aria-hidden=true href=#masterworker如何和modelworker建链>#</a></h5><p>与<code>RolloutWorker-ModelWorker</code>的<code>Push-Pull</code>模式（单向）不同，<code>MasterWorker-ModelWorker</code>使用<code>Request-Reply</code>模式（双向）。</p><ol><li><code>MasterWorker</code>创建<code>Request Client</code></li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># realhf/system/master_worker.py</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>__lazy_init</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># 构建handler路由表</span>
</span></span><span class=line><span class=cl>    <span class=n>handler_routing</span> <span class=o>=</span> <span class=n>copy</span><span class=o>.</span><span class=n>deepcopy</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>msid2mwid</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 为数据并行添加特殊路由</span>
</span></span><span class=line><span class=cl>    <span class=n>src_rpc</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>__rpc_srcs</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>src_rpc_topo</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>model_topos</span><span class=p>[</span><span class=n>src_rpc</span><span class=o>.</span><span class=n>model_name</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>src_rpc_dp_size</span> <span class=o>=</span> <span class=n>src_rpc_topo</span><span class=o>.</span><span class=n>get_dim</span><span class=p>(</span><span class=s2>&#34;data&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>src_rpc_pp_size</span> <span class=o>=</span> <span class=n>src_rpc_topo</span><span class=o>.</span><span class=n>get_dim</span><span class=p>(</span><span class=s2>&#34;pipe&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>src_rpc_dp_size</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 找到每个DP rank对应的ModelWorker</span>
</span></span><span class=line><span class=cl>        <span class=n>rank</span> <span class=o>=</span> <span class=n>src_rpc_topo</span><span class=o>.</span><span class=n>get_rank</span><span class=p>(</span><span class=n>data</span><span class=o>=</span><span class=n>i</span><span class=p>,</span> <span class=n>pipe</span><span class=o>=</span><span class=n>src_rpc_pp_size</span> <span class=o>-</span> <span class=mi>1</span><span class=p>,</span> <span class=n>tensor</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>handler_routing</span><span class=p>[</span><span class=sa>f</span><span class=s2>&#34;__data</span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s2>__&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>msid2mwid</span><span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=n>config_pkg</span><span class=o>.</span><span class=n>ModelShardID</span><span class=o>.</span><span class=n>from_parallelism_rank</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>model_name</span><span class=o>=</span><span class=n>src_rpc</span><span class=o>.</span><span class=n>model_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>topo</span><span class=o>=</span><span class=n>src_rpc_topo</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>parallelism_rank</span><span class=o>=</span><span class=n>rank</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>]</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 添加简单的worker_index映射</span>
</span></span><span class=line><span class=cl>    <span class=n>handler_routing</span><span class=o>.</span><span class=n>update</span><span class=p>({</span><span class=n>i</span><span class=p>:</span> <span class=n>i</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>n_model_workers</span><span class=p>)})</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 创建Request-Reply Stream</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>__stream</span> <span class=o>=</span> <span class=n>request_reply_stream</span><span class=o>.</span><span class=n>make_master_stream</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>worker_info</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>n_subscribers</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>n_model_workers</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>handler_routing</span><span class=o>=</span><span class=n>handler_routing</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># realhf/system/request_reply_stream.py</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>NameResolvingRequestClient</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>experiment_name</span><span class=p>,</span> <span class=n>trial_name</span><span class=p>,</span> <span class=n>n_subscribers</span><span class=p>,</span> <span class=n>handler_routing</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>context</span> <span class=o>=</span> <span class=n>zmq</span><span class=o>.</span><span class=n>Context</span><span class=o>.</span><span class=n>instance</span><span class=p>(</span><span class=n>io_threads</span><span class=o>=</span><span class=n>ZMQ_IO_THREADS</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>host_ip</span> <span class=o>=</span> <span class=n>socket</span><span class=o>.</span><span class=n>gethostbyname</span><span class=p>(</span><span class=n>socket</span><span class=o>.</span><span class=n>gethostname</span><span class=p>())</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 1. 为每个ModelWorker创建发送socket</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>send_sockets</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=n>zmq</span><span class=o>.</span><span class=n>Socket</span><span class=p>]</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_subscribers</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>s</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>context</span><span class=o>.</span><span class=n>socket</span><span class=p>(</span><span class=n>zmq</span><span class=o>.</span><span class=n>PUSH</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>send_port</span> <span class=o>=</span> <span class=n>s</span><span class=o>.</span><span class=n>bind_to_random_port</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;tcp://</span><span class=si>{</span><span class=n>host_ip</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>s</span><span class=o>.</span><span class=n>setsockopt</span><span class=p>(</span><span class=n>zmq</span><span class=o>.</span><span class=n>LINGER</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 注册发送地址到NameResolving</span>
</span></span><span class=line><span class=cl>            <span class=n>master_send_name</span> <span class=o>=</span> <span class=n>names</span><span class=o>.</span><span class=n>request_reply_stream</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>experiment_name</span><span class=p>,</span> <span class=n>trial_name</span><span class=p>,</span> <span class=sa>f</span><span class=s2>&#34;master_send_</span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>name_resolve</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=n>master_send_name</span><span class=p>,</span> <span class=n>value</span><span class=o>=</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>host_ip</span><span class=si>}</span><span class=s2>:</span><span class=si>{</span><span class=n>send_port</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>send_sockets</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>s</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 2. 创建接收socket</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>recv_socket</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>context</span><span class=o>.</span><span class=n>socket</span><span class=p>(</span><span class=n>zmq</span><span class=o>.</span><span class=n>PULL</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>recv_port</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>recv_socket</span><span class=o>.</span><span class=n>bind_to_random_port</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;tcp://</span><span class=si>{</span><span class=n>host_ip</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>recv_socket</span><span class=o>.</span><span class=n>setsockopt</span><span class=p>(</span><span class=n>zmq</span><span class=o>.</span><span class=n>LINGER</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>recv_address</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>host_ip</span><span class=si>}</span><span class=s2>:</span><span class=si>{</span><span class=n>recv_port</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 注册接收地址</span>
</span></span><span class=line><span class=cl>        <span class=n>master_recv_name</span> <span class=o>=</span> <span class=n>names</span><span class=o>.</span><span class=n>request_reply_stream</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>experiment_name</span><span class=p>,</span> <span class=n>trial_name</span><span class=p>,</span> <span class=s2>&#34;master_recv&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>name_resolve</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=n>master_recv_name</span><span class=p>,</span> <span class=n>value</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>recv_address</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 3. 等待所有ModelWorker连接</span>
</span></span><span class=line><span class=cl>        <span class=k>while</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=nb>len</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>name_resolve</span><span class=o>.</span><span class=n>get_subtree</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                    <span class=n>names</span><span class=o>.</span><span class=n>request_reply_stream</span><span class=p>(</span><span class=n>experiment_name</span><span class=p>,</span> <span class=n>trial_name</span><span class=p>,</span> <span class=n>PUBSUB_BARRIER_NAME</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=o>&lt;</span> <span class=n>n_subscribers</span>
</span></span><span class=line><span class=cl>        <span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>time</span><span class=o>.</span><span class=n>sleep</span><span class=p>(</span><span class=mf>0.1</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><ol start=2><li><code>ModelWorker</code>创建<code>Reply Server</code></li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># realhf/system/model_worker.py</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>__lazy_setup</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># 创建与MasterWorker的连接</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>__stream</span> <span class=o>=</span> <span class=n>request_reply_stream</span><span class=o>.</span><span class=n>make_worker_stream</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>worker_info</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>idx</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>__worker_index</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># realhf/system/request_reply_stream.py</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>NameResolvingReplyServer</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>experiment_name</span><span class=p>,</span> <span class=n>trial_name</span><span class=p>,</span> <span class=n>idx</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>context</span> <span class=o>=</span> <span class=n>zmq</span><span class=o>.</span><span class=n>Context</span><span class=o>.</span><span class=n>instance</span><span class=p>(</span><span class=n>io_threads</span><span class=o>=</span><span class=n>ZMQ_IO_THREADS</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 1. 等待MasterWorker注册接收地址</span>
</span></span><span class=line><span class=cl>        <span class=n>send_name</span> <span class=o>=</span> <span class=n>names</span><span class=o>.</span><span class=n>request_reply_stream</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>experiment_name</span><span class=p>,</span> <span class=n>trial_name</span><span class=p>,</span> <span class=s2>&#34;master_recv&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>master_recv_addr</span> <span class=o>=</span> <span class=n>name_resolve</span><span class=o>.</span><span class=n>wait</span><span class=p>(</span><span class=n>send_name</span><span class=p>,</span> <span class=n>timeout</span><span class=o>=</span><span class=mi>300</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>except</span> <span class=ne>TimeoutError</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>logger</span><span class=o>.</span><span class=n>error</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Worker timeout waiting for master receive stream.&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>raise</span> <span class=n>e</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 2. 等待MasterWorker注册发送地址</span>
</span></span><span class=line><span class=cl>        <span class=n>recv_name</span> <span class=o>=</span> <span class=n>names</span><span class=o>.</span><span class=n>request_reply_stream</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>experiment_name</span><span class=p>,</span> <span class=n>trial_name</span><span class=p>,</span> <span class=sa>f</span><span class=s2>&#34;master_send_</span><span class=si>{</span><span class=n>idx</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>master_send_addr</span> <span class=o>=</span> <span class=n>name_resolve</span><span class=o>.</span><span class=n>wait</span><span class=p>(</span><span class=n>recv_name</span><span class=p>,</span> <span class=n>timeout</span><span class=o>=</span><span class=mi>300</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>except</span> <span class=ne>TimeoutError</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>logger</span><span class=o>.</span><span class=n>error</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Worker timeout waiting for master send stream&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>raise</span> <span class=n>e</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 3. 建立连接</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>accept</span><span class=p>(</span><span class=n>master_send_addr</span><span class=p>,</span> <span class=n>master_recv_addr</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 4. 注册到barrier，通知MasterWorker已连接</span>
</span></span><span class=line><span class=cl>        <span class=n>name_resolve</span><span class=o>.</span><span class=n>add_subentry</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>name</span><span class=o>=</span><span class=n>names</span><span class=o>.</span><span class=n>request_reply_stream</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>experiment_name</span><span class=p>,</span> <span class=n>trial_name</span><span class=p>,</span> <span class=n>PUBSUB_BARRIER_NAME</span>
</span></span><span class=line><span class=cl>            <span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>value</span><span class=o>=</span><span class=n>socket</span><span class=o>.</span><span class=n>gethostbyname</span><span class=p>(</span><span class=n>socket</span><span class=o>.</span><span class=n>gethostname</span><span class=p>()),</span>
</span></span><span class=line><span class=cl>            <span class=n>keepalive_ttl</span><span class=o>=</span><span class=mi>1200</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>accept</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>server_send_addr</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>server_recv_addr</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 连接到MasterWorker的发送socket</span>
</span></span><span class=line><span class=cl>        <span class=n>recv_socket</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>context</span><span class=o>.</span><span class=n>socket</span><span class=p>(</span><span class=n>zmq</span><span class=o>.</span><span class=n>PULL</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>recv_socket</span><span class=o>.</span><span class=n>connect</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;tcp://</span><span class=si>{</span><span class=n>server_send_addr</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>recv_socket</span><span class=o>.</span><span class=n>setsockopt</span><span class=p>(</span><span class=n>zmq</span><span class=o>.</span><span class=n>LINGER</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>recv_socket</span> <span class=o>=</span> <span class=n>recv_socket</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 连接到MasterWorker的接收socket</span>
</span></span><span class=line><span class=cl>        <span class=n>send_socket</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>context</span><span class=o>.</span><span class=n>socket</span><span class=p>(</span><span class=n>zmq</span><span class=o>.</span><span class=n>PUSH</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>send_socket</span><span class=o>.</span><span class=n>connect</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;tcp://</span><span class=si>{</span><span class=n>server_recv_addr</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>send_socket</span><span class=o>.</span><span class=n>setsockopt</span><span class=p>(</span><span class=n>zmq</span><span class=o>.</span><span class=n>LINGER</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>send_socket</span> <span class=o>=</span> <span class=n>send_socket</span>
</span></span></code></pre></td></tr></table></div></div><h5 id=为什么request-reply模式要设计路由表>为什么<code>Request-Reply</code>模式要设计路由表？<a hidden class=anchor aria-hidden=true href=#为什么request-reply模式要设计路由表>#</a></h5><blockquote><p>问题本质是<code>Push-Pull</code>模式直接用DP rank分组策略。而<code>MasterWorker</code>和<code>ModelWorker</code>之间的路由策略要设计特定的路由表。</p></blockquote><p>因为<code>RolloutWorker-ModelWorker</code>的数据流场景有以下特点：</p><ul><li>持续推送：RolloutWorker持续生成数据</li><li>负载均衡：只需要确保数据均匀分布</li><li>简单映射：一个RolloutWorker组对应一个ModelWorker</li><li>无状态：不需要跟踪具体的任务状态</li></ul><p>而控制流场景的特点是：</p><ul><li>精确控制：需要精确指定哪个ModelWorker执行哪个任务</li><li>复杂拓扑：模型可能有DP、TP、PP等多种并行维度</li><li>状态管理：需要跟踪请求-响应的状态</li><li>动态分配：任务可能需要根据负载动态分配</li></ul><p>核心还是<strong>复杂模型的并行拓扑问题</strong>，比如还有细粒度的模型分片(tp, pp)等，不是push-pull场景的1：N映射，而是复杂的N:M映射，还需要考虑拓扑、负载、依赖关系等。所以路由表可以确保：</p><ul><li>每个ModelShardID精确映射到对应的ModelWorker</li><li>支持一个ModelWorker承载多个模型分片</li><li>支持复杂的跨模型通信（如Actor-Critic架构）</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 路由表示例</span>
</span></span><span class=line><span class=cl><span class=n>handler_routing</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=c1># 模型分片ID -&gt; ModelWorker索引</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;ModelShardID(model_name=&#39;actor&#39;, dp_rank=0, tp_rank=0, pp_rank=0)&#34;</span><span class=p>:</span> <span class=mi>0</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;ModelShardID(model_name=&#39;actor&#39;, dp_rank=1, tp_rank=0, pp_rank=0)&#34;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 数据并行特殊路由</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;__data0__&#34;</span><span class=p>:</span> <span class=mi>0</span><span class=p>,</span>  <span class=c1># DP rank 0 -&gt; ModelWorker 0</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;__data1__&#34;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>  <span class=c1># DP rank 1 -&gt; ModelWorker 1</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 简单索引映射</span>
</span></span><span class=line><span class=cl>    <span class=mi>0</span><span class=p>:</span> <span class=mi>0</span><span class=p>,</span>  <span class=c1># ModelWorker 0</span>
</span></span><span class=line><span class=cl>    <span class=mi>1</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>  <span class=c1># ModelWorker 1</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><h5 id=不同并行场景下的路由表长什么样>不同并行场景下的路由表长什么样？<a hidden class=anchor aria-hidden=true href=#不同并行场景下的路由表长什么样>#</a></h5><p><strong>场景1：纯DP（dp=2）</strong><br>配置：</p><ul><li><p>2个ModelWorker</p></li><li><p>1种模型结构，DP=2</p></li><li><p>每个ModelWorker承载1个DP rank</p></li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>handler_routing</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=c1># 模型分片映射</span>
</span></span><span class=line><span class=cl>    <span class=n>ModelShardID</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&#34;actor&#34;</span><span class=p>,</span> <span class=n>dp</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>tp</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>pp</span><span class=o>=</span><span class=mi>0</span><span class=p>):</span> <span class=mi>0</span><span class=p>,</span>  <span class=c1># DP rank 0 -&gt; MW 0</span>
</span></span><span class=line><span class=cl>    <span class=n>ModelShardID</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&#34;actor&#34;</span><span class=p>,</span> <span class=n>dp</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>tp</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>pp</span><span class=o>=</span><span class=mi>0</span><span class=p>):</span> <span class=mi>1</span><span class=p>,</span>  <span class=c1># DP rank 1 -&gt; MW 1</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 数据路由映射</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;__data0__&#34;</span><span class=p>:</span> <span class=mi>0</span><span class=p>,</span>  <span class=c1># 数据0 -&gt; MW 0</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;__data1__&#34;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>  <span class=c1># 数据1 -&gt; MW 1</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 用于Worker间的直接通信</span>
</span></span><span class=line><span class=cl>    <span class=mi>0</span><span class=p>:</span> <span class=mi>0</span><span class=p>,</span>  <span class=c1># MW 0 -&gt; MW 0</span>
</span></span><span class=line><span class=cl>    <span class=mi>1</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>  <span class=c1># MW 1 -&gt; MW 1</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><p>特点：</p><ul><li><p>简单的1:1映射</p></li><li><p>每个ModelWorker独立处理一个DP rank</p></li><li><p>数据路由与模型分片路由一致</p></li></ul><p><strong>场景2: DP + TP （DP=2，TP=2）</strong><br>配置：</p><ul><li><p>4个ModelWorker</p></li><li><p>1种模型结构，DP=2, TP=2</p></li><li><p>每个ModelWorker承载1个模型分片</p></li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>handler_routing</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=c1># 模型分片映射 (DP=2, TP=2)</span>
</span></span><span class=line><span class=cl>    <span class=n>ModelShardID</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&#34;actor&#34;</span><span class=p>,</span> <span class=n>dp</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>tp</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>pp</span><span class=o>=</span><span class=mi>0</span><span class=p>):</span> <span class=mi>0</span><span class=p>,</span>  <span class=c1># (0,0) -&gt; MW 0 副本0的前半</span>
</span></span><span class=line><span class=cl>    <span class=n>ModelShardID</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&#34;actor&#34;</span><span class=p>,</span> <span class=n>dp</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>tp</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>pp</span><span class=o>=</span><span class=mi>0</span><span class=p>):</span> <span class=mi>1</span><span class=p>,</span>  <span class=c1># (0,1) -&gt; MW 1 副本0的后半</span>
</span></span><span class=line><span class=cl>    <span class=n>ModelShardID</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&#34;actor&#34;</span><span class=p>,</span> <span class=n>dp</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>tp</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>pp</span><span class=o>=</span><span class=mi>0</span><span class=p>):</span> <span class=mi>2</span><span class=p>,</span>  <span class=c1># (1,0) -&gt; MW 2 副本1的前半</span>
</span></span><span class=line><span class=cl>    <span class=n>ModelShardID</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&#34;actor&#34;</span><span class=p>,</span> <span class=n>dp</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>tp</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>pp</span><span class=o>=</span><span class=mi>0</span><span class=p>):</span> <span class=mi>3</span><span class=p>,</span>  <span class=c1># (1,1) -&gt; MW 3 副本1的后半</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 数据路由映射 (每个DP rank对应多个TP rank)</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;__data0__&#34;</span><span class=p>:</span> <span class=mi>0</span><span class=p>,</span>  <span class=c1># DP rank 0 的head -&gt; MW 0 (tp=0)</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;__data1__&#34;</span><span class=p>:</span> <span class=mi>2</span><span class=p>,</span>  <span class=c1># DP rank 1 的head -&gt; MW 2 (tp=0)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 直接索引映射</span>
</span></span><span class=line><span class=cl>    <span class=mi>0</span><span class=p>:</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>:</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>:</span> <span class=mi>3</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><ul><li><p>前向/反向时，MasterWorker会根据dp/tp/pp的rank，查找ModelShardID，路由到对应的worker（卡号）。</p></li><li><p>数据分发时，比如dp=0的数据，直接通过"<strong>data0</strong>&ldquo;路由到卡0（tp=0的head）；dp=1的数据路由到卡2。</p></li></ul><p>特点：</p><ul><li><p>每个DP rank有多个TP分片</p></li><li><p>数据路由指向每个DP rank的head (tp=0)</p></li><li><p>需要TP内部的通信协调</p></li></ul><p><strong>场景3：DP + TP + PP （DP=2, TP=2, PP=2）</strong><br>配置：</p><ul><li><p>8个ModelWorker</p></li><li><p>1种模型结构，DP=2, TP=2, PP=2</p></li><li><p>每个ModelWorker承载1个模型分片</p></li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>handler_routing</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=c1># 模型分片映射 (DP=2, TP=2, PP=2)</span>
</span></span><span class=line><span class=cl>    <span class=c1># PP=0</span>
</span></span><span class=line><span class=cl>    <span class=n>ModelShardID</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&#34;actor&#34;</span><span class=p>,</span> <span class=n>dp</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>tp</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>pp</span><span class=o>=</span><span class=mi>0</span><span class=p>):</span> <span class=mi>0</span><span class=p>,</span>  <span class=c1># (0,0,0) -&gt; MW 0</span>
</span></span><span class=line><span class=cl>    <span class=n>ModelShardID</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&#34;actor&#34;</span><span class=p>,</span> <span class=n>dp</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>tp</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>pp</span><span class=o>=</span><span class=mi>0</span><span class=p>):</span> <span class=mi>1</span><span class=p>,</span>  <span class=c1># (0,1,0) -&gt; MW 1</span>
</span></span><span class=line><span class=cl>    <span class=n>ModelShardID</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&#34;actor&#34;</span><span class=p>,</span> <span class=n>dp</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>tp</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>pp</span><span class=o>=</span><span class=mi>0</span><span class=p>):</span> <span class=mi>2</span><span class=p>,</span>  <span class=c1># (1,0,0) -&gt; MW 2</span>
</span></span><span class=line><span class=cl>    <span class=n>ModelShardID</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&#34;actor&#34;</span><span class=p>,</span> <span class=n>dp</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>tp</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>pp</span><span class=o>=</span><span class=mi>0</span><span class=p>):</span> <span class=mi>3</span><span class=p>,</span>  <span class=c1># (1,1,0) -&gt; MW 3</span>
</span></span><span class=line><span class=cl>    <span class=c1># PP=1 (最后一层)</span>
</span></span><span class=line><span class=cl>    <span class=n>ModelShardID</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&#34;actor&#34;</span><span class=p>,</span> <span class=n>dp</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>tp</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>pp</span><span class=o>=</span><span class=mi>1</span><span class=p>):</span> <span class=mi>4</span><span class=p>,</span>  <span class=c1># (0,0,1) -&gt; MW 4</span>
</span></span><span class=line><span class=cl>    <span class=n>ModelShardID</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&#34;actor&#34;</span><span class=p>,</span> <span class=n>dp</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>tp</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>pp</span><span class=o>=</span><span class=mi>1</span><span class=p>):</span> <span class=mi>5</span><span class=p>,</span>  <span class=c1># (0,1,1) -&gt; MW 5</span>
</span></span><span class=line><span class=cl>    <span class=n>ModelShardID</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&#34;actor&#34;</span><span class=p>,</span> <span class=n>dp</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>tp</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>pp</span><span class=o>=</span><span class=mi>1</span><span class=p>):</span> <span class=mi>6</span><span class=p>,</span>  <span class=c1># (1,0,1) -&gt; MW 6</span>
</span></span><span class=line><span class=cl>    <span class=n>ModelShardID</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&#34;actor&#34;</span><span class=p>,</span> <span class=n>dp</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>tp</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>pp</span><span class=o>=</span><span class=mi>1</span><span class=p>):</span> <span class=mi>7</span><span class=p>,</span>  <span class=c1># (1,1,1) -&gt; MW 7</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 数据路由映射 (每个dp组的head，通常pp=最后一层, tp=0)</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;__data0__&#34;</span><span class=p>:</span> <span class=mi>4</span><span class=p>,</span>  <span class=c1># DP rank 0 的最后一层 -&gt; MW 4 (pp=1, tp=0)</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;__data1__&#34;</span><span class=p>:</span> <span class=mi>6</span><span class=p>,</span>  <span class=c1># DP rank 1 的最后一层 -&gt; MW 6 (pp=1, tp=0)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 直接索引映射</span>
</span></span><span class=line><span class=cl>    <span class=mi>0</span><span class=p>:</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>:</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>:</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>:</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>:</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>:</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>:</span> <span class=mi>7</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><ul><li>模型函数调用：</li></ul><p>MasterWorker根据dp/tp/pp的rank，构造ModelShardID，查找handler_routing，路由到对应worker（卡号）。</p><ul><li><p>例如：要调度dp=1, tp=0, pp=1的分片，查找ModelShardID(dp=1, tp=0, pp=1)，得到worker id=6（卡6）。</p></li><li><p>数据分发：</p></li></ul><p>数据分发通常路由到每个dp组的“head”，即pp=最后一层、tp=0的分片。</p><ul><li><p>例如：dp=0的数据，查找&rdquo;<strong>data0</strong>"，得到worker id=4（卡4，dp=0, tp=0, pp=1）。</p></li><li><p>dp=1的数据，查找"<strong>data1</strong>"，得到worker id=6（卡6，dp=1, tp=0, pp=1）。</p></li></ul><p>特点：</p><ul><li><p>最复杂的3D并行拓扑</p></li><li><p>数据路由指向每个DP rank的最后一层 (pp=1)</p></li><li><p>需要PP内部的流水线协调</p></li></ul><p><strong>场景4：Actor-Critic架构 (DP=2)</strong><br>配置：</p><ul><li><p>2个ModelWorker</p></li><li><p>Actor和Critic两个模型结构，DP=2</p></li><li><p>每个ModelWorker承载Actor和Critic的同一个DP rank</p></li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>handler_routing</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=c1># Actor模型分片</span>
</span></span><span class=line><span class=cl>    <span class=n>ModelShardID</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&#34;actor&#34;</span><span class=p>,</span> <span class=n>dp</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>tp</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>pp</span><span class=o>=</span><span class=mi>0</span><span class=p>):</span> <span class=mi>0</span><span class=p>,</span>  <span class=c1># Actor DP=0 -&gt; MW 0</span>
</span></span><span class=line><span class=cl>    <span class=n>ModelShardID</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&#34;actor&#34;</span><span class=p>,</span> <span class=n>dp</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>tp</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>pp</span><span class=o>=</span><span class=mi>0</span><span class=p>):</span> <span class=mi>1</span><span class=p>,</span>  <span class=c1># Actor DP=1 -&gt; MW 1</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># Critic模型分片</span>
</span></span><span class=line><span class=cl>    <span class=n>ModelShardID</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&#34;critic&#34;</span><span class=p>,</span> <span class=n>dp</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>tp</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>pp</span><span class=o>=</span><span class=mi>0</span><span class=p>):</span> <span class=mi>0</span><span class=p>,</span>  <span class=c1># Critic DP=0 -&gt; MW 0</span>
</span></span><span class=line><span class=cl>    <span class=n>ModelShardID</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&#34;critic&#34;</span><span class=p>,</span> <span class=n>dp</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>tp</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>pp</span><span class=o>=</span><span class=mi>0</span><span class=p>):</span> <span class=mi>1</span><span class=p>,</span>  <span class=c1># Critic DP=1 -&gt; MW 1</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 数据路由映射 (Actor和Critic共享)</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;__data0__&#34;</span><span class=p>:</span> <span class=mi>0</span><span class=p>,</span>  <span class=c1># 数据0 -&gt; MW 0 (Actor和Critic的DP=0)</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;__data1__&#34;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>  <span class=c1># 数据1 -&gt; MW 1 (Actor和Critic的DP=1)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 直接索引映射</span>
</span></span><span class=line><span class=cl>    <span class=mi>0</span><span class=p>:</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><p>特点：</p><ul><li><p>一个ModelWorker承载多个模型</p></li><li><p>Actor和Critic共享相同的DP rank</p></li><li><p>支持模型间的参数同步</p></li></ul><h5 id=框架针对不同的拓扑是按照什么顺序切分的>框架针对不同的拓扑是按照什么顺序切分的？<a hidden class=anchor aria-hidden=true href=#框架针对不同的拓扑是按照什么顺序切分的>#</a></h5><blockquote><p>从路由表可以看到，3D并行下不同的切分顺序会影响卡和rank的映射，这个问题是一个分布式并行训练的基础问题，和框架的实现一起来理解。</p></blockquote><p>从代码中可以看到，AReaL框架使用固定的切分顺序：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># realhf/base/topology.py</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>ProcessTopology</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>axes</span><span class=p>,</span> <span class=n>dims</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># axes定义了切分顺序，dims定义了每个维度的切分大小</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>axes</span> <span class=o>=</span> <span class=n>axes</span>  <span class=c1># 切分顺序</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>dims</span> <span class=o>=</span> <span class=n>dims</span>  <span class=c1># 切分大小</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 训练时的拓扑</span>
</span></span><span class=line><span class=cl><span class=n>PipeDataTensorParallelTopology</span><span class=p>(</span><span class=n>axes</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;pipe&#39;</span><span class=p>,</span> <span class=s1>&#39;data&#39;</span><span class=p>,</span> <span class=s1>&#39;tensor&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 推理时的拓扑  </span>
</span></span><span class=line><span class=cl><span class=n>DataPipeTensorParallelTopology</span><span class=p>(</span><span class=n>axes</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;data&#39;</span><span class=p>,</span> <span class=s1>&#39;pipe&#39;</span><span class=p>,</span> <span class=s1>&#39;tensor&#39;</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><p>也就是训练和推理的切分拓扑不同。</p><p><strong>标准顺序：PP -> DP -> TP (训练时)</strong>：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 8张卡，DP=2, TP=2, PP=2</span>
</span></span><span class=line><span class=cl><span class=c1># 切分顺序：PP -&gt; DP -&gt; TP</span>
</span></span><span class=line><span class=cl><span class=n>rank</span> <span class=o>=</span> <span class=n>pp_rank</span> <span class=o>*</span> <span class=p>(</span><span class=n>dp_size</span> <span class=o>*</span> <span class=n>tp_size</span><span class=p>)</span> <span class=o>+</span> <span class=n>dp_rank</span> <span class=o>*</span> <span class=n>tp_size</span> <span class=o>+</span> <span class=n>tp_rank</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 映射结果：</span>
</span></span><span class=line><span class=cl><span class=c1># 卡0: pp=0, dp=0, tp=0  (rank=0)</span>
</span></span><span class=line><span class=cl><span class=c1># 卡1: pp=0, dp=0, tp=1  (rank=1)</span>
</span></span><span class=line><span class=cl><span class=c1># 卡2: pp=0, dp=1, tp=0  (rank=2)</span>
</span></span><span class=line><span class=cl><span class=c1># 卡3: pp=0, dp=1, tp=1  (rank=3)</span>
</span></span><span class=line><span class=cl><span class=c1># 卡4: pp=1, dp=0, tp=0  (rank=4)</span>
</span></span><span class=line><span class=cl><span class=c1># 卡5: pp=1, dp=0, tp=1  (rank=5)</span>
</span></span><span class=line><span class=cl><span class=c1># 卡6: pp=1, dp=1, tp=0  (rank=6)</span>
</span></span><span class=line><span class=cl><span class=c1># 卡7: pp=1, dp=1, tp=1  (rank=7)</span>
</span></span></code></pre></td></tr></table></div></div><p>原因：</p><ul><li><p>流水线友好：PP维度相邻的rank在物理上相邻，减少流水线通信开销</p></li><li><p>数据并行效率：同一PP stage内的DP rank可以高效进行AllReduce</p></li><li><p>内存局部性：同一PP stage的数据在内存上更接近</p></li></ul><p><strong>推理时：DP -> PP -> TP</strong>:<br>原因：</p><ul><li><p>数据分发友好：DP rank相邻，便于数据分发</p></li><li><p>推理并行：同一DP组内的PP rank可以并行处理不同batch</p></li><li><p>负载均衡：DP维度优先，便于负载均衡</p></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://pillumina.github.io/tags/framework/>Framework</a></li><li><a href=https://pillumina.github.io/tags/llm/>LLM</a></li><li><a href=https://pillumina.github.io/tags/rl/>RL</a></li></ul><nav class=paginav><a class=prev href=https://pillumina.github.io/posts/aiinfra/02-slime/><span class=title>« Prev</span><br><span>[RL4LLM] 异步RL框架: Slime</span>
</a><a class=next href=https://pillumina.github.io/posts/aiinfra/01-ascend-cloudmatrix/><span class=title>Next »</span><br><span>昇腾超节点CloudMatrix384论文拆解</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share [RL4LLM] 异步RL框架: Areal on x" href="https://x.com/intent/tweet/?text=%5bRL4LLM%5d%20%e5%bc%82%e6%ad%a5RL%e6%a1%86%e6%9e%b6%3a%20Areal&amp;url=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f03-areal%2f&amp;hashtags=framework%2cLLM%2cRL"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [RL4LLM] 异步RL框架: Areal on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f03-areal%2f&amp;title=%5bRL4LLM%5d%20%e5%bc%82%e6%ad%a5RL%e6%a1%86%e6%9e%b6%3a%20Areal&amp;summary=%5bRL4LLM%5d%20%e5%bc%82%e6%ad%a5RL%e6%a1%86%e6%9e%b6%3a%20Areal&amp;source=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f03-areal%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [RL4LLM] 异步RL框架: Areal on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f03-areal%2f&title=%5bRL4LLM%5d%20%e5%bc%82%e6%ad%a5RL%e6%a1%86%e6%9e%b6%3a%20Areal"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [RL4LLM] 异步RL框架: Areal on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f03-areal%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [RL4LLM] 异步RL框架: Areal on whatsapp" href="https://api.whatsapp.com/send?text=%5bRL4LLM%5d%20%e5%bc%82%e6%ad%a5RL%e6%a1%86%e6%9e%b6%3a%20Areal%20-%20https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f03-areal%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [RL4LLM] 异步RL框架: Areal on telegram" href="https://telegram.me/share/url?text=%5bRL4LLM%5d%20%e5%bc%82%e6%ad%a5RL%e6%a1%86%e6%9e%b6%3a%20Areal&amp;url=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f03-areal%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [RL4LLM] 异步RL框架: Areal on ycombinator" href="https://news.ycombinator.com/submitlink?t=%5bRL4LLM%5d%20%e5%bc%82%e6%ad%a5RL%e6%a1%86%e6%9e%b6%3a%20Areal&u=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f03-areal%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul><div class=related-posts><div class=related-series><h3>同系列文章</h3><ul><li><a href=/posts/aiinfra/05-verl-params/>[VeRL] 参数速览</a>
<span class=meta>2025-08-14
· 6 min read</span></li><li><a href=/posts/aiinfra/02-slime/>[RL4LLM] 异步RL框架: Slime</a>
<span class=meta>2025-08-07
· 15 min read</span></li></ul></div><div class=related-tags><h3>相关文章</h3><ul><li><a href=/posts/aiinfra/05-verl-params/>[VeRL] 参数速览</a>
<span class=meta>2025-08-14
· 6 min read
· Tags: framework, LLM, RL</span></li><li><a href=/posts/aiinfra/02-slime/>[RL4LLM] 异步RL框架: Slime</a>
<span class=meta>2025-08-07
· 15 min read
· Tags: framework, LLM, RL</span></li></ul></div></div></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://pillumina.github.io/>CctoctoFX</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg></a><div class=reading-progress-bar></div><script src=https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js></script><script>document.addEventListener("DOMContentLoaded",function(){const t=document.querySelector(".reading-progress-bar");if(!t)return;const n=document.querySelector(".post-single");if(!n)return;function s(){const e=n.getBoundingClientRect(),s=e.height,o=window.innerHeight,i=window.scrollY||window.pageYOffset,a=i/(s-o)*100;t.style.width=`${Math.min(100,Math.max(0,a))}%`}let e=!1;window.addEventListener("scroll",function(){e||(window.requestAnimationFrame(function(){s(),e=!1}),e=!0)}),s()}),document.addEventListener("DOMContentLoaded",function(){mediumZoom("article img:not(.nozoom)",{margin:24,background:"var(--theme)",scrollOffset:0})})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>