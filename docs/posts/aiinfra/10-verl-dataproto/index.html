<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[VeRL] DataProto介绍 | CctoctoFX</title><meta name=keywords content="framework,verl"><meta name=description content='Verl DataProto 实现原理与数据流动分析
目录

1. 概述
2. DataProto 核心架构
3. HybridFlow 设计理念
4. 控制流与计算流分离
5. 数据流动机制
6. Dispatch 模式详解
7. 性能优化策略
8. 总结

1. 概述
Verl 是一个基于 HybridFlow 论文的开源强化学习训练框架，专门为大语言模型的后训练优化而设计。其核心创新在于将控制流和计算流分离，通过 DataProto 协议实现高效的数据交换。
2. DataProto 核心架构
2.1 数据结构设计
DataProto 是 verl 框架中用于数据交换的核心协议，所有在 Worker 之间流转的数据，都被统一封装在一个名为 DataProto 的数据结构中。它不仅仅是一个字典，更承载着 RLHF 流程中所有的信息演变, 基于 PyTorch 的 TensorDict 构建：


1
2
3
4
5


@dataclass
class DataProto:
    batch: TensorDict = None              # 张量数据容器
    non_tensor_batch: dict = field(default_factory=dict)  # 非张量数据
    meta_info: dict = field(default_factory=dict)         # 元信息


核心特性：

统一接口: 提供标准化的数据容器，支持张量和非张量数据
设备管理: 自动处理 GPU/CPU 设备间的数据移动
内存优化: 支持分块处理和内存复用
序列化: 支持高效的序列化和反序列化

2.2 数据一致性检查


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14


def check_consistency(self):
    """检查 DataProto 的一致性"""
    if self.batch is not None:
        assert len(self.batch.batch_size) == 1, "只支持 num_batch_dims=1"
    
    if self.non_tensor_batch is not None:
        for key, val in self.non_tensor_batch.items():
            assert isinstance(val, np.ndarray)
            
    # 检查批次大小一致性
    if self.batch is not None and self.non_tensor_batch is not None:
        batch_size = self.batch.batch_size[0]
        for key, val in self.non_tensor_batch.items():
            assert val.shape[0] == batch_size


3. HybridFlow 设计理念
3.1 设计动机
传统 RL 系统面临的问题：'><meta name=author content="Me"><link rel=canonical href=https://pillumina.github.io/posts/aiinfra/10-verl-dataproto/><link crossorigin=anonymous href=/assets/css/stylesheet.9d388901283682bb45dd422fcaa0d0a2054a3c8ff47c9cc6b2baab15508b1b90.css integrity="sha256-nTiJASg2grtF3UIvyqDQogVKPI/0fJzGsrqrFVCLG5A=" rel="preload stylesheet" as=style><link rel=icon href=https://pillumina.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://pillumina.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://pillumina.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://pillumina.github.io/apple-touch-icon.png><link rel=mask-icon href=https://pillumina.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://pillumina.github.io/posts/aiinfra/10-verl-dataproto/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js crossorigin=anonymous></script><script>(function(){function t(){return document.querySelector(".post-content")||document.querySelector(".post-single")||document.body}function n(e){return/\$\$[\s\S]+?\$\$|\\\(|\\\)|\\\[|\\\]/.test(e)}function s(e){if(window.__mathjaxLoaded)return;window.__mathjaxLoaded=!0,window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code","tt"],ignoreHtmlClass:"no-math"}};var t=document.createElement("script");t.src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js",t.defer=!0,t.onload=function(){window.MathJax&&window.MathJax.typesetPromise&&window.MathJax.typesetPromise([e]).catch(function(e){console.warn("MathJax typeset error",e)})},document.head.appendChild(t)}function e(){try{if(typeof renderMathInElement=="function"){const e=t();renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\[",right:"\\]",display:!0},{left:"\\(",right:"\\)",display:!1}],throwOnError:!1,strict:!1,trust:!0,ignoredTags:["script","noscript","style","textarea","pre","code","tt"],ignoredClasses:["no-math"],macros:{"\\boldsymbol":"\\mathbf{#1}","\\bm":"\\mathbf{#1}"}}),setTimeout(function(){n(e.innerHTML)&&s(e)},200)}}catch(e){console.warn("KaTeX render error:",e)}}document.addEventListener("DOMContentLoaded",function(){e(),setTimeout(e,200)}),window.addEventListener("load",function(){setTimeout(e,0)})})()</script><script src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script><script>const config={startOnLoad:!0,theme:"neutral",themeVariables:{lineColor:"#0f0f0f"},flowchart:{useMaxWidth:!1,htmlLabels:!0}};mermaid.initialize(config),window.onload=()=>{window.mermaid.init(0[0],document.querySelectorAll(".language-mermaid"))}</script><link rel=stylesheet href=/css/custom.min.bda7229c4269a242639e058fb11a4782f02f8d77071ba16609befee67cc41c49.css integrity="sha256-vacinEJpokJjngWPsRpHgvAvjXcHG6FmCb7+5nzEHEk="><script>document.addEventListener("DOMContentLoaded",function(){const t=document.querySelectorAll("h1[id], h2[id], h3[id], h4[id], h5[id], h6[id]"),n=document.querySelectorAll(".toc a");if(t.length===0||n.length===0)return;const s={};t.forEach(e=>{s[e.id]=e.offsetTop});function i(){const t=window.scrollY+100;let e="";for(const[n,o]of Object.entries(s))if(t>=o)e=n;else break;return e}function o(){const e=i();if(n.forEach(e=>{e.classList.remove("active")}),e){const t=document.querySelector(`.toc a[href="#${e}"]`);t&&t.classList.add("active")}}let e=!1;window.addEventListener("scroll",function(){e||(window.requestAnimationFrame(function(){o(),e=!1}),e=!0)}),o()})</script><meta property="og:url" content="https://pillumina.github.io/posts/aiinfra/10-verl-dataproto/"><meta property="og:site_name" content="CctoctoFX"><meta property="og:title" content="[VeRL] DataProto介绍"><meta property="og:description" content='Verl DataProto 实现原理与数据流动分析 目录 1. 概述 2. DataProto 核心架构 3. HybridFlow 设计理念 4. 控制流与计算流分离 5. 数据流动机制 6. Dispatch 模式详解 7. 性能优化策略 8. 总结 1. 概述 Verl 是一个基于 HybridFlow 论文的开源强化学习训练框架，专门为大语言模型的后训练优化而设计。其核心创新在于将控制流和计算流分离，通过 DataProto 协议实现高效的数据交换。
2. DataProto 核心架构 2.1 数据结构设计 DataProto 是 verl 框架中用于数据交换的核心协议，所有在 Worker 之间流转的数据，都被统一封装在一个名为 DataProto 的数据结构中。它不仅仅是一个字典，更承载着 RLHF 流程中所有的信息演变, 基于 PyTorch 的 TensorDict 构建：
1 2 3 4 5 @dataclass class DataProto: batch: TensorDict = None # 张量数据容器 non_tensor_batch: dict = field(default_factory=dict) # 非张量数据 meta_info: dict = field(default_factory=dict) # 元信息 核心特性：
统一接口: 提供标准化的数据容器，支持张量和非张量数据 设备管理: 自动处理 GPU/CPU 设备间的数据移动 内存优化: 支持分块处理和内存复用 序列化: 支持高效的序列化和反序列化 2.2 数据一致性检查 1 2 3 4 5 6 7 8 9 10 11 12 13 14 def check_consistency(self): """检查 DataProto 的一致性""" if self.batch is not None: assert len(self.batch.batch_size) == 1, "只支持 num_batch_dims=1" if self.non_tensor_batch is not None: for key, val in self.non_tensor_batch.items(): assert isinstance(val, np.ndarray) # 检查批次大小一致性 if self.batch is not None and self.non_tensor_batch is not None: batch_size = self.batch.batch_size[0] for key, val in self.non_tensor_batch.items(): assert val.shape[0] == batch_size 3. HybridFlow 设计理念 3.1 设计动机 传统 RL 系统面临的问题：'><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-08-25T11:30:12+08:00"><meta property="article:modified_time" content="2025-08-25T11:30:12+08:00"><meta property="article:tag" content="Framework"><meta property="article:tag" content="Verl"><meta property="og:image" content="https://pillumina.github.io/imgs/icon_head.png"><meta property="og:see_also" content="https://pillumina.github.io/posts/aiinfra/09-verl-agentloop/"><meta property="og:see_also" content="https://pillumina.github.io/posts/aiinfra/05-verl-params/"><meta property="og:see_also" content="https://pillumina.github.io/posts/aiinfra/08-verl-multiturn-2/"><meta property="og:see_also" content="https://pillumina.github.io/posts/aiinfra/07-verl-multiturn-1/"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://pillumina.github.io/imgs/icon_head.png"><meta name=twitter:title content="[VeRL] DataProto介绍"><meta name=twitter:description content='Verl DataProto 实现原理与数据流动分析
目录

1. 概述
2. DataProto 核心架构
3. HybridFlow 设计理念
4. 控制流与计算流分离
5. 数据流动机制
6. Dispatch 模式详解
7. 性能优化策略
8. 总结

1. 概述
Verl 是一个基于 HybridFlow 论文的开源强化学习训练框架，专门为大语言模型的后训练优化而设计。其核心创新在于将控制流和计算流分离，通过 DataProto 协议实现高效的数据交换。
2. DataProto 核心架构
2.1 数据结构设计
DataProto 是 verl 框架中用于数据交换的核心协议，所有在 Worker 之间流转的数据，都被统一封装在一个名为 DataProto 的数据结构中。它不仅仅是一个字典，更承载着 RLHF 流程中所有的信息演变, 基于 PyTorch 的 TensorDict 构建：


1
2
3
4
5


@dataclass
class DataProto:
    batch: TensorDict = None              # 张量数据容器
    non_tensor_batch: dict = field(default_factory=dict)  # 非张量数据
    meta_info: dict = field(default_factory=dict)         # 元信息


核心特性：

统一接口: 提供标准化的数据容器，支持张量和非张量数据
设备管理: 自动处理 GPU/CPU 设备间的数据移动
内存优化: 支持分块处理和内存复用
序列化: 支持高效的序列化和反序列化

2.2 数据一致性检查


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14


def check_consistency(self):
    """检查 DataProto 的一致性"""
    if self.batch is not None:
        assert len(self.batch.batch_size) == 1, "只支持 num_batch_dims=1"
    
    if self.non_tensor_batch is not None:
        for key, val in self.non_tensor_batch.items():
            assert isinstance(val, np.ndarray)
            
    # 检查批次大小一致性
    if self.batch is not None and self.non_tensor_batch is not None:
        batch_size = self.batch.batch_size[0]
        for key, val in self.non_tensor_batch.items():
            assert val.shape[0] == batch_size


3. HybridFlow 设计理念
3.1 设计动机
传统 RL 系统面临的问题：'><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://pillumina.github.io/posts/"},{"@type":"ListItem","position":2,"name":"AI Infra","item":"https://pillumina.github.io/posts/aiinfra/"},{"@type":"ListItem","position":3,"name":"[VeRL] DataProto介绍","item":"https://pillumina.github.io/posts/aiinfra/10-verl-dataproto/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[VeRL] DataProto介绍","name":"[VeRL] DataProto介绍","description":"Verl DataProto 实现原理与数据流动分析 目录 1. 概述 2. DataProto 核心架构 3. HybridFlow 设计理念 4. 控制流与计算流分离 5. 数据流动机制 6. Dispatch 模式详解 7. 性能优化策略 8. 总结 1. 概述 Verl 是一个基于 HybridFlow 论文的开源强化学习训练框架，专门为大语言模型的后训练优化而设计。其核心创新在于将控制流和计算流分离，通过 DataProto 协议实现高效的数据交换。\n2. DataProto 核心架构 2.1 数据结构设计 DataProto 是 verl 框架中用于数据交换的核心协议，所有在 Worker 之间流转的数据，都被统一封装在一个名为 DataProto 的数据结构中。它不仅仅是一个字典，更承载着 RLHF 流程中所有的信息演变, 基于 PyTorch 的 TensorDict 构建：\n1 2 3 4 5 @dataclass class DataProto: batch: TensorDict = None # 张量数据容器 non_tensor_batch: dict = field(default_factory=dict) # 非张量数据 meta_info: dict = field(default_factory=dict) # 元信息 核心特性：\n统一接口: 提供标准化的数据容器，支持张量和非张量数据 设备管理: 自动处理 GPU/CPU 设备间的数据移动 内存优化: 支持分块处理和内存复用 序列化: 支持高效的序列化和反序列化 2.2 数据一致性检查 1 2 3 4 5 6 7 8 9 10 11 12 13 14 def check_consistency(self): \u0026#34;\u0026#34;\u0026#34;检查 DataProto 的一致性\u0026#34;\u0026#34;\u0026#34; if self.batch is not None: assert len(self.batch.batch_size) == 1, \u0026#34;只支持 num_batch_dims=1\u0026#34; if self.non_tensor_batch is not None: for key, val in self.non_tensor_batch.items(): assert isinstance(val, np.ndarray) # 检查批次大小一致性 if self.batch is not None and self.non_tensor_batch is not None: batch_size = self.batch.batch_size[0] for key, val in self.non_tensor_batch.items(): assert val.shape[0] == batch_size 3. HybridFlow 设计理念 3.1 设计动机 传统 RL 系统面临的问题：\n","keywords":["framework","verl"],"articleBody":"Verl DataProto 实现原理与数据流动分析 目录 1. 概述 2. DataProto 核心架构 3. HybridFlow 设计理念 4. 控制流与计算流分离 5. 数据流动机制 6. Dispatch 模式详解 7. 性能优化策略 8. 总结 1. 概述 Verl 是一个基于 HybridFlow 论文的开源强化学习训练框架，专门为大语言模型的后训练优化而设计。其核心创新在于将控制流和计算流分离，通过 DataProto 协议实现高效的数据交换。\n2. DataProto 核心架构 2.1 数据结构设计 DataProto 是 verl 框架中用于数据交换的核心协议，所有在 Worker 之间流转的数据，都被统一封装在一个名为 DataProto 的数据结构中。它不仅仅是一个字典，更承载着 RLHF 流程中所有的信息演变, 基于 PyTorch 的 TensorDict 构建：\n1 2 3 4 5 @dataclass class DataProto: batch: TensorDict = None # 张量数据容器 non_tensor_batch: dict = field(default_factory=dict) # 非张量数据 meta_info: dict = field(default_factory=dict) # 元信息 核心特性：\n统一接口: 提供标准化的数据容器，支持张量和非张量数据 设备管理: 自动处理 GPU/CPU 设备间的数据移动 内存优化: 支持分块处理和内存复用 序列化: 支持高效的序列化和反序列化 2.2 数据一致性检查 1 2 3 4 5 6 7 8 9 10 11 12 13 14 def check_consistency(self): \"\"\"检查 DataProto 的一致性\"\"\" if self.batch is not None: assert len(self.batch.batch_size) == 1, \"只支持 num_batch_dims=1\" if self.non_tensor_batch is not None: for key, val in self.non_tensor_batch.items(): assert isinstance(val, np.ndarray) # 检查批次大小一致性 if self.batch is not None and self.non_tensor_batch is not None: batch_size = self.batch.batch_size[0] for key, val in self.non_tensor_batch.items(): assert val.shape[0] == batch_size 3. HybridFlow 设计理念 3.1 设计动机 传统 RL 系统面临的问题：\n耦合度高: 控制逻辑与计算实现紧密耦合 扩展性差: 难以支持不同的计算后端 复用困难: 算法逻辑难以在不同框架间复用 3.2 解决方案 HybridFlow 采用分离式设计：\ngraph TB\rsubgraph \"控制流 (Control Flow)\"\rA[RL算法逻辑] --\u003e B[训练循环控制]\rB --\u003e C[数据调度]\rC --\u003e D[结果收集]\rend\rsubgraph \"计算流 (Computation Flow)\"\rE[模型初始化] --\u003e F[前向传播]\rF --\u003e G[反向传播]\rG --\u003e H[参数更新]\rend\rD -.-\u003e|DataProto| E\rH -.-\u003e|DataProto| A\rstyle A fill:#4CAF50,stroke:#2E7D32,stroke-width:2px,color:#fff\rstyle E fill:#2196F3,stroke:#1565C0,stroke-width:2px,color:#fff\rstyle D fill:#FF9800,stroke:#E65100,stroke-width:2px,color:#fff\rstyle H fill:#9C27B0,stroke:#6A1B9A,stroke-width:2px,color:#fff 4. 控制流与计算流分离 4.1 控制流 (Control Flow) 控制流负责 RL 算法的核心逻辑，运行在单进程中：\n主要职责：\n训练循环管理 数据批次调度 算法参数控制 结果聚合分析 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class RayPPOTrainer: def fit(self): # 控制流：训练循环 for epoch in range(self.config.trainer.total_epochs): # 1. 数据准备 batch = self._get_training_batch() # 2. 分发到计算流 rollout_data = self.actor_rollout_wg.generate_sequences(batch) # 3. 收集结果 advantages = self._compute_advantages(rollout_data) # 4. 策略更新 self._update_policy(advantages) 4.2 计算流 (Computation Flow) 计算流负责神经网络计算，运行在多进程中：\n主要职责：\n模型前向/反向传播 梯度计算和参数更新 分布式同步 内存管理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @register(dispatch_mode=Dispatch.DP_COMPUTE_PROTO) def generate_sequences(self, data: DataProto) -\u003e DataProto: # 计算流：序列生成 with torch.no_grad(): # 1. 模型推理 outputs = self.model.generate( input_ids=data.batch[\"input_ids\"], attention_mask=data.batch[\"attention_mask\"] ) # 2. 返回结果 return DataProto( batch=TensorDict({ \"generated_ids\": outputs.sequences, \"log_probs\": outputs.log_probs }, batch_size=data.batch.batch_size), meta_info=data.meta_info ) 4.3 分离的优势 graph LR\rsubgraph \"优势分析\"\rA[软件复用性] --\u003e A1[控制流可复用]\rA --\u003e A2[计算流可复用]\rB[开发效率] --\u003e B1[单进程调试]\rB --\u003e B2[模块化开发]\rC[性能优化] --\u003e C1[独立优化]\rC --\u003e C2[灵活调度]\rend\rstyle A fill:#4CAF50,stroke:#2E7D32,stroke-width:2px,color:#fff\rstyle B fill:#2196F3,stroke:#1565C0,stroke-width:2px,color:#fff\rstyle C fill:#FF9800,stroke:#E65100,stroke-width:2px,color:#fff 5. 数据流动机制 在我们追踪 DataProto 在各个 Worker 之间的旅程之前，我们有必要先回答一个更根本的问题：第一个 DataProto 对象是如何诞生的？\n在 veRL 中，DataProto 的声明周期是：\nParquet 文件 -\u003e RLHFDataset -\u003e DataLoader -\u003e batch_dict -\u003e DataProto\nParquet 是 veRL 推荐的数据格式，通常包含 prompt 文本和相关元信息。RLHFDataset 负责读取本地或远程 Parquet 文件，按 max_prompt_length 过滤样本，并应用聊天模板格式化对话。随后，执行分词、填充、截断，将样本转为固定长度的张量。\nDataLoader 在 RayPPOTrainer 中创建，将处理后的样本组织成 batch，产出 batch_dict。\n此时，DataProto 登场。通过 DataProto.from_single_dict(batch_dict)，普通字典被封装为 veRL 内部统一的数据协议，正式进入 RLHF 流程。\n5.1 完整数据流动图 graph TD\rA[训练数据] --\u003e B[DataProto创建]\rB --\u003e C[RayPPOTrainer控制流]\rC --\u003e D[数据分发阶段]\rD --\u003e E[WorkerGroup.generate_sequences]\rE --\u003e F{Dispatch模式选择}\rF --\u003e|DP_COMPUTE_PROTO| G[数据并行分割]\rF --\u003e|ONE_TO_ALL| H[广播分发]\rF --\u003e|ALL_TO_ALL| I[全对全通信]\rG --\u003e J[分发到计算Worker]\rH --\u003e J\rI --\u003e J\rJ --\u003e K[ActorRolloutWorker]\rJ --\u003e L[CriticWorker] J --\u003e M[ReferenceWorker]\rK --\u003e N[序列生成计算]\rL --\u003e O[价值函数计算]\rM --\u003e P[参考策略计算]\rN --\u003e Q[DataProto结果收集]\rO --\u003e Q\rP --\u003e Q\rQ --\u003e R[优势函数计算]\rR --\u003e S[策略梯度更新]\rS --\u003e T[模型参数同步]\rT --\u003e U[下一轮训练]\rU --\u003e D\rstyle A fill:#E3F2FD,stroke:#1976D2,stroke-width:2px\rstyle B fill:#F3E5F5,stroke:#7B1FA2,stroke-width:2px\rstyle C fill:#E8F5E8,stroke:#388E3C,stroke-width:2px\rstyle Q fill:#FFF3E0,stroke:#F57C00,stroke-width:2px\rstyle T fill:#FCE4EC,stroke:#C2185B,stroke-width:2px\rstyle F fill:#E0F2F1,stroke:#00695C,stroke-width:2px 5.2 数据流动时间线 gantt\rtitle DataProto在分布式训练中的时间线\rdateFormat X\raxisFormat %s\rsection 数据准备阶段\r数据加载与预处理 :0, 3\rDataProto对象创建 :3, 4\rsection 分发阶段\r数据分割与调度 :4, 5\r网络传输与分发 :5, 7\rsection 计算阶段\rActor模型推理 :7, 12\rCritic价值计算 :7, 10\rReference策略计算 :7, 11\rsection 收集阶段\r结果收集与合并 :12, 14\r数据格式转换 :14, 15\rsection 更新阶段\r优势函数计算 :15, 16\r策略梯度更新 :16, 18\r模型参数同步 :18, 20 5.3 完整PPO训练角度追踪数据流动 下面我们将以一次 PPO 迭代为例，用一张 端到端的数据流图 来追踪 DataProto 的演变过程。\nRayPPOTrainer 的 fit() 循环从 train_dataloader 中取出一个 batch_dict。这个字典通常只包含 input_ids、attention_mask 等表示 prompt 的基本信息。这些信息被封装成第一个版本的 DataProto 对象。\n接下来进入到 PPO 的 生成 (Generation) 和 准备 (Preparation) 阶段。这个初生的 DataProto 开始了它的旅程，它被 RayPPOTrainer 依次（或并行地）发送给各个 Worker，每经过一个，就会被赋予新的信息。\n流经 RolloutWorker：DataProto v1 被发送去执行 generate_sequences。RolloutWorker 返回生成的 responses，并将其合并，形成 DataProto v2。\nDataProto v2 被同时发送给 RewardModelWorker, ActorWorker (执行 compute_log_prob), 和 CriticWorker (执行 compute_values)。\n这三个 Worker 并行地完成计算，各自返回自己的结果。RayPPOTrainer 将这些结果全部合并，形成了 DataProto v3。\n此时的 DataProto v3 已经包含了计算优势函数所需的所有输入。这个计算通常是轻量级的，因此 RayPPOTrainer 会在 Driver 进程本地 直接调用 compute_advantage 函数。\ncompute_advantage 函数会计算出 advantages 和 returns，并将其加入到数据中，至此，DataProto v4 已经准备好了。\n接下来 DataProto v4 被最后一次分发，分别发送给 ActorWorker 和 CriticWorker 的 update 方法。\nActorWorker 从中取出 advantages, old_log_probs 等信息，计算 PPO 损失并更新自己的权重。CriticWorker 从中取出 returns 作为学习目标，计算 MSE 损失并更新自己的权重。它们返回训练过程中的 metrics，标志着 DataProto 在本次迭代中的使命正式完成。\n6. Dispatch 模式详解 6.1 核心Dispatch模式 1 2 3 4 5 6 7 class Dispatch(DynamicEnum): RANK_ZERO = \"RANK_ZERO\" # 只在rank 0执行 ONE_TO_ALL = \"ONE_TO_ALL\" # 一对多广播 ALL_TO_ALL = \"ALL_TO_ALL\" # 全对全通信 DP_COMPUTE = \"DP_COMPUTE\" # 数据并行计算 DP_COMPUTE_PROTO = \"DP_COMPUTE_PROTO\" # DataProto数据并行 DP_COMPUTE_PROTO_WITH_FUNC = \"DP_COMPUTE_PROTO_WITH_FUNC\" # 带函数的DataProto并行 6.2 DP_COMPUTE_PROTO 实现 1 2 3 4 5 6 7 8 9 10 11 12 def dispatch_dp_compute_data_proto(worker_group, *args, **kwargs): \"\"\"DataProto数据并行分发\"\"\" # 自动分割DataProto到worker数量 splitted_args, splitted_kwargs = _split_args_kwargs_data_proto_with_auto_padding( worker_group.world_size, *args, **kwargs ) return splitted_args, splitted_kwargs def collect_dp_compute_data_proto(worker_group, output): \"\"\"DataProto数据并行收集\"\"\" output = collect_dp_compute(worker_group, output) return _concat_data_proto_or_future(output) 6.3 自动填充机制 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 def _split_args_kwargs_data_proto_with_auto_padding(chunks, *args, **kwargs): \"\"\"支持自动填充的数据分割\"\"\" data_proto_len = None padding_size = None def _padding_and_split_data(obj, chunks): nonlocal data_proto_len, padding_size if isinstance(obj, DataProto) and obj.is_padding_enabled(): if data_proto_len is None: data_proto_len = len(obj) padding_size = (chunks - (data_proto_len % chunks)) if (data_proto_len % chunks \u003e 0) else 0 obj.padding(padding_size=padding_size) return obj.chunk(chunks=chunks) # 处理所有参数 splitted_args = [_padding_and_split_data(arg, chunks) for arg in args] splitted_kwargs = {key: _padding_and_split_data(val, chunks) for key, val in kwargs.items()} return splitted_args, splitted_kwargs 6.4 Dispatch模式选择策略 graph TD\rA[方法调用] --\u003e B{检查register装饰器}\rB --\u003e|有装饰器| C[获取dispatch_mode]\rB --\u003e|无装饰器| D[使用默认模式]\rC --\u003e E{模式类型}\rE --\u003e|DP_COMPUTE_PROTO| F[数据并行处理]\rE --\u003e|ONE_TO_ALL| G[广播处理]\rE --\u003e|ALL_TO_ALL| H[全对全处理]\rF --\u003e I[分割DataProto]\rG --\u003e J[复制到所有Worker]\rH --\u003e K[直接分发]\rI --\u003e L[并行计算]\rJ --\u003e L\rK --\u003e L\rL --\u003e M[收集结果]\rM --\u003e N[合并DataProto]\rstyle A fill:#E3F2FD,stroke:#1976D2,stroke-width:2px\rstyle F fill:#E8F5E8,stroke:#388E3C,stroke-width:2px\rstyle G fill:#FFF3E0,stroke:#F57C00,stroke-width:2px\rstyle H fill:#F3E5F5,stroke:#7B1FA2,stroke-width:2px\rstyle N fill:#FCE4EC,stroke:#C2185B,stroke-width:2px 7. 性能优化策略 7.1 内存优化 分块处理:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def chunk(self, chunks: int) -\u003e list[\"DataProto\"]: \"\"\"将DataProto分割成多个块\"\"\" if self.batch is not None: batch_lst = self.batch.chunk(chunks=chunks, dim=0) else: batch_lst = [None for _ in range(chunks)] # 处理非张量数据 non_tensor_batch_lst = [{} for _ in range(chunks)] for key, val in self.non_tensor_batch.items(): non_tensor_lst = np.array_split(val, chunks) for i in range(chunks): non_tensor_batch_lst[i][key] = non_tensor_lst[i] return [type(self)(batch=batch_lst[i], non_tensor_batch=non_tensor_batch_lst[i], meta_info=self.meta_info) for i in range(chunks)] 内存复用:\n1 2 3 4 5 def to(self, device) -\u003e \"DataProto\": \"\"\"设备间数据移动\"\"\" if self.batch is not None: self.batch = self.batch.to(device) return self 7.2 异步执行 DataProtoFuture:\n1 2 3 4 5 6 7 8 9 10 11 12 13 @dataclass class DataProtoFuture: \"\"\"异步DataProto，避免阻塞控制流\"\"\" collect_fn: Callable futures: list[ray.ObjectRef] dispatch_fn: Callable = None def get(self): output = ray.get(self.futures) output = self.collect_fn(output) if self.dispatch_fn is not None: output = self.dispatch_fn(output) return output 7.3 流水线优化 graph LR\rsubgraph \"传统同步模式\"\rA1[生成] --\u003e B1[训练]\rB1 --\u003e C1[等待]\rC1 --\u003e A1\rend\rsubgraph \"verl异步模式\"\rA2[生成] --\u003e B2[训练]\rB2 --\u003e A2\rA2 -.-\u003e|异步| C2[并行执行]\rend\rstyle A1 fill:#FFCDD2,stroke:#D32F2F,stroke-width:2px\rstyle B1 fill:#FFCDD2,stroke:#D32F2F,stroke-width:2px\rstyle C1 fill:#FFCDD2,stroke:#D32F2F,stroke-width:2px\rstyle A2 fill:#C8E6C9,stroke:#388E3C,stroke-width:2px\rstyle B2 fill:#C8E6C9,stroke:#388E3C,stroke-width:2px\rstyle C2 fill:#C8E6C9,stroke:#388E3C,stroke-width:2px 7.4 网络优化 压缩传输:\n使用高效的序列化格式 支持数据压缩 批量传输减少网络开销 负载均衡:\n动态调整数据分发策略 监控网络延迟和带宽 自适应调整批次大小 8. 具体RL训练示例 8.1 PPO训练中的DataProto实例 让我们通过一个具体的PPO训练过程来展示DataProto的实际使用：\n8.1.1 训练数据准备 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 # 原始训练数据 raw_data = { \"prompts\": [ \"请计算 15 + 27 = ?\", \"求解方程 2x + 5 = 13\", \"一个圆的半径是3，求面积\" ], \"responses\": [ \"15 + 27 = 42\", \"2x + 5 = 13\\nx = 4\", \"面积 = πr² = 9π\" ], \"rewards\": [0.8, 0.9, 0.7] } # 转换为DataProto def create_training_dataproto(raw_data): # 1. 文本编码 tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-7B-Instruct\") prompt_ids = [] response_ids = [] attention_masks = [] for prompt, response in zip(raw_data[\"prompts\"], raw_data[\"responses\"]): # 编码prompt prompt_tokens = tokenizer.encode(prompt, add_special_tokens=True) prompt_ids.append(prompt_tokens) # 编码response response_tokens = tokenizer.encode(response, add_special_tokens=False) response_ids.append(response_tokens) # 创建attention mask total_length = len(prompt_tokens) + len(response_tokens) attention_masks.append([1] * total_length) # 2. 填充到相同长度 max_length = max(len(p) + len(r) for p, r in zip(prompt_ids, response_ids)) padded_prompt_ids = [] padded_response_ids = [] padded_attention_masks = [] for p_ids, r_ids, mask in zip(prompt_ids, response_ids, attention_masks): # 填充prompt padded_p = p_ids + [tokenizer.pad_token_id] * (max_length - len(p_ids) - len(r_ids)) padded_prompt_ids.append(padded_p) # 填充response padded_r = r_ids + [tokenizer.pad_token_id] * (max_length - len(p_ids) - len(r_ids)) padded_response_ids.append(padded_r) # 更新attention mask padded_mask = mask + [0] * (max_length - len(mask)) padded_attention_masks.append(padded_mask) # 3. 创建DataProto training_dataproto = DataProto.from_dict( tensors={ \"prompt_ids\": torch.tensor(padded_prompt_ids, dtype=torch.long), \"response_ids\": torch.tensor(padded_response_ids, dtype=torch.long), \"attention_mask\": torch.tensor(padded_attention_masks, dtype=torch.long), }, non_tensors={ \"raw_prompts\": np.array(raw_data[\"prompts\"], dtype=object), \"raw_responses\": np.array(raw_data[\"responses\"], dtype=object), \"rewards\": np.array(raw_data[\"rewards\"], dtype=np.float32), }, meta_info={ \"dataset_name\": \"math_training\", \"batch_size\": len(raw_data[\"prompts\"]), \"max_length\": max_length, \"tokenizer_name\": \"Qwen/Qwen2.5-7B-Instruct\" } ) return training_dataproto # 创建训练数据 training_data = create_training_dataproto(raw_data) print(\"DataProto结构:\") print(training_data.get_data_info()) 输出示例：\nDataProto结构:\rbatch\rprompt_ids: (3, 512) (torch.int64) cuda:0\rresponse_ids: (3, 512) (torch.int64) cuda:0\rattention_mask: (3, 512) (torch.int64) cuda:0\rnon_tensor_batch\rraw_prompts: ndarray(3,) (object)\rraw_responses: ndarray(3,) (object)\rrewards: ndarray(3,) (float32)\rmeta_info\rdataset_name: str\rbatch_size: int\rmax_length: int\rtokenizer_name: str 8.1.2 数据分发过程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # 假设有4个GPU worker world_size = 4 batch_size = 3 # 原始DataProto original_dataproto = training_data # batch_size=3 # 自动填充到能被4整除的大小 padded_dataproto, pad_size = pad_dataproto_to_divisor(original_dataproto, world_size) # 现在padded_dataproto的batch_size=4 (填充了1个样本) # 分割成4个chunk chunks = padded_dataproto.chunk(chunks=world_size) print(f\"原始batch_size: {len(original_dataproto)}\") print(f\"填充后batch_size: {len(padded_dataproto)}\") print(f\"分割后chunk数量: {len(chunks)}\") print(f\"每个chunk的batch_size: {len(chunks[0])}\") # 分发到各个worker for i, chunk in enumerate(chunks): print(f\"Worker {i} 接收数据:\") print(f\" - prompt_ids shape: {chunk.batch['prompt_ids'].shape}\") print(f\" - 包含样本数: {len(chunk)}\") 8.2 控制流与计算流交互示例 8.2.1 控制流：PPO训练循环 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 class RayPPOTrainer: def __init__(self, config): self.config = config self.actor_rollout_wg = None # Actor和Rollout的WorkerGroup self.critic_wg = None # Critic的WorkerGroup self.ref_policy_wg = None # Reference Policy的WorkerGroup def fit(self): \"\"\"PPO训练的主控制循环\"\"\" for epoch in range(self.config.trainer.total_epochs): print(f\"开始第 {epoch} 轮训练\") # 1. 获取训练批次 batch_dataproto = self._get_training_batch() print(f\"获取训练批次，batch_size: {len(batch_dataproto)}\") # 2. 分发到Actor进行序列生成 print(\"开始序列生成...\") rollout_dataproto = self.actor_rollout_wg.generate_sequences(batch_dataproto) print(f\"序列生成完成，生成 {len(rollout_dataproto)} 个序列\") # 3. 分发到Critic计算价值 print(\"开始价值计算...\") value_dataproto = self.critic_wg.compute_values(rollout_dataproto) print(f\"价值计算完成\") # 4. 分发到Reference Policy计算log概率 print(\"开始参考策略计算...\") ref_log_prob_dataproto = self.ref_policy_wg.compute_log_probs(rollout_dataproto) print(f\"参考策略计算完成\") # 5. 在控制流中计算优势函数 print(\"计算优势函数...\") advantages = self._compute_advantages( rollout_dataproto, value_dataproto, ref_log_prob_dataproto ) # 6. 更新Actor策略 print(\"更新Actor策略...\") self.actor_rollout_wg.update_actor(advantages) # 7. 更新Critic价值网络 print(\"更新Critic价值网络...\") self.critic_wg.update_critic(advantages) print(f\"第 {epoch} 轮训练完成\\n\") def _get_training_batch(self): \"\"\"获取训练批次\"\"\" # 从数据集中采样 batch_data = { \"prompt_ids\": torch.randint(0, 1000, (self.config.data.train_batch_size, 512)), \"attention_mask\": torch.ones(self.config.data.train_batch_size, 512), } return DataProto.from_dict( tensors=batch_data, meta_info={\"epoch\": self.current_epoch} ) def _compute_advantages(self, rollout_data, value_data, ref_log_prob_data): \"\"\"计算优势函数 - 在控制流中执行\"\"\" # 从各个DataProto中提取数据 rewards = rollout_data.batch[\"rewards\"] # [batch_size, seq_len] values = value_data.batch[\"values\"] # [batch_size, seq_len] log_probs = rollout_data.batch[\"log_probs\"] # [batch_size, seq_len] ref_log_probs = ref_log_prob_data.batch[\"log_probs\"] # [batch_size, seq_len] # 计算优势函数 advantages = rewards - values advantages = advantages * rollout_data.batch[\"attention_mask\"] # 计算策略比率 log_ratio = log_probs - ref_log_probs ratio = torch.exp(log_ratio) # 创建优势DataProto advantages_dataproto = DataProto.from_dict( tensors={ \"advantages\": advantages, \"ratio\": ratio, \"rewards\": rewards, \"values\": values }, meta_info=rollout_data.meta_info ) return advantages_dataproto 8.2.2 计算流：Worker实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 @ray.remote class ActorRolloutWorker: def __init__(self, model_config): self.model = None self.config = model_config @register(dispatch_mode=Dispatch.DP_COMPUTE_PROTO) def generate_sequences(self, data: DataProto) -\u003e DataProto: \"\"\"生成序列 - 在计算流中执行\"\"\" print(f\"Worker {self.rank} 开始生成序列，batch_size: {len(data)}\") # 1. 模型推理 with torch.no_grad(): input_ids = data.batch[\"prompt_ids\"] attention_mask = data.batch[\"attention_mask\"] # 生成序列 outputs = self.model.generate( input_ids=input_ids, attention_mask=attention_mask, max_new_tokens=256, do_sample=True, temperature=0.7, return_dict_in_generate=True, output_scores=True ) # 提取生成的token ids generated_ids = outputs.sequences log_probs = torch.stack(outputs.scores, dim=1).log_softmax(dim=-1) # 计算每个token的log概率 token_log_probs = [] for i, seq in enumerate(generated_ids): seq_log_probs = [] for j, token_id in enumerate(seq): if j \u003c len(log_probs[i]): seq_log_probs.append(log_probs[i][j][token_id].item()) token_log_probs.append(seq_log_probs) # 计算奖励（这里使用简单的长度奖励作为示例） rewards = torch.tensor([[len(seq) * 0.1] * len(seq) for seq in generated_ids]) # 2. 创建结果DataProto result_dataproto = DataProto.from_dict( tensors={ \"generated_ids\": generated_ids, \"log_probs\": torch.tensor(token_log_probs), \"rewards\": rewards, \"attention_mask\": torch.ones_like(generated_ids) }, non_tensors={ \"raw_generated_texts\": np.array([ self.tokenizer.decode(seq, skip_special_tokens=True) for seq in generated_ids ], dtype=object) }, meta_info=data.meta_info ) print(f\"Worker {self.rank} 序列生成完成\") return result_dataproto @register(dispatch_mode=Dispatch.DP_COMPUTE_PROTO) def update_actor(self, advantages: DataProto) -\u003e None: \"\"\"更新Actor策略 - 在计算流中执行\"\"\" print(f\"Worker {self.rank} 开始更新Actor策略\") # 1. 提取数据 advantages_tensor = advantages.batch[\"advantages\"] ratio = advantages.batch[\"ratio\"] rewards = advantages.batch[\"rewards\"] # 2. 计算PPO损失 clip_ratio = 0.2 policy_loss_1 = -advantages_tensor * ratio policy_loss_2 = -advantages_tensor * torch.clamp(ratio, 1 - clip_ratio, 1 + clip_ratio) policy_loss = torch.maximum(policy_loss_1, policy_loss_2).mean() # 3. 反向传播 self.optimizer.zero_grad() policy_loss.backward() self.optimizer.step() print(f\"Worker {self.rank} Actor策略更新完成，损失: {policy_loss.item():.4f}\") @ray.remote class CriticWorker: def __init__(self, model_config): self.model = None self.config = model_config @register(dispatch_mode=Dispatch.DP_COMPUTE_PROTO) def compute_values(self, data: DataProto) -\u003e DataProto: \"\"\"计算价值函数 - 在计算流中执行\"\"\" print(f\"Worker {self.rank} 开始计算价值函数\") with torch.no_grad(): input_ids = data.batch[\"generated_ids\"] attention_mask = data.batch[\"attention_mask\"] # 前向传播计算价值 outputs = self.model(input_ids=input_ids, attention_mask=attention_mask) values = outputs.value # [batch_size, seq_len] # 创建价值DataProto value_dataproto = DataProto.from_dict( tensors={\"values\": values}, meta_info=data.meta_info ) print(f\"Worker {self.rank} 价值函数计算完成\") return value_dataproto 8.3 数据流动可视化 8.3.1 单轮训练的数据流动 sequenceDiagram\rparticipant CF as 控制流\rparticipant AW as ActorWorker\rparticipant CW as CriticWorker\rparticipant RW as RefWorker\rCF-\u003e\u003eCF: 创建训练DataProto\rNote over CF: batch_size=256, 包含prompt_ids等\rCF-\u003e\u003eAW: generate_sequences(training_data)\rNote over AW: 自动分割为64个样本/worker\rAW-\u003e\u003eAW: 模型推理生成序列\rAW-\u003e\u003eCF: 返回rollout_data\rNote over CF: 包含generated_ids, log_probs, rewards\rCF-\u003e\u003eCW: compute_values(rollout_data)\rCW-\u003e\u003eCW: 计算价值函数\rCW-\u003e\u003eCF: 返回value_data\rCF-\u003e\u003eRW: compute_log_probs(rollout_data)\rRW-\u003e\u003eRW: 计算参考策略log概率\rRW-\u003e\u003eCF: 返回ref_log_prob_data\rCF-\u003e\u003eCF: 计算优势函数\rNote over CF: advantages = rewards - values\rCF-\u003e\u003eAW: update_actor(advantages)\rCF-\u003e\u003eCW: update_critic(advantages)\rNote over CF: 完成一轮训练 8.3.2 DataProto在训练过程中的形态变化 graph LR\rsubgraph \"训练开始\"\rA1[原始训练数据prompt_ids, attention_maskbatch_size=256]\rend\rsubgraph \"序列生成后\"\rA2[rollout_datagenerated_ids, log_probs, rewardsbatch_size=256]\rend\rsubgraph \"价值计算后\"\rA3[value_datavaluesbatch_size=256]\rend\rsubgraph \"优势计算后\"\rA4[advantages_dataadvantages, ratiobatch_size=256]\rend\rA1 --\u003e A2\rA2 --\u003e A3\rA3 --\u003e A4\rstyle A1 fill:#E3F2FD,stroke:#1976D2,stroke-width:2px\rstyle A2 fill:#E8F5E8,stroke:#388E3C,stroke-width:2px\rstyle A3 fill:#FFF3E0,stroke:#F57C00,stroke-width:2px\rstyle A4 fill:#F3E5F5,stroke:#7B1FA2,stroke-width:2px 8.4 关键特性展示 8.4.1 自动填充机制 1 2 3 4 5 6 7 8 9 10 11 12 13 # 示例：batch_size=250, world_size=4 original_batch_size = 250 world_size = 4 # 计算需要填充的数量 padding_needed = (world_size - (original_batch_size % world_size)) % world_size # padding_needed = 2 # 填充后的batch_size = 252，可以被4整除 final_batch_size = original_batch_size + padding_needed # 252 # 每个worker获得 252 // 4 = 63 个样本 samples_per_worker = final_batch_size // world_size # 63 8.4.2 异步执行示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 控制流中的异步调用 def async_training_step(self): # 1. 异步生成序列 rollout_future = self.actor_rollout_wg.generate_sequences.remote(training_data) # 2. 控制流可以继续其他工作 print(\"序列生成正在进行中...\") # 3. 当需要结果时再等待 rollout_data = ray.get(rollout_future) print(\"序列生成完成\") # 4. 继续后续步骤 value_data = self.critic_wg.compute_values(rollout_data) 9. Ray集群中的物理数据流动 9.1 Ray集群物理架构 9.1.1 集群组成 graph TB\rsubgraph \"Head Node (主节点)\"\rA[Ray Head Process]\rB[Object Store]\rC[GCS - Global Control Service]\rD[Driver Process控制流]\rend\rsubgraph \"Worker Node 1\"\rE[Ray Worker Process 1]\rF[Object Store 1]\rG[ActorRolloutWorker 1]\rH[ActorRolloutWorker 2]\rend\rsubgraph \"Worker Node 2\"\rI[Ray Worker Process 2]\rJ[Object Store 2]\rK[CriticWorker 1]\rL[CriticWorker 2]\rend\rsubgraph \"Worker Node 3\"\rM[Ray Worker Process 3]\rN[Object Store 3]\rO[ReferenceWorker 1]\rP[ReferenceWorker 2]\rend\rA -.-\u003e|心跳| E\rA -.-\u003e|心跳| I\rA -.-\u003e|心跳| M\rD --\u003e|远程调用| G\rD --\u003e|远程调用| H\rD --\u003e|远程调用| K\rD --\u003e|远程调用| L\rD --\u003e|远程调用| O\rD --\u003e|远程调用| P\rB -.-\u003e|数据共享| F\rB -.-\u003e|数据共享| J\rB -.-\u003e|数据共享| N\rstyle A fill:#4CAF50,stroke:#2E7D32,stroke-width:2px,color:#fff\rstyle D fill:#2196F3,stroke:#1565C0,stroke-width:2px,color:#fff\rstyle G fill:#FF9800,stroke:#E65100,stroke-width:2px,color:#fff\rstyle K fill:#9C27B0,stroke:#6A1B9A,stroke-width:2px,color:#fff\rstyle O fill:#607D8B,stroke:#37474F,stroke-width:2px,color:#fff 9.1.2 Ray集群启动过程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # 1. 启动Head节点 ray start --head --port=6379 --dashboard-host=0.0.0.0 --dashboard-port=8265 # 2. 启动Worker节点 ray start --address='head_node_ip:6379' # 3. 在Driver中初始化集群 import ray ray.init(address='ray://head_node_ip:10001') # 4. 创建WorkerGroup resource_pool = RayResourcePool( process_on_nodes=[4, 4, 4], # 每个节点4个进程 use_gpu=True, max_colocate_count=1 ) # 5. 启动Worker进程 actor_rollout_wg = RayWorkerGroup( resource_pool=resource_pool, ray_cls_with_init=RayClassWithInitArgs(ActorRolloutWorker, config) ) 9.2 Ray Object Store 核心概念 在深入理解DataProto的物理传输过程之前，我们需要先了解Ray集群中的Object Store机制，这是数据在节点间传输的基础设施。\n9.2.1 Object Store 概述 Object Store是Ray分布式系统的核心组件，用于在集群节点间高效地存储和共享数据。它基于Apache Arrow的Plasma实现，提供了高性能的分布式内存存储。\ngraph TB\rsubgraph \"Head Node\"\rA[HeadStorePlasma Store] --\u003e B[共享内存池]\rA --\u003e C[元数据管理]\rA --\u003e D[对象引用表]\rend\rsubgraph \"Worker Node\"\rE[WorkerStorePlasma Store] --\u003e F[本地内存池]\rE --\u003e G[本地缓存]\rE --\u003e H[磁盘溢出]\rend\rA -.-\u003e|网络传输| E\rstyle A fill:#4CAF50,stroke:#2E7D32,stroke-width:2px,color:#fff\rstyle E fill:#FF9800,stroke:#E65100,stroke-width:2px,color:#fff 核心组件：\nHeadStore：Head节点上的Object Store，存储全局共享数据，管理元数据和对象引用 WorkerStore：Worker节点上的Object Store，存储本地计算数据，提供快速数据访问 工作原理：\n数据存储：通过ray.put()将数据存储到Object Store，返回ObjectRef 数据获取：通过ray.get(ObjectRef)从Object Store读取数据 内存管理：自动管理内存使用，支持磁盘溢出和垃圾回收 9.2.2 Object Store 在verl中的作用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # Object Store基本操作示例 import ray # 1. 存储DataProto到Object Store data_proto = DataProto.from_dict(tensors={\"input_ids\": torch.randn(256, 512)}) object_ref = ray.put(data_proto) # 存储到本地Object Store # 2. 发送ObjectRef到远程Worker @ray.remote def worker_function(ref): data = ray.get(ref) # 从Object Store获取数据 return process_data(data) # 3. 执行远程调用 future = worker_function.remote(object_ref) result = ray.get(future) 关键特性：\n序列化优化：自动处理DataProto的序列化和反序列化 内存共享：支持跨进程和跨节点的内存共享 网络传输：自动处理网络传输和错误恢复 性能优化：支持数据压缩和缓存机制 9.3 DataProto的物理传输过程 9.3.1 序列化与网络传输 sequenceDiagram\rparticipant D as Driver\rparticipant H as HeadStore\rparticipant W as Worker\rparticipant WS as WorkerStore\rparticipant A as Actor\rD-\u003e\u003eD: 创建DataProto\rNote over D: batch_size=256\rD-\u003e\u003eD: DataProto序列化\rNote over D: TensorDict序列化\rD-\u003e\u003eH: 存储序列化数据\rNote over H: 生成ObjectRef\rD-\u003e\u003eW: 发送ObjectRef\rNote over W: 方法调用\rW-\u003e\u003eH: 获取序列化数据\rH-\u003e\u003eW: 返回数据块\rW-\u003e\u003eW: DataProto反序列化\rNote over W: 重建TensorDict\rW-\u003e\u003eA: 调用generate_sequences\rA-\u003e\u003eA: 模型推理计算\rA-\u003e\u003eA: 创建结果DataProto\rA-\u003e\u003eW: 返回结果\rW-\u003e\u003eW: 结果序列化\rW-\u003e\u003eWS: 存储结果\rW-\u003e\u003eD: 返回ObjectRef\rD-\u003e\u003eWS: 获取结果数据\rD-\u003e\u003eD: 结果反序列化 9.3.2 数据序列化细节 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # DataProto的序列化过程 def __getstate__(self): \"\"\"序列化DataProto\"\"\" import io buffer = io.BytesIO() # 1. 序列化TensorDict if self.batch is not None: batch_to_save = self.batch.contiguous().consolidate() torch.save(batch_to_save, buffer) # 2. 序列化numpy数组和meta_info buffer_bytes = buffer.getvalue() return buffer_bytes, self.non_tensor_batch, self.meta_info def __setstate__(self, data): \"\"\"反序列化DataProto\"\"\" import io batch_deserialized_bytes, non_tensor_batch, meta_info = data # 1. 反序列化TensorDict batch_deserialized = io.BytesIO(initial_bytes=batch_deserialized_bytes) batch = torch.load(batch_deserialized, map_location=\"cpu\") # 2. 重建DataProto self.batch = batch self.non_tensor_batch = non_tensor_batch self.meta_info = meta_info 9.4 分布式数据流动架构 9.4.1 多节点数据分发 graph TD\rsubgraph \"Head Node\"\rA[Driver Process] --\u003e B[DataProto创建]\rB --\u003e C[序列化]\rC --\u003e D[Object Store]\rend\rsubgraph \"Worker Node 1\"\rE[Worker Process 1] --\u003e F[ActorRolloutWorker 1]\rE --\u003e G[ActorRolloutWorker 2]\rend\rsubgraph \"Worker Node 2\"\rH[Worker Process 2] --\u003e I[CriticWorker 1]\rH --\u003e J[CriticWorker 2]\rend\rsubgraph \"Worker Node 3\"\rK[Worker Process 3] --\u003e L[ReferenceWorker 1]\rK --\u003e M[ReferenceWorker 2]\rend\rD -.-\u003e|网络传输| E\rD -.-\u003e|网络传输| H\rD -.-\u003e|网络传输| K\rE --\u003e N[Object Store 1]\rH --\u003e O[Object Store 2]\rK --\u003e P[Object Store 3]\rN -.-\u003e|结果收集| D\rO -.-\u003e|结果收集| D\rP -.-\u003e|结果收集| D\rstyle A fill:#2196F3,stroke:#1565C0,stroke-width:2px,color:#fff\rstyle D fill:#4CAF50,stroke:#2E7D32,stroke-width:2px,color:#fff\rstyle F fill:#FF9800,stroke:#E65100,stroke-width:2px,color:#fff\rstyle I fill:#9C27B0,stroke:#6A1B9A,stroke-width:2px,color:#fff\rstyle L fill:#607D8B,stroke:#37474F,stroke-width:2px,color:#fff 9.4.2 数据并行分发过程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 # 实际的数据分发过程 def dispatch_dp_compute_data_proto(worker_group, *args, **kwargs): \"\"\"DataProto数据并行分发\"\"\" world_size = worker_group.world_size # 例如：8个worker # 1. 自动填充 data_proto = args[0] # 原始DataProto，batch_size=250 padded_data, pad_size = pad_dataproto_to_divisor(data_proto, world_size) # 现在padded_data的batch_size=256 (填充了6个样本) # 2. 分割数据 chunks = padded_data.chunk(chunks=world_size) # 每个chunk的batch_size=32 # 3. 分发到各个worker futures = [] for i, worker in enumerate(worker_group.workers): chunk = chunks[i] # 序列化chunk并通过Ray发送 future = worker.generate_sequences.remote(chunk) futures.append(future) return futures # 在物理层面的实际传输 def physical_data_transfer_example(): \"\"\"展示物理层面的数据传输\"\"\" # 原始数据大小 batch_size = 250 seq_len = 512 vocab_size = 32000 # 计算数据大小 prompt_ids_size = batch_size * seq_len * 4 # int32, bytes attention_mask_size = batch_size * seq_len * 4 # int32, bytes tensor_data_size = prompt_ids_size + attention_mask_size # ~2MB # 序列化开销 serialization_overhead = tensor_data_size * 0.1 # 约10%开销 # 网络传输 network_bandwidth = 10 * 1024 * 1024 # 10Gbps transfer_time = (tensor_data_size + serialization_overhead) / network_bandwidth print(f\"数据大小: {tensor_data_size / 1024 / 1024:.2f} MB\") print(f\"序列化开销: {serialization_overhead / 1024 / 1024:.2f} MB\") print(f\"传输时间: {transfer_time * 1000:.2f} ms\") 9.5 内存管理与对象存储 9.5.1 Ray Object Store架构 graph TB\rsubgraph \"Head Node Object Store\"\rA[Plasma Store] --\u003e B[内存池]\rA --\u003e C[共享内存]\rA --\u003e D[磁盘存储]\rend\rsubgraph \"Worker Node Object Store\"\rE[Plasma Store] --\u003e F[本地内存池]\rE --\u003e G[本地共享内存]\rE --\u003e H[本地磁盘缓存]\rend\rA -.-\u003e|网络传输| E\rsubgraph \"数据生命周期\"\rI[创建DataProto] --\u003e J[序列化]\rJ --\u003e K[存储到Object Store]\rK --\u003e L[生成ObjectRef]\rL --\u003e M[发送到Worker]\rM --\u003e N[Worker反序列化]\rN --\u003e O[计算处理]\rO --\u003e P[结果序列化]\rP --\u003e Q[存储结果]\rQ --\u003e R[返回ObjectRef]\rend\rstyle A fill:#4CAF50,stroke:#2E7D32,stroke-width:2px,color:#fff\rstyle E fill:#FF9800,stroke:#E65100,stroke-width:2px,color:#fff\rstyle I fill:#2196F3,stroke:#1565C0,stroke-width:2px,color:#fff\rstyle O fill:#9C27B0,stroke:#6A1B9A,stroke-width:2px,color:#fff 9.5.2 内存优化策略 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # 内存优化示例 class MemoryOptimizedDataProto: def __init__(self): self.object_refs = {} # 缓存ObjectRef def send_to_worker(self, data_proto, worker_id): \"\"\"优化的数据传输\"\"\" # 1. 检查是否已有缓存 cache_key = f\"{worker_id}_{hash(data_proto)}\" if cache_key in self.object_refs: return self.object_refs[cache_key] # 2. 序列化并存储 object_ref = ray.put(data_proto) self.object_refs[cache_key] = object_ref # 3. 发送到worker return object_ref def cleanup_cache(self): \"\"\"清理缓存\"\"\" for ref in self.object_refs.values(): ray.delete(ref) self.object_refs.clear() 9.6 网络拓扑与性能优化 9.6.1 网络拓扑图 graph TB\rsubgraph \"数据中心网络\"\rA[Head Node10Gbps] --\u003e B[Top of Rack Switch]\rB --\u003e C[Worker Node 110Gbps]\rB --\u003e D[Worker Node 210Gbps]\rB --\u003e E[Worker Node 310Gbps]\rB --\u003e F[Worker Node 410Gbps]\rend\rsubgraph \"节点内部\"\rC --\u003e G[GPU 0]\rC --\u003e H[GPU 1]\rC --\u003e I[GPU 2]\rC --\u003e J[GPU 3]\rend\rsubgraph \"数据流动路径\"\rK[Driver] --\u003e L[序列化]\rL --\u003e M[网络传输]\rM --\u003e N[Worker接收]\rN --\u003e O[反序列化]\rO --\u003e P[GPU计算]\rP --\u003e Q[结果序列化]\rQ --\u003e R[网络返回]\rR --\u003e S[Driver接收]\rend\rstyle A fill:#4CAF50,stroke:#2E7D32,stroke-width:2px,color:#fff\rstyle C fill:#FF9800,stroke:#E65100,stroke-width:2px,color:#fff\rstyle G fill:#2196F3,stroke:#1565C0,stroke-width:2px,color:#fff\rstyle K fill:#9C27B0,stroke:#6A1B9A,stroke-width:2px,color:#fff Verl 通过 DataProto 和 HybridFlow 设计，成功解决了大规模强化学习训练中的架构挑战，为LLM后训练提供了高效、灵活、可扩展的解决方案。\n","wordCount":"3513","inLanguage":"en","image":"https://pillumina.github.io/imgs/icon_head.png","datePublished":"2025-08-25T11:30:12+08:00","dateModified":"2025-08-25T11:30:12+08:00","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://pillumina.github.io/posts/aiinfra/10-verl-dataproto/"},"publisher":{"@type":"Organization","name":"CctoctoFX","logo":{"@type":"ImageObject","url":"https://pillumina.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://pillumina.github.io/ accesskey=h title="CctoctoFX (Alt + H)"><img src=https://pillumina.github.io/apple-touch-icon.png alt aria-label=logo height=30>CctoctoFX</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://pillumina.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://pillumina.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://pillumina.github.io/posts/aiinfra/ title="AI Infra"><span>AI Infra</span></a></li><li><a href=https://pillumina.github.io/posts/llmtheory/ title=Thoery><span>Thoery</span></a></li><li><a href=https://pillumina.github.io/posts/programming/ title=Programming><span>Programming</span></a></li><li><a href=https://pillumina.github.io/social/ title=Social><span>Social</span></a></li><li><a href=https://pillumina.github.io/open_courses/ title=Study><span>Study</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://pillumina.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://pillumina.github.io/posts/>Posts</a>&nbsp;»&nbsp;<a href=https://pillumina.github.io/posts/aiinfra/>AI Infra</a></div><h1 class="post-title entry-hint-parent">[VeRL] DataProto介绍</h1><div class=post-meta><span title='2025-08-25 11:30:12 +0800 CST'>August 25, 2025</span>&nbsp;·&nbsp;17 min&nbsp;·&nbsp;3513 words&nbsp;·&nbsp;Me</div></header><div class="toc side left"><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#目录>目录</a></li><li><a href=#1-概述>1. 概述</a></li><li><a href=#2-dataproto-核心架构>2. DataProto 核心架构</a><ul><li><a href=#21-数据结构设计>2.1 数据结构设计</a></li><li><a href=#22-数据一致性检查>2.2 数据一致性检查</a></li></ul></li><li><a href=#3-hybridflow-设计理念>3. HybridFlow 设计理念</a><ul><li><a href=#31-设计动机>3.1 设计动机</a></li><li><a href=#32-解决方案>3.2 解决方案</a></li></ul></li><li><a href=#4-控制流与计算流分离>4. 控制流与计算流分离</a><ul><li><a href=#41-控制流-control-flow>4.1 控制流 (Control Flow)</a></li><li><a href=#42-计算流-computation-flow>4.2 计算流 (Computation Flow)</a></li><li><a href=#43-分离的优势>4.3 分离的优势</a></li></ul></li><li><a href=#5-数据流动机制>5. 数据流动机制</a><ul><li><a href=#51-完整数据流动图>5.1 完整数据流动图</a></li><li><a href=#52-数据流动时间线>5.2 数据流动时间线</a></li><li><a href=#53-完整ppo训练角度追踪数据流动>5.3 完整PPO训练角度追踪数据流动</a></li></ul></li><li><a href=#6-dispatch-模式详解>6. Dispatch 模式详解</a><ul><li><a href=#61-核心dispatch模式>6.1 核心Dispatch模式</a></li><li><a href=#62-dp_compute_proto-实现>6.2 DP_COMPUTE_PROTO 实现</a></li><li><a href=#63-自动填充机制>6.3 自动填充机制</a></li><li><a href=#64-dispatch模式选择策略>6.4 Dispatch模式选择策略</a></li></ul></li><li><a href=#7-性能优化策略>7. 性能优化策略</a><ul><li><a href=#71-内存优化>7.1 内存优化</a></li><li><a href=#72-异步执行>7.2 异步执行</a></li><li><a href=#73-流水线优化>7.3 流水线优化</a></li><li><a href=#74-网络优化>7.4 网络优化</a></li></ul></li><li><a href=#8-具体rl训练示例>8. 具体RL训练示例</a><ul><li><a href=#81-ppo训练中的dataproto实例>8.1 PPO训练中的DataProto实例</a></li><li><a href=#82-控制流与计算流交互示例>8.2 控制流与计算流交互示例</a></li><li><a href=#83-数据流动可视化>8.3 数据流动可视化</a></li><li><a href=#84-关键特性展示>8.4 关键特性展示</a></li></ul></li><li><a href=#9-ray集群中的物理数据流动>9. Ray集群中的物理数据流动</a><ul><li><a href=#91-ray集群物理架构>9.1 Ray集群物理架构</a></li><li><a href=#92-ray-object-store-核心概念>9.2 Ray Object Store 核心概念</a></li><li><a href=#93-dataproto的物理传输过程>9.3 DataProto的物理传输过程</a></li><li><a href=#94-分布式数据流动架构>9.4 分布式数据流动架构</a></li><li><a href=#95-内存管理与对象存储>9.5 内存管理与对象存储</a></li><li><a href=#96-网络拓扑与性能优化>9.6 网络拓扑与性能优化</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h1 id=verl-dataproto-实现原理与数据流动分析>Verl DataProto 实现原理与数据流动分析<a hidden class=anchor aria-hidden=true href=#verl-dataproto-实现原理与数据流动分析>#</a></h1><h2 id=目录>目录<a hidden class=anchor aria-hidden=true href=#目录>#</a></h2><ul><li><a href=/posts/aiinfra/10-verl-dataproto/#1-%e6%a6%82%e8%bf%b0>1. 概述</a></li><li><a href=/posts/aiinfra/10-verl-dataproto/#2-dataproto-%e6%a0%b8%e5%bf%83%e6%9e%b6%e6%9e%84>2. DataProto 核心架构</a></li><li><a href=/posts/aiinfra/10-verl-dataproto/#3-hybridflow-%e8%ae%be%e8%ae%a1%e7%90%86%e5%bf%b5>3. HybridFlow 设计理念</a></li><li><a href=/posts/aiinfra/10-verl-dataproto/#4-%e6%8e%a7%e5%88%b6%e6%b5%81%e4%b8%8e%e8%ae%a1%e7%ae%97%e6%b5%81%e5%88%86%e7%a6%bb>4. 控制流与计算流分离</a></li><li><a href=/posts/aiinfra/10-verl-dataproto/#5-%e6%95%b0%e6%8d%ae%e6%b5%81%e5%8a%a8%e6%9c%ba%e5%88%b6>5. 数据流动机制</a></li><li><a href=/posts/aiinfra/10-verl-dataproto/#6-dispatch-%e6%a8%a1%e5%bc%8f%e8%af%a6%e8%a7%a3>6. Dispatch 模式详解</a></li><li><a href=/posts/aiinfra/10-verl-dataproto/#7-%e6%80%a7%e8%83%bd%e4%bc%98%e5%8c%96%e7%ad%96%e7%95%a5>7. 性能优化策略</a></li><li><a href=/posts/aiinfra/10-verl-dataproto/#8-%e6%80%bb%e7%bb%93>8. 总结</a></li></ul><h2 id=1-概述>1. 概述<a hidden class=anchor aria-hidden=true href=#1-概述>#</a></h2><p>Verl 是一个基于 HybridFlow 论文的开源强化学习训练框架，专门为大语言模型的后训练优化而设计。其核心创新在于将控制流和计算流分离，通过 DataProto 协议实现高效的数据交换。</p><h2 id=2-dataproto-核心架构>2. DataProto 核心架构<a hidden class=anchor aria-hidden=true href=#2-dataproto-核心架构>#</a></h2><h3 id=21-数据结构设计>2.1 数据结构设计<a hidden class=anchor aria-hidden=true href=#21-数据结构设计>#</a></h3><p>DataProto 是 verl 框架中用于数据交换的核心协议，所有在 Worker 之间流转的数据，都被统一封装在一个名为 DataProto 的数据结构中。它不仅仅是一个字典，更承载着 RLHF 流程中所有的信息演变, 基于 PyTorch 的 TensorDict 构建：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@dataclass</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>DataProto</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>batch</span><span class=p>:</span> <span class=n>TensorDict</span> <span class=o>=</span> <span class=kc>None</span>              <span class=c1># 张量数据容器</span>
</span></span><span class=line><span class=cl>    <span class=n>non_tensor_batch</span><span class=p>:</span> <span class=nb>dict</span> <span class=o>=</span> <span class=n>field</span><span class=p>(</span><span class=n>default_factory</span><span class=o>=</span><span class=nb>dict</span><span class=p>)</span>  <span class=c1># 非张量数据</span>
</span></span><span class=line><span class=cl>    <span class=n>meta_info</span><span class=p>:</span> <span class=nb>dict</span> <span class=o>=</span> <span class=n>field</span><span class=p>(</span><span class=n>default_factory</span><span class=o>=</span><span class=nb>dict</span><span class=p>)</span>         <span class=c1># 元信息</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>核心特性：</strong></p><ul><li><strong>统一接口</strong>: 提供标准化的数据容器，支持张量和非张量数据</li><li><strong>设备管理</strong>: 自动处理 GPU/CPU 设备间的数据移动</li><li><strong>内存优化</strong>: 支持分块处理和内存复用</li><li><strong>序列化</strong>: 支持高效的序列化和反序列化</li></ul><h3 id=22-数据一致性检查>2.2 数据一致性检查<a hidden class=anchor aria-hidden=true href=#22-数据一致性检查>#</a></h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>check_consistency</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;检查 DataProto 的一致性&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>batch</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>assert</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>batch</span><span class=o>.</span><span class=n>batch_size</span><span class=p>)</span> <span class=o>==</span> <span class=mi>1</span><span class=p>,</span> <span class=s2>&#34;只支持 num_batch_dims=1&#34;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>non_tensor_batch</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>key</span><span class=p>,</span> <span class=n>val</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>non_tensor_batch</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=k>assert</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>val</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>    <span class=c1># 检查批次大小一致性</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>batch</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span> <span class=ow>and</span> <span class=bp>self</span><span class=o>.</span><span class=n>non_tensor_batch</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>batch_size</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>batch</span><span class=o>.</span><span class=n>batch_size</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>key</span><span class=p>,</span> <span class=n>val</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>non_tensor_batch</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=k>assert</span> <span class=n>val</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>==</span> <span class=n>batch_size</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=3-hybridflow-设计理念>3. HybridFlow 设计理念<a hidden class=anchor aria-hidden=true href=#3-hybridflow-设计理念>#</a></h2><h3 id=31-设计动机>3.1 设计动机<a hidden class=anchor aria-hidden=true href=#31-设计动机>#</a></h3><p>传统 RL 系统面临的问题：</p><ul><li><strong>耦合度高</strong>: 控制逻辑与计算实现紧密耦合</li><li><strong>扩展性差</strong>: 难以支持不同的计算后端</li><li><strong>复用困难</strong>: 算法逻辑难以在不同框架间复用</li></ul><h3 id=32-解决方案>3.2 解决方案<a hidden class=anchor aria-hidden=true href=#32-解决方案>#</a></h3><p>HybridFlow 采用分离式设计：</p><pre class=mermaid>
  graph TB
    subgraph &#34;控制流 (Control Flow)&#34;
        A[RL算法逻辑] --&gt; B[训练循环控制]
        B --&gt; C[数据调度]
        C --&gt; D[结果收集]
    end
    
    subgraph &#34;计算流 (Computation Flow)&#34;
        E[模型初始化] --&gt; F[前向传播]
        F --&gt; G[反向传播]
        G --&gt; H[参数更新]
    end
    
    D -.-&gt;|DataProto| E
    H -.-&gt;|DataProto| A
    
    style A fill:#4CAF50,stroke:#2E7D32,stroke-width:2px,color:#fff
    style E fill:#2196F3,stroke:#1565C0,stroke-width:2px,color:#fff
    style D fill:#FF9800,stroke:#E65100,stroke-width:2px,color:#fff
    style H fill:#9C27B0,stroke:#6A1B9A,stroke-width:2px,color:#fff
</pre><h2 id=4-控制流与计算流分离>4. 控制流与计算流分离<a hidden class=anchor aria-hidden=true href=#4-控制流与计算流分离>#</a></h2><h3 id=41-控制流-control-flow>4.1 控制流 (Control Flow)<a hidden class=anchor aria-hidden=true href=#41-控制流-control-flow>#</a></h3><p>控制流负责 RL 算法的核心逻辑，运行在单进程中：</p><p><strong>主要职责：</strong></p><ul><li>训练循环管理</li><li>数据批次调度</li><li>算法参数控制</li><li>结果聚合分析</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>RayPPOTrainer</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>fit</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 控制流：训练循环</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>total_epochs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=c1># 1. 数据准备</span>
</span></span><span class=line><span class=cl>            <span class=n>batch</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_get_training_batch</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 2. 分发到计算流</span>
</span></span><span class=line><span class=cl>            <span class=n>rollout_data</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>actor_rollout_wg</span><span class=o>.</span><span class=n>generate_sequences</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 3. 收集结果</span>
</span></span><span class=line><span class=cl>            <span class=n>advantages</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_compute_advantages</span><span class=p>(</span><span class=n>rollout_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 4. 策略更新</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>_update_policy</span><span class=p>(</span><span class=n>advantages</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=42-计算流-computation-flow>4.2 计算流 (Computation Flow)<a hidden class=anchor aria-hidden=true href=#42-计算流-computation-flow>#</a></h3><p>计算流负责神经网络计算，运行在多进程中：</p><p><strong>主要职责：</strong></p><ul><li>模型前向/反向传播</li><li>梯度计算和参数更新</li><li>分布式同步</li><li>内存管理</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@register</span><span class=p>(</span><span class=n>dispatch_mode</span><span class=o>=</span><span class=n>Dispatch</span><span class=o>.</span><span class=n>DP_COMPUTE_PROTO</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>generate_sequences</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>data</span><span class=p>:</span> <span class=n>DataProto</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>DataProto</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># 计算流：序列生成</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=c1># 1. 模型推理</span>
</span></span><span class=line><span class=cl>        <span class=n>outputs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>input_ids</span><span class=o>=</span><span class=n>data</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;input_ids&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>            <span class=n>attention_mask</span><span class=o>=</span><span class=n>data</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;attention_mask&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 2. 返回结果</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>DataProto</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>batch</span><span class=o>=</span><span class=n>TensorDict</span><span class=p>({</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;generated_ids&#34;</span><span class=p>:</span> <span class=n>outputs</span><span class=o>.</span><span class=n>sequences</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;log_probs&#34;</span><span class=p>:</span> <span class=n>outputs</span><span class=o>.</span><span class=n>log_probs</span>
</span></span><span class=line><span class=cl>            <span class=p>},</span> <span class=n>batch_size</span><span class=o>=</span><span class=n>data</span><span class=o>.</span><span class=n>batch</span><span class=o>.</span><span class=n>batch_size</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>meta_info</span><span class=o>=</span><span class=n>data</span><span class=o>.</span><span class=n>meta_info</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=43-分离的优势>4.3 分离的优势<a hidden class=anchor aria-hidden=true href=#43-分离的优势>#</a></h3><pre class=mermaid>
  graph LR
    subgraph &#34;优势分析&#34;
        A[软件复用性] --&gt; A1[控制流可复用]
        A --&gt; A2[计算流可复用]
        
        B[开发效率] --&gt; B1[单进程调试]
        B --&gt; B2[模块化开发]
        
        C[性能优化] --&gt; C1[独立优化]
        C --&gt; C2[灵活调度]
    end
    
    style A fill:#4CAF50,stroke:#2E7D32,stroke-width:2px,color:#fff
    style B fill:#2196F3,stroke:#1565C0,stroke-width:2px,color:#fff
    style C fill:#FF9800,stroke:#E65100,stroke-width:2px,color:#fff
</pre><h2 id=5-数据流动机制>5. 数据流动机制<a hidden class=anchor aria-hidden=true href=#5-数据流动机制>#</a></h2><p>在我们追踪 DataProto 在各个 Worker 之间的旅程之前，我们有必要先回答一个更根本的问题：第一个 DataProto 对象是如何诞生的？</p><p>在 veRL 中，DataProto 的声明周期是：</p><p><strong>Parquet 文件 -> RLHFDataset -> DataLoader -> batch_dict -> DataProto</strong></p><p>Parquet 是 veRL 推荐的数据格式，通常包含 prompt 文本和相关元信息。RLHFDataset 负责读取本地或远程 Parquet 文件，按 max_prompt_length 过滤样本，并应用聊天模板格式化对话。随后，执行分词、填充、截断，将样本转为固定长度的张量。</p><p>DataLoader 在 RayPPOTrainer 中创建，将处理后的样本组织成 batch，产出 batch_dict。</p><p>此时，DataProto 登场。通过 DataProto.<code>from_single_dict(batch_dict)</code>，普通字典被封装为 veRL 内部统一的数据协议，正式进入 RLHF 流程。</p><h3 id=51-完整数据流动图>5.1 完整数据流动图<a hidden class=anchor aria-hidden=true href=#51-完整数据流动图>#</a></h3><pre class=mermaid>
  graph TD
    A[训练数据] --&gt; B[DataProto创建]
    B --&gt; C[RayPPOTrainer控制流]
    
    C --&gt; D[数据分发阶段]
    D --&gt; E[WorkerGroup.generate_sequences]
    
    E --&gt; F{Dispatch模式选择}
    F --&gt;|DP_COMPUTE_PROTO| G[数据并行分割]
    F --&gt;|ONE_TO_ALL| H[广播分发]
    F --&gt;|ALL_TO_ALL| I[全对全通信]
    
    G --&gt; J[分发到计算Worker]
    H --&gt; J
    I --&gt; J
    
    J --&gt; K[ActorRolloutWorker]
    J --&gt; L[CriticWorker] 
    J --&gt; M[ReferenceWorker]
    
    K --&gt; N[序列生成计算]
    L --&gt; O[价值函数计算]
    M --&gt; P[参考策略计算]
    
    N --&gt; Q[DataProto结果收集]
    O --&gt; Q
    P --&gt; Q
    
    Q --&gt; R[优势函数计算]
    R --&gt; S[策略梯度更新]
    S --&gt; T[模型参数同步]
    
    T --&gt; U[下一轮训练]
    U --&gt; D
    
    style A fill:#E3F2FD,stroke:#1976D2,stroke-width:2px
    style B fill:#F3E5F5,stroke:#7B1FA2,stroke-width:2px
    style C fill:#E8F5E8,stroke:#388E3C,stroke-width:2px
    style Q fill:#FFF3E0,stroke:#F57C00,stroke-width:2px
    style T fill:#FCE4EC,stroke:#C2185B,stroke-width:2px
    style F fill:#E0F2F1,stroke:#00695C,stroke-width:2px
</pre><h3 id=52-数据流动时间线>5.2 数据流动时间线<a hidden class=anchor aria-hidden=true href=#52-数据流动时间线>#</a></h3><pre class=mermaid>
  gantt
    title DataProto在分布式训练中的时间线
    dateFormat X
    axisFormat %s
    
    section 数据准备阶段
    数据加载与预处理    :0, 3
    DataProto对象创建   :3, 4
    
    section 分发阶段
    数据分割与调度     :4, 5
    网络传输与分发     :5, 7
    
    section 计算阶段
    Actor模型推理      :7, 12
    Critic价值计算     :7, 10
    Reference策略计算  :7, 11
    
    section 收集阶段
    结果收集与合并     :12, 14
    数据格式转换       :14, 15
    
    section 更新阶段
    优势函数计算       :15, 16
    策略梯度更新       :16, 18
    模型参数同步       :18, 20
</pre><h3 id=53-完整ppo训练角度追踪数据流动>5.3 完整PPO训练角度追踪数据流动<a hidden class=anchor aria-hidden=true href=#53-完整ppo训练角度追踪数据流动>#</a></h3><p>下面我们将以一次 PPO 迭代为例，用一张 端到端的数据流图 来追踪 DataProto 的演变过程。</p><p><img alt=ppo-dp loading=lazy src=https://space.keter.top/assets/images/ppo-6cc3e009f22fdb8153c92898f698cf7b.png data-zoomable></p><p>RayPPOTrainer 的 <code>fit(</code>) 循环从 <code>train_dataloader</code> 中取出一个 <code>batch_dict</code>。这个字典通常只包含 <code>input_ids</code>、<code>attention_mask</code> 等表示 prompt 的基本信息。这些信息被封装成第一个版本的 <code>DataProto</code> 对象。</p><p>接下来进入到 PPO 的 生成 (Generation) 和 准备 (Preparation) 阶段。这个初生的 DataProto 开始了它的旅程，它被 RayPPOTrainer 依次（或并行地）发送给各个 Worker，每经过一个，就会被赋予新的信息。</p><p>流经 <code>RolloutWorker</code>：<code>DataProto v1</code> 被发送去执行 <code>generate_sequences</code>。<code>RolloutWorker</code> 返回生成的 responses，并将其合并，形成 <code>DataProto v2</code>。</p><p><code>DataProto v</code>2 被同时发送给 <code>RewardModelWorker</code>, <code>ActorWorker</code> (执行 <code>compute_log_prob</code>), 和 <code>CriticWorker</code> (执行 <code>compute_values</code>)。</p><p>这三个 Worker 并行地完成计算，各自返回自己的结果。<code>RayPPOTrainer</code> 将这些结果全部合并，形成了 <code>DataProto v3</code>。</p><p>此时的 <code>DataProto v3</code> 已经包含了计算优势函数所需的所有输入。这个计算通常是轻量级的，因此 <code>RayPPOTrainer</code> 会在 Driver 进程本地 直接调用 <code>compute_advantage</code> 函数。</p><p><code>compute_advantage</code> 函数会计算出 advantages 和 returns，并将其加入到数据中，至此，<code>DataProto v4</code> 已经准备好了。</p><p>接下来 <code>DataProto v4</code> 被最后一次分发，分别发送给 <code>ActorWorker</code> 和 <code>CriticWorker</code> 的 <code>update</code> 方法。</p><p><code>ActorWorker</code> 从中取出 advantages, old_log_probs 等信息，计算 PPO 损失并更新自己的权重。<code>CriticWorker</code> 从中取出 returns 作为学习目标，计算 MSE 损失并更新自己的权重。它们返回训练过程中的 metrics，标志着 DataProto 在本次迭代中的使命正式完成。</p><h2 id=6-dispatch-模式详解>6. Dispatch 模式详解<a hidden class=anchor aria-hidden=true href=#6-dispatch-模式详解>#</a></h2><h3 id=61-核心dispatch模式>6.1 核心Dispatch模式<a hidden class=anchor aria-hidden=true href=#61-核心dispatch模式>#</a></h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Dispatch</span><span class=p>(</span><span class=n>DynamicEnum</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>RANK_ZERO</span> <span class=o>=</span> <span class=s2>&#34;RANK_ZERO&#34;</span>                    <span class=c1># 只在rank 0执行</span>
</span></span><span class=line><span class=cl>    <span class=n>ONE_TO_ALL</span> <span class=o>=</span> <span class=s2>&#34;ONE_TO_ALL&#34;</span>                  <span class=c1># 一对多广播</span>
</span></span><span class=line><span class=cl>    <span class=n>ALL_TO_ALL</span> <span class=o>=</span> <span class=s2>&#34;ALL_TO_ALL&#34;</span>                  <span class=c1># 全对全通信</span>
</span></span><span class=line><span class=cl>    <span class=n>DP_COMPUTE</span> <span class=o>=</span> <span class=s2>&#34;DP_COMPUTE&#34;</span>                   <span class=c1># 数据并行计算</span>
</span></span><span class=line><span class=cl>    <span class=n>DP_COMPUTE_PROTO</span> <span class=o>=</span> <span class=s2>&#34;DP_COMPUTE_PROTO&#34;</span>       <span class=c1># DataProto数据并行</span>
</span></span><span class=line><span class=cl>    <span class=n>DP_COMPUTE_PROTO_WITH_FUNC</span> <span class=o>=</span> <span class=s2>&#34;DP_COMPUTE_PROTO_WITH_FUNC&#34;</span>  <span class=c1># 带函数的DataProto并行</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=62-dp_compute_proto-实现>6.2 DP_COMPUTE_PROTO 实现<a hidden class=anchor aria-hidden=true href=#62-dp_compute_proto-实现>#</a></h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>dispatch_dp_compute_data_proto</span><span class=p>(</span><span class=n>worker_group</span><span class=p>,</span> <span class=o>*</span><span class=n>args</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;DataProto数据并行分发&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># 自动分割DataProto到worker数量</span>
</span></span><span class=line><span class=cl>    <span class=n>splitted_args</span><span class=p>,</span> <span class=n>splitted_kwargs</span> <span class=o>=</span> <span class=n>_split_args_kwargs_data_proto_with_auto_padding</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>worker_group</span><span class=o>.</span><span class=n>world_size</span><span class=p>,</span> <span class=o>*</span><span class=n>args</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>splitted_args</span><span class=p>,</span> <span class=n>splitted_kwargs</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>collect_dp_compute_data_proto</span><span class=p>(</span><span class=n>worker_group</span><span class=p>,</span> <span class=n>output</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;DataProto数据并行收集&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>output</span> <span class=o>=</span> <span class=n>collect_dp_compute</span><span class=p>(</span><span class=n>worker_group</span><span class=p>,</span> <span class=n>output</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>_concat_data_proto_or_future</span><span class=p>(</span><span class=n>output</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=63-自动填充机制>6.3 自动填充机制<a hidden class=anchor aria-hidden=true href=#63-自动填充机制>#</a></h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>_split_args_kwargs_data_proto_with_auto_padding</span><span class=p>(</span><span class=n>chunks</span><span class=p>,</span> <span class=o>*</span><span class=n>args</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;支持自动填充的数据分割&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>data_proto_len</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>    <span class=n>padding_size</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_padding_and_split_data</span><span class=p>(</span><span class=n>obj</span><span class=p>,</span> <span class=n>chunks</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>nonlocal</span> <span class=n>data_proto_len</span><span class=p>,</span> <span class=n>padding_size</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>obj</span><span class=p>,</span> <span class=n>DataProto</span><span class=p>)</span> <span class=ow>and</span> <span class=n>obj</span><span class=o>.</span><span class=n>is_padding_enabled</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>data_proto_len</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>data_proto_len</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>obj</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>padding_size</span> <span class=o>=</span> <span class=p>(</span><span class=n>chunks</span> <span class=o>-</span> <span class=p>(</span><span class=n>data_proto_len</span> <span class=o>%</span> <span class=n>chunks</span><span class=p>))</span> <span class=k>if</span> <span class=p>(</span><span class=n>data_proto_len</span> <span class=o>%</span> <span class=n>chunks</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>)</span> <span class=k>else</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>            <span class=n>obj</span><span class=o>.</span><span class=n>padding</span><span class=p>(</span><span class=n>padding_size</span><span class=o>=</span><span class=n>padding_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>obj</span><span class=o>.</span><span class=n>chunk</span><span class=p>(</span><span class=n>chunks</span><span class=o>=</span><span class=n>chunks</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 处理所有参数</span>
</span></span><span class=line><span class=cl>    <span class=n>splitted_args</span> <span class=o>=</span> <span class=p>[</span><span class=n>_padding_and_split_data</span><span class=p>(</span><span class=n>arg</span><span class=p>,</span> <span class=n>chunks</span><span class=p>)</span> <span class=k>for</span> <span class=n>arg</span> <span class=ow>in</span> <span class=n>args</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>splitted_kwargs</span> <span class=o>=</span> <span class=p>{</span><span class=n>key</span><span class=p>:</span> <span class=n>_padding_and_split_data</span><span class=p>(</span><span class=n>val</span><span class=p>,</span> <span class=n>chunks</span><span class=p>)</span> <span class=k>for</span> <span class=n>key</span><span class=p>,</span> <span class=n>val</span> <span class=ow>in</span> <span class=n>kwargs</span><span class=o>.</span><span class=n>items</span><span class=p>()}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>splitted_args</span><span class=p>,</span> <span class=n>splitted_kwargs</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=64-dispatch模式选择策略>6.4 Dispatch模式选择策略<a hidden class=anchor aria-hidden=true href=#64-dispatch模式选择策略>#</a></h3><pre class=mermaid>
  graph TD
    A[方法调用] --&gt; B{检查register装饰器}
    B --&gt;|有装饰器| C[获取dispatch_mode]
    B --&gt;|无装饰器| D[使用默认模式]
    
    C --&gt; E{模式类型}
    E --&gt;|DP_COMPUTE_PROTO| F[数据并行处理]
    E --&gt;|ONE_TO_ALL| G[广播处理]
    E --&gt;|ALL_TO_ALL| H[全对全处理]
    
    F --&gt; I[分割DataProto]
    G --&gt; J[复制到所有Worker]
    H --&gt; K[直接分发]
    
    I --&gt; L[并行计算]
    J --&gt; L
    K --&gt; L
    
    L --&gt; M[收集结果]
    M --&gt; N[合并DataProto]
    
    style A fill:#E3F2FD,stroke:#1976D2,stroke-width:2px
    style F fill:#E8F5E8,stroke:#388E3C,stroke-width:2px
    style G fill:#FFF3E0,stroke:#F57C00,stroke-width:2px
    style H fill:#F3E5F5,stroke:#7B1FA2,stroke-width:2px
    style N fill:#FCE4EC,stroke:#C2185B,stroke-width:2px
</pre><h2 id=7-性能优化策略>7. 性能优化策略<a hidden class=anchor aria-hidden=true href=#7-性能优化策略>#</a></h2><h3 id=71-内存优化>7.1 内存优化<a hidden class=anchor aria-hidden=true href=#71-内存优化>#</a></h3><p><strong>分块处理</strong>:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>chunk</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>chunks</span><span class=p>:</span> <span class=nb>int</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>list</span><span class=p>[</span><span class=s2>&#34;DataProto&#34;</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;将DataProto分割成多个块&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>batch</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>batch_lst</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>batch</span><span class=o>.</span><span class=n>chunk</span><span class=p>(</span><span class=n>chunks</span><span class=o>=</span><span class=n>chunks</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>batch_lst</span> <span class=o>=</span> <span class=p>[</span><span class=kc>None</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>chunks</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 处理非张量数据</span>
</span></span><span class=line><span class=cl>    <span class=n>non_tensor_batch_lst</span> <span class=o>=</span> <span class=p>[{}</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>chunks</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>key</span><span class=p>,</span> <span class=n>val</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>non_tensor_batch</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>non_tensor_lst</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array_split</span><span class=p>(</span><span class=n>val</span><span class=p>,</span> <span class=n>chunks</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>chunks</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>non_tensor_batch_lst</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=n>key</span><span class=p>]</span> <span class=o>=</span> <span class=n>non_tensor_lst</span><span class=p>[</span><span class=n>i</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>[</span><span class=nb>type</span><span class=p>(</span><span class=bp>self</span><span class=p>)(</span><span class=n>batch</span><span class=o>=</span><span class=n>batch_lst</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>                      <span class=n>non_tensor_batch</span><span class=o>=</span><span class=n>non_tensor_batch_lst</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>                      <span class=n>meta_info</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>meta_info</span><span class=p>)</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>chunks</span><span class=p>)]</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>内存复用</strong>:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>to</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>device</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=s2>&#34;DataProto&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;设备间数据移动&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>batch</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>batch</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>batch</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=bp>self</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=72-异步执行>7.2 异步执行<a hidden class=anchor aria-hidden=true href=#72-异步执行>#</a></h3><p><strong>DataProtoFuture</strong>:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@dataclass</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>DataProtoFuture</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;异步DataProto，避免阻塞控制流&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>collect_fn</span><span class=p>:</span> <span class=n>Callable</span>
</span></span><span class=line><span class=cl>    <span class=n>futures</span><span class=p>:</span> <span class=nb>list</span><span class=p>[</span><span class=n>ray</span><span class=o>.</span><span class=n>ObjectRef</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>dispatch_fn</span><span class=p>:</span> <span class=n>Callable</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>get</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>output</span> <span class=o>=</span> <span class=n>ray</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>futures</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>collect_fn</span><span class=p>(</span><span class=n>output</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>dispatch_fn</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>dispatch_fn</span><span class=p>(</span><span class=n>output</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>output</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=73-流水线优化>7.3 流水线优化<a hidden class=anchor aria-hidden=true href=#73-流水线优化>#</a></h3><pre class=mermaid>
  graph LR
    subgraph &#34;传统同步模式&#34;
        A1[生成] --&gt; B1[训练]
        B1 --&gt; C1[等待]
        C1 --&gt; A1
    end
    
    subgraph &#34;verl异步模式&#34;
        A2[生成] --&gt; B2[训练]
        B2 --&gt; A2
        A2 -.-&gt;|异步| C2[并行执行]
    end
    
    style A1 fill:#FFCDD2,stroke:#D32F2F,stroke-width:2px
    style B1 fill:#FFCDD2,stroke:#D32F2F,stroke-width:2px
    style C1 fill:#FFCDD2,stroke:#D32F2F,stroke-width:2px
    
    style A2 fill:#C8E6C9,stroke:#388E3C,stroke-width:2px
    style B2 fill:#C8E6C9,stroke:#388E3C,stroke-width:2px
    style C2 fill:#C8E6C9,stroke:#388E3C,stroke-width:2px
</pre><h3 id=74-网络优化>7.4 网络优化<a hidden class=anchor aria-hidden=true href=#74-网络优化>#</a></h3><p><strong>压缩传输</strong>:</p><ul><li>使用高效的序列化格式</li><li>支持数据压缩</li><li>批量传输减少网络开销</li></ul><p><strong>负载均衡</strong>:</p><ul><li>动态调整数据分发策略</li><li>监控网络延迟和带宽</li><li>自适应调整批次大小</li></ul><h2 id=8-具体rl训练示例>8. 具体RL训练示例<a hidden class=anchor aria-hidden=true href=#8-具体rl训练示例>#</a></h2><h3 id=81-ppo训练中的dataproto实例>8.1 PPO训练中的DataProto实例<a hidden class=anchor aria-hidden=true href=#81-ppo训练中的dataproto实例>#</a></h3><p>让我们通过一个具体的PPO训练过程来展示DataProto的实际使用：</p><h4 id=811-训练数据准备>8.1.1 训练数据准备<a hidden class=anchor aria-hidden=true href=#811-训练数据准备>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span><span class=lnt>72
</span><span class=lnt>73
</span><span class=lnt>74
</span><span class=lnt>75
</span><span class=lnt>76
</span><span class=lnt>77
</span><span class=lnt>78
</span><span class=lnt>79
</span><span class=lnt>80
</span><span class=lnt>81
</span><span class=lnt>82
</span><span class=lnt>83
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 原始训练数据</span>
</span></span><span class=line><span class=cl><span class=n>raw_data</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;prompts&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;请计算 15 + 27 = ?&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;求解方程 2x + 5 = 13&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;一个圆的半径是3，求面积&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;responses&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;15 + 27 = 42&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;2x + 5 = 13</span><span class=se>\n</span><span class=s2>x = 4&#34;</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>        <span class=s2>&#34;面积 = πr² = 9π&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;rewards&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mf>0.8</span><span class=p>,</span> <span class=mf>0.9</span><span class=p>,</span> <span class=mf>0.7</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 转换为DataProto</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>create_training_dataproto</span><span class=p>(</span><span class=n>raw_data</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># 1. 文本编码</span>
</span></span><span class=line><span class=cl>    <span class=n>tokenizer</span> <span class=o>=</span> <span class=n>AutoTokenizer</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&#34;Qwen/Qwen2.5-7B-Instruct&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>prompt_ids</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>response_ids</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>attention_masks</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>prompt</span><span class=p>,</span> <span class=n>response</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>raw_data</span><span class=p>[</span><span class=s2>&#34;prompts&#34;</span><span class=p>],</span> <span class=n>raw_data</span><span class=p>[</span><span class=s2>&#34;responses&#34;</span><span class=p>]):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 编码prompt</span>
</span></span><span class=line><span class=cl>        <span class=n>prompt_tokens</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=n>prompt</span><span class=p>,</span> <span class=n>add_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>prompt_ids</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>prompt_tokens</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 编码response</span>
</span></span><span class=line><span class=cl>        <span class=n>response_tokens</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=n>response</span><span class=p>,</span> <span class=n>add_special_tokens</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>response_ids</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>response_tokens</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 创建attention mask</span>
</span></span><span class=line><span class=cl>        <span class=n>total_length</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>prompt_tokens</span><span class=p>)</span> <span class=o>+</span> <span class=nb>len</span><span class=p>(</span><span class=n>response_tokens</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>attention_masks</span><span class=o>.</span><span class=n>append</span><span class=p>([</span><span class=mi>1</span><span class=p>]</span> <span class=o>*</span> <span class=n>total_length</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 2. 填充到相同长度</span>
</span></span><span class=line><span class=cl>    <span class=n>max_length</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>p</span><span class=p>)</span> <span class=o>+</span> <span class=nb>len</span><span class=p>(</span><span class=n>r</span><span class=p>)</span> <span class=k>for</span> <span class=n>p</span><span class=p>,</span> <span class=n>r</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>prompt_ids</span><span class=p>,</span> <span class=n>response_ids</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>padded_prompt_ids</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>padded_response_ids</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>padded_attention_masks</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>p_ids</span><span class=p>,</span> <span class=n>r_ids</span><span class=p>,</span> <span class=n>mask</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>prompt_ids</span><span class=p>,</span> <span class=n>response_ids</span><span class=p>,</span> <span class=n>attention_masks</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 填充prompt</span>
</span></span><span class=line><span class=cl>        <span class=n>padded_p</span> <span class=o>=</span> <span class=n>p_ids</span> <span class=o>+</span> <span class=p>[</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>pad_token_id</span><span class=p>]</span> <span class=o>*</span> <span class=p>(</span><span class=n>max_length</span> <span class=o>-</span> <span class=nb>len</span><span class=p>(</span><span class=n>p_ids</span><span class=p>)</span> <span class=o>-</span> <span class=nb>len</span><span class=p>(</span><span class=n>r_ids</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>padded_prompt_ids</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>padded_p</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 填充response</span>
</span></span><span class=line><span class=cl>        <span class=n>padded_r</span> <span class=o>=</span> <span class=n>r_ids</span> <span class=o>+</span> <span class=p>[</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>pad_token_id</span><span class=p>]</span> <span class=o>*</span> <span class=p>(</span><span class=n>max_length</span> <span class=o>-</span> <span class=nb>len</span><span class=p>(</span><span class=n>p_ids</span><span class=p>)</span> <span class=o>-</span> <span class=nb>len</span><span class=p>(</span><span class=n>r_ids</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>padded_response_ids</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>padded_r</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 更新attention mask</span>
</span></span><span class=line><span class=cl>        <span class=n>padded_mask</span> <span class=o>=</span> <span class=n>mask</span> <span class=o>+</span> <span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=p>(</span><span class=n>max_length</span> <span class=o>-</span> <span class=nb>len</span><span class=p>(</span><span class=n>mask</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>padded_attention_masks</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>padded_mask</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 3. 创建DataProto</span>
</span></span><span class=line><span class=cl>    <span class=n>training_dataproto</span> <span class=o>=</span> <span class=n>DataProto</span><span class=o>.</span><span class=n>from_dict</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>tensors</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;prompt_ids&#34;</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>padded_prompt_ids</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>long</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;response_ids&#34;</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>padded_response_ids</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>long</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;attention_mask&#34;</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>padded_attention_masks</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>long</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=n>non_tensors</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;raw_prompts&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>raw_data</span><span class=p>[</span><span class=s2>&#34;prompts&#34;</span><span class=p>],</span> <span class=n>dtype</span><span class=o>=</span><span class=nb>object</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;raw_responses&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>raw_data</span><span class=p>[</span><span class=s2>&#34;responses&#34;</span><span class=p>],</span> <span class=n>dtype</span><span class=o>=</span><span class=nb>object</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;rewards&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>raw_data</span><span class=p>[</span><span class=s2>&#34;rewards&#34;</span><span class=p>],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>float32</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=n>meta_info</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;dataset_name&#34;</span><span class=p>:</span> <span class=s2>&#34;math_training&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;batch_size&#34;</span><span class=p>:</span> <span class=nb>len</span><span class=p>(</span><span class=n>raw_data</span><span class=p>[</span><span class=s2>&#34;prompts&#34;</span><span class=p>]),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;max_length&#34;</span><span class=p>:</span> <span class=n>max_length</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;tokenizer_name&#34;</span><span class=p>:</span> <span class=s2>&#34;Qwen/Qwen2.5-7B-Instruct&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>training_dataproto</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 创建训练数据</span>
</span></span><span class=line><span class=cl><span class=n>training_data</span> <span class=o>=</span> <span class=n>create_training_dataproto</span><span class=p>(</span><span class=n>raw_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;DataProto结构:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>training_data</span><span class=o>.</span><span class=n>get_data_info</span><span class=p>())</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>输出示例：</strong></p><pre tabindex=0><code>DataProto结构:
batch
  prompt_ids: (3, 512) (torch.int64) cuda:0
  response_ids: (3, 512) (torch.int64) cuda:0
  attention_mask: (3, 512) (torch.int64) cuda:0
non_tensor_batch
  raw_prompts: ndarray(3,) (object)
  raw_responses: ndarray(3,) (object)
  rewards: ndarray(3,) (float32)
meta_info
  dataset_name: str
  batch_size: int
  max_length: int
  tokenizer_name: str
</code></pre><h4 id=812-数据分发过程>8.1.2 数据分发过程<a hidden class=anchor aria-hidden=true href=#812-数据分发过程>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 假设有4个GPU worker</span>
</span></span><span class=line><span class=cl><span class=n>world_size</span> <span class=o>=</span> <span class=mi>4</span>
</span></span><span class=line><span class=cl><span class=n>batch_size</span> <span class=o>=</span> <span class=mi>3</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 原始DataProto</span>
</span></span><span class=line><span class=cl><span class=n>original_dataproto</span> <span class=o>=</span> <span class=n>training_data</span>  <span class=c1># batch_size=3</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 自动填充到能被4整除的大小</span>
</span></span><span class=line><span class=cl><span class=n>padded_dataproto</span><span class=p>,</span> <span class=n>pad_size</span> <span class=o>=</span> <span class=n>pad_dataproto_to_divisor</span><span class=p>(</span><span class=n>original_dataproto</span><span class=p>,</span> <span class=n>world_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 现在padded_dataproto的batch_size=4 (填充了1个样本)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 分割成4个chunk</span>
</span></span><span class=line><span class=cl><span class=n>chunks</span> <span class=o>=</span> <span class=n>padded_dataproto</span><span class=o>.</span><span class=n>chunk</span><span class=p>(</span><span class=n>chunks</span><span class=o>=</span><span class=n>world_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;原始batch_size: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>original_dataproto</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;填充后batch_size: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>padded_dataproto</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;分割后chunk数量: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>chunks</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;每个chunk的batch_size: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>chunks</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 分发到各个worker</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>chunk</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>chunks</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Worker </span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s2> 接收数据:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;  - prompt_ids shape: </span><span class=si>{</span><span class=n>chunk</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s1>&#39;prompt_ids&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;  - 包含样本数: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>chunk</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=82-控制流与计算流交互示例>8.2 控制流与计算流交互示例<a hidden class=anchor aria-hidden=true href=#82-控制流与计算流交互示例>#</a></h3><h4 id=821-控制流ppo训练循环>8.2.1 控制流：PPO训练循环<a hidden class=anchor aria-hidden=true href=#821-控制流ppo训练循环>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span><span class=lnt>72
</span><span class=lnt>73
</span><span class=lnt>74
</span><span class=lnt>75
</span><span class=lnt>76
</span><span class=lnt>77
</span><span class=lnt>78
</span><span class=lnt>79
</span><span class=lnt>80
</span><span class=lnt>81
</span><span class=lnt>82
</span><span class=lnt>83
</span><span class=lnt>84
</span><span class=lnt>85
</span><span class=lnt>86
</span><span class=lnt>87
</span><span class=lnt>88
</span><span class=lnt>89
</span><span class=lnt>90
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>RayPPOTrainer</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>config</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>config</span> <span class=o>=</span> <span class=n>config</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>actor_rollout_wg</span> <span class=o>=</span> <span class=kc>None</span>  <span class=c1># Actor和Rollout的WorkerGroup</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>critic_wg</span> <span class=o>=</span> <span class=kc>None</span>         <span class=c1># Critic的WorkerGroup</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>ref_policy_wg</span> <span class=o>=</span> <span class=kc>None</span>     <span class=c1># Reference Policy的WorkerGroup</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>fit</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;PPO训练的主控制循环&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>total_epochs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;开始第 </span><span class=si>{</span><span class=n>epoch</span><span class=si>}</span><span class=s2> 轮训练&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 1. 获取训练批次</span>
</span></span><span class=line><span class=cl>            <span class=n>batch_dataproto</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_get_training_batch</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;获取训练批次，batch_size: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>batch_dataproto</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 2. 分发到Actor进行序列生成</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;开始序列生成...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>rollout_dataproto</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>actor_rollout_wg</span><span class=o>.</span><span class=n>generate_sequences</span><span class=p>(</span><span class=n>batch_dataproto</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;序列生成完成，生成 </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>rollout_dataproto</span><span class=p>)</span><span class=si>}</span><span class=s2> 个序列&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 3. 分发到Critic计算价值</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;开始价值计算...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>value_dataproto</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>critic_wg</span><span class=o>.</span><span class=n>compute_values</span><span class=p>(</span><span class=n>rollout_dataproto</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;价值计算完成&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 4. 分发到Reference Policy计算log概率</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;开始参考策略计算...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>ref_log_prob_dataproto</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>ref_policy_wg</span><span class=o>.</span><span class=n>compute_log_probs</span><span class=p>(</span><span class=n>rollout_dataproto</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;参考策略计算完成&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 5. 在控制流中计算优势函数</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;计算优势函数...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>advantages</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_compute_advantages</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>rollout_dataproto</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>                <span class=n>value_dataproto</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>                <span class=n>ref_log_prob_dataproto</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 6. 更新Actor策略</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;更新Actor策略...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>actor_rollout_wg</span><span class=o>.</span><span class=n>update_actor</span><span class=p>(</span><span class=n>advantages</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 7. 更新Critic价值网络</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;更新Critic价值网络...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>critic_wg</span><span class=o>.</span><span class=n>update_critic</span><span class=p>(</span><span class=n>advantages</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;第 </span><span class=si>{</span><span class=n>epoch</span><span class=si>}</span><span class=s2> 轮训练完成</span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_get_training_batch</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;获取训练批次&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=c1># 从数据集中采样</span>
</span></span><span class=line><span class=cl>        <span class=n>batch_data</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;prompt_ids&#34;</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1000</span><span class=p>,</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>train_batch_size</span><span class=p>,</span> <span class=mi>512</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;attention_mask&#34;</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>ones</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>train_batch_size</span><span class=p>,</span> <span class=mi>512</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>DataProto</span><span class=o>.</span><span class=n>from_dict</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>tensors</span><span class=o>=</span><span class=n>batch_data</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>meta_info</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;epoch&#34;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>current_epoch</span><span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_compute_advantages</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>rollout_data</span><span class=p>,</span> <span class=n>value_data</span><span class=p>,</span> <span class=n>ref_log_prob_data</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;计算优势函数 - 在控制流中执行&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=c1># 从各个DataProto中提取数据</span>
</span></span><span class=line><span class=cl>        <span class=n>rewards</span> <span class=o>=</span> <span class=n>rollout_data</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;rewards&#34;</span><span class=p>]</span>  <span class=c1># [batch_size, seq_len]</span>
</span></span><span class=line><span class=cl>        <span class=n>values</span> <span class=o>=</span> <span class=n>value_data</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;values&#34;</span><span class=p>]</span>      <span class=c1># [batch_size, seq_len]</span>
</span></span><span class=line><span class=cl>        <span class=n>log_probs</span> <span class=o>=</span> <span class=n>rollout_data</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;log_probs&#34;</span><span class=p>]</span>  <span class=c1># [batch_size, seq_len]</span>
</span></span><span class=line><span class=cl>        <span class=n>ref_log_probs</span> <span class=o>=</span> <span class=n>ref_log_prob_data</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;log_probs&#34;</span><span class=p>]</span>  <span class=c1># [batch_size, seq_len]</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 计算优势函数</span>
</span></span><span class=line><span class=cl>        <span class=n>advantages</span> <span class=o>=</span> <span class=n>rewards</span> <span class=o>-</span> <span class=n>values</span>
</span></span><span class=line><span class=cl>        <span class=n>advantages</span> <span class=o>=</span> <span class=n>advantages</span> <span class=o>*</span> <span class=n>rollout_data</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;attention_mask&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 计算策略比率</span>
</span></span><span class=line><span class=cl>        <span class=n>log_ratio</span> <span class=o>=</span> <span class=n>log_probs</span> <span class=o>-</span> <span class=n>ref_log_probs</span>
</span></span><span class=line><span class=cl>        <span class=n>ratio</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=n>log_ratio</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 创建优势DataProto</span>
</span></span><span class=line><span class=cl>        <span class=n>advantages_dataproto</span> <span class=o>=</span> <span class=n>DataProto</span><span class=o>.</span><span class=n>from_dict</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>tensors</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;advantages&#34;</span><span class=p>:</span> <span class=n>advantages</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;ratio&#34;</span><span class=p>:</span> <span class=n>ratio</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;rewards&#34;</span><span class=p>:</span> <span class=n>rewards</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;values&#34;</span><span class=p>:</span> <span class=n>values</span>
</span></span><span class=line><span class=cl>            <span class=p>},</span>
</span></span><span class=line><span class=cl>            <span class=n>meta_info</span><span class=o>=</span><span class=n>rollout_data</span><span class=o>.</span><span class=n>meta_info</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>advantages_dataproto</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=822-计算流worker实现>8.2.2 计算流：Worker实现<a hidden class=anchor aria-hidden=true href=#822-计算流worker实现>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span><span class=lnt>108
</span><span class=lnt>109
</span><span class=lnt>110
</span><span class=lnt>111
</span><span class=lnt>112
</span><span class=lnt>113
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@ray.remote</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>ActorRolloutWorker</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model_config</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>model</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>config</span> <span class=o>=</span> <span class=n>model_config</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>    <span class=nd>@register</span><span class=p>(</span><span class=n>dispatch_mode</span><span class=o>=</span><span class=n>Dispatch</span><span class=o>.</span><span class=n>DP_COMPUTE_PROTO</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>generate_sequences</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>data</span><span class=p>:</span> <span class=n>DataProto</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>DataProto</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;生成序列 - 在计算流中执行&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Worker </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>rank</span><span class=si>}</span><span class=s2> 开始生成序列，batch_size: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>data</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 1. 模型推理</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>input_ids</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;prompt_ids&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=n>attention_mask</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;attention_mask&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 生成序列</span>
</span></span><span class=line><span class=cl>            <span class=n>outputs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>input_ids</span><span class=o>=</span><span class=n>input_ids</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>attention_mask</span><span class=o>=</span><span class=n>attention_mask</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>max_new_tokens</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>do_sample</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>temperature</span><span class=o>=</span><span class=mf>0.7</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>return_dict_in_generate</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>output_scores</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 提取生成的token ids</span>
</span></span><span class=line><span class=cl>            <span class=n>generated_ids</span> <span class=o>=</span> <span class=n>outputs</span><span class=o>.</span><span class=n>sequences</span>
</span></span><span class=line><span class=cl>            <span class=n>log_probs</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>(</span><span class=n>outputs</span><span class=o>.</span><span class=n>scores</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>log_softmax</span><span class=p>(</span><span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 计算每个token的log概率</span>
</span></span><span class=line><span class=cl>            <span class=n>token_log_probs</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>seq</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>generated_ids</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=n>seq_log_probs</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>                <span class=k>for</span> <span class=n>j</span><span class=p>,</span> <span class=n>token_id</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>seq</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                    <span class=k>if</span> <span class=n>j</span> <span class=o>&lt;</span> <span class=nb>len</span><span class=p>(</span><span class=n>log_probs</span><span class=p>[</span><span class=n>i</span><span class=p>]):</span>
</span></span><span class=line><span class=cl>                        <span class=n>seq_log_probs</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>log_probs</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=n>j</span><span class=p>][</span><span class=n>token_id</span><span class=p>]</span><span class=o>.</span><span class=n>item</span><span class=p>())</span>
</span></span><span class=line><span class=cl>                <span class=n>token_log_probs</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>seq_log_probs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 计算奖励（这里使用简单的长度奖励作为示例）</span>
</span></span><span class=line><span class=cl>            <span class=n>rewards</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([[</span><span class=nb>len</span><span class=p>(</span><span class=n>seq</span><span class=p>)</span> <span class=o>*</span> <span class=mf>0.1</span><span class=p>]</span> <span class=o>*</span> <span class=nb>len</span><span class=p>(</span><span class=n>seq</span><span class=p>)</span> <span class=k>for</span> <span class=n>seq</span> <span class=ow>in</span> <span class=n>generated_ids</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 2. 创建结果DataProto</span>
</span></span><span class=line><span class=cl>        <span class=n>result_dataproto</span> <span class=o>=</span> <span class=n>DataProto</span><span class=o>.</span><span class=n>from_dict</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>tensors</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;generated_ids&#34;</span><span class=p>:</span> <span class=n>generated_ids</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;log_probs&#34;</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>token_log_probs</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;rewards&#34;</span><span class=p>:</span> <span class=n>rewards</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;attention_mask&#34;</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>ones_like</span><span class=p>(</span><span class=n>generated_ids</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=p>},</span>
</span></span><span class=line><span class=cl>            <span class=n>non_tensors</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;raw_generated_texts&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span>
</span></span><span class=line><span class=cl>                    <span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>seq</span><span class=p>,</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span> 
</span></span><span class=line><span class=cl>                    <span class=k>for</span> <span class=n>seq</span> <span class=ow>in</span> <span class=n>generated_ids</span>
</span></span><span class=line><span class=cl>                <span class=p>],</span> <span class=n>dtype</span><span class=o>=</span><span class=nb>object</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=p>},</span>
</span></span><span class=line><span class=cl>            <span class=n>meta_info</span><span class=o>=</span><span class=n>data</span><span class=o>.</span><span class=n>meta_info</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Worker </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>rank</span><span class=si>}</span><span class=s2> 序列生成完成&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>result_dataproto</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=nd>@register</span><span class=p>(</span><span class=n>dispatch_mode</span><span class=o>=</span><span class=n>Dispatch</span><span class=o>.</span><span class=n>DP_COMPUTE_PROTO</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>update_actor</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>advantages</span><span class=p>:</span> <span class=n>DataProto</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;更新Actor策略 - 在计算流中执行&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Worker </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>rank</span><span class=si>}</span><span class=s2> 开始更新Actor策略&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 1. 提取数据</span>
</span></span><span class=line><span class=cl>        <span class=n>advantages_tensor</span> <span class=o>=</span> <span class=n>advantages</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;advantages&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>ratio</span> <span class=o>=</span> <span class=n>advantages</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;ratio&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>rewards</span> <span class=o>=</span> <span class=n>advantages</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;rewards&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 2. 计算PPO损失</span>
</span></span><span class=line><span class=cl>        <span class=n>clip_ratio</span> <span class=o>=</span> <span class=mf>0.2</span>
</span></span><span class=line><span class=cl>        <span class=n>policy_loss_1</span> <span class=o>=</span> <span class=o>-</span><span class=n>advantages_tensor</span> <span class=o>*</span> <span class=n>ratio</span>
</span></span><span class=line><span class=cl>        <span class=n>policy_loss_2</span> <span class=o>=</span> <span class=o>-</span><span class=n>advantages_tensor</span> <span class=o>*</span> <span class=n>torch</span><span class=o>.</span><span class=n>clamp</span><span class=p>(</span><span class=n>ratio</span><span class=p>,</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>clip_ratio</span><span class=p>,</span> <span class=mi>1</span> <span class=o>+</span> <span class=n>clip_ratio</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>policy_loss</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>maximum</span><span class=p>(</span><span class=n>policy_loss_1</span><span class=p>,</span> <span class=n>policy_loss_2</span><span class=p>)</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 3. 反向传播</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>policy_loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Worker </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>rank</span><span class=si>}</span><span class=s2> Actor策略更新完成，损失: </span><span class=si>{</span><span class=n>policy_loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@ray.remote</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>CriticWorker</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model_config</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>model</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>config</span> <span class=o>=</span> <span class=n>model_config</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>    <span class=nd>@register</span><span class=p>(</span><span class=n>dispatch_mode</span><span class=o>=</span><span class=n>Dispatch</span><span class=o>.</span><span class=n>DP_COMPUTE_PROTO</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>compute_values</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>data</span><span class=p>:</span> <span class=n>DataProto</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>DataProto</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;计算价值函数 - 在计算流中执行&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Worker </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>rank</span><span class=si>}</span><span class=s2> 开始计算价值函数&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>input_ids</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;generated_ids&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=n>attention_mask</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;attention_mask&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 前向传播计算价值</span>
</span></span><span class=line><span class=cl>            <span class=n>outputs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=p>(</span><span class=n>input_ids</span><span class=o>=</span><span class=n>input_ids</span><span class=p>,</span> <span class=n>attention_mask</span><span class=o>=</span><span class=n>attention_mask</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>values</span> <span class=o>=</span> <span class=n>outputs</span><span class=o>.</span><span class=n>value</span>  <span class=c1># [batch_size, seq_len]</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 创建价值DataProto</span>
</span></span><span class=line><span class=cl>        <span class=n>value_dataproto</span> <span class=o>=</span> <span class=n>DataProto</span><span class=o>.</span><span class=n>from_dict</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>tensors</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;values&#34;</span><span class=p>:</span> <span class=n>values</span><span class=p>},</span>
</span></span><span class=line><span class=cl>            <span class=n>meta_info</span><span class=o>=</span><span class=n>data</span><span class=o>.</span><span class=n>meta_info</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Worker </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>rank</span><span class=si>}</span><span class=s2> 价值函数计算完成&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>value_dataproto</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=83-数据流动可视化>8.3 数据流动可视化<a hidden class=anchor aria-hidden=true href=#83-数据流动可视化>#</a></h3><h4 id=831-单轮训练的数据流动>8.3.1 单轮训练的数据流动<a hidden class=anchor aria-hidden=true href=#831-单轮训练的数据流动>#</a></h4><pre class=mermaid>
  sequenceDiagram
    participant CF as 控制流
    participant AW as ActorWorker
    participant CW as CriticWorker
    participant RW as RefWorker
    
    CF-&gt;&gt;CF: 创建训练DataProto
    Note over CF: batch_size=256, 包含prompt_ids等
    
    CF-&gt;&gt;AW: generate_sequences(training_data)
    Note over AW: 自动分割为64个样本/worker
    
    AW-&gt;&gt;AW: 模型推理生成序列
    AW-&gt;&gt;CF: 返回rollout_data
    Note over CF: 包含generated_ids, log_probs, rewards
    
    CF-&gt;&gt;CW: compute_values(rollout_data)
    CW-&gt;&gt;CW: 计算价值函数
    CW-&gt;&gt;CF: 返回value_data
    
    CF-&gt;&gt;RW: compute_log_probs(rollout_data)
    RW-&gt;&gt;RW: 计算参考策略log概率
    RW-&gt;&gt;CF: 返回ref_log_prob_data
    
    CF-&gt;&gt;CF: 计算优势函数
    Note over CF: advantages = rewards - values
    
    CF-&gt;&gt;AW: update_actor(advantages)
    CF-&gt;&gt;CW: update_critic(advantages)
    
    Note over CF: 完成一轮训练
</pre><h4 id=832-dataproto在训练过程中的形态变化>8.3.2 DataProto在训练过程中的形态变化<a hidden class=anchor aria-hidden=true href=#832-dataproto在训练过程中的形态变化>#</a></h4><pre class=mermaid>
  graph LR
    subgraph &#34;训练开始&#34;
        A1[原始训练数据&lt;br/&gt;prompt_ids, attention_mask&lt;br/&gt;batch_size=256]
    end
    
    subgraph &#34;序列生成后&#34;
        A2[rollout_data&lt;br/&gt;generated_ids, log_probs, rewards&lt;br/&gt;batch_size=256]
    end
    
    subgraph &#34;价值计算后&#34;
        A3[value_data&lt;br/&gt;values&lt;br/&gt;batch_size=256]
    end
    
    subgraph &#34;优势计算后&#34;
        A4[advantages_data&lt;br/&gt;advantages, ratio&lt;br/&gt;batch_size=256]
    end
    
    A1 --&gt; A2
    A2 --&gt; A3
    A3 --&gt; A4
    
    style A1 fill:#E3F2FD,stroke:#1976D2,stroke-width:2px
    style A2 fill:#E8F5E8,stroke:#388E3C,stroke-width:2px
    style A3 fill:#FFF3E0,stroke:#F57C00,stroke-width:2px
    style A4 fill:#F3E5F5,stroke:#7B1FA2,stroke-width:2px
</pre><h3 id=84-关键特性展示>8.4 关键特性展示<a hidden class=anchor aria-hidden=true href=#84-关键特性展示>#</a></h3><h4 id=841-自动填充机制>8.4.1 自动填充机制<a hidden class=anchor aria-hidden=true href=#841-自动填充机制>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 示例：batch_size=250, world_size=4</span>
</span></span><span class=line><span class=cl><span class=n>original_batch_size</span> <span class=o>=</span> <span class=mi>250</span>
</span></span><span class=line><span class=cl><span class=n>world_size</span> <span class=o>=</span> <span class=mi>4</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 计算需要填充的数量</span>
</span></span><span class=line><span class=cl><span class=n>padding_needed</span> <span class=o>=</span> <span class=p>(</span><span class=n>world_size</span> <span class=o>-</span> <span class=p>(</span><span class=n>original_batch_size</span> <span class=o>%</span> <span class=n>world_size</span><span class=p>))</span> <span class=o>%</span> <span class=n>world_size</span>
</span></span><span class=line><span class=cl><span class=c1># padding_needed = 2</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 填充后的batch_size = 252，可以被4整除</span>
</span></span><span class=line><span class=cl><span class=n>final_batch_size</span> <span class=o>=</span> <span class=n>original_batch_size</span> <span class=o>+</span> <span class=n>padding_needed</span>  <span class=c1># 252</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 每个worker获得 252 // 4 = 63 个样本</span>
</span></span><span class=line><span class=cl><span class=n>samples_per_worker</span> <span class=o>=</span> <span class=n>final_batch_size</span> <span class=o>//</span> <span class=n>world_size</span>  <span class=c1># 63</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=842-异步执行示例>8.4.2 异步执行示例<a hidden class=anchor aria-hidden=true href=#842-异步执行示例>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 控制流中的异步调用</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>async_training_step</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># 1. 异步生成序列</span>
</span></span><span class=line><span class=cl>    <span class=n>rollout_future</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>actor_rollout_wg</span><span class=o>.</span><span class=n>generate_sequences</span><span class=o>.</span><span class=n>remote</span><span class=p>(</span><span class=n>training_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 2. 控制流可以继续其他工作</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;序列生成正在进行中...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 3. 当需要结果时再等待</span>
</span></span><span class=line><span class=cl>    <span class=n>rollout_data</span> <span class=o>=</span> <span class=n>ray</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>rollout_future</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;序列生成完成&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 4. 继续后续步骤</span>
</span></span><span class=line><span class=cl>    <span class=n>value_data</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>critic_wg</span><span class=o>.</span><span class=n>compute_values</span><span class=p>(</span><span class=n>rollout_data</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=9-ray集群中的物理数据流动>9. Ray集群中的物理数据流动<a hidden class=anchor aria-hidden=true href=#9-ray集群中的物理数据流动>#</a></h2><h3 id=91-ray集群物理架构>9.1 Ray集群物理架构<a hidden class=anchor aria-hidden=true href=#91-ray集群物理架构>#</a></h3><h4 id=911-集群组成>9.1.1 集群组成<a hidden class=anchor aria-hidden=true href=#911-集群组成>#</a></h4><pre class=mermaid>
  graph TB
    subgraph &#34;Head Node (主节点)&#34;
        A[Ray Head Process]
        B[Object Store]
        C[GCS - Global Control Service]
        D[Driver Process&lt;br/&gt;控制流]
    end
    
    subgraph &#34;Worker Node 1&#34;
        E[Ray Worker Process 1]
        F[Object Store 1]
        G[ActorRolloutWorker 1]
        H[ActorRolloutWorker 2]
    end
    
    subgraph &#34;Worker Node 2&#34;
        I[Ray Worker Process 2]
        J[Object Store 2]
        K[CriticWorker 1]
        L[CriticWorker 2]
    end
    
    subgraph &#34;Worker Node 3&#34;
        M[Ray Worker Process 3]
        N[Object Store 3]
        O[ReferenceWorker 1]
        P[ReferenceWorker 2]
    end
    
    A -.-&gt;|心跳| E
    A -.-&gt;|心跳| I
    A -.-&gt;|心跳| M
    
    D --&gt;|远程调用| G
    D --&gt;|远程调用| H
    D --&gt;|远程调用| K
    D --&gt;|远程调用| L
    D --&gt;|远程调用| O
    D --&gt;|远程调用| P
    
    B -.-&gt;|数据共享| F
    B -.-&gt;|数据共享| J
    B -.-&gt;|数据共享| N
    
    style A fill:#4CAF50,stroke:#2E7D32,stroke-width:2px,color:#fff
    style D fill:#2196F3,stroke:#1565C0,stroke-width:2px,color:#fff
    style G fill:#FF9800,stroke:#E65100,stroke-width:2px,color:#fff
    style K fill:#9C27B0,stroke:#6A1B9A,stroke-width:2px,color:#fff
    style O fill:#607D8B,stroke:#37474F,stroke-width:2px,color:#fff
</pre><h4 id=912-ray集群启动过程>9.1.2 Ray集群启动过程<a hidden class=anchor aria-hidden=true href=#912-ray集群启动过程>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 1. 启动Head节点</span>
</span></span><span class=line><span class=cl><span class=n>ray</span> <span class=n>start</span> <span class=o>--</span><span class=n>head</span> <span class=o>--</span><span class=n>port</span><span class=o>=</span><span class=mi>6379</span> <span class=o>--</span><span class=n>dashboard</span><span class=o>-</span><span class=n>host</span><span class=o>=</span><span class=mf>0.0.0.0</span> <span class=o>--</span><span class=n>dashboard</span><span class=o>-</span><span class=n>port</span><span class=o>=</span><span class=mi>8265</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. 启动Worker节点</span>
</span></span><span class=line><span class=cl><span class=n>ray</span> <span class=n>start</span> <span class=o>--</span><span class=n>address</span><span class=o>=</span><span class=s1>&#39;head_node_ip:6379&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 3. 在Driver中初始化集群</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>ray</span>
</span></span><span class=line><span class=cl><span class=n>ray</span><span class=o>.</span><span class=n>init</span><span class=p>(</span><span class=n>address</span><span class=o>=</span><span class=s1>&#39;ray://head_node_ip:10001&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 4. 创建WorkerGroup</span>
</span></span><span class=line><span class=cl><span class=n>resource_pool</span> <span class=o>=</span> <span class=n>RayResourcePool</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>process_on_nodes</span><span class=o>=</span><span class=p>[</span><span class=mi>4</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span>  <span class=c1># 每个节点4个进程</span>
</span></span><span class=line><span class=cl>    <span class=n>use_gpu</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>max_colocate_count</span><span class=o>=</span><span class=mi>1</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 5. 启动Worker进程</span>
</span></span><span class=line><span class=cl><span class=n>actor_rollout_wg</span> <span class=o>=</span> <span class=n>RayWorkerGroup</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>resource_pool</span><span class=o>=</span><span class=n>resource_pool</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>ray_cls_with_init</span><span class=o>=</span><span class=n>RayClassWithInitArgs</span><span class=p>(</span><span class=n>ActorRolloutWorker</span><span class=p>,</span> <span class=n>config</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=92-ray-object-store-核心概念>9.2 Ray Object Store 核心概念<a hidden class=anchor aria-hidden=true href=#92-ray-object-store-核心概念>#</a></h3><p>在深入理解DataProto的物理传输过程之前，我们需要先了解Ray集群中的Object Store机制，这是数据在节点间传输的基础设施。</p><h4 id=921-object-store-概述>9.2.1 Object Store 概述<a hidden class=anchor aria-hidden=true href=#921-object-store-概述>#</a></h4><p><strong>Object Store</strong>是Ray分布式系统的核心组件，用于在集群节点间高效地存储和共享数据。它基于Apache Arrow的Plasma实现，提供了高性能的分布式内存存储。</p><pre class=mermaid>
  graph TB
    subgraph &#34;Head Node&#34;
        A[HeadStore&lt;br/&gt;Plasma Store] --&gt; B[共享内存池]
        A --&gt; C[元数据管理]
        A --&gt; D[对象引用表]
    end
    
    subgraph &#34;Worker Node&#34;
        E[WorkerStore&lt;br/&gt;Plasma Store] --&gt; F[本地内存池]
        E --&gt; G[本地缓存]
        E --&gt; H[磁盘溢出]
    end
    
    A -.-&gt;|网络传输| E
    
    style A fill:#4CAF50,stroke:#2E7D32,stroke-width:2px,color:#fff
    style E fill:#FF9800,stroke:#E65100,stroke-width:2px,color:#fff
</pre><p><strong>核心组件：</strong></p><ul><li><strong>HeadStore</strong>：Head节点上的Object Store，存储全局共享数据，管理元数据和对象引用</li><li><strong>WorkerStore</strong>：Worker节点上的Object Store，存储本地计算数据，提供快速数据访问</li></ul><p><strong>工作原理：</strong></p><ol><li><strong>数据存储</strong>：通过<code>ray.put()</code>将数据存储到Object Store，返回ObjectRef</li><li><strong>数据获取</strong>：通过<code>ray.get(ObjectRef)</code>从Object Store读取数据</li><li><strong>内存管理</strong>：自动管理内存使用，支持磁盘溢出和垃圾回收</li></ol><h4 id=922-object-store-在verl中的作用>9.2.2 Object Store 在verl中的作用<a hidden class=anchor aria-hidden=true href=#922-object-store-在verl中的作用>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Object Store基本操作示例</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>ray</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 1. 存储DataProto到Object Store</span>
</span></span><span class=line><span class=cl><span class=n>data_proto</span> <span class=o>=</span> <span class=n>DataProto</span><span class=o>.</span><span class=n>from_dict</span><span class=p>(</span><span class=n>tensors</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;input_ids&#34;</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>256</span><span class=p>,</span> <span class=mi>512</span><span class=p>)})</span>
</span></span><span class=line><span class=cl><span class=n>object_ref</span> <span class=o>=</span> <span class=n>ray</span><span class=o>.</span><span class=n>put</span><span class=p>(</span><span class=n>data_proto</span><span class=p>)</span>  <span class=c1># 存储到本地Object Store</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. 发送ObjectRef到远程Worker</span>
</span></span><span class=line><span class=cl><span class=nd>@ray.remote</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>worker_function</span><span class=p>(</span><span class=n>ref</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span> <span class=o>=</span> <span class=n>ray</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>ref</span><span class=p>)</span>  <span class=c1># 从Object Store获取数据</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>process_data</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 3. 执行远程调用</span>
</span></span><span class=line><span class=cl><span class=n>future</span> <span class=o>=</span> <span class=n>worker_function</span><span class=o>.</span><span class=n>remote</span><span class=p>(</span><span class=n>object_ref</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>result</span> <span class=o>=</span> <span class=n>ray</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>future</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>关键特性：</strong></p><ul><li><strong>序列化优化</strong>：自动处理DataProto的序列化和反序列化</li><li><strong>内存共享</strong>：支持跨进程和跨节点的内存共享</li><li><strong>网络传输</strong>：自动处理网络传输和错误恢复</li><li><strong>性能优化</strong>：支持数据压缩和缓存机制</li></ul><h3 id=93-dataproto的物理传输过程>9.3 DataProto的物理传输过程<a hidden class=anchor aria-hidden=true href=#93-dataproto的物理传输过程>#</a></h3><h4 id=931-序列化与网络传输>9.3.1 序列化与网络传输<a hidden class=anchor aria-hidden=true href=#931-序列化与网络传输>#</a></h4><pre class=mermaid>
  sequenceDiagram
    participant D as Driver
    participant H as HeadStore
    participant W as Worker
    participant WS as WorkerStore
    participant A as Actor
    
    D-&gt;&gt;D: 创建DataProto
    Note over D: batch_size=256
    
    D-&gt;&gt;D: DataProto序列化
    Note over D: TensorDict序列化
    
    D-&gt;&gt;H: 存储序列化数据
    Note over H: 生成ObjectRef
    
    D-&gt;&gt;W: 发送ObjectRef
    Note over W: 方法调用
    
    W-&gt;&gt;H: 获取序列化数据
    H-&gt;&gt;W: 返回数据块
    
    W-&gt;&gt;W: DataProto反序列化
    Note over W: 重建TensorDict
    
    W-&gt;&gt;A: 调用generate_sequences
    A-&gt;&gt;A: 模型推理计算
    
    A-&gt;&gt;A: 创建结果DataProto
    A-&gt;&gt;W: 返回结果
    
    W-&gt;&gt;W: 结果序列化
    W-&gt;&gt;WS: 存储结果
    
    W-&gt;&gt;D: 返回ObjectRef
    D-&gt;&gt;WS: 获取结果数据
    D-&gt;&gt;D: 结果反序列化
</pre><h4 id=932-数据序列化细节>9.3.2 数据序列化细节<a hidden class=anchor aria-hidden=true href=#932-数据序列化细节>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># DataProto的序列化过程</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>__getstate__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;序列化DataProto&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=kn>import</span> <span class=nn>io</span>
</span></span><span class=line><span class=cl>    <span class=n>buffer</span> <span class=o>=</span> <span class=n>io</span><span class=o>.</span><span class=n>BytesIO</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 1. 序列化TensorDict</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>batch</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>batch_to_save</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>batch</span><span class=o>.</span><span class=n>contiguous</span><span class=p>()</span><span class=o>.</span><span class=n>consolidate</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>torch</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=n>batch_to_save</span><span class=p>,</span> <span class=n>buffer</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 2. 序列化numpy数组和meta_info</span>
</span></span><span class=line><span class=cl>    <span class=n>buffer_bytes</span> <span class=o>=</span> <span class=n>buffer</span><span class=o>.</span><span class=n>getvalue</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>buffer_bytes</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>non_tensor_batch</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>meta_info</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>__setstate__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>data</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;反序列化DataProto&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=kn>import</span> <span class=nn>io</span>
</span></span><span class=line><span class=cl>    <span class=n>batch_deserialized_bytes</span><span class=p>,</span> <span class=n>non_tensor_batch</span><span class=p>,</span> <span class=n>meta_info</span> <span class=o>=</span> <span class=n>data</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 1. 反序列化TensorDict</span>
</span></span><span class=line><span class=cl>    <span class=n>batch_deserialized</span> <span class=o>=</span> <span class=n>io</span><span class=o>.</span><span class=n>BytesIO</span><span class=p>(</span><span class=n>initial_bytes</span><span class=o>=</span><span class=n>batch_deserialized_bytes</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>batch</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>batch_deserialized</span><span class=p>,</span> <span class=n>map_location</span><span class=o>=</span><span class=s2>&#34;cpu&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 2. 重建DataProto</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>batch</span> <span class=o>=</span> <span class=n>batch</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>non_tensor_batch</span> <span class=o>=</span> <span class=n>non_tensor_batch</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>meta_info</span> <span class=o>=</span> <span class=n>meta_info</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=94-分布式数据流动架构>9.4 分布式数据流动架构<a hidden class=anchor aria-hidden=true href=#94-分布式数据流动架构>#</a></h3><h4 id=941-多节点数据分发>9.4.1 多节点数据分发<a hidden class=anchor aria-hidden=true href=#941-多节点数据分发>#</a></h4><pre class=mermaid>
  graph TD
    subgraph &#34;Head Node&#34;
        A[Driver Process] --&gt; B[DataProto创建]
        B --&gt; C[序列化]
        C --&gt; D[Object Store]
    end
    
    subgraph &#34;Worker Node 1&#34;
        E[Worker Process 1] --&gt; F[ActorRolloutWorker 1]
        E --&gt; G[ActorRolloutWorker 2]
    end
    
    subgraph &#34;Worker Node 2&#34;
        H[Worker Process 2] --&gt; I[CriticWorker 1]
        H --&gt; J[CriticWorker 2]
    end
    
    subgraph &#34;Worker Node 3&#34;
        K[Worker Process 3] --&gt; L[ReferenceWorker 1]
        K --&gt; M[ReferenceWorker 2]
    end
    
    D -.-&gt;|网络传输| E
    D -.-&gt;|网络传输| H
    D -.-&gt;|网络传输| K
    
    E --&gt; N[Object Store 1]
    H --&gt; O[Object Store 2]
    K --&gt; P[Object Store 3]
    
    N -.-&gt;|结果收集| D
    O -.-&gt;|结果收集| D
    P -.-&gt;|结果收集| D
    
    style A fill:#2196F3,stroke:#1565C0,stroke-width:2px,color:#fff
    style D fill:#4CAF50,stroke:#2E7D32,stroke-width:2px,color:#fff
    style F fill:#FF9800,stroke:#E65100,stroke-width:2px,color:#fff
    style I fill:#9C27B0,stroke:#6A1B9A,stroke-width:2px,color:#fff
    style L fill:#607D8B,stroke:#37474F,stroke-width:2px,color:#fff
</pre><h4 id=942-数据并行分发过程>9.4.2 数据并行分发过程<a hidden class=anchor aria-hidden=true href=#942-数据并行分发过程>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 实际的数据分发过程</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>dispatch_dp_compute_data_proto</span><span class=p>(</span><span class=n>worker_group</span><span class=p>,</span> <span class=o>*</span><span class=n>args</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;DataProto数据并行分发&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>world_size</span> <span class=o>=</span> <span class=n>worker_group</span><span class=o>.</span><span class=n>world_size</span>  <span class=c1># 例如：8个worker</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 1. 自动填充</span>
</span></span><span class=line><span class=cl>    <span class=n>data_proto</span> <span class=o>=</span> <span class=n>args</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>  <span class=c1># 原始DataProto，batch_size=250</span>
</span></span><span class=line><span class=cl>    <span class=n>padded_data</span><span class=p>,</span> <span class=n>pad_size</span> <span class=o>=</span> <span class=n>pad_dataproto_to_divisor</span><span class=p>(</span><span class=n>data_proto</span><span class=p>,</span> <span class=n>world_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 现在padded_data的batch_size=256 (填充了6个样本)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 2. 分割数据</span>
</span></span><span class=line><span class=cl>    <span class=n>chunks</span> <span class=o>=</span> <span class=n>padded_data</span><span class=o>.</span><span class=n>chunk</span><span class=p>(</span><span class=n>chunks</span><span class=o>=</span><span class=n>world_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 每个chunk的batch_size=32</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 3. 分发到各个worker</span>
</span></span><span class=line><span class=cl>    <span class=n>futures</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>worker</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>worker_group</span><span class=o>.</span><span class=n>workers</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>chunk</span> <span class=o>=</span> <span class=n>chunks</span><span class=p>[</span><span class=n>i</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=c1># 序列化chunk并通过Ray发送</span>
</span></span><span class=line><span class=cl>        <span class=n>future</span> <span class=o>=</span> <span class=n>worker</span><span class=o>.</span><span class=n>generate_sequences</span><span class=o>.</span><span class=n>remote</span><span class=p>(</span><span class=n>chunk</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>futures</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>future</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>futures</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 在物理层面的实际传输</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>physical_data_transfer_example</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;展示物理层面的数据传输&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 原始数据大小</span>
</span></span><span class=line><span class=cl>    <span class=n>batch_size</span> <span class=o>=</span> <span class=mi>250</span>
</span></span><span class=line><span class=cl>    <span class=n>seq_len</span> <span class=o>=</span> <span class=mi>512</span>
</span></span><span class=line><span class=cl>    <span class=n>vocab_size</span> <span class=o>=</span> <span class=mi>32000</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 计算数据大小</span>
</span></span><span class=line><span class=cl>    <span class=n>prompt_ids_size</span> <span class=o>=</span> <span class=n>batch_size</span> <span class=o>*</span> <span class=n>seq_len</span> <span class=o>*</span> <span class=mi>4</span>  <span class=c1># int32, bytes</span>
</span></span><span class=line><span class=cl>    <span class=n>attention_mask_size</span> <span class=o>=</span> <span class=n>batch_size</span> <span class=o>*</span> <span class=n>seq_len</span> <span class=o>*</span> <span class=mi>4</span>  <span class=c1># int32, bytes</span>
</span></span><span class=line><span class=cl>    <span class=n>tensor_data_size</span> <span class=o>=</span> <span class=n>prompt_ids_size</span> <span class=o>+</span> <span class=n>attention_mask_size</span>  <span class=c1># ~2MB</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 序列化开销</span>
</span></span><span class=line><span class=cl>    <span class=n>serialization_overhead</span> <span class=o>=</span> <span class=n>tensor_data_size</span> <span class=o>*</span> <span class=mf>0.1</span>  <span class=c1># 约10%开销</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 网络传输</span>
</span></span><span class=line><span class=cl>    <span class=n>network_bandwidth</span> <span class=o>=</span> <span class=mi>10</span> <span class=o>*</span> <span class=mi>1024</span> <span class=o>*</span> <span class=mi>1024</span>  <span class=c1># 10Gbps</span>
</span></span><span class=line><span class=cl>    <span class=n>transfer_time</span> <span class=o>=</span> <span class=p>(</span><span class=n>tensor_data_size</span> <span class=o>+</span> <span class=n>serialization_overhead</span><span class=p>)</span> <span class=o>/</span> <span class=n>network_bandwidth</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;数据大小: </span><span class=si>{</span><span class=n>tensor_data_size</span> <span class=o>/</span> <span class=mi>1024</span> <span class=o>/</span> <span class=mi>1024</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2> MB&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;序列化开销: </span><span class=si>{</span><span class=n>serialization_overhead</span> <span class=o>/</span> <span class=mi>1024</span> <span class=o>/</span> <span class=mi>1024</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2> MB&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;传输时间: </span><span class=si>{</span><span class=n>transfer_time</span> <span class=o>*</span> <span class=mi>1000</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2> ms&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=95-内存管理与对象存储>9.5 内存管理与对象存储<a hidden class=anchor aria-hidden=true href=#95-内存管理与对象存储>#</a></h3><h4 id=951-ray-object-store架构>9.5.1 Ray Object Store架构<a hidden class=anchor aria-hidden=true href=#951-ray-object-store架构>#</a></h4><pre class=mermaid>
  graph TB
    subgraph &#34;Head Node Object Store&#34;
        A[Plasma Store] --&gt; B[内存池]
        A --&gt; C[共享内存]
        A --&gt; D[磁盘存储]
    end
    
    subgraph &#34;Worker Node Object Store&#34;
        E[Plasma Store] --&gt; F[本地内存池]
        E --&gt; G[本地共享内存]
        E --&gt; H[本地磁盘缓存]
    end
    
    A -.-&gt;|网络传输| E
    
    subgraph &#34;数据生命周期&#34;
        I[创建DataProto] --&gt; J[序列化]
        J --&gt; K[存储到Object Store]
        K --&gt; L[生成ObjectRef]
        L --&gt; M[发送到Worker]
        M --&gt; N[Worker反序列化]
        N --&gt; O[计算处理]
        O --&gt; P[结果序列化]
        P --&gt; Q[存储结果]
        Q --&gt; R[返回ObjectRef]
    end
    
    style A fill:#4CAF50,stroke:#2E7D32,stroke-width:2px,color:#fff
    style E fill:#FF9800,stroke:#E65100,stroke-width:2px,color:#fff
    style I fill:#2196F3,stroke:#1565C0,stroke-width:2px,color:#fff
    style O fill:#9C27B0,stroke:#6A1B9A,stroke-width:2px,color:#fff
</pre><h4 id=952-内存优化策略>9.5.2 内存优化策略<a hidden class=anchor aria-hidden=true href=#952-内存优化策略>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 内存优化示例</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>MemoryOptimizedDataProto</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>object_refs</span> <span class=o>=</span> <span class=p>{}</span>  <span class=c1># 缓存ObjectRef</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>send_to_worker</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>data_proto</span><span class=p>,</span> <span class=n>worker_id</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;优化的数据传输&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 1. 检查是否已有缓存</span>
</span></span><span class=line><span class=cl>        <span class=n>cache_key</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>worker_id</span><span class=si>}</span><span class=s2>_</span><span class=si>{</span><span class=nb>hash</span><span class=p>(</span><span class=n>data_proto</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>cache_key</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>object_refs</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>object_refs</span><span class=p>[</span><span class=n>cache_key</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 2. 序列化并存储</span>
</span></span><span class=line><span class=cl>        <span class=n>object_ref</span> <span class=o>=</span> <span class=n>ray</span><span class=o>.</span><span class=n>put</span><span class=p>(</span><span class=n>data_proto</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>object_refs</span><span class=p>[</span><span class=n>cache_key</span><span class=p>]</span> <span class=o>=</span> <span class=n>object_ref</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 3. 发送到worker</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>object_ref</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>cleanup_cache</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;清理缓存&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>ref</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>object_refs</span><span class=o>.</span><span class=n>values</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>ray</span><span class=o>.</span><span class=n>delete</span><span class=p>(</span><span class=n>ref</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>object_refs</span><span class=o>.</span><span class=n>clear</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=96-网络拓扑与性能优化>9.6 网络拓扑与性能优化<a hidden class=anchor aria-hidden=true href=#96-网络拓扑与性能优化>#</a></h3><h4 id=961-网络拓扑图>9.6.1 网络拓扑图<a hidden class=anchor aria-hidden=true href=#961-网络拓扑图>#</a></h4><pre class=mermaid>
  graph TB
    subgraph &#34;数据中心网络&#34;
        A[Head Node&lt;br/&gt;10Gbps] --&gt; B[Top of Rack Switch]
        B --&gt; C[Worker Node 1&lt;br/&gt;10Gbps]
        B --&gt; D[Worker Node 2&lt;br/&gt;10Gbps]
        B --&gt; E[Worker Node 3&lt;br/&gt;10Gbps]
        B --&gt; F[Worker Node 4&lt;br/&gt;10Gbps]
    end
    
    subgraph &#34;节点内部&#34;
        C --&gt; G[GPU 0]
        C --&gt; H[GPU 1]
        C --&gt; I[GPU 2]
        C --&gt; J[GPU 3]
    end
    
    subgraph &#34;数据流动路径&#34;
        K[Driver] --&gt; L[序列化]
        L --&gt; M[网络传输]
        M --&gt; N[Worker接收]
        N --&gt; O[反序列化]
        O --&gt; P[GPU计算]
        P --&gt; Q[结果序列化]
        Q --&gt; R[网络返回]
        R --&gt; S[Driver接收]
    end
    
    style A fill:#4CAF50,stroke:#2E7D32,stroke-width:2px,color:#fff
    style C fill:#FF9800,stroke:#E65100,stroke-width:2px,color:#fff
    style G fill:#2196F3,stroke:#1565C0,stroke-width:2px,color:#fff
    style K fill:#9C27B0,stroke:#6A1B9A,stroke-width:2px,color:#fff
</pre><p>Verl 通过 DataProto 和 HybridFlow 设计，成功解决了大规模强化学习训练中的架构挑战，为LLM后训练提供了高效、灵活、可扩展的解决方案。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://pillumina.github.io/tags/framework/>Framework</a></li><li><a href=https://pillumina.github.io/tags/verl/>Verl</a></li></ul><nav class=paginav><a class=next href=https://pillumina.github.io/posts/aiinfra/09-verl-agentloop/><span class=title>Next »</span><br><span>[VeRL] AgentLoop源码走读</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share [VeRL] DataProto介绍 on x" href="https://x.com/intent/tweet/?text=%5bVeRL%5d%20DataProto%e4%bb%8b%e7%bb%8d&amp;url=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f10-verl-dataproto%2f&amp;hashtags=framework%2cverl"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [VeRL] DataProto介绍 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f10-verl-dataproto%2f&amp;title=%5bVeRL%5d%20DataProto%e4%bb%8b%e7%bb%8d&amp;summary=%5bVeRL%5d%20DataProto%e4%bb%8b%e7%bb%8d&amp;source=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f10-verl-dataproto%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [VeRL] DataProto介绍 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f10-verl-dataproto%2f&title=%5bVeRL%5d%20DataProto%e4%bb%8b%e7%bb%8d"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [VeRL] DataProto介绍 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f10-verl-dataproto%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [VeRL] DataProto介绍 on whatsapp" href="https://api.whatsapp.com/send?text=%5bVeRL%5d%20DataProto%e4%bb%8b%e7%bb%8d%20-%20https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f10-verl-dataproto%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [VeRL] DataProto介绍 on telegram" href="https://telegram.me/share/url?text=%5bVeRL%5d%20DataProto%e4%bb%8b%e7%bb%8d&amp;url=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f10-verl-dataproto%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [VeRL] DataProto介绍 on ycombinator" href="https://news.ycombinator.com/submitlink?t=%5bVeRL%5d%20DataProto%e4%bb%8b%e7%bb%8d&u=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f10-verl-dataproto%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul><div class=related-posts><div class=related-series><h3>同系列文章</h3><ul><li><a href=/posts/aiinfra/09-verl-agentloop/>[VeRL] AgentLoop源码走读</a>
<span class=meta>2025-08-14
· 15 min read</span></li><li><a href=/posts/aiinfra/05-verl-params/>[VeRL] 参数速览</a>
<span class=meta>2025-08-14
· 6 min read</span></li><li><a href=/posts/aiinfra/08-verl-multiturn-2/>[VeRL] Multi-Turn RL训练源码走读（2）</a>
<span class=meta>2025-08-03
· 27 min read</span></li><li><a href=/posts/aiinfra/07-verl-multiturn-1/>[VeRL] Multi-Turn RL训练源码走读（1）</a>
<span class=meta>2025-08-03
· 27 min read</span></li></ul></div><div class=related-tags><h3>相关文章</h3><ul><li><a href=/posts/aiinfra/09-verl-agentloop/>[VeRL] AgentLoop源码走读</a>
<span class=meta>2025-08-14
· 15 min read
· Tags: framework, verl, sglang</span></li><li><a href=/posts/aiinfra/05-verl-params/>[VeRL] 参数速览</a>
<span class=meta>2025-08-14
· 6 min read
· Tags: framework, verl</span></li><li><a href=/posts/aiinfra/02-slime/>[RL4LLM] 异步RL框架: Slime</a>
<span class=meta>2025-08-07
· 15 min read
· Tags: framework, LLM, RL</span></li><li><a href=/posts/aiinfra/03-areal/>[RL4LLM] 异步RL框架: Areal</a>
<span class=meta>2025-08-07
· 23 min read
· Tags: framework, LLM, RL</span></li></ul></div></div></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://pillumina.github.io/>CctoctoFX</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg></a><div class=reading-progress-bar></div><script src=https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js></script><script>document.addEventListener("DOMContentLoaded",function(){const t=document.querySelector(".reading-progress-bar");if(!t)return;const n=document.querySelector(".post-single");if(!n)return;function s(){const e=n.getBoundingClientRect(),s=e.height,o=window.innerHeight,i=window.scrollY||window.pageYOffset,a=i/(s-o)*100;t.style.width=`${Math.min(100,Math.max(0,a))}%`}let e=!1;window.addEventListener("scroll",function(){e||(window.requestAnimationFrame(function(){s(),e=!1}),e=!0)}),s()}),document.addEventListener("DOMContentLoaded",function(){mediumZoom("article img:not(.nozoom)",{margin:24,background:"var(--theme)",scrollOffset:0})})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>