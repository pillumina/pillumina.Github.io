<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[VeRL] DataProto介绍 | CctoctoFX</title><meta name=keywords content="framework,verl"><meta name=description content='Verl DataProto 实现原理与数据流动分析
目录

1. 概述
2. DataProto 核心架构
3. HybridFlow 设计理念
4. 控制流与计算流分离
5. 数据流动机制
6. Dispatch 模式详解
7. 性能优化策略
8. 总结

1. 概述
Verl 是一个基于 HybridFlow 论文的开源强化学习训练框架，专门为大语言模型的后训练优化而设计。其核心创新在于将控制流和计算流分离，通过 DataProto 协议实现高效的数据交换。
2. DataProto 核心架构
2.1 数据结构设计
DataProto 是 verl 框架中用于数据交换的核心协议，基于 PyTorch 的 TensorDict 构建：


1
2
3
4
5


@dataclass
class DataProto:
    batch: TensorDict = None              # 张量数据容器
    non_tensor_batch: dict = field(default_factory=dict)  # 非张量数据
    meta_info: dict = field(default_factory=dict)         # 元信息


核心特性：

统一接口: 提供标准化的数据容器，支持张量和非张量数据
设备管理: 自动处理 GPU/CPU 设备间的数据移动
内存优化: 支持分块处理和内存复用
序列化: 支持高效的序列化和反序列化

2.2 数据一致性检查


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14


def check_consistency(self):
    """检查 DataProto 的一致性"""
    if self.batch is not None:
        assert len(self.batch.batch_size) == 1, "只支持 num_batch_dims=1"
    
    if self.non_tensor_batch is not None:
        for key, val in self.non_tensor_batch.items():
            assert isinstance(val, np.ndarray)
            
    # 检查批次大小一致性
    if self.batch is not None and self.non_tensor_batch is not None:
        batch_size = self.batch.batch_size[0]
        for key, val in self.non_tensor_batch.items():
            assert val.shape[0] == batch_size


3. HybridFlow 设计理念
3.1 设计动机
传统 RL 系统面临的问题：'><meta name=author content="Me"><link rel=canonical href=https://pillumina.github.io/posts/aiinfra/10-verl-dataproto/><link crossorigin=anonymous href=/assets/css/stylesheet.9d388901283682bb45dd422fcaa0d0a2054a3c8ff47c9cc6b2baab15508b1b90.css integrity="sha256-nTiJASg2grtF3UIvyqDQogVKPI/0fJzGsrqrFVCLG5A=" rel="preload stylesheet" as=style><link rel=icon href=https://pillumina.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://pillumina.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://pillumina.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://pillumina.github.io/apple-touch-icon.png><link rel=mask-icon href=https://pillumina.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://pillumina.github.io/posts/aiinfra/10-verl-dataproto/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js crossorigin=anonymous></script><script>(function(){function t(){return document.querySelector(".post-content")||document.querySelector(".post-single")||document.body}function n(e){return/\$\$[\s\S]+?\$\$|\\\(|\\\)|\\\[|\\\]/.test(e)}function s(e){if(window.__mathjaxLoaded)return;window.__mathjaxLoaded=!0,window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code","tt"],ignoreHtmlClass:"no-math"}};var t=document.createElement("script");t.src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js",t.defer=!0,t.onload=function(){window.MathJax&&window.MathJax.typesetPromise&&window.MathJax.typesetPromise([e]).catch(function(e){console.warn("MathJax typeset error",e)})},document.head.appendChild(t)}function e(){try{if(typeof renderMathInElement=="function"){const e=t();renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\[",right:"\\]",display:!0},{left:"\\(",right:"\\)",display:!1}],throwOnError:!1,strict:!1,trust:!0,ignoredTags:["script","noscript","style","textarea","pre","code","tt"],ignoredClasses:["no-math"],macros:{"\\boldsymbol":"\\mathbf{#1}","\\bm":"\\mathbf{#1}"}}),setTimeout(function(){n(e.innerHTML)&&s(e)},200)}}catch(e){console.warn("KaTeX render error:",e)}}document.addEventListener("DOMContentLoaded",function(){e(),setTimeout(e,200)}),window.addEventListener("load",function(){setTimeout(e,0)})})()</script><script src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script><script>const config={startOnLoad:!0,theme:"neutral",themeVariables:{lineColor:"#0f0f0f"},flowchart:{useMaxWidth:!1,htmlLabels:!0}};mermaid.initialize(config),window.onload=()=>{window.mermaid.init(0[0],document.querySelectorAll(".language-mermaid"))}</script><link rel=stylesheet href=/css/custom.min.bda7229c4269a242639e058fb11a4782f02f8d77071ba16609befee67cc41c49.css integrity="sha256-vacinEJpokJjngWPsRpHgvAvjXcHG6FmCb7+5nzEHEk="><script>document.addEventListener("DOMContentLoaded",function(){const t=document.querySelectorAll("h1[id], h2[id], h3[id], h4[id], h5[id], h6[id]"),n=document.querySelectorAll(".toc a");if(t.length===0||n.length===0)return;const s={};t.forEach(e=>{s[e.id]=e.offsetTop});function i(){const t=window.scrollY+100;let e="";for(const[n,o]of Object.entries(s))if(t>=o)e=n;else break;return e}function o(){const e=i();if(n.forEach(e=>{e.classList.remove("active")}),e){const t=document.querySelector(`.toc a[href="#${e}"]`);t&&t.classList.add("active")}}let e=!1;window.addEventListener("scroll",function(){e||(window.requestAnimationFrame(function(){o(),e=!1}),e=!0)}),o()})</script><meta property="og:url" content="https://pillumina.github.io/posts/aiinfra/10-verl-dataproto/"><meta property="og:site_name" content="CctoctoFX"><meta property="og:title" content="[VeRL] DataProto介绍"><meta property="og:description" content='Verl DataProto 实现原理与数据流动分析 目录 1. 概述 2. DataProto 核心架构 3. HybridFlow 设计理念 4. 控制流与计算流分离 5. 数据流动机制 6. Dispatch 模式详解 7. 性能优化策略 8. 总结 1. 概述 Verl 是一个基于 HybridFlow 论文的开源强化学习训练框架，专门为大语言模型的后训练优化而设计。其核心创新在于将控制流和计算流分离，通过 DataProto 协议实现高效的数据交换。
2. DataProto 核心架构 2.1 数据结构设计 DataProto 是 verl 框架中用于数据交换的核心协议，基于 PyTorch 的 TensorDict 构建：
1 2 3 4 5 @dataclass class DataProto: batch: TensorDict = None # 张量数据容器 non_tensor_batch: dict = field(default_factory=dict) # 非张量数据 meta_info: dict = field(default_factory=dict) # 元信息 核心特性：
统一接口: 提供标准化的数据容器，支持张量和非张量数据 设备管理: 自动处理 GPU/CPU 设备间的数据移动 内存优化: 支持分块处理和内存复用 序列化: 支持高效的序列化和反序列化 2.2 数据一致性检查 1 2 3 4 5 6 7 8 9 10 11 12 13 14 def check_consistency(self): """检查 DataProto 的一致性""" if self.batch is not None: assert len(self.batch.batch_size) == 1, "只支持 num_batch_dims=1" if self.non_tensor_batch is not None: for key, val in self.non_tensor_batch.items(): assert isinstance(val, np.ndarray) # 检查批次大小一致性 if self.batch is not None and self.non_tensor_batch is not None: batch_size = self.batch.batch_size[0] for key, val in self.non_tensor_batch.items(): assert val.shape[0] == batch_size 3. HybridFlow 设计理念 3.1 设计动机 传统 RL 系统面临的问题：'><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-08-25T11:30:12+08:00"><meta property="article:modified_time" content="2025-08-25T11:30:12+08:00"><meta property="article:tag" content="Framework"><meta property="article:tag" content="Verl"><meta property="og:image" content="https://pillumina.github.io/imgs/icon_head.png"><meta property="og:see_also" content="https://pillumina.github.io/posts/aiinfra/09-verl-agentloop/"><meta property="og:see_also" content="https://pillumina.github.io/posts/aiinfra/05-verl-params/"><meta property="og:see_also" content="https://pillumina.github.io/posts/aiinfra/08-verl-multiturn-2/"><meta property="og:see_also" content="https://pillumina.github.io/posts/aiinfra/07-verl-multiturn-1/"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://pillumina.github.io/imgs/icon_head.png"><meta name=twitter:title content="[VeRL] DataProto介绍"><meta name=twitter:description content='Verl DataProto 实现原理与数据流动分析
目录

1. 概述
2. DataProto 核心架构
3. HybridFlow 设计理念
4. 控制流与计算流分离
5. 数据流动机制
6. Dispatch 模式详解
7. 性能优化策略
8. 总结

1. 概述
Verl 是一个基于 HybridFlow 论文的开源强化学习训练框架，专门为大语言模型的后训练优化而设计。其核心创新在于将控制流和计算流分离，通过 DataProto 协议实现高效的数据交换。
2. DataProto 核心架构
2.1 数据结构设计
DataProto 是 verl 框架中用于数据交换的核心协议，基于 PyTorch 的 TensorDict 构建：


1
2
3
4
5


@dataclass
class DataProto:
    batch: TensorDict = None              # 张量数据容器
    non_tensor_batch: dict = field(default_factory=dict)  # 非张量数据
    meta_info: dict = field(default_factory=dict)         # 元信息


核心特性：

统一接口: 提供标准化的数据容器，支持张量和非张量数据
设备管理: 自动处理 GPU/CPU 设备间的数据移动
内存优化: 支持分块处理和内存复用
序列化: 支持高效的序列化和反序列化

2.2 数据一致性检查


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14


def check_consistency(self):
    """检查 DataProto 的一致性"""
    if self.batch is not None:
        assert len(self.batch.batch_size) == 1, "只支持 num_batch_dims=1"
    
    if self.non_tensor_batch is not None:
        for key, val in self.non_tensor_batch.items():
            assert isinstance(val, np.ndarray)
            
    # 检查批次大小一致性
    if self.batch is not None and self.non_tensor_batch is not None:
        batch_size = self.batch.batch_size[0]
        for key, val in self.non_tensor_batch.items():
            assert val.shape[0] == batch_size


3. HybridFlow 设计理念
3.1 设计动机
传统 RL 系统面临的问题：'><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://pillumina.github.io/posts/"},{"@type":"ListItem","position":2,"name":"AI Infra","item":"https://pillumina.github.io/posts/aiinfra/"},{"@type":"ListItem","position":3,"name":"[VeRL] DataProto介绍","item":"https://pillumina.github.io/posts/aiinfra/10-verl-dataproto/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[VeRL] DataProto介绍","name":"[VeRL] DataProto介绍","description":"Verl DataProto 实现原理与数据流动分析 目录 1. 概述 2. DataProto 核心架构 3. HybridFlow 设计理念 4. 控制流与计算流分离 5. 数据流动机制 6. Dispatch 模式详解 7. 性能优化策略 8. 总结 1. 概述 Verl 是一个基于 HybridFlow 论文的开源强化学习训练框架，专门为大语言模型的后训练优化而设计。其核心创新在于将控制流和计算流分离，通过 DataProto 协议实现高效的数据交换。\n2. DataProto 核心架构 2.1 数据结构设计 DataProto 是 verl 框架中用于数据交换的核心协议，基于 PyTorch 的 TensorDict 构建：\n1 2 3 4 5 @dataclass class DataProto: batch: TensorDict = None # 张量数据容器 non_tensor_batch: dict = field(default_factory=dict) # 非张量数据 meta_info: dict = field(default_factory=dict) # 元信息 核心特性：\n统一接口: 提供标准化的数据容器，支持张量和非张量数据 设备管理: 自动处理 GPU/CPU 设备间的数据移动 内存优化: 支持分块处理和内存复用 序列化: 支持高效的序列化和反序列化 2.2 数据一致性检查 1 2 3 4 5 6 7 8 9 10 11 12 13 14 def check_consistency(self): \u0026#34;\u0026#34;\u0026#34;检查 DataProto 的一致性\u0026#34;\u0026#34;\u0026#34; if self.batch is not None: assert len(self.batch.batch_size) == 1, \u0026#34;只支持 num_batch_dims=1\u0026#34; if self.non_tensor_batch is not None: for key, val in self.non_tensor_batch.items(): assert isinstance(val, np.ndarray) # 检查批次大小一致性 if self.batch is not None and self.non_tensor_batch is not None: batch_size = self.batch.batch_size[0] for key, val in self.non_tensor_batch.items(): assert val.shape[0] == batch_size 3. HybridFlow 设计理念 3.1 设计动机 传统 RL 系统面临的问题：\n","keywords":["framework","verl"],"articleBody":"Verl DataProto 实现原理与数据流动分析 目录 1. 概述 2. DataProto 核心架构 3. HybridFlow 设计理念 4. 控制流与计算流分离 5. 数据流动机制 6. Dispatch 模式详解 7. 性能优化策略 8. 总结 1. 概述 Verl 是一个基于 HybridFlow 论文的开源强化学习训练框架，专门为大语言模型的后训练优化而设计。其核心创新在于将控制流和计算流分离，通过 DataProto 协议实现高效的数据交换。\n2. DataProto 核心架构 2.1 数据结构设计 DataProto 是 verl 框架中用于数据交换的核心协议，基于 PyTorch 的 TensorDict 构建：\n1 2 3 4 5 @dataclass class DataProto: batch: TensorDict = None # 张量数据容器 non_tensor_batch: dict = field(default_factory=dict) # 非张量数据 meta_info: dict = field(default_factory=dict) # 元信息 核心特性：\n统一接口: 提供标准化的数据容器，支持张量和非张量数据 设备管理: 自动处理 GPU/CPU 设备间的数据移动 内存优化: 支持分块处理和内存复用 序列化: 支持高效的序列化和反序列化 2.2 数据一致性检查 1 2 3 4 5 6 7 8 9 10 11 12 13 14 def check_consistency(self): \"\"\"检查 DataProto 的一致性\"\"\" if self.batch is not None: assert len(self.batch.batch_size) == 1, \"只支持 num_batch_dims=1\" if self.non_tensor_batch is not None: for key, val in self.non_tensor_batch.items(): assert isinstance(val, np.ndarray) # 检查批次大小一致性 if self.batch is not None and self.non_tensor_batch is not None: batch_size = self.batch.batch_size[0] for key, val in self.non_tensor_batch.items(): assert val.shape[0] == batch_size 3. HybridFlow 设计理念 3.1 设计动机 传统 RL 系统面临的问题：\n耦合度高: 控制逻辑与计算实现紧密耦合 扩展性差: 难以支持不同的计算后端 复用困难: 算法逻辑难以在不同框架间复用 3.2 解决方案 HybridFlow 采用分离式设计：\ngraph TB\rsubgraph \"控制流 (Control Flow)\"\rA[RL算法逻辑] --\u003e B[训练循环控制]\rB --\u003e C[数据调度]\rC --\u003e D[结果收集]\rend\rsubgraph \"计算流 (Computation Flow)\"\rE[模型初始化] --\u003e F[前向传播]\rF --\u003e G[反向传播]\rG --\u003e H[参数更新]\rend\rD -.-\u003e|DataProto| E\rH -.-\u003e|DataProto| A\rstyle A fill:#4CAF50,stroke:#2E7D32,stroke-width:2px,color:#fff\rstyle E fill:#2196F3,stroke:#1565C0,stroke-width:2px,color:#fff\rstyle D fill:#FF9800,stroke:#E65100,stroke-width:2px,color:#fff\rstyle H fill:#9C27B0,stroke:#6A1B9A,stroke-width:2px,color:#fff 4. 控制流与计算流分离 4.1 控制流 (Control Flow) 控制流负责 RL 算法的核心逻辑，运行在单进程中：\n主要职责：\n训练循环管理 数据批次调度 算法参数控制 结果聚合分析 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class RayPPOTrainer: def fit(self): # 控制流：训练循环 for epoch in range(self.config.trainer.total_epochs): # 1. 数据准备 batch = self._get_training_batch() # 2. 分发到计算流 rollout_data = self.actor_rollout_wg.generate_sequences(batch) # 3. 收集结果 advantages = self._compute_advantages(rollout_data) # 4. 策略更新 self._update_policy(advantages) 4.2 计算流 (Computation Flow) 计算流负责神经网络计算，运行在多进程中：\n主要职责：\n模型前向/反向传播 梯度计算和参数更新 分布式同步 内存管理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @register(dispatch_mode=Dispatch.DP_COMPUTE_PROTO) def generate_sequences(self, data: DataProto) -\u003e DataProto: # 计算流：序列生成 with torch.no_grad(): # 1. 模型推理 outputs = self.model.generate( input_ids=data.batch[\"input_ids\"], attention_mask=data.batch[\"attention_mask\"] ) # 2. 返回结果 return DataProto( batch=TensorDict({ \"generated_ids\": outputs.sequences, \"log_probs\": outputs.log_probs }, batch_size=data.batch.batch_size), meta_info=data.meta_info ) 4.3 分离的优势 graph LR\rsubgraph \"优势分析\"\rA[软件复用性] --\u003e A1[控制流可复用]\rA --\u003e A2[计算流可复用]\rB[开发效率] --\u003e B1[单进程调试]\rB --\u003e B2[模块化开发]\rC[性能优化] --\u003e C1[独立优化]\rC --\u003e C2[灵活调度]\rend\rstyle A fill:#4CAF50,stroke:#2E7D32,stroke-width:2px,color:#fff\rstyle B fill:#2196F3,stroke:#1565C0,stroke-width:2px,color:#fff\rstyle C fill:#FF9800,stroke:#E65100,stroke-width:2px,color:#fff 5. 数据流动机制 5.1 完整数据流动图 graph TD\rA[训练数据] --\u003e B[DataProto创建]\rB --\u003e C[RayPPOTrainer控制流]\rC --\u003e D[数据分发阶段]\rD --\u003e E[WorkerGroup.generate_sequences]\rE --\u003e F{Dispatch模式选择}\rF --\u003e|DP_COMPUTE_PROTO| G[数据并行分割]\rF --\u003e|ONE_TO_ALL| H[广播分发]\rF --\u003e|ALL_TO_ALL| I[全对全通信]\rG --\u003e J[分发到计算Worker]\rH --\u003e J\rI --\u003e J\rJ --\u003e K[ActorRolloutWorker]\rJ --\u003e L[CriticWorker] J --\u003e M[ReferenceWorker]\rK --\u003e N[序列生成计算]\rL --\u003e O[价值函数计算]\rM --\u003e P[参考策略计算]\rN --\u003e Q[DataProto结果收集]\rO --\u003e Q\rP --\u003e Q\rQ --\u003e R[优势函数计算]\rR --\u003e S[策略梯度更新]\rS --\u003e T[模型参数同步]\rT --\u003e U[下一轮训练]\rU --\u003e D\rstyle A fill:#E3F2FD,stroke:#1976D2,stroke-width:2px\rstyle B fill:#F3E5F5,stroke:#7B1FA2,stroke-width:2px\rstyle C fill:#E8F5E8,stroke:#388E3C,stroke-width:2px\rstyle Q fill:#FFF3E0,stroke:#F57C00,stroke-width:2px\rstyle T fill:#FCE4EC,stroke:#C2185B,stroke-width:2px\rstyle F fill:#E0F2F1,stroke:#00695C,stroke-width:2px 5.2 数据流动时间线 gantt\rtitle DataProto在分布式训练中的时间线\rdateFormat X\raxisFormat %s\rsection 数据准备阶段\r数据加载与预处理 :0, 3\rDataProto对象创建 :3, 4\rsection 分发阶段\r数据分割与调度 :4, 5\r网络传输与分发 :5, 7\rsection 计算阶段\rActor模型推理 :7, 12\rCritic价值计算 :7, 10\rReference策略计算 :7, 11\rsection 收集阶段\r结果收集与合并 :12, 14\r数据格式转换 :14, 15\rsection 更新阶段\r优势函数计算 :15, 16\r策略梯度更新 :16, 18\r模型参数同步 :18, 20 6. Dispatch 模式详解 6.1 核心Dispatch模式 1 2 3 4 5 6 7 class Dispatch(DynamicEnum): RANK_ZERO = \"RANK_ZERO\" # 只在rank 0执行 ONE_TO_ALL = \"ONE_TO_ALL\" # 一对多广播 ALL_TO_ALL = \"ALL_TO_ALL\" # 全对全通信 DP_COMPUTE = \"DP_COMPUTE\" # 数据并行计算 DP_COMPUTE_PROTO = \"DP_COMPUTE_PROTO\" # DataProto数据并行 DP_COMPUTE_PROTO_WITH_FUNC = \"DP_COMPUTE_PROTO_WITH_FUNC\" # 带函数的DataProto并行 6.2 DP_COMPUTE_PROTO 实现 1 2 3 4 5 6 7 8 9 10 11 12 def dispatch_dp_compute_data_proto(worker_group, *args, **kwargs): \"\"\"DataProto数据并行分发\"\"\" # 自动分割DataProto到worker数量 splitted_args, splitted_kwargs = _split_args_kwargs_data_proto_with_auto_padding( worker_group.world_size, *args, **kwargs ) return splitted_args, splitted_kwargs def collect_dp_compute_data_proto(worker_group, output): \"\"\"DataProto数据并行收集\"\"\" output = collect_dp_compute(worker_group, output) return _concat_data_proto_or_future(output) 6.3 自动填充机制 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 def _split_args_kwargs_data_proto_with_auto_padding(chunks, *args, **kwargs): \"\"\"支持自动填充的数据分割\"\"\" data_proto_len = None padding_size = None def _padding_and_split_data(obj, chunks): nonlocal data_proto_len, padding_size if isinstance(obj, DataProto) and obj.is_padding_enabled(): if data_proto_len is None: data_proto_len = len(obj) padding_size = (chunks - (data_proto_len % chunks)) if (data_proto_len % chunks \u003e 0) else 0 obj.padding(padding_size=padding_size) return obj.chunk(chunks=chunks) # 处理所有参数 splitted_args = [_padding_and_split_data(arg, chunks) for arg in args] splitted_kwargs = {key: _padding_and_split_data(val, chunks) for key, val in kwargs.items()} return splitted_args, splitted_kwargs 6.4 Dispatch模式选择策略 graph TD\rA[方法调用] --\u003e B{检查register装饰器}\rB --\u003e|有装饰器| C[获取dispatch_mode]\rB --\u003e|无装饰器| D[使用默认模式]\rC --\u003e E{模式类型}\rE --\u003e|DP_COMPUTE_PROTO| F[数据并行处理]\rE --\u003e|ONE_TO_ALL| G[广播处理]\rE --\u003e|ALL_TO_ALL| H[全对全处理]\rF --\u003e I[分割DataProto]\rG --\u003e J[复制到所有Worker]\rH --\u003e K[直接分发]\rI --\u003e L[并行计算]\rJ --\u003e L\rK --\u003e L\rL --\u003e M[收集结果]\rM --\u003e N[合并DataProto]\rstyle A fill:#E3F2FD,stroke:#1976D2,stroke-width:2px\rstyle F fill:#E8F5E8,stroke:#388E3C,stroke-width:2px\rstyle G fill:#FFF3E0,stroke:#F57C00,stroke-width:2px\rstyle H fill:#F3E5F5,stroke:#7B1FA2,stroke-width:2px\rstyle N fill:#FCE4EC,stroke:#C2185B,stroke-width:2px 7. 性能优化策略 7.1 内存优化 分块处理:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def chunk(self, chunks: int) -\u003e list[\"DataProto\"]: \"\"\"将DataProto分割成多个块\"\"\" if self.batch is not None: batch_lst = self.batch.chunk(chunks=chunks, dim=0) else: batch_lst = [None for _ in range(chunks)] # 处理非张量数据 non_tensor_batch_lst = [{} for _ in range(chunks)] for key, val in self.non_tensor_batch.items(): non_tensor_lst = np.array_split(val, chunks) for i in range(chunks): non_tensor_batch_lst[i][key] = non_tensor_lst[i] return [type(self)(batch=batch_lst[i], non_tensor_batch=non_tensor_batch_lst[i], meta_info=self.meta_info) for i in range(chunks)] 内存复用:\n1 2 3 4 5 def to(self, device) -\u003e \"DataProto\": \"\"\"设备间数据移动\"\"\" if self.batch is not None: self.batch = self.batch.to(device) return self 7.2 异步执行 DataProtoFuture:\n1 2 3 4 5 6 7 8 9 10 11 12 13 @dataclass class DataProtoFuture: \"\"\"异步DataProto，避免阻塞控制流\"\"\" collect_fn: Callable futures: list[ray.ObjectRef] dispatch_fn: Callable = None def get(self): output = ray.get(self.futures) output = self.collect_fn(output) if self.dispatch_fn is not None: output = self.dispatch_fn(output) return output 7.3 流水线优化 graph LR\rsubgraph \"传统同步模式\"\rA1[生成] --\u003e B1[训练]\rB1 --\u003e C1[等待]\rC1 --\u003e A1\rend\rsubgraph \"verl异步模式\"\rA2[生成] --\u003e B2[训练]\rB2 --\u003e A2\rA2 -.-\u003e|异步| C2[并行执行]\rend\rstyle A1 fill:#FFCDD2,stroke:#D32F2F,stroke-width:2px\rstyle B1 fill:#FFCDD2,stroke:#D32F2F,stroke-width:2px\rstyle C1 fill:#FFCDD2,stroke:#D32F2F,stroke-width:2px\rstyle A2 fill:#C8E6C9,stroke:#388E3C,stroke-width:2px\rstyle B2 fill:#C8E6C9,stroke:#388E3C,stroke-width:2px\rstyle C2 fill:#C8E6C9,stroke:#388E3C,stroke-width:2px 7.4 网络优化 压缩传输:\n使用高效的序列化格式 支持数据压缩 批量传输减少网络开销 负载均衡:\n动态调整数据分发策略 监控网络延迟和带宽 自适应调整批次大小 8. 具体RL训练示例 8.1 PPO训练中的DataProto实例 让我们通过一个具体的PPO训练过程来展示DataProto的实际使用：\n8.1.1 训练数据准备 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 # 原始训练数据 raw_data = { \"prompts\": [ \"请计算 15 + 27 = ?\", \"求解方程 2x + 5 = 13\", \"一个圆的半径是3，求面积\" ], \"responses\": [ \"15 + 27 = 42\", \"2x + 5 = 13\\nx = 4\", \"面积 = πr² = 9π\" ], \"rewards\": [0.8, 0.9, 0.7] } # 转换为DataProto def create_training_dataproto(raw_data): # 1. 文本编码 tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-7B-Instruct\") prompt_ids = [] response_ids = [] attention_masks = [] for prompt, response in zip(raw_data[\"prompts\"], raw_data[\"responses\"]): # 编码prompt prompt_tokens = tokenizer.encode(prompt, add_special_tokens=True) prompt_ids.append(prompt_tokens) # 编码response response_tokens = tokenizer.encode(response, add_special_tokens=False) response_ids.append(response_tokens) # 创建attention mask total_length = len(prompt_tokens) + len(response_tokens) attention_masks.append([1] * total_length) # 2. 填充到相同长度 max_length = max(len(p) + len(r) for p, r in zip(prompt_ids, response_ids)) padded_prompt_ids = [] padded_response_ids = [] padded_attention_masks = [] for p_ids, r_ids, mask in zip(prompt_ids, response_ids, attention_masks): # 填充prompt padded_p = p_ids + [tokenizer.pad_token_id] * (max_length - len(p_ids) - len(r_ids)) padded_prompt_ids.append(padded_p) # 填充response padded_r = r_ids + [tokenizer.pad_token_id] * (max_length - len(p_ids) - len(r_ids)) padded_response_ids.append(padded_r) # 更新attention mask padded_mask = mask + [0] * (max_length - len(mask)) padded_attention_masks.append(padded_mask) # 3. 创建DataProto training_dataproto = DataProto.from_dict( tensors={ \"prompt_ids\": torch.tensor(padded_prompt_ids, dtype=torch.long), \"response_ids\": torch.tensor(padded_response_ids, dtype=torch.long), \"attention_mask\": torch.tensor(padded_attention_masks, dtype=torch.long), }, non_tensors={ \"raw_prompts\": np.array(raw_data[\"prompts\"], dtype=object), \"raw_responses\": np.array(raw_data[\"responses\"], dtype=object), \"rewards\": np.array(raw_data[\"rewards\"], dtype=np.float32), }, meta_info={ \"dataset_name\": \"math_training\", \"batch_size\": len(raw_data[\"prompts\"]), \"max_length\": max_length, \"tokenizer_name\": \"Qwen/Qwen2.5-7B-Instruct\" } ) return training_dataproto # 创建训练数据 training_data = create_training_dataproto(raw_data) print(\"DataProto结构:\") print(training_data.get_data_info()) 输出示例：\nDataProto结构:\rbatch\rprompt_ids: (3, 512) (torch.int64) cuda:0\rresponse_ids: (3, 512) (torch.int64) cuda:0\rattention_mask: (3, 512) (torch.int64) cuda:0\rnon_tensor_batch\rraw_prompts: ndarray(3,) (object)\rraw_responses: ndarray(3,) (object)\rrewards: ndarray(3,) (float32)\rmeta_info\rdataset_name: str\rbatch_size: int\rmax_length: int\rtokenizer_name: str 8.1.2 数据分发过程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # 假设有4个GPU worker world_size = 4 batch_size = 3 # 原始DataProto original_dataproto = training_data # batch_size=3 # 自动填充到能被4整除的大小 padded_dataproto, pad_size = pad_dataproto_to_divisor(original_dataproto, world_size) # 现在padded_dataproto的batch_size=4 (填充了1个样本) # 分割成4个chunk chunks = padded_dataproto.chunk(chunks=world_size) print(f\"原始batch_size: {len(original_dataproto)}\") print(f\"填充后batch_size: {len(padded_dataproto)}\") print(f\"分割后chunk数量: {len(chunks)}\") print(f\"每个chunk的batch_size: {len(chunks[0])}\") # 分发到各个worker for i, chunk in enumerate(chunks): print(f\"Worker {i} 接收数据:\") print(f\" - prompt_ids shape: {chunk.batch['prompt_ids'].shape}\") print(f\" - 包含样本数: {len(chunk)}\") 8.2 控制流与计算流交互示例 8.2.1 控制流：PPO训练循环 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 class RayPPOTrainer: def __init__(self, config): self.config = config self.actor_rollout_wg = None # Actor和Rollout的WorkerGroup self.critic_wg = None # Critic的WorkerGroup self.ref_policy_wg = None # Reference Policy的WorkerGroup def fit(self): \"\"\"PPO训练的主控制循环\"\"\" for epoch in range(self.config.trainer.total_epochs): print(f\"开始第 {epoch} 轮训练\") # 1. 获取训练批次 batch_dataproto = self._get_training_batch() print(f\"获取训练批次，batch_size: {len(batch_dataproto)}\") # 2. 分发到Actor进行序列生成 print(\"开始序列生成...\") rollout_dataproto = self.actor_rollout_wg.generate_sequences(batch_dataproto) print(f\"序列生成完成，生成 {len(rollout_dataproto)} 个序列\") # 3. 分发到Critic计算价值 print(\"开始价值计算...\") value_dataproto = self.critic_wg.compute_values(rollout_dataproto) print(f\"价值计算完成\") # 4. 分发到Reference Policy计算log概率 print(\"开始参考策略计算...\") ref_log_prob_dataproto = self.ref_policy_wg.compute_log_probs(rollout_dataproto) print(f\"参考策略计算完成\") # 5. 在控制流中计算优势函数 print(\"计算优势函数...\") advantages = self._compute_advantages( rollout_dataproto, value_dataproto, ref_log_prob_dataproto ) # 6. 更新Actor策略 print(\"更新Actor策略...\") self.actor_rollout_wg.update_actor(advantages) # 7. 更新Critic价值网络 print(\"更新Critic价值网络...\") self.critic_wg.update_critic(advantages) print(f\"第 {epoch} 轮训练完成\\n\") def _get_training_batch(self): \"\"\"获取训练批次\"\"\" # 从数据集中采样 batch_data = { \"prompt_ids\": torch.randint(0, 1000, (self.config.data.train_batch_size, 512)), \"attention_mask\": torch.ones(self.config.data.train_batch_size, 512), } return DataProto.from_dict( tensors=batch_data, meta_info={\"epoch\": self.current_epoch} ) def _compute_advantages(self, rollout_data, value_data, ref_log_prob_data): \"\"\"计算优势函数 - 在控制流中执行\"\"\" # 从各个DataProto中提取数据 rewards = rollout_data.batch[\"rewards\"] # [batch_size, seq_len] values = value_data.batch[\"values\"] # [batch_size, seq_len] log_probs = rollout_data.batch[\"log_probs\"] # [batch_size, seq_len] ref_log_probs = ref_log_prob_data.batch[\"log_probs\"] # [batch_size, seq_len] # 计算优势函数 advantages = rewards - values advantages = advantages * rollout_data.batch[\"attention_mask\"] # 计算策略比率 log_ratio = log_probs - ref_log_probs ratio = torch.exp(log_ratio) # 创建优势DataProto advantages_dataproto = DataProto.from_dict( tensors={ \"advantages\": advantages, \"ratio\": ratio, \"rewards\": rewards, \"values\": values }, meta_info=rollout_data.meta_info ) return advantages_dataproto 8.2.2 计算流：Worker实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 @ray.remote class ActorRolloutWorker: def __init__(self, model_config): self.model = None self.config = model_config @register(dispatch_mode=Dispatch.DP_COMPUTE_PROTO) def generate_sequences(self, data: DataProto) -\u003e DataProto: \"\"\"生成序列 - 在计算流中执行\"\"\" print(f\"Worker {self.rank} 开始生成序列，batch_size: {len(data)}\") # 1. 模型推理 with torch.no_grad(): input_ids = data.batch[\"prompt_ids\"] attention_mask = data.batch[\"attention_mask\"] # 生成序列 outputs = self.model.generate( input_ids=input_ids, attention_mask=attention_mask, max_new_tokens=256, do_sample=True, temperature=0.7, return_dict_in_generate=True, output_scores=True ) # 提取生成的token ids generated_ids = outputs.sequences log_probs = torch.stack(outputs.scores, dim=1).log_softmax(dim=-1) # 计算每个token的log概率 token_log_probs = [] for i, seq in enumerate(generated_ids): seq_log_probs = [] for j, token_id in enumerate(seq): if j \u003c len(log_probs[i]): seq_log_probs.append(log_probs[i][j][token_id].item()) token_log_probs.append(seq_log_probs) # 计算奖励（这里使用简单的长度奖励作为示例） rewards = torch.tensor([[len(seq) * 0.1] * len(seq) for seq in generated_ids]) # 2. 创建结果DataProto result_dataproto = DataProto.from_dict( tensors={ \"generated_ids\": generated_ids, \"log_probs\": torch.tensor(token_log_probs), \"rewards\": rewards, \"attention_mask\": torch.ones_like(generated_ids) }, non_tensors={ \"raw_generated_texts\": np.array([ self.tokenizer.decode(seq, skip_special_tokens=True) for seq in generated_ids ], dtype=object) }, meta_info=data.meta_info ) print(f\"Worker {self.rank} 序列生成完成\") return result_dataproto @register(dispatch_mode=Dispatch.DP_COMPUTE_PROTO) def update_actor(self, advantages: DataProto) -\u003e None: \"\"\"更新Actor策略 - 在计算流中执行\"\"\" print(f\"Worker {self.rank} 开始更新Actor策略\") # 1. 提取数据 advantages_tensor = advantages.batch[\"advantages\"] ratio = advantages.batch[\"ratio\"] rewards = advantages.batch[\"rewards\"] # 2. 计算PPO损失 clip_ratio = 0.2 policy_loss_1 = -advantages_tensor * ratio policy_loss_2 = -advantages_tensor * torch.clamp(ratio, 1 - clip_ratio, 1 + clip_ratio) policy_loss = torch.maximum(policy_loss_1, policy_loss_2).mean() # 3. 反向传播 self.optimizer.zero_grad() policy_loss.backward() self.optimizer.step() print(f\"Worker {self.rank} Actor策略更新完成，损失: {policy_loss.item():.4f}\") @ray.remote class CriticWorker: def __init__(self, model_config): self.model = None self.config = model_config @register(dispatch_mode=Dispatch.DP_COMPUTE_PROTO) def compute_values(self, data: DataProto) -\u003e DataProto: \"\"\"计算价值函数 - 在计算流中执行\"\"\" print(f\"Worker {self.rank} 开始计算价值函数\") with torch.no_grad(): input_ids = data.batch[\"generated_ids\"] attention_mask = data.batch[\"attention_mask\"] # 前向传播计算价值 outputs = self.model(input_ids=input_ids, attention_mask=attention_mask) values = outputs.value # [batch_size, seq_len] # 创建价值DataProto value_dataproto = DataProto.from_dict( tensors={\"values\": values}, meta_info=data.meta_info ) print(f\"Worker {self.rank} 价值函数计算完成\") return value_dataproto 8.3 数据流动可视化 8.3.1 单轮训练的数据流动 sequenceDiagram\rparticipant CF as 控制流\rparticipant AW as ActorWorker\rparticipant CW as CriticWorker\rparticipant RW as RefWorker\rCF-\u003e\u003eCF: 创建训练DataProto\rNote over CF: batch_size=256, 包含prompt_ids等\rCF-\u003e\u003eAW: generate_sequences(training_data)\rNote over AW: 自动分割为64个样本/worker\rAW-\u003e\u003eAW: 模型推理生成序列\rAW-\u003e\u003eCF: 返回rollout_data\rNote over CF: 包含generated_ids, log_probs, rewards\rCF-\u003e\u003eCW: compute_values(rollout_data)\rCW-\u003e\u003eCW: 计算价值函数\rCW-\u003e\u003eCF: 返回value_data\rCF-\u003e\u003eRW: compute_log_probs(rollout_data)\rRW-\u003e\u003eRW: 计算参考策略log概率\rRW-\u003e\u003eCF: 返回ref_log_prob_data\rCF-\u003e\u003eCF: 计算优势函数\rNote over CF: advantages = rewards - values\rCF-\u003e\u003eAW: update_actor(advantages)\rCF-\u003e\u003eCW: update_critic(advantages)\rNote over CF: 完成一轮训练 8.3.2 DataProto在训练过程中的形态变化 graph LR\rsubgraph \"训练开始\"\rA1[原始训练数据prompt_ids, attention_maskbatch_size=256]\rend\rsubgraph \"序列生成后\"\rA2[rollout_datagenerated_ids, log_probs, rewardsbatch_size=256]\rend\rsubgraph \"价值计算后\"\rA3[value_datavaluesbatch_size=256]\rend\rsubgraph \"优势计算后\"\rA4[advantages_dataadvantages, ratiobatch_size=256]\rend\rA1 --\u003e A2\rA2 --\u003e A3\rA3 --\u003e A4\rstyle A1 fill:#E3F2FD,stroke:#1976D2,stroke-width:2px\rstyle A2 fill:#E8F5E8,stroke:#388E3C,stroke-width:2px\rstyle A3 fill:#FFF3E0,stroke:#F57C00,stroke-width:2px\rstyle A4 fill:#F3E5F5,stroke:#7B1FA2,stroke-width:2px 8.4 关键特性展示 8.4.1 自动填充机制 1 2 3 4 5 6 7 8 9 10 11 12 13 # 示例：batch_size=250, world_size=4 original_batch_size = 250 world_size = 4 # 计算需要填充的数量 padding_needed = (world_size - (original_batch_size % world_size)) % world_size # padding_needed = 2 # 填充后的batch_size = 252，可以被4整除 final_batch_size = original_batch_size + padding_needed # 252 # 每个worker获得 252 // 4 = 63 个样本 samples_per_worker = final_batch_size // world_size # 63 8.4.2 异步执行示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 控制流中的异步调用 def async_training_step(self): # 1. 异步生成序列 rollout_future = self.actor_rollout_wg.generate_sequences.remote(training_data) # 2. 控制流可以继续其他工作 print(\"序列生成正在进行中...\") # 3. 当需要结果时再等待 rollout_data = ray.get(rollout_future) print(\"序列生成完成\") # 4. 继续后续步骤 value_data = self.critic_wg.compute_values(rollout_data) 9. 总结 9.1 核心优势 架构清晰: 控制流与计算流分离，职责明确 高度可扩展: 支持多种计算后端和并行策略 开发友好: 单进程控制流便于调试和开发 性能优异: 异步执行和内存优化提升训练效率 9.2 技术特点 DataProto协议: 统一的数据交换接口 Dispatch模式: 灵活的数据分发策略 异步执行: 支持非阻塞的分布式计算 内存优化: 高效的内存管理和复用机制 9.3 应用场景 大规模RL训练: 支持多节点、多GPU训练 算法研究: 便于实现和测试新的RL算法 生产部署: 支持高效的模型训练和推理 框架扩展: 易于集成新的计算后端和优化策略 Verl 通过 DataProto 和 HybridFlow 设计，成功解决了大规模强化学习训练中的架构挑战，为LLM后训练提供了高效、灵活、可扩展的解决方案。\n","wordCount":"2319","inLanguage":"en","image":"https://pillumina.github.io/imgs/icon_head.png","datePublished":"2025-08-25T11:30:12+08:00","dateModified":"2025-08-25T11:30:12+08:00","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://pillumina.github.io/posts/aiinfra/10-verl-dataproto/"},"publisher":{"@type":"Organization","name":"CctoctoFX","logo":{"@type":"ImageObject","url":"https://pillumina.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://pillumina.github.io/ accesskey=h title="CctoctoFX (Alt + H)"><img src=https://pillumina.github.io/apple-touch-icon.png alt aria-label=logo height=30>CctoctoFX</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://pillumina.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://pillumina.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://pillumina.github.io/posts/aiinfra/ title="AI Infra"><span>AI Infra</span></a></li><li><a href=https://pillumina.github.io/posts/llmtheory/ title=Thoery><span>Thoery</span></a></li><li><a href=https://pillumina.github.io/posts/programming/ title=Programming><span>Programming</span></a></li><li><a href=https://pillumina.github.io/social/ title=Social><span>Social</span></a></li><li><a href=https://pillumina.github.io/open_courses/ title=Study><span>Study</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://pillumina.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://pillumina.github.io/posts/>Posts</a>&nbsp;»&nbsp;<a href=https://pillumina.github.io/posts/aiinfra/>AI Infra</a></div><h1 class="post-title entry-hint-parent">[VeRL] DataProto介绍</h1><div class=post-meta><span title='2025-08-25 11:30:12 +0800 CST'>August 25, 2025</span>&nbsp;·&nbsp;11 min&nbsp;·&nbsp;2319 words&nbsp;·&nbsp;Me</div></header><div class="toc side left"><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#目录>目录</a></li><li><a href=#1-概述>1. 概述</a></li><li><a href=#2-dataproto-核心架构>2. DataProto 核心架构</a><ul><li><a href=#21-数据结构设计>2.1 数据结构设计</a></li><li><a href=#22-数据一致性检查>2.2 数据一致性检查</a></li></ul></li><li><a href=#3-hybridflow-设计理念>3. HybridFlow 设计理念</a><ul><li><a href=#31-设计动机>3.1 设计动机</a></li><li><a href=#32-解决方案>3.2 解决方案</a></li></ul></li><li><a href=#4-控制流与计算流分离>4. 控制流与计算流分离</a><ul><li><a href=#41-控制流-control-flow>4.1 控制流 (Control Flow)</a></li><li><a href=#42-计算流-computation-flow>4.2 计算流 (Computation Flow)</a></li><li><a href=#43-分离的优势>4.3 分离的优势</a></li></ul></li><li><a href=#5-数据流动机制>5. 数据流动机制</a><ul><li><a href=#51-完整数据流动图>5.1 完整数据流动图</a></li><li><a href=#52-数据流动时间线>5.2 数据流动时间线</a></li></ul></li><li><a href=#6-dispatch-模式详解>6. Dispatch 模式详解</a><ul><li><a href=#61-核心dispatch模式>6.1 核心Dispatch模式</a></li><li><a href=#62-dp_compute_proto-实现>6.2 DP_COMPUTE_PROTO 实现</a></li><li><a href=#63-自动填充机制>6.3 自动填充机制</a></li><li><a href=#64-dispatch模式选择策略>6.4 Dispatch模式选择策略</a></li></ul></li><li><a href=#7-性能优化策略>7. 性能优化策略</a><ul><li><a href=#71-内存优化>7.1 内存优化</a></li><li><a href=#72-异步执行>7.2 异步执行</a></li><li><a href=#73-流水线优化>7.3 流水线优化</a></li><li><a href=#74-网络优化>7.4 网络优化</a></li></ul></li><li><a href=#8-具体rl训练示例>8. 具体RL训练示例</a><ul><li><a href=#81-ppo训练中的dataproto实例>8.1 PPO训练中的DataProto实例</a></li><li><a href=#82-控制流与计算流交互示例>8.2 控制流与计算流交互示例</a></li><li><a href=#83-数据流动可视化>8.3 数据流动可视化</a></li><li><a href=#84-关键特性展示>8.4 关键特性展示</a></li></ul></li><li><a href=#9-总结>9. 总结</a><ul><li><a href=#91-核心优势>9.1 核心优势</a></li><li><a href=#92-技术特点>9.2 技术特点</a></li><li><a href=#93-应用场景>9.3 应用场景</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h1 id=verl-dataproto-实现原理与数据流动分析>Verl DataProto 实现原理与数据流动分析<a hidden class=anchor aria-hidden=true href=#verl-dataproto-实现原理与数据流动分析>#</a></h1><h2 id=目录>目录<a hidden class=anchor aria-hidden=true href=#目录>#</a></h2><ul><li><a href=/posts/aiinfra/10-verl-dataproto/#1-%e6%a6%82%e8%bf%b0>1. 概述</a></li><li><a href=/posts/aiinfra/10-verl-dataproto/#2-dataproto-%e6%a0%b8%e5%bf%83%e6%9e%b6%e6%9e%84>2. DataProto 核心架构</a></li><li><a href=/posts/aiinfra/10-verl-dataproto/#3-hybridflow-%e8%ae%be%e8%ae%a1%e7%90%86%e5%bf%b5>3. HybridFlow 设计理念</a></li><li><a href=/posts/aiinfra/10-verl-dataproto/#4-%e6%8e%a7%e5%88%b6%e6%b5%81%e4%b8%8e%e8%ae%a1%e7%ae%97%e6%b5%81%e5%88%86%e7%a6%bb>4. 控制流与计算流分离</a></li><li><a href=/posts/aiinfra/10-verl-dataproto/#5-%e6%95%b0%e6%8d%ae%e6%b5%81%e5%8a%a8%e6%9c%ba%e5%88%b6>5. 数据流动机制</a></li><li><a href=/posts/aiinfra/10-verl-dataproto/#6-dispatch-%e6%a8%a1%e5%bc%8f%e8%af%a6%e8%a7%a3>6. Dispatch 模式详解</a></li><li><a href=/posts/aiinfra/10-verl-dataproto/#7-%e6%80%a7%e8%83%bd%e4%bc%98%e5%8c%96%e7%ad%96%e7%95%a5>7. 性能优化策略</a></li><li><a href=/posts/aiinfra/10-verl-dataproto/#8-%e6%80%bb%e7%bb%93>8. 总结</a></li></ul><h2 id=1-概述>1. 概述<a hidden class=anchor aria-hidden=true href=#1-概述>#</a></h2><p>Verl 是一个基于 HybridFlow 论文的开源强化学习训练框架，专门为大语言模型的后训练优化而设计。其核心创新在于将控制流和计算流分离，通过 DataProto 协议实现高效的数据交换。</p><h2 id=2-dataproto-核心架构>2. DataProto 核心架构<a hidden class=anchor aria-hidden=true href=#2-dataproto-核心架构>#</a></h2><h3 id=21-数据结构设计>2.1 数据结构设计<a hidden class=anchor aria-hidden=true href=#21-数据结构设计>#</a></h3><p>DataProto 是 verl 框架中用于数据交换的核心协议，基于 PyTorch 的 TensorDict 构建：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@dataclass</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>DataProto</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>batch</span><span class=p>:</span> <span class=n>TensorDict</span> <span class=o>=</span> <span class=kc>None</span>              <span class=c1># 张量数据容器</span>
</span></span><span class=line><span class=cl>    <span class=n>non_tensor_batch</span><span class=p>:</span> <span class=nb>dict</span> <span class=o>=</span> <span class=n>field</span><span class=p>(</span><span class=n>default_factory</span><span class=o>=</span><span class=nb>dict</span><span class=p>)</span>  <span class=c1># 非张量数据</span>
</span></span><span class=line><span class=cl>    <span class=n>meta_info</span><span class=p>:</span> <span class=nb>dict</span> <span class=o>=</span> <span class=n>field</span><span class=p>(</span><span class=n>default_factory</span><span class=o>=</span><span class=nb>dict</span><span class=p>)</span>         <span class=c1># 元信息</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>核心特性：</strong></p><ul><li><strong>统一接口</strong>: 提供标准化的数据容器，支持张量和非张量数据</li><li><strong>设备管理</strong>: 自动处理 GPU/CPU 设备间的数据移动</li><li><strong>内存优化</strong>: 支持分块处理和内存复用</li><li><strong>序列化</strong>: 支持高效的序列化和反序列化</li></ul><h3 id=22-数据一致性检查>2.2 数据一致性检查<a hidden class=anchor aria-hidden=true href=#22-数据一致性检查>#</a></h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>check_consistency</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;检查 DataProto 的一致性&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>batch</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>assert</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>batch</span><span class=o>.</span><span class=n>batch_size</span><span class=p>)</span> <span class=o>==</span> <span class=mi>1</span><span class=p>,</span> <span class=s2>&#34;只支持 num_batch_dims=1&#34;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>non_tensor_batch</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>key</span><span class=p>,</span> <span class=n>val</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>non_tensor_batch</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=k>assert</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>val</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>    <span class=c1># 检查批次大小一致性</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>batch</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span> <span class=ow>and</span> <span class=bp>self</span><span class=o>.</span><span class=n>non_tensor_batch</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>batch_size</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>batch</span><span class=o>.</span><span class=n>batch_size</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>key</span><span class=p>,</span> <span class=n>val</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>non_tensor_batch</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=k>assert</span> <span class=n>val</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>==</span> <span class=n>batch_size</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=3-hybridflow-设计理念>3. HybridFlow 设计理念<a hidden class=anchor aria-hidden=true href=#3-hybridflow-设计理念>#</a></h2><h3 id=31-设计动机>3.1 设计动机<a hidden class=anchor aria-hidden=true href=#31-设计动机>#</a></h3><p>传统 RL 系统面临的问题：</p><ul><li><strong>耦合度高</strong>: 控制逻辑与计算实现紧密耦合</li><li><strong>扩展性差</strong>: 难以支持不同的计算后端</li><li><strong>复用困难</strong>: 算法逻辑难以在不同框架间复用</li></ul><h3 id=32-解决方案>3.2 解决方案<a hidden class=anchor aria-hidden=true href=#32-解决方案>#</a></h3><p>HybridFlow 采用分离式设计：</p><pre class=mermaid>
  graph TB
    subgraph &#34;控制流 (Control Flow)&#34;
        A[RL算法逻辑] --&gt; B[训练循环控制]
        B --&gt; C[数据调度]
        C --&gt; D[结果收集]
    end
    
    subgraph &#34;计算流 (Computation Flow)&#34;
        E[模型初始化] --&gt; F[前向传播]
        F --&gt; G[反向传播]
        G --&gt; H[参数更新]
    end
    
    D -.-&gt;|DataProto| E
    H -.-&gt;|DataProto| A
    
    style A fill:#4CAF50,stroke:#2E7D32,stroke-width:2px,color:#fff
    style E fill:#2196F3,stroke:#1565C0,stroke-width:2px,color:#fff
    style D fill:#FF9800,stroke:#E65100,stroke-width:2px,color:#fff
    style H fill:#9C27B0,stroke:#6A1B9A,stroke-width:2px,color:#fff
</pre><h2 id=4-控制流与计算流分离>4. 控制流与计算流分离<a hidden class=anchor aria-hidden=true href=#4-控制流与计算流分离>#</a></h2><h3 id=41-控制流-control-flow>4.1 控制流 (Control Flow)<a hidden class=anchor aria-hidden=true href=#41-控制流-control-flow>#</a></h3><p>控制流负责 RL 算法的核心逻辑，运行在单进程中：</p><p><strong>主要职责：</strong></p><ul><li>训练循环管理</li><li>数据批次调度</li><li>算法参数控制</li><li>结果聚合分析</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>RayPPOTrainer</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>fit</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 控制流：训练循环</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>total_epochs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=c1># 1. 数据准备</span>
</span></span><span class=line><span class=cl>            <span class=n>batch</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_get_training_batch</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 2. 分发到计算流</span>
</span></span><span class=line><span class=cl>            <span class=n>rollout_data</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>actor_rollout_wg</span><span class=o>.</span><span class=n>generate_sequences</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 3. 收集结果</span>
</span></span><span class=line><span class=cl>            <span class=n>advantages</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_compute_advantages</span><span class=p>(</span><span class=n>rollout_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 4. 策略更新</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>_update_policy</span><span class=p>(</span><span class=n>advantages</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=42-计算流-computation-flow>4.2 计算流 (Computation Flow)<a hidden class=anchor aria-hidden=true href=#42-计算流-computation-flow>#</a></h3><p>计算流负责神经网络计算，运行在多进程中：</p><p><strong>主要职责：</strong></p><ul><li>模型前向/反向传播</li><li>梯度计算和参数更新</li><li>分布式同步</li><li>内存管理</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@register</span><span class=p>(</span><span class=n>dispatch_mode</span><span class=o>=</span><span class=n>Dispatch</span><span class=o>.</span><span class=n>DP_COMPUTE_PROTO</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>generate_sequences</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>data</span><span class=p>:</span> <span class=n>DataProto</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>DataProto</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># 计算流：序列生成</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=c1># 1. 模型推理</span>
</span></span><span class=line><span class=cl>        <span class=n>outputs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>input_ids</span><span class=o>=</span><span class=n>data</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;input_ids&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>            <span class=n>attention_mask</span><span class=o>=</span><span class=n>data</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;attention_mask&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 2. 返回结果</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>DataProto</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>batch</span><span class=o>=</span><span class=n>TensorDict</span><span class=p>({</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;generated_ids&#34;</span><span class=p>:</span> <span class=n>outputs</span><span class=o>.</span><span class=n>sequences</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;log_probs&#34;</span><span class=p>:</span> <span class=n>outputs</span><span class=o>.</span><span class=n>log_probs</span>
</span></span><span class=line><span class=cl>            <span class=p>},</span> <span class=n>batch_size</span><span class=o>=</span><span class=n>data</span><span class=o>.</span><span class=n>batch</span><span class=o>.</span><span class=n>batch_size</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>meta_info</span><span class=o>=</span><span class=n>data</span><span class=o>.</span><span class=n>meta_info</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=43-分离的优势>4.3 分离的优势<a hidden class=anchor aria-hidden=true href=#43-分离的优势>#</a></h3><pre class=mermaid>
  graph LR
    subgraph &#34;优势分析&#34;
        A[软件复用性] --&gt; A1[控制流可复用]
        A --&gt; A2[计算流可复用]
        
        B[开发效率] --&gt; B1[单进程调试]
        B --&gt; B2[模块化开发]
        
        C[性能优化] --&gt; C1[独立优化]
        C --&gt; C2[灵活调度]
    end
    
    style A fill:#4CAF50,stroke:#2E7D32,stroke-width:2px,color:#fff
    style B fill:#2196F3,stroke:#1565C0,stroke-width:2px,color:#fff
    style C fill:#FF9800,stroke:#E65100,stroke-width:2px,color:#fff
</pre><h2 id=5-数据流动机制>5. 数据流动机制<a hidden class=anchor aria-hidden=true href=#5-数据流动机制>#</a></h2><h3 id=51-完整数据流动图>5.1 完整数据流动图<a hidden class=anchor aria-hidden=true href=#51-完整数据流动图>#</a></h3><pre class=mermaid>
  graph TD
    A[训练数据] --&gt; B[DataProto创建]
    B --&gt; C[RayPPOTrainer控制流]
    
    C --&gt; D[数据分发阶段]
    D --&gt; E[WorkerGroup.generate_sequences]
    
    E --&gt; F{Dispatch模式选择}
    F --&gt;|DP_COMPUTE_PROTO| G[数据并行分割]
    F --&gt;|ONE_TO_ALL| H[广播分发]
    F --&gt;|ALL_TO_ALL| I[全对全通信]
    
    G --&gt; J[分发到计算Worker]
    H --&gt; J
    I --&gt; J
    
    J --&gt; K[ActorRolloutWorker]
    J --&gt; L[CriticWorker] 
    J --&gt; M[ReferenceWorker]
    
    K --&gt; N[序列生成计算]
    L --&gt; O[价值函数计算]
    M --&gt; P[参考策略计算]
    
    N --&gt; Q[DataProto结果收集]
    O --&gt; Q
    P --&gt; Q
    
    Q --&gt; R[优势函数计算]
    R --&gt; S[策略梯度更新]
    S --&gt; T[模型参数同步]
    
    T --&gt; U[下一轮训练]
    U --&gt; D
    
    style A fill:#E3F2FD,stroke:#1976D2,stroke-width:2px
    style B fill:#F3E5F5,stroke:#7B1FA2,stroke-width:2px
    style C fill:#E8F5E8,stroke:#388E3C,stroke-width:2px
    style Q fill:#FFF3E0,stroke:#F57C00,stroke-width:2px
    style T fill:#FCE4EC,stroke:#C2185B,stroke-width:2px
    style F fill:#E0F2F1,stroke:#00695C,stroke-width:2px
</pre><h3 id=52-数据流动时间线>5.2 数据流动时间线<a hidden class=anchor aria-hidden=true href=#52-数据流动时间线>#</a></h3><pre class=mermaid>
  gantt
    title DataProto在分布式训练中的时间线
    dateFormat X
    axisFormat %s
    
    section 数据准备阶段
    数据加载与预处理    :0, 3
    DataProto对象创建   :3, 4
    
    section 分发阶段
    数据分割与调度     :4, 5
    网络传输与分发     :5, 7
    
    section 计算阶段
    Actor模型推理      :7, 12
    Critic价值计算     :7, 10
    Reference策略计算  :7, 11
    
    section 收集阶段
    结果收集与合并     :12, 14
    数据格式转换       :14, 15
    
    section 更新阶段
    优势函数计算       :15, 16
    策略梯度更新       :16, 18
    模型参数同步       :18, 20
</pre><h2 id=6-dispatch-模式详解>6. Dispatch 模式详解<a hidden class=anchor aria-hidden=true href=#6-dispatch-模式详解>#</a></h2><h3 id=61-核心dispatch模式>6.1 核心Dispatch模式<a hidden class=anchor aria-hidden=true href=#61-核心dispatch模式>#</a></h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Dispatch</span><span class=p>(</span><span class=n>DynamicEnum</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>RANK_ZERO</span> <span class=o>=</span> <span class=s2>&#34;RANK_ZERO&#34;</span>                    <span class=c1># 只在rank 0执行</span>
</span></span><span class=line><span class=cl>    <span class=n>ONE_TO_ALL</span> <span class=o>=</span> <span class=s2>&#34;ONE_TO_ALL&#34;</span>                  <span class=c1># 一对多广播</span>
</span></span><span class=line><span class=cl>    <span class=n>ALL_TO_ALL</span> <span class=o>=</span> <span class=s2>&#34;ALL_TO_ALL&#34;</span>                  <span class=c1># 全对全通信</span>
</span></span><span class=line><span class=cl>    <span class=n>DP_COMPUTE</span> <span class=o>=</span> <span class=s2>&#34;DP_COMPUTE&#34;</span>                   <span class=c1># 数据并行计算</span>
</span></span><span class=line><span class=cl>    <span class=n>DP_COMPUTE_PROTO</span> <span class=o>=</span> <span class=s2>&#34;DP_COMPUTE_PROTO&#34;</span>       <span class=c1># DataProto数据并行</span>
</span></span><span class=line><span class=cl>    <span class=n>DP_COMPUTE_PROTO_WITH_FUNC</span> <span class=o>=</span> <span class=s2>&#34;DP_COMPUTE_PROTO_WITH_FUNC&#34;</span>  <span class=c1># 带函数的DataProto并行</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=62-dp_compute_proto-实现>6.2 DP_COMPUTE_PROTO 实现<a hidden class=anchor aria-hidden=true href=#62-dp_compute_proto-实现>#</a></h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>dispatch_dp_compute_data_proto</span><span class=p>(</span><span class=n>worker_group</span><span class=p>,</span> <span class=o>*</span><span class=n>args</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;DataProto数据并行分发&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># 自动分割DataProto到worker数量</span>
</span></span><span class=line><span class=cl>    <span class=n>splitted_args</span><span class=p>,</span> <span class=n>splitted_kwargs</span> <span class=o>=</span> <span class=n>_split_args_kwargs_data_proto_with_auto_padding</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>worker_group</span><span class=o>.</span><span class=n>world_size</span><span class=p>,</span> <span class=o>*</span><span class=n>args</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>splitted_args</span><span class=p>,</span> <span class=n>splitted_kwargs</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>collect_dp_compute_data_proto</span><span class=p>(</span><span class=n>worker_group</span><span class=p>,</span> <span class=n>output</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;DataProto数据并行收集&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>output</span> <span class=o>=</span> <span class=n>collect_dp_compute</span><span class=p>(</span><span class=n>worker_group</span><span class=p>,</span> <span class=n>output</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>_concat_data_proto_or_future</span><span class=p>(</span><span class=n>output</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=63-自动填充机制>6.3 自动填充机制<a hidden class=anchor aria-hidden=true href=#63-自动填充机制>#</a></h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>_split_args_kwargs_data_proto_with_auto_padding</span><span class=p>(</span><span class=n>chunks</span><span class=p>,</span> <span class=o>*</span><span class=n>args</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;支持自动填充的数据分割&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>data_proto_len</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>    <span class=n>padding_size</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_padding_and_split_data</span><span class=p>(</span><span class=n>obj</span><span class=p>,</span> <span class=n>chunks</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>nonlocal</span> <span class=n>data_proto_len</span><span class=p>,</span> <span class=n>padding_size</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>obj</span><span class=p>,</span> <span class=n>DataProto</span><span class=p>)</span> <span class=ow>and</span> <span class=n>obj</span><span class=o>.</span><span class=n>is_padding_enabled</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>data_proto_len</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>data_proto_len</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>obj</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>padding_size</span> <span class=o>=</span> <span class=p>(</span><span class=n>chunks</span> <span class=o>-</span> <span class=p>(</span><span class=n>data_proto_len</span> <span class=o>%</span> <span class=n>chunks</span><span class=p>))</span> <span class=k>if</span> <span class=p>(</span><span class=n>data_proto_len</span> <span class=o>%</span> <span class=n>chunks</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>)</span> <span class=k>else</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>            <span class=n>obj</span><span class=o>.</span><span class=n>padding</span><span class=p>(</span><span class=n>padding_size</span><span class=o>=</span><span class=n>padding_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>obj</span><span class=o>.</span><span class=n>chunk</span><span class=p>(</span><span class=n>chunks</span><span class=o>=</span><span class=n>chunks</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 处理所有参数</span>
</span></span><span class=line><span class=cl>    <span class=n>splitted_args</span> <span class=o>=</span> <span class=p>[</span><span class=n>_padding_and_split_data</span><span class=p>(</span><span class=n>arg</span><span class=p>,</span> <span class=n>chunks</span><span class=p>)</span> <span class=k>for</span> <span class=n>arg</span> <span class=ow>in</span> <span class=n>args</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>splitted_kwargs</span> <span class=o>=</span> <span class=p>{</span><span class=n>key</span><span class=p>:</span> <span class=n>_padding_and_split_data</span><span class=p>(</span><span class=n>val</span><span class=p>,</span> <span class=n>chunks</span><span class=p>)</span> <span class=k>for</span> <span class=n>key</span><span class=p>,</span> <span class=n>val</span> <span class=ow>in</span> <span class=n>kwargs</span><span class=o>.</span><span class=n>items</span><span class=p>()}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>splitted_args</span><span class=p>,</span> <span class=n>splitted_kwargs</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=64-dispatch模式选择策略>6.4 Dispatch模式选择策略<a hidden class=anchor aria-hidden=true href=#64-dispatch模式选择策略>#</a></h3><pre class=mermaid>
  graph TD
    A[方法调用] --&gt; B{检查register装饰器}
    B --&gt;|有装饰器| C[获取dispatch_mode]
    B --&gt;|无装饰器| D[使用默认模式]
    
    C --&gt; E{模式类型}
    E --&gt;|DP_COMPUTE_PROTO| F[数据并行处理]
    E --&gt;|ONE_TO_ALL| G[广播处理]
    E --&gt;|ALL_TO_ALL| H[全对全处理]
    
    F --&gt; I[分割DataProto]
    G --&gt; J[复制到所有Worker]
    H --&gt; K[直接分发]
    
    I --&gt; L[并行计算]
    J --&gt; L
    K --&gt; L
    
    L --&gt; M[收集结果]
    M --&gt; N[合并DataProto]
    
    style A fill:#E3F2FD,stroke:#1976D2,stroke-width:2px
    style F fill:#E8F5E8,stroke:#388E3C,stroke-width:2px
    style G fill:#FFF3E0,stroke:#F57C00,stroke-width:2px
    style H fill:#F3E5F5,stroke:#7B1FA2,stroke-width:2px
    style N fill:#FCE4EC,stroke:#C2185B,stroke-width:2px
</pre><h2 id=7-性能优化策略>7. 性能优化策略<a hidden class=anchor aria-hidden=true href=#7-性能优化策略>#</a></h2><h3 id=71-内存优化>7.1 内存优化<a hidden class=anchor aria-hidden=true href=#71-内存优化>#</a></h3><p><strong>分块处理</strong>:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>chunk</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>chunks</span><span class=p>:</span> <span class=nb>int</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>list</span><span class=p>[</span><span class=s2>&#34;DataProto&#34;</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;将DataProto分割成多个块&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>batch</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>batch_lst</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>batch</span><span class=o>.</span><span class=n>chunk</span><span class=p>(</span><span class=n>chunks</span><span class=o>=</span><span class=n>chunks</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>batch_lst</span> <span class=o>=</span> <span class=p>[</span><span class=kc>None</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>chunks</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 处理非张量数据</span>
</span></span><span class=line><span class=cl>    <span class=n>non_tensor_batch_lst</span> <span class=o>=</span> <span class=p>[{}</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>chunks</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>key</span><span class=p>,</span> <span class=n>val</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>non_tensor_batch</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>non_tensor_lst</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array_split</span><span class=p>(</span><span class=n>val</span><span class=p>,</span> <span class=n>chunks</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>chunks</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>non_tensor_batch_lst</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=n>key</span><span class=p>]</span> <span class=o>=</span> <span class=n>non_tensor_lst</span><span class=p>[</span><span class=n>i</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>[</span><span class=nb>type</span><span class=p>(</span><span class=bp>self</span><span class=p>)(</span><span class=n>batch</span><span class=o>=</span><span class=n>batch_lst</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>                      <span class=n>non_tensor_batch</span><span class=o>=</span><span class=n>non_tensor_batch_lst</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>                      <span class=n>meta_info</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>meta_info</span><span class=p>)</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>chunks</span><span class=p>)]</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>内存复用</strong>:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>to</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>device</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=s2>&#34;DataProto&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;设备间数据移动&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>batch</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>batch</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>batch</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=bp>self</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=72-异步执行>7.2 异步执行<a hidden class=anchor aria-hidden=true href=#72-异步执行>#</a></h3><p><strong>DataProtoFuture</strong>:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@dataclass</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>DataProtoFuture</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;异步DataProto，避免阻塞控制流&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>collect_fn</span><span class=p>:</span> <span class=n>Callable</span>
</span></span><span class=line><span class=cl>    <span class=n>futures</span><span class=p>:</span> <span class=nb>list</span><span class=p>[</span><span class=n>ray</span><span class=o>.</span><span class=n>ObjectRef</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>dispatch_fn</span><span class=p>:</span> <span class=n>Callable</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>get</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>output</span> <span class=o>=</span> <span class=n>ray</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>futures</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>collect_fn</span><span class=p>(</span><span class=n>output</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>dispatch_fn</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>dispatch_fn</span><span class=p>(</span><span class=n>output</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>output</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=73-流水线优化>7.3 流水线优化<a hidden class=anchor aria-hidden=true href=#73-流水线优化>#</a></h3><pre class=mermaid>
  graph LR
    subgraph &#34;传统同步模式&#34;
        A1[生成] --&gt; B1[训练]
        B1 --&gt; C1[等待]
        C1 --&gt; A1
    end
    
    subgraph &#34;verl异步模式&#34;
        A2[生成] --&gt; B2[训练]
        B2 --&gt; A2
        A2 -.-&gt;|异步| C2[并行执行]
    end
    
    style A1 fill:#FFCDD2,stroke:#D32F2F,stroke-width:2px
    style B1 fill:#FFCDD2,stroke:#D32F2F,stroke-width:2px
    style C1 fill:#FFCDD2,stroke:#D32F2F,stroke-width:2px
    
    style A2 fill:#C8E6C9,stroke:#388E3C,stroke-width:2px
    style B2 fill:#C8E6C9,stroke:#388E3C,stroke-width:2px
    style C2 fill:#C8E6C9,stroke:#388E3C,stroke-width:2px
</pre><h3 id=74-网络优化>7.4 网络优化<a hidden class=anchor aria-hidden=true href=#74-网络优化>#</a></h3><p><strong>压缩传输</strong>:</p><ul><li>使用高效的序列化格式</li><li>支持数据压缩</li><li>批量传输减少网络开销</li></ul><p><strong>负载均衡</strong>:</p><ul><li>动态调整数据分发策略</li><li>监控网络延迟和带宽</li><li>自适应调整批次大小</li></ul><h2 id=8-具体rl训练示例>8. 具体RL训练示例<a hidden class=anchor aria-hidden=true href=#8-具体rl训练示例>#</a></h2><h3 id=81-ppo训练中的dataproto实例>8.1 PPO训练中的DataProto实例<a hidden class=anchor aria-hidden=true href=#81-ppo训练中的dataproto实例>#</a></h3><p>让我们通过一个具体的PPO训练过程来展示DataProto的实际使用：</p><h4 id=811-训练数据准备>8.1.1 训练数据准备<a hidden class=anchor aria-hidden=true href=#811-训练数据准备>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span><span class=lnt>72
</span><span class=lnt>73
</span><span class=lnt>74
</span><span class=lnt>75
</span><span class=lnt>76
</span><span class=lnt>77
</span><span class=lnt>78
</span><span class=lnt>79
</span><span class=lnt>80
</span><span class=lnt>81
</span><span class=lnt>82
</span><span class=lnt>83
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 原始训练数据</span>
</span></span><span class=line><span class=cl><span class=n>raw_data</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;prompts&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;请计算 15 + 27 = ?&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;求解方程 2x + 5 = 13&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;一个圆的半径是3，求面积&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;responses&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;15 + 27 = 42&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;2x + 5 = 13</span><span class=se>\n</span><span class=s2>x = 4&#34;</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>        <span class=s2>&#34;面积 = πr² = 9π&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;rewards&#34;</span><span class=p>:</span> <span class=p>[</span><span class=mf>0.8</span><span class=p>,</span> <span class=mf>0.9</span><span class=p>,</span> <span class=mf>0.7</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 转换为DataProto</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>create_training_dataproto</span><span class=p>(</span><span class=n>raw_data</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># 1. 文本编码</span>
</span></span><span class=line><span class=cl>    <span class=n>tokenizer</span> <span class=o>=</span> <span class=n>AutoTokenizer</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&#34;Qwen/Qwen2.5-7B-Instruct&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>prompt_ids</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>response_ids</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>attention_masks</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>prompt</span><span class=p>,</span> <span class=n>response</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>raw_data</span><span class=p>[</span><span class=s2>&#34;prompts&#34;</span><span class=p>],</span> <span class=n>raw_data</span><span class=p>[</span><span class=s2>&#34;responses&#34;</span><span class=p>]):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 编码prompt</span>
</span></span><span class=line><span class=cl>        <span class=n>prompt_tokens</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=n>prompt</span><span class=p>,</span> <span class=n>add_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>prompt_ids</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>prompt_tokens</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 编码response</span>
</span></span><span class=line><span class=cl>        <span class=n>response_tokens</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=n>response</span><span class=p>,</span> <span class=n>add_special_tokens</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>response_ids</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>response_tokens</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 创建attention mask</span>
</span></span><span class=line><span class=cl>        <span class=n>total_length</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>prompt_tokens</span><span class=p>)</span> <span class=o>+</span> <span class=nb>len</span><span class=p>(</span><span class=n>response_tokens</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>attention_masks</span><span class=o>.</span><span class=n>append</span><span class=p>([</span><span class=mi>1</span><span class=p>]</span> <span class=o>*</span> <span class=n>total_length</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 2. 填充到相同长度</span>
</span></span><span class=line><span class=cl>    <span class=n>max_length</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>p</span><span class=p>)</span> <span class=o>+</span> <span class=nb>len</span><span class=p>(</span><span class=n>r</span><span class=p>)</span> <span class=k>for</span> <span class=n>p</span><span class=p>,</span> <span class=n>r</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>prompt_ids</span><span class=p>,</span> <span class=n>response_ids</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>padded_prompt_ids</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>padded_response_ids</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>padded_attention_masks</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>p_ids</span><span class=p>,</span> <span class=n>r_ids</span><span class=p>,</span> <span class=n>mask</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>prompt_ids</span><span class=p>,</span> <span class=n>response_ids</span><span class=p>,</span> <span class=n>attention_masks</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 填充prompt</span>
</span></span><span class=line><span class=cl>        <span class=n>padded_p</span> <span class=o>=</span> <span class=n>p_ids</span> <span class=o>+</span> <span class=p>[</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>pad_token_id</span><span class=p>]</span> <span class=o>*</span> <span class=p>(</span><span class=n>max_length</span> <span class=o>-</span> <span class=nb>len</span><span class=p>(</span><span class=n>p_ids</span><span class=p>)</span> <span class=o>-</span> <span class=nb>len</span><span class=p>(</span><span class=n>r_ids</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>padded_prompt_ids</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>padded_p</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 填充response</span>
</span></span><span class=line><span class=cl>        <span class=n>padded_r</span> <span class=o>=</span> <span class=n>r_ids</span> <span class=o>+</span> <span class=p>[</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>pad_token_id</span><span class=p>]</span> <span class=o>*</span> <span class=p>(</span><span class=n>max_length</span> <span class=o>-</span> <span class=nb>len</span><span class=p>(</span><span class=n>p_ids</span><span class=p>)</span> <span class=o>-</span> <span class=nb>len</span><span class=p>(</span><span class=n>r_ids</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>padded_response_ids</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>padded_r</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 更新attention mask</span>
</span></span><span class=line><span class=cl>        <span class=n>padded_mask</span> <span class=o>=</span> <span class=n>mask</span> <span class=o>+</span> <span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=p>(</span><span class=n>max_length</span> <span class=o>-</span> <span class=nb>len</span><span class=p>(</span><span class=n>mask</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>padded_attention_masks</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>padded_mask</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 3. 创建DataProto</span>
</span></span><span class=line><span class=cl>    <span class=n>training_dataproto</span> <span class=o>=</span> <span class=n>DataProto</span><span class=o>.</span><span class=n>from_dict</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>tensors</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;prompt_ids&#34;</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>padded_prompt_ids</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>long</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;response_ids&#34;</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>padded_response_ids</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>long</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;attention_mask&#34;</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>padded_attention_masks</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>long</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=n>non_tensors</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;raw_prompts&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>raw_data</span><span class=p>[</span><span class=s2>&#34;prompts&#34;</span><span class=p>],</span> <span class=n>dtype</span><span class=o>=</span><span class=nb>object</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;raw_responses&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>raw_data</span><span class=p>[</span><span class=s2>&#34;responses&#34;</span><span class=p>],</span> <span class=n>dtype</span><span class=o>=</span><span class=nb>object</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;rewards&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>raw_data</span><span class=p>[</span><span class=s2>&#34;rewards&#34;</span><span class=p>],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>float32</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=n>meta_info</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;dataset_name&#34;</span><span class=p>:</span> <span class=s2>&#34;math_training&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;batch_size&#34;</span><span class=p>:</span> <span class=nb>len</span><span class=p>(</span><span class=n>raw_data</span><span class=p>[</span><span class=s2>&#34;prompts&#34;</span><span class=p>]),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;max_length&#34;</span><span class=p>:</span> <span class=n>max_length</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;tokenizer_name&#34;</span><span class=p>:</span> <span class=s2>&#34;Qwen/Qwen2.5-7B-Instruct&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>training_dataproto</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 创建训练数据</span>
</span></span><span class=line><span class=cl><span class=n>training_data</span> <span class=o>=</span> <span class=n>create_training_dataproto</span><span class=p>(</span><span class=n>raw_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;DataProto结构:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>training_data</span><span class=o>.</span><span class=n>get_data_info</span><span class=p>())</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>输出示例：</strong></p><pre tabindex=0><code>DataProto结构:
batch
  prompt_ids: (3, 512) (torch.int64) cuda:0
  response_ids: (3, 512) (torch.int64) cuda:0
  attention_mask: (3, 512) (torch.int64) cuda:0
non_tensor_batch
  raw_prompts: ndarray(3,) (object)
  raw_responses: ndarray(3,) (object)
  rewards: ndarray(3,) (float32)
meta_info
  dataset_name: str
  batch_size: int
  max_length: int
  tokenizer_name: str
</code></pre><h4 id=812-数据分发过程>8.1.2 数据分发过程<a hidden class=anchor aria-hidden=true href=#812-数据分发过程>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 假设有4个GPU worker</span>
</span></span><span class=line><span class=cl><span class=n>world_size</span> <span class=o>=</span> <span class=mi>4</span>
</span></span><span class=line><span class=cl><span class=n>batch_size</span> <span class=o>=</span> <span class=mi>3</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 原始DataProto</span>
</span></span><span class=line><span class=cl><span class=n>original_dataproto</span> <span class=o>=</span> <span class=n>training_data</span>  <span class=c1># batch_size=3</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 自动填充到能被4整除的大小</span>
</span></span><span class=line><span class=cl><span class=n>padded_dataproto</span><span class=p>,</span> <span class=n>pad_size</span> <span class=o>=</span> <span class=n>pad_dataproto_to_divisor</span><span class=p>(</span><span class=n>original_dataproto</span><span class=p>,</span> <span class=n>world_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 现在padded_dataproto的batch_size=4 (填充了1个样本)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 分割成4个chunk</span>
</span></span><span class=line><span class=cl><span class=n>chunks</span> <span class=o>=</span> <span class=n>padded_dataproto</span><span class=o>.</span><span class=n>chunk</span><span class=p>(</span><span class=n>chunks</span><span class=o>=</span><span class=n>world_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;原始batch_size: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>original_dataproto</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;填充后batch_size: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>padded_dataproto</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;分割后chunk数量: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>chunks</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;每个chunk的batch_size: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>chunks</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 分发到各个worker</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>chunk</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>chunks</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Worker </span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s2> 接收数据:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;  - prompt_ids shape: </span><span class=si>{</span><span class=n>chunk</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s1>&#39;prompt_ids&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;  - 包含样本数: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>chunk</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=82-控制流与计算流交互示例>8.2 控制流与计算流交互示例<a hidden class=anchor aria-hidden=true href=#82-控制流与计算流交互示例>#</a></h3><h4 id=821-控制流ppo训练循环>8.2.1 控制流：PPO训练循环<a hidden class=anchor aria-hidden=true href=#821-控制流ppo训练循环>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span><span class=lnt>72
</span><span class=lnt>73
</span><span class=lnt>74
</span><span class=lnt>75
</span><span class=lnt>76
</span><span class=lnt>77
</span><span class=lnt>78
</span><span class=lnt>79
</span><span class=lnt>80
</span><span class=lnt>81
</span><span class=lnt>82
</span><span class=lnt>83
</span><span class=lnt>84
</span><span class=lnt>85
</span><span class=lnt>86
</span><span class=lnt>87
</span><span class=lnt>88
</span><span class=lnt>89
</span><span class=lnt>90
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>RayPPOTrainer</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>config</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>config</span> <span class=o>=</span> <span class=n>config</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>actor_rollout_wg</span> <span class=o>=</span> <span class=kc>None</span>  <span class=c1># Actor和Rollout的WorkerGroup</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>critic_wg</span> <span class=o>=</span> <span class=kc>None</span>         <span class=c1># Critic的WorkerGroup</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>ref_policy_wg</span> <span class=o>=</span> <span class=kc>None</span>     <span class=c1># Reference Policy的WorkerGroup</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>fit</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;PPO训练的主控制循环&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>trainer</span><span class=o>.</span><span class=n>total_epochs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;开始第 </span><span class=si>{</span><span class=n>epoch</span><span class=si>}</span><span class=s2> 轮训练&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 1. 获取训练批次</span>
</span></span><span class=line><span class=cl>            <span class=n>batch_dataproto</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_get_training_batch</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;获取训练批次，batch_size: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>batch_dataproto</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 2. 分发到Actor进行序列生成</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;开始序列生成...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>rollout_dataproto</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>actor_rollout_wg</span><span class=o>.</span><span class=n>generate_sequences</span><span class=p>(</span><span class=n>batch_dataproto</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;序列生成完成，生成 </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>rollout_dataproto</span><span class=p>)</span><span class=si>}</span><span class=s2> 个序列&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 3. 分发到Critic计算价值</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;开始价值计算...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>value_dataproto</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>critic_wg</span><span class=o>.</span><span class=n>compute_values</span><span class=p>(</span><span class=n>rollout_dataproto</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;价值计算完成&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 4. 分发到Reference Policy计算log概率</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;开始参考策略计算...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>ref_log_prob_dataproto</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>ref_policy_wg</span><span class=o>.</span><span class=n>compute_log_probs</span><span class=p>(</span><span class=n>rollout_dataproto</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;参考策略计算完成&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 5. 在控制流中计算优势函数</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;计算优势函数...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>advantages</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_compute_advantages</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>rollout_dataproto</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>                <span class=n>value_dataproto</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>                <span class=n>ref_log_prob_dataproto</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 6. 更新Actor策略</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;更新Actor策略...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>actor_rollout_wg</span><span class=o>.</span><span class=n>update_actor</span><span class=p>(</span><span class=n>advantages</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 7. 更新Critic价值网络</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;更新Critic价值网络...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>critic_wg</span><span class=o>.</span><span class=n>update_critic</span><span class=p>(</span><span class=n>advantages</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;第 </span><span class=si>{</span><span class=n>epoch</span><span class=si>}</span><span class=s2> 轮训练完成</span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_get_training_batch</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;获取训练批次&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=c1># 从数据集中采样</span>
</span></span><span class=line><span class=cl>        <span class=n>batch_data</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;prompt_ids&#34;</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1000</span><span class=p>,</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>train_batch_size</span><span class=p>,</span> <span class=mi>512</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;attention_mask&#34;</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>ones</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>train_batch_size</span><span class=p>,</span> <span class=mi>512</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>DataProto</span><span class=o>.</span><span class=n>from_dict</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>tensors</span><span class=o>=</span><span class=n>batch_data</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>meta_info</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;epoch&#34;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>current_epoch</span><span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_compute_advantages</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>rollout_data</span><span class=p>,</span> <span class=n>value_data</span><span class=p>,</span> <span class=n>ref_log_prob_data</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;计算优势函数 - 在控制流中执行&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=c1># 从各个DataProto中提取数据</span>
</span></span><span class=line><span class=cl>        <span class=n>rewards</span> <span class=o>=</span> <span class=n>rollout_data</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;rewards&#34;</span><span class=p>]</span>  <span class=c1># [batch_size, seq_len]</span>
</span></span><span class=line><span class=cl>        <span class=n>values</span> <span class=o>=</span> <span class=n>value_data</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;values&#34;</span><span class=p>]</span>      <span class=c1># [batch_size, seq_len]</span>
</span></span><span class=line><span class=cl>        <span class=n>log_probs</span> <span class=o>=</span> <span class=n>rollout_data</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;log_probs&#34;</span><span class=p>]</span>  <span class=c1># [batch_size, seq_len]</span>
</span></span><span class=line><span class=cl>        <span class=n>ref_log_probs</span> <span class=o>=</span> <span class=n>ref_log_prob_data</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;log_probs&#34;</span><span class=p>]</span>  <span class=c1># [batch_size, seq_len]</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 计算优势函数</span>
</span></span><span class=line><span class=cl>        <span class=n>advantages</span> <span class=o>=</span> <span class=n>rewards</span> <span class=o>-</span> <span class=n>values</span>
</span></span><span class=line><span class=cl>        <span class=n>advantages</span> <span class=o>=</span> <span class=n>advantages</span> <span class=o>*</span> <span class=n>rollout_data</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;attention_mask&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 计算策略比率</span>
</span></span><span class=line><span class=cl>        <span class=n>log_ratio</span> <span class=o>=</span> <span class=n>log_probs</span> <span class=o>-</span> <span class=n>ref_log_probs</span>
</span></span><span class=line><span class=cl>        <span class=n>ratio</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=n>log_ratio</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 创建优势DataProto</span>
</span></span><span class=line><span class=cl>        <span class=n>advantages_dataproto</span> <span class=o>=</span> <span class=n>DataProto</span><span class=o>.</span><span class=n>from_dict</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>tensors</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;advantages&#34;</span><span class=p>:</span> <span class=n>advantages</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;ratio&#34;</span><span class=p>:</span> <span class=n>ratio</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;rewards&#34;</span><span class=p>:</span> <span class=n>rewards</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;values&#34;</span><span class=p>:</span> <span class=n>values</span>
</span></span><span class=line><span class=cl>            <span class=p>},</span>
</span></span><span class=line><span class=cl>            <span class=n>meta_info</span><span class=o>=</span><span class=n>rollout_data</span><span class=o>.</span><span class=n>meta_info</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>advantages_dataproto</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=822-计算流worker实现>8.2.2 计算流：Worker实现<a hidden class=anchor aria-hidden=true href=#822-计算流worker实现>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span><span class=lnt>108
</span><span class=lnt>109
</span><span class=lnt>110
</span><span class=lnt>111
</span><span class=lnt>112
</span><span class=lnt>113
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@ray.remote</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>ActorRolloutWorker</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model_config</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>model</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>config</span> <span class=o>=</span> <span class=n>model_config</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>    <span class=nd>@register</span><span class=p>(</span><span class=n>dispatch_mode</span><span class=o>=</span><span class=n>Dispatch</span><span class=o>.</span><span class=n>DP_COMPUTE_PROTO</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>generate_sequences</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>data</span><span class=p>:</span> <span class=n>DataProto</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>DataProto</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;生成序列 - 在计算流中执行&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Worker </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>rank</span><span class=si>}</span><span class=s2> 开始生成序列，batch_size: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>data</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 1. 模型推理</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>input_ids</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;prompt_ids&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=n>attention_mask</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;attention_mask&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 生成序列</span>
</span></span><span class=line><span class=cl>            <span class=n>outputs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>input_ids</span><span class=o>=</span><span class=n>input_ids</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>attention_mask</span><span class=o>=</span><span class=n>attention_mask</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>max_new_tokens</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>do_sample</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>temperature</span><span class=o>=</span><span class=mf>0.7</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>return_dict_in_generate</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>output_scores</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 提取生成的token ids</span>
</span></span><span class=line><span class=cl>            <span class=n>generated_ids</span> <span class=o>=</span> <span class=n>outputs</span><span class=o>.</span><span class=n>sequences</span>
</span></span><span class=line><span class=cl>            <span class=n>log_probs</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>(</span><span class=n>outputs</span><span class=o>.</span><span class=n>scores</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>log_softmax</span><span class=p>(</span><span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 计算每个token的log概率</span>
</span></span><span class=line><span class=cl>            <span class=n>token_log_probs</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>seq</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>generated_ids</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=n>seq_log_probs</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>                <span class=k>for</span> <span class=n>j</span><span class=p>,</span> <span class=n>token_id</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>seq</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                    <span class=k>if</span> <span class=n>j</span> <span class=o>&lt;</span> <span class=nb>len</span><span class=p>(</span><span class=n>log_probs</span><span class=p>[</span><span class=n>i</span><span class=p>]):</span>
</span></span><span class=line><span class=cl>                        <span class=n>seq_log_probs</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>log_probs</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=n>j</span><span class=p>][</span><span class=n>token_id</span><span class=p>]</span><span class=o>.</span><span class=n>item</span><span class=p>())</span>
</span></span><span class=line><span class=cl>                <span class=n>token_log_probs</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>seq_log_probs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 计算奖励（这里使用简单的长度奖励作为示例）</span>
</span></span><span class=line><span class=cl>            <span class=n>rewards</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([[</span><span class=nb>len</span><span class=p>(</span><span class=n>seq</span><span class=p>)</span> <span class=o>*</span> <span class=mf>0.1</span><span class=p>]</span> <span class=o>*</span> <span class=nb>len</span><span class=p>(</span><span class=n>seq</span><span class=p>)</span> <span class=k>for</span> <span class=n>seq</span> <span class=ow>in</span> <span class=n>generated_ids</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 2. 创建结果DataProto</span>
</span></span><span class=line><span class=cl>        <span class=n>result_dataproto</span> <span class=o>=</span> <span class=n>DataProto</span><span class=o>.</span><span class=n>from_dict</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>tensors</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;generated_ids&#34;</span><span class=p>:</span> <span class=n>generated_ids</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;log_probs&#34;</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>token_log_probs</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;rewards&#34;</span><span class=p>:</span> <span class=n>rewards</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;attention_mask&#34;</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>ones_like</span><span class=p>(</span><span class=n>generated_ids</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=p>},</span>
</span></span><span class=line><span class=cl>            <span class=n>non_tensors</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;raw_generated_texts&#34;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span>
</span></span><span class=line><span class=cl>                    <span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>seq</span><span class=p>,</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span> 
</span></span><span class=line><span class=cl>                    <span class=k>for</span> <span class=n>seq</span> <span class=ow>in</span> <span class=n>generated_ids</span>
</span></span><span class=line><span class=cl>                <span class=p>],</span> <span class=n>dtype</span><span class=o>=</span><span class=nb>object</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=p>},</span>
</span></span><span class=line><span class=cl>            <span class=n>meta_info</span><span class=o>=</span><span class=n>data</span><span class=o>.</span><span class=n>meta_info</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Worker </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>rank</span><span class=si>}</span><span class=s2> 序列生成完成&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>result_dataproto</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=nd>@register</span><span class=p>(</span><span class=n>dispatch_mode</span><span class=o>=</span><span class=n>Dispatch</span><span class=o>.</span><span class=n>DP_COMPUTE_PROTO</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>update_actor</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>advantages</span><span class=p>:</span> <span class=n>DataProto</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;更新Actor策略 - 在计算流中执行&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Worker </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>rank</span><span class=si>}</span><span class=s2> 开始更新Actor策略&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 1. 提取数据</span>
</span></span><span class=line><span class=cl>        <span class=n>advantages_tensor</span> <span class=o>=</span> <span class=n>advantages</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;advantages&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>ratio</span> <span class=o>=</span> <span class=n>advantages</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;ratio&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>rewards</span> <span class=o>=</span> <span class=n>advantages</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;rewards&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 2. 计算PPO损失</span>
</span></span><span class=line><span class=cl>        <span class=n>clip_ratio</span> <span class=o>=</span> <span class=mf>0.2</span>
</span></span><span class=line><span class=cl>        <span class=n>policy_loss_1</span> <span class=o>=</span> <span class=o>-</span><span class=n>advantages_tensor</span> <span class=o>*</span> <span class=n>ratio</span>
</span></span><span class=line><span class=cl>        <span class=n>policy_loss_2</span> <span class=o>=</span> <span class=o>-</span><span class=n>advantages_tensor</span> <span class=o>*</span> <span class=n>torch</span><span class=o>.</span><span class=n>clamp</span><span class=p>(</span><span class=n>ratio</span><span class=p>,</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>clip_ratio</span><span class=p>,</span> <span class=mi>1</span> <span class=o>+</span> <span class=n>clip_ratio</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>policy_loss</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>maximum</span><span class=p>(</span><span class=n>policy_loss_1</span><span class=p>,</span> <span class=n>policy_loss_2</span><span class=p>)</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 3. 反向传播</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>policy_loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Worker </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>rank</span><span class=si>}</span><span class=s2> Actor策略更新完成，损失: </span><span class=si>{</span><span class=n>policy_loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@ray.remote</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>CriticWorker</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model_config</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>model</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>config</span> <span class=o>=</span> <span class=n>model_config</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>    <span class=nd>@register</span><span class=p>(</span><span class=n>dispatch_mode</span><span class=o>=</span><span class=n>Dispatch</span><span class=o>.</span><span class=n>DP_COMPUTE_PROTO</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>compute_values</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>data</span><span class=p>:</span> <span class=n>DataProto</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>DataProto</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;计算价值函数 - 在计算流中执行&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Worker </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>rank</span><span class=si>}</span><span class=s2> 开始计算价值函数&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>input_ids</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;generated_ids&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=n>attention_mask</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>batch</span><span class=p>[</span><span class=s2>&#34;attention_mask&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># 前向传播计算价值</span>
</span></span><span class=line><span class=cl>            <span class=n>outputs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=p>(</span><span class=n>input_ids</span><span class=o>=</span><span class=n>input_ids</span><span class=p>,</span> <span class=n>attention_mask</span><span class=o>=</span><span class=n>attention_mask</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>values</span> <span class=o>=</span> <span class=n>outputs</span><span class=o>.</span><span class=n>value</span>  <span class=c1># [batch_size, seq_len]</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 创建价值DataProto</span>
</span></span><span class=line><span class=cl>        <span class=n>value_dataproto</span> <span class=o>=</span> <span class=n>DataProto</span><span class=o>.</span><span class=n>from_dict</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>tensors</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;values&#34;</span><span class=p>:</span> <span class=n>values</span><span class=p>},</span>
</span></span><span class=line><span class=cl>            <span class=n>meta_info</span><span class=o>=</span><span class=n>data</span><span class=o>.</span><span class=n>meta_info</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Worker </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>rank</span><span class=si>}</span><span class=s2> 价值函数计算完成&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>value_dataproto</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=83-数据流动可视化>8.3 数据流动可视化<a hidden class=anchor aria-hidden=true href=#83-数据流动可视化>#</a></h3><h4 id=831-单轮训练的数据流动>8.3.1 单轮训练的数据流动<a hidden class=anchor aria-hidden=true href=#831-单轮训练的数据流动>#</a></h4><pre class=mermaid>
  sequenceDiagram
    participant CF as 控制流
    participant AW as ActorWorker
    participant CW as CriticWorker
    participant RW as RefWorker
    
    CF-&gt;&gt;CF: 创建训练DataProto
    Note over CF: batch_size=256, 包含prompt_ids等
    
    CF-&gt;&gt;AW: generate_sequences(training_data)
    Note over AW: 自动分割为64个样本/worker
    
    AW-&gt;&gt;AW: 模型推理生成序列
    AW-&gt;&gt;CF: 返回rollout_data
    Note over CF: 包含generated_ids, log_probs, rewards
    
    CF-&gt;&gt;CW: compute_values(rollout_data)
    CW-&gt;&gt;CW: 计算价值函数
    CW-&gt;&gt;CF: 返回value_data
    
    CF-&gt;&gt;RW: compute_log_probs(rollout_data)
    RW-&gt;&gt;RW: 计算参考策略log概率
    RW-&gt;&gt;CF: 返回ref_log_prob_data
    
    CF-&gt;&gt;CF: 计算优势函数
    Note over CF: advantages = rewards - values
    
    CF-&gt;&gt;AW: update_actor(advantages)
    CF-&gt;&gt;CW: update_critic(advantages)
    
    Note over CF: 完成一轮训练
</pre><h4 id=832-dataproto在训练过程中的形态变化>8.3.2 DataProto在训练过程中的形态变化<a hidden class=anchor aria-hidden=true href=#832-dataproto在训练过程中的形态变化>#</a></h4><pre class=mermaid>
  graph LR
    subgraph &#34;训练开始&#34;
        A1[原始训练数据&lt;br/&gt;prompt_ids, attention_mask&lt;br/&gt;batch_size=256]
    end
    
    subgraph &#34;序列生成后&#34;
        A2[rollout_data&lt;br/&gt;generated_ids, log_probs, rewards&lt;br/&gt;batch_size=256]
    end
    
    subgraph &#34;价值计算后&#34;
        A3[value_data&lt;br/&gt;values&lt;br/&gt;batch_size=256]
    end
    
    subgraph &#34;优势计算后&#34;
        A4[advantages_data&lt;br/&gt;advantages, ratio&lt;br/&gt;batch_size=256]
    end
    
    A1 --&gt; A2
    A2 --&gt; A3
    A3 --&gt; A4
    
    style A1 fill:#E3F2FD,stroke:#1976D2,stroke-width:2px
    style A2 fill:#E8F5E8,stroke:#388E3C,stroke-width:2px
    style A3 fill:#FFF3E0,stroke:#F57C00,stroke-width:2px
    style A4 fill:#F3E5F5,stroke:#7B1FA2,stroke-width:2px
</pre><h3 id=84-关键特性展示>8.4 关键特性展示<a hidden class=anchor aria-hidden=true href=#84-关键特性展示>#</a></h3><h4 id=841-自动填充机制>8.4.1 自动填充机制<a hidden class=anchor aria-hidden=true href=#841-自动填充机制>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 示例：batch_size=250, world_size=4</span>
</span></span><span class=line><span class=cl><span class=n>original_batch_size</span> <span class=o>=</span> <span class=mi>250</span>
</span></span><span class=line><span class=cl><span class=n>world_size</span> <span class=o>=</span> <span class=mi>4</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 计算需要填充的数量</span>
</span></span><span class=line><span class=cl><span class=n>padding_needed</span> <span class=o>=</span> <span class=p>(</span><span class=n>world_size</span> <span class=o>-</span> <span class=p>(</span><span class=n>original_batch_size</span> <span class=o>%</span> <span class=n>world_size</span><span class=p>))</span> <span class=o>%</span> <span class=n>world_size</span>
</span></span><span class=line><span class=cl><span class=c1># padding_needed = 2</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 填充后的batch_size = 252，可以被4整除</span>
</span></span><span class=line><span class=cl><span class=n>final_batch_size</span> <span class=o>=</span> <span class=n>original_batch_size</span> <span class=o>+</span> <span class=n>padding_needed</span>  <span class=c1># 252</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 每个worker获得 252 // 4 = 63 个样本</span>
</span></span><span class=line><span class=cl><span class=n>samples_per_worker</span> <span class=o>=</span> <span class=n>final_batch_size</span> <span class=o>//</span> <span class=n>world_size</span>  <span class=c1># 63</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=842-异步执行示例>8.4.2 异步执行示例<a hidden class=anchor aria-hidden=true href=#842-异步执行示例>#</a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 控制流中的异步调用</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>async_training_step</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># 1. 异步生成序列</span>
</span></span><span class=line><span class=cl>    <span class=n>rollout_future</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>actor_rollout_wg</span><span class=o>.</span><span class=n>generate_sequences</span><span class=o>.</span><span class=n>remote</span><span class=p>(</span><span class=n>training_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 2. 控制流可以继续其他工作</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;序列生成正在进行中...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 3. 当需要结果时再等待</span>
</span></span><span class=line><span class=cl>    <span class=n>rollout_data</span> <span class=o>=</span> <span class=n>ray</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>rollout_future</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;序列生成完成&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 4. 继续后续步骤</span>
</span></span><span class=line><span class=cl>    <span class=n>value_data</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>critic_wg</span><span class=o>.</span><span class=n>compute_values</span><span class=p>(</span><span class=n>rollout_data</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=9-总结>9. 总结<a hidden class=anchor aria-hidden=true href=#9-总结>#</a></h2><h3 id=91-核心优势>9.1 核心优势<a hidden class=anchor aria-hidden=true href=#91-核心优势>#</a></h3><ol><li><strong>架构清晰</strong>: 控制流与计算流分离，职责明确</li><li><strong>高度可扩展</strong>: 支持多种计算后端和并行策略</li><li><strong>开发友好</strong>: 单进程控制流便于调试和开发</li><li><strong>性能优异</strong>: 异步执行和内存优化提升训练效率</li></ol><h3 id=92-技术特点>9.2 技术特点<a hidden class=anchor aria-hidden=true href=#92-技术特点>#</a></h3><ul><li><strong>DataProto协议</strong>: 统一的数据交换接口</li><li><strong>Dispatch模式</strong>: 灵活的数据分发策略</li><li><strong>异步执行</strong>: 支持非阻塞的分布式计算</li><li><strong>内存优化</strong>: 高效的内存管理和复用机制</li></ul><h3 id=93-应用场景>9.3 应用场景<a hidden class=anchor aria-hidden=true href=#93-应用场景>#</a></h3><ul><li><strong>大规模RL训练</strong>: 支持多节点、多GPU训练</li><li><strong>算法研究</strong>: 便于实现和测试新的RL算法</li><li><strong>生产部署</strong>: 支持高效的模型训练和推理</li><li><strong>框架扩展</strong>: 易于集成新的计算后端和优化策略</li></ul><p>Verl 通过 DataProto 和 HybridFlow 设计，成功解决了大规模强化学习训练中的架构挑战，为LLM后训练提供了高效、灵活、可扩展的解决方案。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://pillumina.github.io/tags/framework/>Framework</a></li><li><a href=https://pillumina.github.io/tags/verl/>Verl</a></li></ul><nav class=paginav><a class=next href=https://pillumina.github.io/posts/aiinfra/09-verl-agentloop/><span class=title>Next »</span><br><span>[VeRL] AgentLoop源码走读</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share [VeRL] DataProto介绍 on x" href="https://x.com/intent/tweet/?text=%5bVeRL%5d%20DataProto%e4%bb%8b%e7%bb%8d&amp;url=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f10-verl-dataproto%2f&amp;hashtags=framework%2cverl"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [VeRL] DataProto介绍 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f10-verl-dataproto%2f&amp;title=%5bVeRL%5d%20DataProto%e4%bb%8b%e7%bb%8d&amp;summary=%5bVeRL%5d%20DataProto%e4%bb%8b%e7%bb%8d&amp;source=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f10-verl-dataproto%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [VeRL] DataProto介绍 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f10-verl-dataproto%2f&title=%5bVeRL%5d%20DataProto%e4%bb%8b%e7%bb%8d"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [VeRL] DataProto介绍 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f10-verl-dataproto%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [VeRL] DataProto介绍 on whatsapp" href="https://api.whatsapp.com/send?text=%5bVeRL%5d%20DataProto%e4%bb%8b%e7%bb%8d%20-%20https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f10-verl-dataproto%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [VeRL] DataProto介绍 on telegram" href="https://telegram.me/share/url?text=%5bVeRL%5d%20DataProto%e4%bb%8b%e7%bb%8d&amp;url=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f10-verl-dataproto%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share [VeRL] DataProto介绍 on ycombinator" href="https://news.ycombinator.com/submitlink?t=%5bVeRL%5d%20DataProto%e4%bb%8b%e7%bb%8d&u=https%3a%2f%2fpillumina.github.io%2fposts%2faiinfra%2f10-verl-dataproto%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul><div class=related-posts><div class=related-series><h3>同系列文章</h3><ul><li><a href=/posts/aiinfra/09-verl-agentloop/>[VeRL] AgentLoop源码走读</a>
<span class=meta>2025-08-14
· 15 min read</span></li><li><a href=/posts/aiinfra/05-verl-params/>[VeRL] 参数速览</a>
<span class=meta>2025-08-14
· 6 min read</span></li><li><a href=/posts/aiinfra/08-verl-multiturn-2/>[VeRL] Multi-Turn RL训练源码走读（2）</a>
<span class=meta>2025-08-03
· 27 min read</span></li><li><a href=/posts/aiinfra/07-verl-multiturn-1/>[VeRL] Multi-Turn RL训练源码走读（1）</a>
<span class=meta>2025-08-03
· 27 min read</span></li></ul></div><div class=related-tags><h3>相关文章</h3><ul><li><a href=/posts/aiinfra/09-verl-agentloop/>[VeRL] AgentLoop源码走读</a>
<span class=meta>2025-08-14
· 15 min read
· Tags: framework, verl, sglang</span></li><li><a href=/posts/aiinfra/05-verl-params/>[VeRL] 参数速览</a>
<span class=meta>2025-08-14
· 6 min read
· Tags: framework, verl</span></li><li><a href=/posts/aiinfra/02-slime/>[RL4LLM] 异步RL框架: Slime</a>
<span class=meta>2025-08-07
· 15 min read
· Tags: framework, LLM, RL</span></li><li><a href=/posts/aiinfra/03-areal/>[RL4LLM] 异步RL框架: Areal</a>
<span class=meta>2025-08-07
· 23 min read
· Tags: framework, LLM, RL</span></li></ul></div></div></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://pillumina.github.io/>CctoctoFX</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg></a><div class=reading-progress-bar></div><script src=https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js></script><script>document.addEventListener("DOMContentLoaded",function(){const t=document.querySelector(".reading-progress-bar");if(!t)return;const n=document.querySelector(".post-single");if(!n)return;function s(){const e=n.getBoundingClientRect(),s=e.height,o=window.innerHeight,i=window.scrollY||window.pageYOffset,a=i/(s-o)*100;t.style.width=`${Math.min(100,Math.max(0,a))}%`}let e=!1;window.addEventListener("scroll",function(){e||(window.requestAnimationFrame(function(){s(),e=!1}),e=!0)}),s()}),document.addEventListener("DOMContentLoaded",function(){mediumZoom("article img:not(.nozoom)",{margin:24,background:"var(--theme)",scrollOffset:0})})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>